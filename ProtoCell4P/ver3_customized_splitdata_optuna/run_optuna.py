# run.py
import argparse
from config import Config
from utils import set_global_seed
import optuna
from utils import train_with_oom_retry
import numpy as np
import os

# (íŒŒì´ì¬ 3.7+ ì´ìƒ) stdoutì„ ì¤„ë‹¨ìœ„ ë²„í¼ë§ìœ¼ë¡œ ë³€ê²½
try:
    sys.stdout.reconfigure(line_buffering=True)
except Exception:
    pass

HP_SPACE = {
    "lr":        [1e-4, 1e-3, 1e-2],
    "max_epoch": [50, 75, 100],
    "z_dim":     [32, 64, 128],  # encoder/decoder ì¶œë ¥ ì°¨ì›
    "h_dim":     [8, 16, 32],
    "n_proto":   [8, 16, 32],
    # pretrain epochì€ ê³ ì • {75}
}
# === run.py ìƒë‹¨ì— ì¶”ê°€ ===
import torch
from torch.utils.data import DataLoader
from copy import deepcopy
# run.py
# run.py ìƒë‹¨
from types import SimpleNamespace


def make_trial_cfg(base_cfg, hp):
    tcfg = SimpleNamespace(
        # íŠœë‹ ëŒ€ìƒ
        lr=hp["lr"],
        max_epoch=hp["max_epoch"],
        z_dim=hp["z_dim"],
        h_dim=hp["h_dim"],
        n_proto=hp["n_proto"],

        # ê³ ì •/ë³µì‚¬
        n_layers=getattr(base_cfg, "n_layers", 2),
        batch_size=getattr(base_cfg, "batch_size", 4),
        device=getattr(base_cfg, "device", "cpu"),
        d_min=getattr(base_cfg, "d_min", 1),
        lr_pretrain=getattr(base_cfg, "lr_pretrain", 1e-2),
        max_epoch_pretrain=75,
        keep_sparse=getattr(base_cfg, "keep_sparse", True),
        test_step=getattr(base_cfg, "test_step", 1),

        # â˜… ì¶”ê°€: lambdas, n_ct, seedê¹Œì§€ ë³µì‚¬
        lambdas=getattr(base_cfg, "lambdas", None),
        n_ct=getattr(base_cfg, "n_ct", None),
        seed=getattr(base_cfg, "seed", None),

        # â˜… ê²½ë¡œ í•„ìˆ˜ ë³µì‚¬
        checkpoint_dir=getattr(base_cfg, "checkpoint_dir", None),
        log_dir=getattr(base_cfg, "log_dir", None),
    )
    # í•„ìš”ì‹œ ë””ë ‰í† ë¦¬ ë³´ì¥
    if tcfg.checkpoint_dir:
        os.makedirs(tcfg.checkpoint_dir, exist_ok=True)
    if tcfg.log_dir:
        os.makedirs(tcfg.log_dir, exist_ok=True)
    return tcfg


def make_loaders_from_cfg(cfg, batch_size, phase):
    """
    cfg._build()ë¡œ ë§Œë“  splitì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ DataLoaderë¥¼ ìƒì„±.
    phase: "valid_only" | "valid_plus_test"
    """
    train_loader = DataLoader(cfg.train_set, batch_size=batch_size if not cfg.subsample else 8*batch_size,
                              shuffle=True,  collate_fn=cfg.collate_fn)
    val_loader   = DataLoader(cfg.val_set,   batch_size=cfg.batch_size, shuffle=False, collate_fn=cfg.collate_fn)
    loaders = {"train": train_loader, "val": val_loader}
    if phase == "valid_plus_test":
        test_loader  = DataLoader(cfg.test_set,  batch_size=cfg.batch_size, shuffle=False, collate_fn=cfg.collate_fn)
        loaders["test"] = test_loader
    return loaders

def build_model_and_optim(tcfg, cfg, phase="valid_only"):
    """
    tcfg: trialìš© í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ë°˜ì˜ëœ Config (z_dim/h_dim/n_proto/lr/max_epoch ë“± ë³€ê²½)
    cfg : ë°ì´í„° split/ë©”íƒ€ë¥¼ ê°€ì§„ ì›ë³¸ Config (ì…ë ¥ì°¨ì›, í´ë˜ìŠ¤ìˆ˜ ë“± ì¶”ì¶œ)
    """
    # input_dim / n_classes / n_ctëŠ” cfg._build()ì—ì„œ ì´ë¯¸ ê³„ì‚°ë¨
    input_dim   = cfg.model.input_dim     # ProtoCellì´ ì´ë¯¸ í•œë²ˆ ë§Œë“¤ì–´ì ¸ ìˆì–´ ì…ë ¥ì°¨ì› ë³´ìœ 
    n_classes   = cfg.n_classes
    n_ct        = cfg.n_ct
    lambdas     = cfg.lambdas
    # n_layersë¥¼ tcfgì—ì„œ ì½ë˜, ì—†ìœ¼ë©´ cfgì˜ ê°’ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
    n_layers = getattr(tcfg, "n_layers", getattr(cfg, "n_layers", 2))

    # fresh model ìƒì„± (trial HP ë°˜ì˜)
    from model import ProtoCell, BaseModel
    if cfg.model_type == "ProtoCell":
        model = ProtoCell(input_dim, tcfg.h_dim, tcfg.z_dim, n_layers,
                          tcfg.n_proto, n_classes, lambdas, n_ct,
                          tcfg.device, d_min=tcfg.d_min)
    elif cfg.model_type == "BaseModel":
        model = BaseModel(input_dim, tcfg.h_dim, tcfg.z_dim, n_layers,
                          tcfg.n_proto, n_classes, lambdas, n_ct,
                          tcfg.device, d_min=tcfg.d_min)
    else:
        raise ValueError(f"Model {cfg.model_type} not supported")

    model.to(tcfg.device)
    optimizer = torch.optim.Adam(model.parameters(), lr=tcfg.lr)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)

    loaders = make_loaders_from_cfg(cfg, batch_size=tcfg.batch_size, phase=phase)
    meta = dict(input_dim=input_dim, n_classes=n_classes, n_ct=n_ct)
    return model, optimizer, scheduler, loaders, meta

def run_pretrain(model, loaders, tcfg, logger=None, keep_sparse=True):
    """
    config.pyì˜ pretrain ë£¨í”„ë¥¼ ìš”ì•½ ì´ì‹. (êµ¬í˜„ì€ ê¸°ì¡´ê³¼ ë™ì¼ ë¡œì§) 
    """
    model.train()
    optim_pre = torch.optim.Adam(model.parameters(), lr=tcfg.lr_pretrain)
    best_metric = None
    for epoch in range(tcfg.max_epoch_pretrain):
        train_loss = 0.0
        for bat in loaders["train"]:
            optim_pre.zero_grad()
            out = model.pretrain(*bat, sparse=keep_sparse)
            loss = out[0] if isinstance(out, tuple) else out
            loss.backward()
            optim_pre.step()
            train_loss += loss.item() * len(bat[0])
        # ğŸ”½ ë§¤ epoch í”„ë¦°íŠ¸
        print(f"[Pretrain] Epoch {epoch+1}/{tcfg.max_epoch_pretrain} "
              f"| Avg Loss={train_loss/len(loaders['train'].dataset):.4f}", flush=True)
        
        # ì£¼ê¸°ì  valid
        if (epoch + 1) % tcfg.test_step == 0:
            model.eval()
            val_loss = 0.0
            with torch.no_grad():
                for bat in loaders["val"]:
                    out = model.pretrain(*bat, sparse=keep_sparse)
                    loss = out[0] if isinstance(out, tuple) else out
                    val_loss += loss.item() * len(bat[0])
            curr_metric = - val_loss / len(loaders["val"].dataset)
            if best_metric is None or curr_metric > best_metric:
                ckpt_dir = getattr(tcfg, "checkpoint_dir", None)
                if ckpt_dir:                  # â† ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì €ì¥ ìŠ¤í‚µ
                    os.makedirs(ckpt_dir, exist_ok=True)
                    torch.save(model.state_dict(), os.path.join(ckpt_dir, "pretrain.pt"))
                best_metric = curr_metric
            model.train()

def run_train_eval_only_valid(model, loaders, tcfg, logger=None, keep_sparse=True):

    """
    train + validë§Œìœ¼ë¡œ í•™ìŠµí•˜ê³  valid AUC(ë˜ëŠ” val loss ë“±)ë¥¼ ë°˜í™˜ â†’ Optuna objectiveì—ì„œ ì‚¬ìš©.
    (ê¸°ì¡´ train() ë£¨í”„ ë¡œì§ì„ ìš”ì•½ ì´ì‹. ì§€í‘œ ê³„ì‚°ë²•ì€ config.pyì™€ ë™ì¼) 
    """
    print("train + validë§Œìœ¼ë¡œ í•™ìŠµí•˜ê³  valid AUCë¥¼ ë°˜í™˜ â†’ Optuna objectiveì—ì„œ ì‚¬ìš©.")
    import time
    import torch
    from sklearn.metrics import roc_auc_score

    optim = torch.optim.Adam(model.parameters(), lr=tcfg.lr)
    pretrained = getattr(tcfg, "pretrained", False)

    best_metric = -1e18

    for epoch in range(tcfg.max_epoch):
        # =======================
        # Train
        # =======================
        model.train()
        train_loss_sum = 0.0
        train_count = 0

        for bat in loaders["train"]:
            optim.zero_grad()

            if len(bat) == 3:  # (x, y, ct)
                loss, logits, ct_logit = model(*bat, sparse=keep_sparse)
                # if not pretrained:
                #     loss = loss + model.pretrain(*bat, sparse=keep_sparse)[0]  # (loss, ct_logit)
            else:              # (x, y)
                loss, logits = model(*bat, sparse=keep_sparse)
                # if not pretrained:
                #     loss = loss + model.pretrain(*bat, sparse=keep_sparse)    # loss only
            
            loss.backward()
            optim.step()

            # í‰ê· ì„ ìœ„í•´ ìƒ˜í”Œ ìˆ˜ ê¸°ì¤€ ëˆ„ì 
            batch_n = len(bat[0])
            train_loss_sum += loss.item() * batch_n
            train_count += batch_n

        train_loss_avg = train_loss_sum / max(1, train_count)

            # optimizerëŠ” ë°”ê¹¥ì—ì„œ ë°›ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ê°„ë‹¨í™”ë¥¼ ìœ„í•´ ìƒˆë¡œ ì„ ì–¸
        # ê°„ë‹¨í™”ë¥¼ í”¼í•˜ë ¤ë©´ build_model_and_optimì—ì„œ optimizerë¥¼ ë°˜í™˜ë°›ì•„ ì—¬ê¸°ì„œ ì‚¬ìš©í•˜ì„¸ìš”.
        # (ì•„ë˜ ìµœì¢… ì½”ë“œ ë¸”ë¡ì—ì„œëŠ” optimizerë¥¼ í•¨ê»˜ ì‚¬ìš©)

        # valid
        # =======================
        # Validation
        # =======================
        model.eval()
        val_loss_sum = 0.0
        val_count = 0
        y_truth_list = []
        y_score_list = []

        with torch.no_grad():
            for bat in loaders["val"]:
                if len(bat) == 3:
                    loss, logits, ct_logit = model(*bat, sparse=keep_sparse)
                else:
                    loss, logits = model(*bat, sparse=keep_sparse)

                batch_n = len(bat[0])
                val_loss_sum += loss.item() * batch_n
                val_count += batch_n

                # AUC ê³„ì‚°ì„ ìœ„í•´ì„œë§Œ ëª¨ìŒ
                y_truth_list.append(bat[1].cpu())
                y_score_list.append(torch.softmax(logits, dim=1).cpu())

        val_loss_avg = val_loss_sum / max(1, val_count)

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        y_truth = torch.cat(y_truth_list)
        y_score = torch.cat(y_score_list)
        if y_score.shape[1] == 2:
            val_auc = roc_auc_score(y_truth.numpy(), y_score.numpy()[:, 1])
        else:
            val_auc = roc_auc_score(y_truth.numpy(), y_score.numpy(), multi_class="ovo")

        curr_metric = val_auc  # í•„ìš”ì‹œ val_lossë¥¼ ì¡°í•©í•´ë„ ë¨

        print(f"[epoch {epoch}] train_loss={train_loss_avg:.4f} "
            f"val_loss={val_loss_avg:.4f} val_auc={val_auc:.4f}", flush=True)

        if curr_metric > best_metric:
            best_metric = curr_metric

    return best_metric

def run_train_and_test(model, loaders, optimizer, tcfg, keep_sparse=True):
    """
    train + validë¡œ í•™ìŠµ(ë² ìŠ¤íŠ¸ ëª¨ë¸) í›„ test í‰ê°€ë¥¼ ë°˜í™˜
    ë°˜í™˜: (auc, acc, cm, recall, precision) í˜•íƒœ
    (ì§€í‘œ ê³„ì‚°ì€ config.pyì˜ í…ŒìŠ¤íŠ¸ íŒŒíŠ¸ì™€ ë™ì¼) 
    """

    from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix, recall_score, precision_score
    
    pretrained = getattr(tcfg, "pretrained", False)
    best_metric = -1e18
    best_state = None

    # === í•™ìŠµ ===
    for epoch in range(tcfg.max_epoch):
        model.train()
        train_loss_sum, train_count = 0.0, 0

        for bat in loaders["train"]:
            optimizer.zero_grad()

            # out = model(*bat, sparse=keep_sparse)
            # loss, logits = out[0], out[1]                 # CTê°€ ìˆì–´ë„ ì•ˆì „

            if len(bat) == 3:  # (x, y, ct)
                loss, logits, ct_logit = model(*bat, sparse=keep_sparse)
            else:              # (x, y)
                loss, logits = model(*bat, sparse=keep_sparse)
            
            if not pretrained:
                # pretrain() ë°˜í™˜: CT ìˆìœ¼ë©´ (loss, ct_logit), ì—†ìœ¼ë©´ loss
                # ë³¸ í•™ìŠµ ì¤‘ì—ë„ pretrain ì†ì‹¤ì„ ì¶”ê°€ë¡œ ë„£ì„ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” í”Œë˜ê·¸ì˜ˆìš”.
                # tcfg.pretrained=Trueë©´ â†’ ì´ë¯¸ ë³„ë„ë¡œ pretrain ë‹¨ê³„ë¥¼ ë§ˆì¹œ ìƒíƒœë¼ê³  ê°€ì • â†’ ë³¸í•™ìŠµì—ì„œëŠ” cross-entropy ë¶„ë¥˜ ì†ì‹¤ë§Œ ì”€.
                # tcfg.pretrained=Falseë©´ â†’ ì‚¬ì „í•™ìŠµì„ ì•ˆ í–ˆë‹¤ê³  ê°€ì • â†’ ë³¸í•™ìŠµ ê³¼ì •ì—ì„œë„ ë§¤ ë°°ì¹˜ë§ˆë‹¤ pretrain ì†ì‹¤ì„ í•¨ê»˜ ì¶”ê°€í•˜ì—¬ latent spaceë¥¼ ê°™ì´ ì •ëˆ.
                pre = model.pretrain(*bat, sparse=keep_sparse)
                loss = loss + (pre[0] if isinstance(pre, (list, tuple)) else pre)

            loss.backward()
            optimizer.step()

            batch_n = len(bat[0])
            train_loss_sum += loss.item() * batch_n
            train_count += batch_n

        avg_train_loss = train_loss_sum / max(1, train_count)

        # === ê²€ì¦ ===
        model.eval()
        vloss_sum, vcount = 0.0, 0
        y_truth_list, y_score_list = [], []

        with torch.no_grad():
            for bat in loaders["val"]:
                out = model(*bat, sparse=keep_sparse)
                loss, logits = out[0], out[1]

                batch_n = len(bat[0])
                vloss_sum += loss.item() * batch_n
                vcount += batch_n

                y_truth_list.append(bat[1].cpu())
                y_score_list.append(torch.softmax(logits, dim=1).cpu())

        avg_val_loss = vloss_sum / max(1, vcount)

        y_truth = torch.cat(y_truth_list)
        y_score = torch.cat(y_score_list)
        y_pred = y_score.argmax(dim=1)

        if y_score.shape[1] == 2:
            val_auc = roc_auc_score(y_truth.numpy(), y_score.numpy()[:, 1])
        else:
            val_auc = roc_auc_score(y_truth.numpy(), y_score.numpy(), multi_class="ovo")
        val_acc = accuracy_score(y_truth.numpy(), y_pred.numpy())
        val_f1  = f1_score(y_truth.numpy(), y_pred.numpy(), average="macro")

        print(
            f"[Train+Valid] Epoch {epoch+1}/{tcfg.max_epoch} "
            f"| TrainLoss={avg_train_loss:.4f} "
            f"| ValLoss={avg_val_loss:.4f} "
            f"| ValAUC={val_auc:.4f} "
            f"| ValACC={val_acc:.4f} "
            f"| ValF1={val_f1:.4f}",
            flush=True
        )

        if val_auc > best_metric:
            from copy import deepcopy
            best_metric = val_auc
            best_state = deepcopy(model.state_dict())


    # === best ë¡œë“œ í›„ test ===
    if best_state is not None:
        model.load_state_dict(best_state)

    model.eval()
    y_truth_list, y_score_list = [], []
    with torch.no_grad():
        for bat in loaders["test"]:
            out = model(*bat, sparse=keep_sparse)
            logits = out[1]  # out[0]=loss, out[1]=logits
            y_truth_list.append(bat[1].cpu())
            y_score_list.append(torch.softmax(logits, dim=1).cpu())

    import torch as _torch
    y_truth = _torch.cat(y_truth_list)
    y_score = _torch.cat(y_score_list)
    y_pred = y_score.argmax(dim=1)

    acc = accuracy_score(y_truth.numpy(), y_pred.numpy())
    if y_score.shape[1] == 2:
        auc = roc_auc_score(y_truth.numpy(), y_score.numpy()[:, 1])
    else:
        auc = roc_auc_score(y_truth.numpy(), y_score.numpy(), multi_class="ovo")
    cm = confusion_matrix(y_truth.numpy(), y_pred.numpy())
    recall = recall_score(y_truth.numpy(), y_pred.numpy(), average="macro")
    precision = precision_score(y_truth.numpy(), y_pred.numpy(), average="macro")

    import numpy as _np
    cm_str = _np.array2string(cm, separator=' ', max_line_width=120)
    print(
        f"[Test] AUC={auc:.4f} | ACC={acc:.4f} | RECALL={recall:.4f} | PREC={precision:.4f}\n"
        f"[Test] Confusion Matrix (rows=true, cols=pred):\n{cm_str}",
        flush=True
    )

    return auc, acc, cm, recall, precision

def tune_one_fold(cfg):
    """
    cfg: í˜„ì¬ foldì˜ ë°ì´í„° splitì„ ë‹´ì€ Config (cfg._build() ì™„ë£Œ ìƒíƒœ)
    ë‚´ë¶€ì—ì„œ trialìš© tcfgë¥¼ ë§Œë“¤ì–´ ëª¨í˜•ì„ freshí•˜ê²Œ ìƒì„± â†’ valid AUC ìµœëŒ€í™”ë¥¼ ëª©í‘œë¡œ íƒìƒ‰
    """
    def objective(trial):
        hp = suggest(trial)
        tcfg = make_trial_cfg(cfg, hp)    # âœ… ê°€ë²¼ìš´ ì„¤ì • ê°ì²´ ìƒì„±
        tcfg.lr        = hp["lr"]
        tcfg.max_epoch = hp["max_epoch"]
        tcfg.z_dim     = hp["z_dim"]
        tcfg.h_dim     = hp["h_dim"]
        tcfg.n_proto   = hp["n_proto"]
        tcfg.max_epoch_pretrain = 75  # ê³ ì •

        def _call():
            model, optim, sched, loaders, meta = build_model_and_optim(tcfg, cfg, phase="valid_only")
            # pretrain
            # if tcfg.max_epoch_pretrain > 0:
            #     run_pretrain(model, loaders, tcfg, keep_sparse=cfg.keep_sparse)
            # train+validë§Œ
            return run_train_eval_only_valid(model, loaders, tcfg, keep_sparse=cfg.keep_sparse)

        # OOM ë°±ì˜¤í”„(8â†’4â†’2â†’1)
        return train_with_oom_retry(
            _call,
            backoff=(256, 128, 64, 32, 16, 8, 4, 2, 1),
            get_bs=lambda: tcfg.batch_size,
            set_bs=lambda b: setattr(tcfg, "batch_size", b),
        )

    study = optuna.create_study(direction="maximize")
    target = cfg.n_trials if hasattr(cfg, "n_trials") else 10
    attempts = 0
    while True:
        study.optimize(objective, n_trials=1, catch=())
        attempts += 1
        n_success = sum(t.state.name == "COMPLETE" for t in study.trials)
        if n_success >= target or attempts >= target * 50:
            break
    return sorted(study.best_trials, key=lambda t: t.value)[: getattr(cfg, "top_k", 1) ]

def suggest(trial):
    return {
        "lr": trial.suggest_categorical("lr", HP_SPACE["lr"]),
        "max_epoch": trial.suggest_categorical("max_epoch", HP_SPACE["max_epoch"]),
        "z_dim": trial.suggest_categorical("z_dim", HP_SPACE["z_dim"]),
        "h_dim": trial.suggest_categorical("h_dim", HP_SPACE["h_dim"]),
        "n_proto": trial.suggest_categorical("n_proto", HP_SPACE["n_proto"]),
    }

def main():
    p = argparse.ArgumentParser()

    # í•„ìˆ˜/í•µì‹¬
    p.add_argument("--data", default="split_datasets")
    p.add_argument("--data_location", required=True, help="base path of split datasets")
    p.add_argument("--tasks", nargs="+", default=["covid", "cardio", "kidney"])
    p.add_argument("--n_repeats", type=int, default=5)
    p.add_argument("--n_folds", type=int, default=5)

    # í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° (í•„ìš”í•œ ê²ƒë§Œ ì˜ˆì‹œë¡œ)
    p.add_argument("--lr", type=float, default=1e-4)
    p.add_argument("--max_epoch", type=int, default=75)
    p.add_argument("--batch_size", type=int, default=3)
    p.add_argument("--h_dim", type=int, default=128)
    p.add_argument("--z_dim", type=int, default=32)
    p.add_argument("--n_layers", type=int, default=2)
    p.add_argument("--n_proto", type=int, default=8)
    p.add_argument("--device", default="cuda:0")
    p.add_argument("--exp_str", default=None) # ì‹¤í—˜ ì´ë¦„(íƒœê·¸)â€**ì´ì—ìš”. ì´ ê°’ì´ Config ì•ˆì—ì„œ ì²´í¬í¬ì¸íŠ¸/ë¡œê·¸ ê²½ë¡œë¥¼ ë§Œë“œëŠ” ë° ê¼­ ì“°ì…ë‹ˆë‹¤.
    p.add_argument(
        "--cell_type_annotation",
        type=str,
        default=None,
        help="obs column name to use as cell type annotation (e.g. 'manual_annotation' or 'singler_annotation')"
)


    # ë¶ˆë¦¬ì–¸ í”Œë˜ê·¸ëŠ” BooleanOptionalAction ê¶Œì¥ (ë„ë ¤ë©´ --no-xxx)
    p.add_argument("--keep_sparse", action=argparse.BooleanOptionalAction, default=False)
    p.add_argument("--lognorm", action=argparse.BooleanOptionalAction, default=True)
    p.add_argument("--pretrained", action=argparse.BooleanOptionalAction, default=False)
    p.add_argument("--subsample", action=argparse.BooleanOptionalAction, default=False)
    p.add_argument("--eval", action=argparse.BooleanOptionalAction, default=False)
    p.add_argument("--load_ct", action=argparse.BooleanOptionalAction, default=False)

    # ê¸°íƒ€
    p.add_argument("--model", default="ProtoCell", choices=["ProtoCell", "BaseModel"],
            help="which model architecture to use")
    p.add_argument("--d_min", type=float, default=1.0)
    p.add_argument("--lambda_1", type=float, default=1.0)
    p.add_argument("--lambda_2", type=float, default=1.0)
    p.add_argument("--lambda_3", type=float, default=1.0)
    p.add_argument("--lambda_4", type=float, default=1.0)
    p.add_argument("--lambda_5", type=float, default=1.0)
    p.add_argument("--lambda_6", type=float, default=1.0)
    p.add_argument("--lr_pretrain", type=float, default=1e-2)
    p.add_argument("--max_epoch_pretrain", type=int, default=0)
    
    # run.py - argparse ì •ì˜ë¶€ ê·¼ì²˜ì— ì¶”ê°€ (Python 3.8 í˜¸í™˜)
    p.add_argument("--tune", dest="tune", action="store_true", help="enable Optuna tuning")
    p.add_argument("--no-tune", dest="tune", action="store_false", help="disable Optuna tuning")
    p.set_defaults(tune=True)

    p.add_argument("--n_trials", type=int, default=3, help="number of successful trials per fold")
    p.add_argument("--top_k", type=int, default=1, help="how many top trials to test on the test set")


    # ì‹œë“œ (ë°ì´í„° splitì—” ì•ˆ ì“°ê³ , ì¬í˜„ì„±ìš©)
    p.add_argument("--base_seed", type=int, default=42)

    args = p.parse_args()

    print(">>> Start >>>")
    for task in args.tasks:
        # === [NEW] ì´ taskì—ì„œì˜ ë°˜ë³µë³„ ìš”ì•½ì„ ë‹´ì•„ ë‘˜ ì»¨í…Œì´ë„ˆ
        task_repeat_summaries = []   # list of dicts: {"repeat": int, "auc": float, "acc": float, "recall": float, "prec": float}

        for repeat in range(args.n_repeats):
            # === [NEW] í•œ repeat ì•ˆì—ì„œ 5ê°œ foldì˜ ì§€í‘œë“¤ì„ ëª¨ì•„ë‘ëŠ” ì»¨í…Œì´ë„ˆ
            fold_aucs, fold_accs, fold_recalls, fold_precs = [], [], [], []
            fold_cms = []  # í˜¼ë™í–‰ë ¬ë„ í•©ì‚° ê°€ëŠ¥

            for fold in range(args.n_folds):
                seed = args.base_seed + repeat * 10 + fold
                set_global_seed(seed)
                print(f"\nğŸ” Task={task} | Repeat={repeat} | Fold={fold} | Seed={seed}")

                base = args.exp_str
                derived_exp = f"{base}_{task}_r{repeat}_f{fold}"
                
                print(">>> constructing Config", flush=True)

                cfg = Config(
                    data=args.data,
                    task=task,
                    data_location=args.data_location,
                    repeat=repeat,
                    fold=fold,
                    keep_sparse=args.keep_sparse,
                    lognorm=args.lognorm,
                    seed=seed,
                    # ì•„ë˜ëŠ” ê¸°ì¡´ Configì— ì´ë¯¸ ìˆëŠ” ì¸ìë“¤ ì—°ê²° (í•„ìš”í•œ ê²ƒë§Œ ì˜ˆì‹œ)
                    model=args.model,   
                    cell_type_annotation=args.cell_type_annotation,   # â˜… ì¶”ê°€
                    exp_str=derived_exp,
                    lr=args.lr,
                    max_epoch=args.max_epoch,
                    batch_size=args.batch_size,
                    h_dim=args.h_dim,
                    z_dim=args.z_dim,
                    n_layers=args.n_layers,
                    n_proto=args.n_proto,
                    device=args.device,
                    d_min=args.d_min,
                    lambda_1=args.lambda_1,
                    lambda_2=args.lambda_2,
                    lambda_3=args.lambda_3,
                    lambda_4=args.lambda_4,
                    lambda_5=args.lambda_5,
                    lambda_6=args.lambda_6,
                    pretrained=args.pretrained,
                    lr_pretrain=args.lr_pretrain,
                    max_epoch_pretrain=args.max_epoch_pretrain,
                    load_ct=args.load_ct,
                    eval=args.eval,
                    subsample=args.subsample,
                )
                # cfg ìƒì„± ì§í›„
                cfg.tune = args.tune
                cfg.n_trials = args.n_trials
                cfg.top_k = args.top_k

                # === (A) íŠœë‹: validë§Œìœ¼ë¡œ HP íƒìƒ‰ ===
                print(">>> TUNING", flush=True)
                best_trials = tune_one_fold(cfg) if getattr(cfg, "tune", True) else []

                # === (B) ê°™ì€ foldì—ì„œ ìµœì¢… í•™ìŠµ + test í‰ê°€ ===
                print(">>> ìµœì¢… í•™ìŠµ + TEST í‰ê°€", flush=True)
                from copy import deepcopy
                auc = acc = rec = pre = None
                cm_use = None

                if best_trials:
                    best_fold = None
                    for t in best_trials:
                        hp = t.params
                        tcfg = make_trial_cfg(cfg, hp) 
                        tcfg.lr        = hp["lr"]
                        tcfg.max_epoch = hp["max_epoch"]
                        tcfg.z_dim     = hp["z_dim"]
                        tcfg.h_dim     = hp["h_dim"]
                        tcfg.n_proto   = hp["n_proto"]
                        tcfg.max_epoch_pretrain = 75

                        # âœ… ë¡œê·¸
                        logger = getattr(cfg, "logger", print)  # ì•ˆì „í•˜ê²Œ

                        # âœ… ìµœì¢… í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê·¸ (tcfg ê¸°ì¤€)
                        logger("*" * 40)
                        logger(f"[BEST from Optuna] value={t.value:.6f}  params={hp}")
                        logger(f"Learning rate: {tcfg.lr:.6f}")
                        logger(f"Max epoch: {int(tcfg.max_epoch)}")
                        logger(f"Batch size: {int(tcfg.batch_size)}")
                        logger(f"Test step: {int(tcfg.test_step)}")
                        logger(f"Hidden dim: {int(tcfg.h_dim)}")
                        logger(f"Latent dim (z_dim): {int(tcfg.z_dim)}")
                        logger(f"Number of prototypes: {int(tcfg.n_proto)}")
                        logger(f"Lambdas: {tcfg.lambdas}")
                        logger(f"D_min: {tcfg.d_min}")
                        logger(f"Device: {tcfg.device}")
                        logger(f"Seed: {tcfg.seed}")
                        logger("*" * 40)
                        logger("")

                        # ìµœì¢… í•™ìŠµ + í…ŒìŠ¤íŠ¸
                        def _call():
                            model, optimizer, sched, loaders, meta = build_model_and_optim(tcfg, cfg, phase="valid_plus_test")
                            if getattr(tcfg, "max_epoch_pretrain", 0) > 0:
                                run_pretrain(model, loaders, tcfg, keep_sparse=cfg.keep_sparse)
                            return run_train_and_test(model, loaders, optimizer, tcfg, keep_sparse=cfg.keep_sparse)

                        try:
                            auc, acc, cm, rec, pre = train_with_oom_retry(
                                _call, backoff=(256, 128, 64, 32, 16, 8, 4, 2, 1),
                                get_bs=lambda: tcfg.batch_size,
                                set_bs=lambda b: setattr(tcfg, "batch_size", b),
                            )
                            if (best_fold is None) or (auc > best_fold["auc"]):
                                best_fold = dict(auc=auc, acc=acc, cm=cm, recall=rec, precision=pre)
                        except RuntimeError as e:
                            if "out of memory" in str(e).lower():
                                print(f"[WARN] OOM on final test for params {hp} â†’ skip")
                            else:
                                raise

                    # ê° fold ê²°ê³¼ ê¸°ë¡/ë¡œê·¸ 
                    if best_fold:
                        auc, acc, cm_use, rec, pre = (
                            best_fold["auc"], best_fold["acc"], best_fold["cm"], best_fold["recall"], best_fold["precision"]
                        )
                        print(f"[Fold{fold} Result] AUC={auc:.4f} | ACC={acc:.4f} | RECALL={rec:.4f} | PREC={pre:.4f}")
                    else:
                        # ì „ë¶€ OOM ë“±ìœ¼ë¡œ ì‹¤íŒ¨í•œ ê²½ìš°
                        print(f"[Fold{fold} Result] (no valid result)")

                else:
                    # íŠœë‹ ì—†ì´ í˜„ì¬ cfgë¡œ
                    tcfg = deepcopy(cfg)
                    model, optimizer, sched, loaders, meta = build_model_and_optim(tcfg, cfg, phase="valid_plus_test")
                    if tcfg.max_epoch_pretrain > 0:
                        run_pretrain(model, loaders, tcfg, keep_sparse=cfg.keep_sparse)
                    auc, acc, cm_use, rec, pre = run_train_and_test(model, loaders, optimizer, tcfg, keep_sparse=cfg.keep_sparse)
                    print(f"[Fold{fold} Result] AUC={auc:.4f} | ACC={acc:.4f} | RECALL={rec:.4f} | PREC={pre:.4f}")

                # === [NEW] fold ê²°ê³¼ë¥¼ ì»¨í…Œì´ë„ˆì— ì ì¬ (Noneì´ë©´ NaN ì²˜ë¦¬)
                def _tofloat(x): 
                    return float(x) if x is not None else np.nan

                fold_aucs.append(_tofloat(auc))
                fold_accs.append(_tofloat(acc))
                fold_recalls.append(_tofloat(rec))
                fold_precs.append(_tofloat(pre))
                if cm_use is not None:
                    fold_cms.append(np.asarray(cm_use, dtype=np.int64))



            # === [NEW] â¸ ê° repeat ì¢…ë£Œ í›„: 5ê°œ fold í‰ê· /í‘œì¤€í¸ì°¨ ì¶œë ¥
            r_auc_mean, r_auc_std = np.nanmean(fold_aucs), np.nanstd(fold_aucs)
            r_acc_mean, r_acc_std = np.nanmean(fold_accs), np.nanstd(fold_accs)
            r_rec_mean, r_rec_std = np.nanmean(fold_recalls), np.nanstd(fold_recalls)
            r_pre_mean, r_pre_std = np.nanmean(fold_precs), np.nanstd(fold_precs)

            print(
                f"\nğŸ“Œ [Repeat {repeat} Summary over {args.n_folds} folds]"
                f"  AUC={r_auc_mean:.4f}Â±{r_auc_std:.4f}"
                f" | ACC={r_acc_mean:.4f}Â±{r_acc_std:.4f}"
                f" | RECALL={r_rec_mean:.4f}Â±{r_rec_std:.4f}"
                f" | PREC={r_pre_mean:.4f}Â±{r_pre_std:.4f}"
            )

            # (ì„ íƒ) í˜¼ë™í–‰ë ¬ í•©ì‚° í‘œì‹œ
            if len(fold_cms) > 0:
                cm_sum = np.add.reduce(fold_cms)
                print("   Î£ Confusion Matrix over folds:\n", cm_sum)

            # === [NEW] task ìˆ˜ì¤€ ìš”ì•½ì— ì¶”ê°€(ë‚˜ì¤‘ì— ì „ì²´ ìš”ì•½ ë•Œ ì‚¬ìš©)
            task_repeat_summaries.append({
                "repeat": repeat,
                "auc": r_auc_mean,
                "acc": r_acc_mean,
                "recall": r_rec_mean,
                "prec": r_pre_mean,
            })


        # === [NEW] âœ… ëª¨ë“  repeat ì¢…ë£Œ í›„: ì´ taskì— ëŒ€í•œ ì „ì²´ ìš”ì•½ ì¬ì •ë¦¬ ì¶œë ¥
        print("\n" + "="*72)
        print(f"ğŸ§¾ Task='{task}' â€” Summary by Repeat (means over {args.n_folds} folds)")
        for rs in task_repeat_summaries:
            print(
                f"  - Repeat {rs['repeat']}: "
                f"AUC={rs['auc']:.4f} | ACC={rs['acc']:.4f} | RECALL={rs['recall']:.4f} | PREC={rs['prec']:.4f}"
            )

        # ìµœì¢…(ëª¨ë“  repeat í‰ê· ) 1ì¤„
        final_auc = np.nanmean([rs["auc"] for rs in task_repeat_summaries])
        final_acc = np.nanmean([rs["acc"] for rs in task_repeat_summaries])
        final_rec = np.nanmean([rs["recall"] for rs in task_repeat_summaries])
        final_pre = np.nanmean([rs["prec"] for rs in task_repeat_summaries])

        print("-"*72)
        print(
            f"âœ… FINAL (Task='{task}', across {args.n_repeats} repeats, each averaged over {args.n_folds} folds)\n"
            f"   AUC={final_auc:.4f} | ACC={final_acc:.4f} | RECALL={final_rec:.4f} | PREC={final_pre:.4f}"
        )
        print("="*72 + "\n")

        
if __name__ == "__main__":
    main()

