import numpy as np
import pickle
import scanpy
import pandas as pd


def Covid_data(args):
    if args.task == 'haniffa':
        id_dict = {'Critical ': 1, 'Death': -1, 'Severe': 1, 'nan': -1, 'LPS': 0, 'Non-covid': 0, 'Asymptomatic': 1,
                   'Mild': 1, 'Healthy': 0, 'Moderate': 1}

        if args.pca == True:
            with open('./data/Haniffa/Haniffa_X_pca.npy', 'rb') as f:
                origin = np.load(f)
        else:
            with open('./data/Haniffa/origin.npy', 'rb') as f:
                origin = np.load(f)

        a_file = open('./data/Haniffa/patient_id.pkl', "rb")
        patient_id = pickle.load(a_file)
        a_file.close()

        a_file = open('./data/Haniffa/labels.pkl', "rb")
        labels = pickle.load(a_file)
        a_file.close()

        a_file = open('./data/Haniffa/cell_type.pkl', "rb")
        cell_type = pickle.load(a_file)
        a_file.close()

        a_file = open('./data/Haniffa/cell_type_large.pkl', "rb")
        cell_type_large = pickle.load(a_file)
        a_file.close()
    elif args.task == 'combat':
        id_dict = {'COVID_HCW_MILD': 1, 'COVID_CRIT': 1, 'COVID_MILD': 1, 'COVID_SEV': 1, 'COVID_LDN': 1, 'HV': 0,
                   'Flu': 0, 'Sepsis': 0}

        if args.pca == True:
            with open('./data/COMBAT/COMBAT_X_pca.npy', 'rb') as f:
                origin = np.load(f)
        else:
            with open('./data/COMBAT/origin.npy', 'rb') as f:
                origin = np.load(f)

        a_file = open('./data/COMBAT/patient_id.pkl', "rb")
        patient_id = pickle.load(a_file)
        a_file.close()

        a_file = open('./data/COMBAT/labels.pkl', "rb")
        labels = pickle.load(a_file)
        a_file.close()

        a_file = open('./data/COMBAT/cell_type.pkl', "rb")
        cell_type = pickle.load(a_file)
        a_file.close()

        a_file = open('./data/COMBAT/cell_type_large.pkl', "rb")
        cell_type_large = pickle.load(a_file)
        a_file.close()
    else:
        id_dict = {}
        if args.task == 'severity':
            id_dict = {'mild/moderate': 0, 'severe/critical': 1, 'control': -1}
        elif args.task == 'stage':
            id_dict = {'convalescence': 0, 'progression': 1, 'control': -1}

        if args.pca == True:
            with open('./data/SC4/covid_pca.npy', 'rb') as f:
                origin = np.load(f)
        else:
            with open('./data/SC4/origin.npy', 'rb') as f:
                origin = np.load(f)

        a_file = open('./data/SC4/patient_id.pkl', "rb")
        patient_id = pickle.load(a_file)
        a_file.close()

        a_file = open('./data/SC4/' + args.task + '_label.pkl', "rb")
        labels = pickle.load(a_file)
        a_file.close()

        if args.task == 'severity':
            a_file = open('./data/SC4/stage_label.pkl', "rb")
            stage_labels = pickle.load(a_file)
            a_file.close()

        a_file = open('./data/SC4/cell_type.pkl', "rb")
        cell_type = pickle.load(a_file)
        a_file.close()

        a_file = open('./data/SC4/cell_type_large.pkl', "rb")
        cell_type_large = pickle.load(a_file)
        a_file.close()

    labels_ = np.array(labels.map(id_dict))

    if args.task == 'severity':
        id_dict_ = {'convalescence': 0, 'progression': 1, 'control': 0}
        labels_stage = np.array(stage_labels.map(id_dict_))

    l_dict = {}
    indices = np.arange(origin.shape[0])
    p_ids = sorted(set(patient_id))
    p_idx = []

    if args.task == 'combat':
        top_class = []
        for tc in (
        'PB', 'CD4.TEFF.prolif', 'PLT', 'B.INT', 'CD8.TEFF.prolif', 'B.MEM', 'NK.cyc', 'RET', 'B.NAIVE', 'NK.mitohi'):
            top_class.append(indices[cell_type_large == tc])
        selected = np.concatenate(top_class)
    elif args.task == 'haniffa':
        top_class = []
        for tc in (
        'B_immature', 'C1_CD16_mono', 'CD4.Prolif', 'HSC_erythroid', 'RBC', 'Plasma_cell_IgG', 'pDC', 'Plasma_cell_IgA',
        'Platelets', 'Plasmablast'):
            top_class.append(indices[cell_type_large == tc])
        selected = np.concatenate(top_class)
    elif args.task == 'severity':
        top_class = []
        for tc in (
        'Macro_c3-EREG', 'Epi-Squamous', 'Neu_c5-GSTP1(high)OASL(low)', 'Epi-Ciliated', 'Neu_c3-CST7', 'Neu_c4-RSAD2',
        'Epi-Secretory', 'Mega', 'Neu_c1-IL1B', 'Macro_c6-VCAN', 'DC_c3-LAMP3', 'Neu_c6-FGF23', 'Macro_c2-CCL3L1',
        'Mono_c1-CD14-CCL3', 'Neu_c2-CXCR4(low)', 'B_c05-MZB1-XBP1', 'DC_c1-CLEC9A', 'Mono_c4-CD14-CD16'):
            top_class.append(indices[cell_type_large == tc])
        selected = np.concatenate(top_class)
    elif args.task == 'stage':
        top_class = []
        for tc in (
        'Neu_c5-GSTP1(high)OASL(low)', 'Neu_c3-CST7', 'Macro_c3-EREG', 'Epi-Squamous', 'Mega', 'Epi-Ciliated',
        'Mono_c5-CD16', 'Neu_c4-RSAD2', 'Epi-Secretory', 'Neu_c1-IL1B', 'DC_c1-CLEC9A', 'DC_c3-LAMP3',
        'Neu_c2-CXCR4(low)', 'Mono_c4-CD14-CD16', 'Mono_c1-CD14-CCL3', 'Macro_c6-VCAN'):
            top_class.append(indices[cell_type_large == tc])
        selected = np.concatenate(top_class)
    for i in p_ids:
        idx = indices[patient_id == i]
        if len(idx) < 500:
            continue
        if len(set(labels_[idx])) > 1:
            for ii in sorted(set(labels_[idx])):
                if ii > -1:
                    iidx = idx[labels_[idx] == ii]
                    tt_idx = iidx
                    # tt_idx = np.intersect1d(iidx, selected)
                    # tt_idx = np.setdiff1d(iidx, selected)
                    if len(tt_idx) < 1:
                        continue
                    p_idx.append(tt_idx)
                    l_dict[labels_[iidx[0]]] = l_dict.get(labels_[iidx[0]], 0) + 1
        else:
            if args.task == 'severity':
                if (labels_[idx[0]] > -1) and (labels_stage[idx[0]]) > 0:
                    tt_idx = idx
                    # tt_idx = np.intersect1d(idx, selected)
                    # tt_idx = np.setdiff1d(idx, selected)
                    if len(tt_idx) < 1:
                        continue
                    p_idx.append(tt_idx)
                    l_dict[labels_[idx[0]]] = l_dict.get(labels_[idx[0]], 0) + 1
            else:
                if labels_[idx[0]] > -1:
                    tt_idx = idx
                    # tt_idx = np.intersect1d(idx, selected)
                    # tt_idx = np.setdiff1d(idx, selected)
                    if len(tt_idx) < 1:
                        continue
                    p_idx.append(tt_idx)
                    l_dict[labels_[idx[0]]] = l_dict.get(labels_[idx[0]], 0) + 1

    # print(l_dict)

    return p_idx, labels_, cell_type, patient_id, origin, cell_type_large

# dataloader.pyÏóê ÏûàÎäî Custom_data()Î•º h5adÍ∞Ä ÏïÑÎãàÎùº 
# Ïù¥ÎØ∏ loadÎêú AnnData Í∞ùÏ≤¥Î•º Î∞õÏïÑ Ï≤òÎ¶¨ÌïòÎäî Î≤ÑÏ†ÑÏúºÎ°ú ÌïòÎÇò Ï∂îÍ∞ÄÌïòÎ©¥ Îê©ÎãàÎã§.
def Custom_data_from_loaded(data, args):
    # 1. ÎùºÎ≤® Îß§Ìïë Ï†ïÏùò
    id_dict = {
        'normal': 0,
        'COVID-19': 1,
        'hypertrophic cardiomyopathy':1,
        'dilated cardiomyopathy':2,

        'Healthy_stone_donor':0,
        'Healthy_living_donor':0,
        'CKD':1,
        'AKI':2
    }

    # 2. ÌôòÏûê ID, ÎùºÎ≤®, ÏÖÄ ÌÉÄÏûÖ Ï†ïÎ≥¥ Ï∂îÏ∂ú
    patient_id = data.obs['patient'] if 'patient' in data.obs else data.obs['donor_id']
    labels = data.obs['disease__ontology_label']  if 'disease__ontology_label' in data.obs else data.obs['disease_category']

    # cell_type = data.obs[args.cell_type_annotation]
    # üîß Ïó¨Í∏∞ ÏàòÏ†ï: args.cell_type_annotation Ïö∞ÏÑ† ÏÇ¨Ïö©
    anno_col = getattr(args, "cell_type_annotation", "manual_annotation")
    if anno_col in data.obs:
        cell_type = data.obs[anno_col].astype("string").fillna("Unknown")
        print("cell type : ", cell_type)
    else:
        print(f"‚ö†Ô∏è '{anno_col}' Ïª¨ÎüºÏù¥ ÏóÜÏñ¥ 'manual_annotation'Î°ú ÎåÄÏ≤¥Ìï©ÎãàÎã§.")
        cell_type = data.obs['manual_annotation'].astype("string").fillna("Unknown")
    
    # cell_type = data.obs['manual_annotation']
    # cell_type = data.obs['singler_annotation']

    pd.set_option('display.max_seq_items', None)  # Ïú†ÎãàÌÅ¨ Ìï≠Î™© Ï∂úÎ†• Ï†úÌïú Ìï¥Ï†ú
    print("cell type annotation : ",cell_type)
    print("‚úÖ [DEBUG] manual_annotation Ïú†ÎãàÌÅ¨Í∞í:", list(cell_type.unique()))
    # print("‚úÖ [DEBUG] manual_annotation isna sum:", cell_type.isna().sum())
    # print("‚úÖ [DEBUG] manual_annotation dtype:", cell_type.dtype)

    # print("‚úÖ [DEBUG] NaN ÏúÑÏπòÎì§:")
    # print(cell_type[cell_type.isna()])

    # 3. expression Îç∞Ïù¥ÌÑ∞ ÏÑ†ÌÉù
    if args.pca:
        origin = data.obsm['X_pca']
    else:
        origin = data.X.toarray() if not isinstance(data.X, np.ndarray) else data.X

    # 4. ÎùºÎ≤®ÏùÑ Ïà´ÏûêÎ°ú Î≥ÄÌôò
    labels_ = np.array(labels.map(id_dict))

    # 5. ÌôòÏûêÎ≥Ñ Ïù∏Îç±Ïä§Î•º Íµ¨ÏÑ±
    l_dict = {}
    indices = np.arange(origin.shape[0])
    p_ids = sorted(set(patient_id))
    p_idx = []
    
    
    # ÌôòÏûê Îã®ÏúÑÎ°ú ÏÖÄÏùÑ Î™®ÏïÑ,
    # Îã§ÎùºÎ≤®Ïù¥Î©¥ ÎùºÎ≤®Î≥ÑÎ°ú Ï™ºÍ∞úÏñ¥ Ïù∏Îç±Ïä§ Î¨∂ÏùåÏùÑ ÎßåÎì§Í≥†,
    # Îã®Ïùº ÎùºÎ≤®Ïù¥Î©¥ ÌôòÏûê Ï†ÑÏ≤¥ ÏÖÄ Î¨∂ÏùåÏùÑ ÎßåÎì§Ïñ¥,
    # Ïù¥ Î¨∂Ïùå(=ÌõÑÏÜç Îã®Í≥ÑÏóêÏÑú bagÏúºÎ°ú Ïì∞Ïùº ÏõêÏ≤ú ÏßëÌï©) Îì§ÏùÑ p_idx Î¶¨Ïä§Ìä∏Ïóê Ï∞®Í≥°Ï∞®Í≥° ÏåìÎäî Î°úÏßÅÏûÖÎãàÎã§.

    for i in p_ids: # Î™®Îì† ÌôòÏûê ID(p_ids)Î•º ÌïòÎÇòÏî© ÏàúÌöåÌï©ÎãàÎã§. Ïó¨Í∏∞ÏÑú Î∞òÎ≥µ Î≥ÄÏàò iÎäî ‚ÄúÌòÑÏû¨ ÌôòÏûê ID‚ÄùÏûÖÎãàÎã§.
        idx = indices[patient_id == i] # ÌòÑÏû¨ ÌôòÏûê iÏóê ÏÜçÌïòÎäî ÏÖÄÎì§Ïùò Ï†ÑÏ≤¥ Ïù∏Îç±Ïä§Î•º ÎΩëÏäµÎãàÎã§.
                                        # patient_id == iÍ∞Ä Î∂àÎ¶¨Ïñ∏ ÎßàÏä§ÌÅ¨(Í∏∏Ïù¥ = Ï†ÑÏ≤¥ ÏÖÄ Ïàò)Î•º ÎßåÎì§Í≥†,
                                        # Í∑∏ ÎßàÏä§ÌÅ¨Î°ú indicesÎ•º ÌïÑÌÑ∞ÎßÅÌï¥ Ìï¥Îãπ ÌôòÏûêÏùò ÏÖÄ Ïù∏Îç±Ïä§ Î∞∞Ïó¥ idxÎ•º ÏñªÏäµÎãàÎã§.
        if len(set(labels_[idx])) > 1:   # one patient with more than one labels # Ïù¥ ÌôòÏûê iÏùò ÏÖÄÎì§(idx)Ïóê ÏÑúÎ°ú Îã§Î•∏ ÎùºÎ≤®Ïù¥ 2Í∞ú Ïù¥ÏÉÅ ÏûàÎäîÏßÄ ÌôïÏù∏Ìï©ÎãàÎã§.
            for ii in sorted(set(labels_[idx])): # ÌôòÏûê iÏóêÏÑú ÎùºÎ≤®Î≥ÑÎ°ú ÎÇòÎàÑÏñ¥ Ï≤òÎ¶¨ÌïòÍ∏∞ ÏúÑÌï¥, Ïú†Ïùº ÎùºÎ≤®Îì§ÏùÑ Ï†ïÎ†¨Ìï¥ÏÑú ÌïòÎÇòÏî© ÏàúÌöåÌï©ÎãàÎã§. # Ïòà: ÎùºÎ≤® ÏßëÌï©Ïù¥ {0, 1, -1}Ïù¥ÎùºÎ©¥ -1, 0, 1 ÏàúÏúºÎ°ú ÎèåÏïÑÏöî.
                if ii > -1: # Ïú†Ìö® ÎùºÎ≤®Îßå ÏÇ¨Ïö©Ìï©ÎãàÎã§. # ex: 0,1,2
                    iidx = idx[labels_[idx] == ii] # ÌòÑÏû¨ ÎùºÎ≤® iiÏóê Ìï¥ÎãπÌïòÎäî Î∂ÄÎ∂Ñ ÏÖÄ Ïù∏Îç±Ïä§ Î¨∂ÏùåÏùÑ ÎßåÎì≠ÎãàÎã§.
                                                    # labels_[idx] == iiÎäî Í∏∏Ïù¥ len(idx)Ïù∏ Î∂àÎ¶¨Ïñ∏ ÎßàÏä§ÌÅ¨,
                                                    # Í∑∏Í±∏Î°ú idxÎ•º Îã§Ïãú ÌïÑÌÑ∞ÎßÅÌïòÎ©¥ ‚ÄúÌôòÏûê i & ÎùºÎ≤® ii‚Äù Ï°∞Í±¥ÏùÑ ÎßåÏ°±ÌïòÎäî ÏÖÄ Ïù∏Îç±Ïä§ Î∞∞Ïó¥ iidxÍ∞Ä Îê©ÎãàÎã§.
                    tt_idx = iidx
                    # ‚òÖ Í∞úÏàò Ï≤¥ÌÅ¨(ÏµúÏÜå ÏÖÄ Ïàò Ï°∞Í±¥) ÏóÜÏù¥ Ï†ÑÎ∂Ä Ï∂îÍ∞ÄÌïòÍ∏∞ ÏúÑÌï¥ Ïù¥ ÏΩîÎìúÎäî Ï£ºÏÑùÏ≤òÎ¶¨ ÌïòÏûê
                    # if len(tt_idx) < 500:  # exclude the sample with the number of cells fewer than 500
                    #     continue
                    p_idx.append(tt_idx) # ÎùºÎ≤®Î≥ÑÎ°ú Ï™ºÍ∞† Ïù∏Îç±Ïä§ Î¨∂Ïùå(iidx) ÏùÑ p_idx Î¶¨Ïä§Ìä∏Ïóê ÎÑ£ÏäµÎãàÎã§.
                                            # ÎÇòÏ§ë Îã®Í≥Ñ(ÏÉòÌîåÎßÅ/Î°úÎçî/Î™®Îç∏)ÏóêÏÑú Ïù¥ Î¨∂ÏùåÏùÑ ‚ÄúÌïú bagÏùò ÏõêÏ≤ú Ïû¨Î£å‚ÄùÎ°ú ÏÇ¨Ïö©Ìï©ÎãàÎã§.
                                            # Îã§ÎùºÎ≤® ÌôòÏûêÎäî ÎùºÎ≤® Í∞úÏàòÎßåÌÅº Ïó¨Îü¨ Î¨∂ÏùåÏù¥ ÏÉùÍπÅÎãàÎã§.
                    l_dict[labels_[iidx[0]]] = l_dict.get(labels_[iidx[0]], 0) + 1     # p_idxÏóê ÌïòÎÇòÏùò Ïù∏Îç±Ïä§ Î¨∂Ïùå(= ÌôòÏûê-ÎùºÎ≤® Í∑∏Î£π)ÏùÑ Ï∂îÍ∞ÄÌï† Îïå, Í∑∏ Î¨∂ÏùåÏùò ÎùºÎ≤®ÏùÑ keyÎ°ú Ìï¥ÏÑú l_dict Í∞íÏùÑ +1 Ï¶ùÍ∞Ä

        else: # Ïù¥ Î∂ÑÍ∏∞Îäî Îã®Ïùº ÎùºÎ≤® ÌôòÏûêÏù∏ Í≤ΩÏö∞(= Ïú†Ïùº ÎùºÎ≤® Í∞úÏàò == 1)ÏûÖÎãàÎã§.
            if labels_[idx[0]] > -1: # Í∑∏ Îã®Ïùº ÎùºÎ≤®Ïù¥ Ïú†Ìö®ÌïúÏßÄ ÌôïÏù∏Ìï©ÎãàÎã§. (Ïó¨Í∏∞ÏÑúÎèÑ -1ÏùÄ Ï†úÏô∏)
                                    # Ï£ºÏùò: idxÍ∞Ä ÎπÑÏñ¥ÏûàÎã§Î©¥ idx[0]ÏóêÏÑú ÏóêÎü¨Í∞Ä ÎÇ©ÎãàÎã§. ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÌôòÏûêÏóê ÏµúÏÜå 1Í∞ú ÏÖÄÏù¥ ÏûàÎã§Í≥† Í∞ÄÏ†ïÌï©ÎãàÎã§.
                tt_idx = idx
                # ‚òÖ Í∞úÏàò Ï≤¥ÌÅ¨(ÏµúÏÜå ÏÖÄ Ïàò Ï°∞Í±¥) ÏóÜÏù¥ Ï†ÑÎ∂Ä Ï∂îÍ∞ÄÌïòÍ∏∞ ÏúÑÌï¥ Ïù¥ ÏΩîÎìúÎäî Ï£ºÏÑùÏ≤òÎ¶¨ ÌïòÏûê
                # if len(tt_idx) < 500:  # exclude the sample with the number of cells fewer than 500
                #     continue
                p_idx.append(tt_idx) # Îã®Ïùº ÎùºÎ≤® ÌôòÏûêÎäî ÌôòÏûê Ï†ÑÏ≤¥ ÏÖÄ Ïù∏Îç±Ïä§ Î¨∂Ïùå(idx)ÏùÑ Í∑∏ÎåÄÎ°ú p_idxÏóê Ï∂îÍ∞ÄÌï©ÎãàÎã§.
                                     # Ïù¥Î†áÍ≤å ÌïòÎ©¥, Îã®Ïùº ÎùºÎ≤® ÌôòÏûêÎäî Î¨∂Ïùå 1Í∞ú, Îã§ÎùºÎ≤® ÌôòÏûêÎäî ÎùºÎ≤® ÏàòÎßåÌÅº Ïó¨Îü¨ Î¨∂ÏùåÏù¥ Îì§Ïñ¥Í∞ÄÍ≤å Îê©ÎãàÎã§.
                l_dict[labels_[idx[0]]] = l_dict.get(labels_[idx[0]], 0) + 1     # p_idxÏóê ÌïòÎÇòÏùò Ïù∏Îç±Ïä§ Î¨∂Ïùå(= ÌôòÏûê-ÎùºÎ≤® Í∑∏Î£π)ÏùÑ Ï∂îÍ∞ÄÌï† Îïå, Í∑∏ Î¨∂ÏùåÏùò ÎùºÎ≤®ÏùÑ keyÎ°ú Ìï¥ÏÑú l_dict Í∞íÏùÑ +1 Ï¶ùÍ∞Ä

    print("ÎùºÎ≤®Î≥Ñ Í∑∏Î£π Í∞úÏàò",l_dict) # Îã§ÎùºÎ≤® ÌôòÏûêÎäî ÎùºÎ≤®ÎßàÎã§ Ïó¨Îü¨ Î¨∂ÏùåÏúºÎ°ú Ïû°ÌûàÎãà Í∑∏ÎßåÌÅº Ïó¨Îü¨ Î≤à Ïπ¥Ïö¥Ìä∏Îê©ÎãàÎã§.
    # ex) ÎùºÎ≤®Î≥Ñ Í∑∏Î£π Í∞úÏàò {1: 3, 2: 2, 0: 4} # https://chatgpt.com/s/t_689d6521e6088191bb414a646b947ee5 

    # 6. numpy Í∏∞Î∞òÏúºÎ°ú Î∞òÌôò
    return p_idx, labels_, np.array(cell_type), np.array(patient_id), origin


# def Custom_data(args):
#     '''
#     !!! Need to change line 178 before running the code !!!
#     '''
#     data = scanpy.read_h5ad(args.dataset)
#     ### Cardio data Ïã§Ìñâ ÏΩîÎìú
#     if args.task == 'custom_cardio':
#         id_dict = {
#             'normal': 0,
#             'hypertrophic cardiomyopathy': 1,
#             'dilated cardiomyopathy': 2
#         }
#         patient_id = data.obs['patient']
#         labels = data.obs['disease__ontology_label']
#         cell_type = data.obs['cell_type_annotation']
    
#     ### Covid data Ïã§Ìñâ ÏΩîÎìú
#     elif args.task == 'custom_covid':
#         id_dict = {
#             'normal': 0,
#             'COVID-19': 1
#         }
#         patient_id = data.obs['donor_id']
#         labels = data.obs['disease__ontology_label']        
#         cell_type = data.obs['cell_type_annotation']
    
#     else:
#         raise ValueError(f"Unsupported task for Custom_data: {args.task}")

#     # data = scanpy.read_h5ad(args.dataset)
#     if args.pca == True:
#         origin = data.obsm['X_pca']
#     else:
#         # origin = data.layers['raw']
#         # pca False ; ÏàòÏ†ï 2
#         origin = data.X.toarray() if not isinstance(data.X, np.ndarray) else data.X

    
#     # patient_id = data.obs['patient_id']

#     # labels = data.obs['Outcome']

#     # cell_type = data.obs['cell_type']

#     cell_type_large = None
#     # This (high resolution) cell_type is only for attention analysis, not necessary
#     # cell_type_large = data.obs['cell_type_large']

#     labels_ = np.array(labels.map(id_dict))

#     l_dict = {}
#     indices = np.arange(origin.shape[0])
#     p_ids = sorted(set(patient_id))
#     p_idx = []

#     for i in p_ids:
#         idx = indices[patient_id == i]
#         if len(set(labels_[idx])) > 1:   # one patient with more than one labels
#             for ii in sorted(set(labels_[idx])):
#                 if ii > -1:
#                     iidx = idx[labels_[idx] == ii]
#                     tt_idx = iidx
#                     # if len(tt_idx) < 500:  # exclude the sample with the number of cells fewer than 500
#                     if len(tt_idx) < max(args.train_sample_cells, args.test_sample_cells):
#                         continue
#                     p_idx.append(tt_idx)
#                     l_dict[labels_[iidx[0]]] = l_dict.get(labels_[iidx[0]], 0) + 1
#         else:
#             if labels_[idx[0]] > -1:
#                 tt_idx = idx
#                 # if len(tt_idx) < 500:  # exclude the sample with the number of cells fewer than 500
#                 if len(tt_idx) < max(args.train_sample_cells, args.test_sample_cells):
#                     continue
#                 p_idx.append(tt_idx)
#                 l_dict[labels_[idx[0]]] = l_dict.get(labels_[idx[0]], 0) + 1

#     # print(l_dict)

#     return p_idx, labels_, cell_type, patient_id, origin, cell_type_large
