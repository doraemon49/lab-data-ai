Namespace(seed=240, batch_size=1, learning_rate=0.003, weight_decay=0.0001, epochs=100, task='custom_cardio', emb_dim=128, h_dim=128, dropout=0.3, layers=1, heads=8, train_sample_cells=500, test_sample_cells=500, train_num_sample=20, test_num_sample=100, model='Transformer', dataset='/data/project/kim89/0805_data', inter_only=False, same_pheno=0, augment_num=100, alpha=1.0, repeat=5, all=1, min_size=6000, n_splits=5, pca=False, mix_type=1, norm_first=False, warmup=False, top_k=1, cell_type_annotation='manual_annotation')
🔁 Repeat 0, Fold 0
cell type :  CAACCAAAGACCCGCT-1-2              cardiac muscle cell
ACGGTTACATCGAACT-1-2              cardiac muscle cell
ACCCTCATCCGGCAGT-1-2              cardiac muscle cell
AACACACCACGGTCTG-1-2              cardiac muscle cell
AAACGCTTCACCGGGT-1-2              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 463212, dtype: string
cell type annotation :  CAACCAAAGACCCGCT-1-2              cardiac muscle cell
ACGGTTACATCGAACT-1-2              cardiac muscle cell
ACCCTCATCCGGCAGT-1-2              cardiac muscle cell
AACACACCACGGTCTG-1-2              cardiac muscle cell
AAACGCTTCACCGGGT-1-2              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 463212, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'vascular associated smooth muscle cell', 'macrophage', 'endocardial cell', 'endothelial cell of lymphatic vessel', 'cardiac endothelial cell', 'cardiac ventricle fibroblast', 'pericyte cell', 'cardiac neuron', 'lymphocyte', 'mast cell', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 12}
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 129477, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 129477, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {1: 3, 2: 2, 0: 4}
🔍 Split #1
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 33
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 9
  → train 환자 ID: ['P1290', 'P1300', 'P1304', 'P1358', 'P1371', 'P1425', 'P1430', 'P1462', 'P1479', 'P1504', 'P1508', 'P1510', 'P1515', 'P1516', 'P1539', 'P1540', 'P1547', 'P1549', 'P1558', 'P1582', 'P1600', 'P1602', 'P1606', 'P1610', 'P1617', 'P1630', 'P1631', 'P1678', 'P1685', 'P1707', 'P1718', 'P1722', 'P1735']
  → test  환자 ID: ['P1422', 'P1437', 'P1447', 'P1472', 'P1561', 'P1603', 'P1622', 'P1702', 'P1726']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1462, Label: 1
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1422, Label: 1
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1472, Label: 2
    ID: P1561, Label: 0
    ID: P1603, Label: 0
    ID: P1622, Label: 0
    ID: P1702, Label: 0
    ID: P1726, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 33
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 33
기존 (train) label_stat 33
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 11
test_p_index 9
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1540, Label=0, 셀개수=11638
→ valid 환자 ID 및 라벨:
   총 개수: 11
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1617, Label=2, 셀개수=17986
→ test 환자 ID 및 라벨:
   총 개수: 9
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1726, Label=1, 셀개수=12389
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0              cardiac muscle cell
1              cardiac muscle cell
2              cardiac muscle cell
3              cardiac muscle cell
4              cardiac muscle cell
                    ...           
592684    cardiac endothelial cell
592685    cardiac endothelial cell
592686    cardiac endothelial cell
592687    cardiac endothelial cell
592688    cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:12,  7.94it/s]  2%|▏         | 2/100 [00:00<00:12,  8.08it/s]  3%|▎         | 3/100 [00:00<00:12,  8.02it/s]  4%|▍         | 4/100 [00:00<00:11,  8.13it/s]  5%|▌         | 5/100 [00:00<00:11,  8.24it/s]  6%|▌         | 6/100 [00:00<00:11,  8.36it/s]  7%|▋         | 7/100 [00:00<00:11,  8.43it/s]  8%|▊         | 8/100 [00:00<00:10,  8.51it/s]  9%|▉         | 9/100 [00:01<00:10,  8.48it/s] 10%|█         | 10/100 [00:01<00:10,  8.66it/s] 11%|█         | 11/100 [00:01<00:10,  8.63it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.61it/s] 13%|█▎        | 13/100 [00:01<00:10,  8.67it/s] 14%|█▍        | 14/100 [00:01<00:09,  8.63it/s] 15%|█▌        | 15/100 [00:01<00:09,  8.66it/s] 16%|█▌        | 16/100 [00:01<00:09,  8.59it/s] 17%|█▋        | 17/100 [00:02<00:09,  8.54it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.51it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.55it/s] 20%|██        | 20/100 [00:02<00:09,  8.47it/s] 21%|██        | 21/100 [00:02<00:09,  8.44it/s] 22%|██▏       | 22/100 [00:02<00:09,  8.36it/s] 23%|██▎       | 23/100 [00:02<00:09,  8.34it/s] 24%|██▍       | 24/100 [00:02<00:08,  8.51it/s] 25%|██▌       | 25/100 [00:02<00:08,  8.58it/s] 26%|██▌       | 26/100 [00:03<00:08,  8.49it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.59it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.58it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.53it/s] 30%|███       | 30/100 [00:03<00:07,  8.75it/s] 31%|███       | 31/100 [00:03<00:08,  8.57it/s] 32%|███▏      | 32/100 [00:03<00:07,  8.56it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.63it/s] 34%|███▍      | 34/100 [00:03<00:07,  8.59it/s] 35%|███▌      | 35/100 [00:04<00:07,  8.38it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.42it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.31it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.38it/s] 39%|███▉      | 39/100 [00:04<00:07,  8.45it/s] 40%|████      | 40/100 [00:04<00:07,  8.44it/s] 41%|████      | 41/100 [00:04<00:06,  8.49it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.45it/s] 43%|████▎     | 43/100 [00:05<00:06,  8.51it/s] 44%|████▍     | 44/100 [00:05<00:06,  8.57it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.59it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.70it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.62it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.56it/s] 49%|████▉     | 49/100 [00:05<00:05,  8.60it/s] 50%|█████     | 50/100 [00:05<00:05,  8.58it/s] 51%|█████     | 51/100 [00:05<00:05,  8.50it/s] 52%|█████▏    | 52/100 [00:06<00:05,  8.57it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.57it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.55it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.67it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.46it/s] 57%|█████▋    | 57/100 [00:06<00:05,  8.42it/s] 58%|█████▊    | 58/100 [00:06<00:04,  8.40it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.45it/s] 60%|██████    | 60/100 [00:07<00:04,  8.50it/s] 61%|██████    | 61/100 [00:07<00:04,  8.67it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.51it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.41it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.61it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.60it/s] 66%|██████▌   | 66/100 [00:07<00:04,  8.42it/s] 67%|██████▋   | 67/100 [00:07<00:03,  8.44it/s] 68%|██████▊   | 68/100 [00:08<00:03,  8.26it/s] 69%|██████▉   | 69/100 [00:08<00:03,  8.29it/s] 70%|███████   | 70/100 [00:08<00:03,  8.29it/s] 71%|███████   | 71/100 [00:08<00:03,  8.36it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.40it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.40it/s] 74%|███████▍  | 74/100 [00:08<00:03,  8.35it/s] 75%|███████▌  | 75/100 [00:08<00:02,  8.50it/s] 76%|███████▌  | 76/100 [00:08<00:02,  8.52it/s] 77%|███████▋  | 77/100 [00:09<00:02,  8.64it/s] 78%|███████▊  | 78/100 [00:09<00:02,  8.68it/s] 79%|███████▉  | 79/100 [00:09<00:02,  8.60it/s] 80%|████████  | 80/100 [00:09<00:02,  8.43it/s] 81%|████████  | 81/100 [00:09<00:02,  8.44it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.31it/s] 83%|████████▎ | 83/100 [00:09<00:02,  8.27it/s] 84%|████████▍ | 84/100 [00:09<00:01,  8.14it/s] 85%|████████▌ | 85/100 [00:10<00:01,  8.22it/s] 86%|████████▌ | 86/100 [00:10<00:01,  8.30it/s] 87%|████████▋ | 87/100 [00:10<00:01,  8.32it/s] 88%|████████▊ | 88/100 [00:10<00:01,  8.38it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.48it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.52it/s] 91%|█████████ | 91/100 [00:10<00:01,  8.57it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.43it/s] 93%|█████████▎| 93/100 [00:10<00:00,  8.40it/s] 94%|█████████▍| 94/100 [00:11<00:00,  8.43it/s] 95%|█████████▌| 95/100 [00:11<00:00,  8.37it/s] 96%|█████████▌| 96/100 [00:11<00:00,  8.21it/s] 97%|█████████▋| 97/100 [00:11<00:00,  8.34it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.54it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.39it/s]100%|██████████| 100/100 [00:11<00:00,  8.26it/s]100%|██████████| 100/100 [00:11<00:00,  8.46it/s]
[I 2025-08-27 02:03:12,441] A new study created in memory with name: no-name-8ee227bb-453a-4971-bdcd-21a032dce1ba
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 3.60 MB
Memory Reserved: 22.00 MB
cuda
Epoch 1, Train Loss 0.910833, Valid_loss 2.072650
Epoch 2, Train Loss 0.740728, Valid_loss 1.477999
Epoch 3, Train Loss 0.519063, Valid_loss 1.370576
Epoch 4, Train Loss 0.520206, Valid_loss 1.625605
Epoch 5, Train Loss 0.406880, Valid_loss 0.914168
Epoch 6, Train Loss 0.405302, Valid_loss 1.385911
Epoch 7, Train Loss 0.391373, Valid_loss 1.350348
Epoch 8, Train Loss 0.331589, Valid_loss 1.357570
Epoch 9, Train Loss 0.292834, Valid_loss 1.777271
Epoch 10, Train Loss 0.254783, Valid_loss 1.643949
Epoch 11, Train Loss 0.340180, Valid_loss 1.689977
Epoch 12, Train Loss 0.239897, Valid_loss 1.627714
Epoch 13, Train Loss 0.213004, Valid_loss 1.349632
Epoch 14, Train Loss 0.178870, Valid_loss 2.175393
Epoch 15, Train Loss 0.156582, Valid_loss 2.179251
Epoch 16, Train Loss 0.181759, Valid_loss 1.793045
Epoch 17, Train Loss 0.118858, Valid_loss 2.680647
Epoch 18, Train Loss 0.149083, Valid_loss 2.116312
Epoch 19, Train Loss 0.081833, Valid_loss 2.520728
Epoch 20, Train Loss 0.069490, Valid_loss 3.098448
Epoch 21, Train Loss 0.187978, Valid_loss 2.482089
Epoch 22, Train Loss 0.216569, Valid_loss 1.481176
Epoch 23, Train Loss 0.149999, Valid_loss 2.762186
Epoch 24, Train Loss 0.191087, Valid_loss 2.417206
Epoch 25, Train Loss 0.130890, Valid_loss 1.625048
Epoch 26, Train Loss 0.187837, Valid_loss 1.723152
Epoch 27, Train Loss 0.173009, Valid_loss 1.945774
Epoch 28, Train Loss 0.125541, Valid_loss 2.479448
Epoch 29, Train Loss 0.097678, Valid_loss 2.971612
Epoch 30, Train Loss 0.077263, Valid_loss 3.052164
Epoch 31, Train Loss 0.044061, Valid_loss 3.394424
Epoch 32, Train Loss 0.055854, Valid_loss 3.517923
Epoch 33, Train Loss 0.117248, Valid_loss 2.273340
Epoch 34, Train Loss 0.047123, Valid_loss 2.677413
Epoch 35, Train Loss 0.032557, Valid_loss 2.602262
Epoch 36, Train Loss 0.029022, Valid_loss 3.261018
Epoch 37, Train Loss 0.031440, Valid_loss 3.156067
Epoch 38, Train Loss 0.032483, Valid_loss 1.440632
Epoch 39, Train Loss 0.029558, Valid_loss 1.936765
Epoch 40, Train Loss 0.029454, Valid_loss 2.575159
Epoch 41, Train Loss 0.026844, Valid_loss 3.609778
Epoch 42, Train Loss 0.025438, Valid_loss 2.599132
Epoch 43, Train Loss 0.027199, Valid_loss 3.822188
Epoch 44, Train Loss 0.029615, Valid_loss 3.336337
Epoch 45, Train Loss 0.026008, Valid_loss 3.662174
Epoch 46, Train Loss 0.035222, Valid_loss 2.371226
Epoch 47, Train Loss 0.026172, Valid_loss 3.364623
Epoch 48, Train Loss 0.026577, Valid_loss 3.047212
Epoch 49, Train Loss 0.025264, Valid_loss 3.960724
Epoch 50, Train Loss 0.028181, Valid_loss 2.750543
Epoch 51, Train Loss 0.022238, Valid_loss 3.582861
Epoch 52, Train Loss 0.022000, Valid_loss 4.024549
[I 2025-08-27 02:22:18,973] Trial 0 finished with value: 0.9141680399400436 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 1, 'dropout': 0.0, 'weight_decay': 0.0001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.9141680399400436.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.941885, Valid_loss 2.234812
Epoch 2, Train Loss 0.941416, Valid_loss 1.685269
Epoch 3, Train Loss 0.897321, Valid_loss 1.711913
Epoch 4, Train Loss 0.880750, Valid_loss 2.068180
Epoch 5, Train Loss 0.885759, Valid_loss 1.732856
Epoch 6, Train Loss 0.863079, Valid_loss 1.570141
Epoch 7, Train Loss 0.895874, Valid_loss 1.596430
Epoch 8, Train Loss 0.876982, Valid_loss 1.518331
Epoch 9, Train Loss 0.890108, Valid_loss 1.571665
Epoch 10, Train Loss 0.871903, Valid_loss 1.771481
Epoch 11, Train Loss 0.875632, Valid_loss 1.558016
Epoch 12, Train Loss 0.876265, Valid_loss 1.720774
Epoch 13, Train Loss 0.876010, Valid_loss 1.658240
Epoch 14, Train Loss 0.869810, Valid_loss 1.754280
Epoch 15, Train Loss 0.856905, Valid_loss 1.815390
Epoch 16, Train Loss 0.867527, Valid_loss 1.720453
Epoch 17, Train Loss 0.855270, Valid_loss 1.828574
Epoch 18, Train Loss 0.871129, Valid_loss 1.769729
Epoch 19, Train Loss 0.852001, Valid_loss 1.747999
Epoch 20, Train Loss 0.849179, Valid_loss 1.684018
Epoch 21, Train Loss 0.861825, Valid_loss 1.729597
Epoch 22, Train Loss 0.858293, Valid_loss 1.828961
Epoch 23, Train Loss 0.856465, Valid_loss 1.877647
Epoch 24, Train Loss 0.857262, Valid_loss 1.893741
Epoch 25, Train Loss 0.855324, Valid_loss 1.974341
Epoch 26, Train Loss 0.854463, Valid_loss 1.947147
Epoch 27, Train Loss 0.863614, Valid_loss 1.920962
Epoch 28, Train Loss 0.857134, Valid_loss 1.933804
Epoch 29, Train Loss 0.854680, Valid_loss 1.956337
Epoch 30, Train Loss 0.856192, Valid_loss 1.960859
Epoch 31, Train Loss 0.855538, Valid_loss 1.961095
Epoch 32, Train Loss 0.858231, Valid_loss 1.944871
Epoch 33, Train Loss 0.855718, Valid_loss 1.948021
Epoch 34, Train Loss 0.853900, Valid_loss 1.950613
Epoch 35, Train Loss 0.853820, Valid_loss 1.966408
Epoch 36, Train Loss 0.875847, Valid_loss 1.944963
Epoch 37, Train Loss 0.858877, Valid_loss 1.955852
Epoch 38, Train Loss 0.853410, Valid_loss 1.958961
Epoch 39, Train Loss 0.855135, Valid_loss 1.941323
Epoch 40, Train Loss 0.855925, Valid_loss 1.985127
Epoch 41, Train Loss 0.854233, Valid_loss 1.951179
Epoch 42, Train Loss 0.854295, Valid_loss 1.952325
Epoch 43, Train Loss 0.856662, Valid_loss 1.955524
Epoch 44, Train Loss 0.857533, Valid_loss 2.032778
Epoch 45, Train Loss 0.862448, Valid_loss 1.933000
Epoch 46, Train Loss 0.855314, Valid_loss 1.952315
Epoch 47, Train Loss 0.855125, Valid_loss 1.950124
Epoch 48, Train Loss 0.855539, Valid_loss 1.995563
Epoch 49, Train Loss 0.856253, Valid_loss 1.986914
Epoch 50, Train Loss 0.854876, Valid_loss 1.934488
Epoch 51, Train Loss 0.853355, Valid_loss 1.934465
Epoch 52, Train Loss 0.852001, Valid_loss 1.956328
Epoch 53, Train Loss 0.852664, Valid_loss 1.949155
Epoch 54, Train Loss 0.852527, Valid_loss 1.948712
Epoch 55, Train Loss 0.854447, Valid_loss 1.946514
Epoch 56, Train Loss 0.852395, Valid_loss 1.948713
Epoch 57, Train Loss 0.852075, Valid_loss 1.954474
[I 2025-08-27 02:51:35,534] Trial 1 finished with value: 1.5183309750123457 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.9141680399400436.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.968781, Valid_loss 1.469773
Epoch 2, Train Loss 0.886725, Valid_loss 1.644469
Epoch 3, Train Loss 0.862178, Valid_loss 1.484883
Epoch 4, Train Loss 0.852327, Valid_loss 1.502160
Epoch 5, Train Loss 0.800882, Valid_loss 1.533537
Epoch 6, Train Loss 0.750005, Valid_loss 1.554666
Epoch 7, Train Loss 0.762492, Valid_loss 1.577070
Epoch 8, Train Loss 0.678277, Valid_loss 1.542961
Epoch 9, Train Loss 0.720603, Valid_loss 1.624798
Epoch 10, Train Loss 0.710355, Valid_loss 1.471813
Epoch 11, Train Loss 0.699166, Valid_loss 1.500835
Epoch 12, Train Loss 0.771748, Valid_loss 1.470424
Epoch 13, Train Loss 0.651938, Valid_loss 1.443537
Epoch 14, Train Loss 0.654626, Valid_loss 1.448318
Epoch 15, Train Loss 0.670396, Valid_loss 1.402037
Epoch 16, Train Loss 0.637376, Valid_loss 1.389202
Epoch 17, Train Loss 0.615476, Valid_loss 1.423076
Epoch 18, Train Loss 0.629538, Valid_loss 1.531035
Epoch 19, Train Loss 0.634703, Valid_loss 1.348406
Epoch 20, Train Loss 0.585448, Valid_loss 1.373895
Epoch 21, Train Loss 0.604907, Valid_loss 1.321547
Epoch 22, Train Loss 0.612413, Valid_loss 1.344015
Epoch 23, Train Loss 0.599928, Valid_loss 1.331245
Epoch 24, Train Loss 0.554458, Valid_loss 1.416990
Epoch 25, Train Loss 0.603392, Valid_loss 1.318086
Epoch 26, Train Loss 0.566255, Valid_loss 1.388757
Epoch 27, Train Loss 0.585682, Valid_loss 1.304596
Epoch 28, Train Loss 0.617833, Valid_loss 1.319964
Epoch 29, Train Loss 0.620527, Valid_loss 1.300028
Epoch 30, Train Loss 0.550697, Valid_loss 1.328490
Epoch 31, Train Loss 0.535332, Valid_loss 1.376728
Epoch 32, Train Loss 0.530882, Valid_loss 1.273887
Epoch 33, Train Loss 0.575805, Valid_loss 1.276014
Epoch 34, Train Loss 0.512043, Valid_loss 1.355999
Epoch 35, Train Loss 0.553494, Valid_loss 1.557504
Epoch 36, Train Loss 0.499354, Valid_loss 1.315508
Epoch 37, Train Loss 0.670350, Valid_loss 1.323054
Epoch 38, Train Loss 0.564334, Valid_loss 2.175113
Epoch 39, Train Loss 0.642262, Valid_loss 2.245966
Epoch 40, Train Loss 0.541918, Valid_loss 1.321076
Epoch 41, Train Loss 0.424970, Valid_loss 1.300183
Epoch 42, Train Loss 0.560978, Valid_loss 1.677461
Epoch 43, Train Loss 0.579464, Valid_loss 1.306650
Epoch 44, Train Loss 0.527723, Valid_loss 1.424934
Epoch 45, Train Loss 0.461857, Valid_loss 1.338102
Epoch 46, Train Loss 0.394983, Valid_loss 1.457831
Epoch 47, Train Loss 0.556972, Valid_loss 1.300286
Epoch 48, Train Loss 0.523122, Valid_loss 1.289686
Epoch 49, Train Loss 0.488557, Valid_loss 1.479577
Epoch 50, Train Loss 0.530410, Valid_loss 1.415975
Epoch 51, Train Loss 0.475708, Valid_loss 1.262676
Epoch 52, Train Loss 0.508131, Valid_loss 1.468475
Epoch 53, Train Loss 0.563575, Valid_loss 1.377744
Epoch 54, Train Loss 0.508951, Valid_loss 1.662159
Epoch 55, Train Loss 0.425326, Valid_loss 1.614939
Epoch 56, Train Loss 0.424303, Valid_loss 1.519783
Epoch 57, Train Loss 0.458320, Valid_loss 1.473069
Epoch 58, Train Loss 0.490663, Valid_loss 1.740005
Epoch 59, Train Loss 0.397319, Valid_loss 1.514271
Epoch 60, Train Loss 0.507908, Valid_loss 1.409225
Epoch 61, Train Loss 0.446520, Valid_loss 1.569743
Epoch 62, Train Loss 0.437060, Valid_loss 1.682244
[I 2025-08-27 03:23:22,302] Trial 2 finished with value: 1.2626756375486201 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.7, 'weight_decay': 0.001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.9141680399400436.
선택된 trial params: {'learning_rate': 0.001, 'epochs': 100, 'heads': 1, 'dropout': 0.0, 'weight_decay': 0.0001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=9, batch_size=1 -> steps=9
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.878001, Valid_loss 2.211029
Epoch 2, Train Loss 0.689646, Valid_loss 1.592002
Epoch 3, Train Loss 0.559601, Valid_loss 1.395708
Epoch 4, Train Loss 0.452619, Valid_loss 1.374021
Epoch 5, Train Loss 0.316456, Valid_loss 1.566382
Epoch 6, Train Loss 0.399080, Valid_loss 1.353800
Epoch 7, Train Loss 0.355403, Valid_loss 1.613201
Epoch 8, Train Loss 0.301060, Valid_loss 1.397555
Epoch 9, Train Loss 0.292483, Valid_loss 1.677974
Epoch 10, Train Loss 0.366947, Valid_loss 1.096703
Epoch 11, Train Loss 0.273705, Valid_loss 1.294349
Epoch 12, Train Loss 0.324611, Valid_loss 1.840316
Epoch 13, Train Loss 0.258627, Valid_loss 1.612709
Epoch 14, Train Loss 0.276148, Valid_loss 1.482690
Epoch 15, Train Loss 0.224486, Valid_loss 1.478567
Epoch 16, Train Loss 0.216826, Valid_loss 1.637729
Epoch 17, Train Loss 0.182800, Valid_loss 1.761360
Epoch 18, Train Loss 0.150605, Valid_loss 2.083834
Epoch 19, Train Loss 0.096246, Valid_loss 2.603482
Epoch 20, Train Loss 0.116997, Valid_loss 2.766511
Epoch 21, Train Loss 0.113146, Valid_loss 2.367171
Epoch 22, Train Loss 0.069293, Valid_loss 2.753240
Epoch 23, Train Loss 0.076578, Valid_loss 2.840682
Epoch 24, Train Loss 0.080070, Valid_loss 3.025734
Epoch 25, Train Loss 0.080194, Valid_loss 2.259190
Epoch 26, Train Loss 0.073448, Valid_loss 3.215845
Epoch 27, Train Loss 0.058704, Valid_loss 3.164243
Epoch 28, Train Loss 0.082209, Valid_loss 3.555164
Epoch 29, Train Loss 0.055297, Valid_loss 3.810811
Epoch 30, Train Loss 0.140029, Valid_loss 2.974987
Epoch 31, Train Loss 0.150863, Valid_loss 3.068089
Epoch 32, Train Loss 0.053184, Valid_loss 3.277106
Epoch 33, Train Loss 0.056794, Valid_loss 3.216118
Epoch 34, Train Loss 0.068832, Valid_loss 2.983035
Epoch 35, Train Loss 0.070384, Valid_loss 3.525258
Epoch 36, Train Loss 0.066670, Valid_loss 3.603975
Epoch 37, Train Loss 0.065913, Valid_loss 3.686283
Epoch 38, Train Loss 0.064622, Valid_loss 3.742937
Epoch 39, Train Loss 0.064429, Valid_loss 3.835602
Epoch 40, Train Loss 0.067121, Valid_loss 3.827932
Epoch 41, Train Loss 0.063041, Valid_loss 3.896306
Epoch 42, Train Loss 0.065867, Valid_loss 3.929780
Epoch 43, Train Loss 0.064513, Valid_loss 3.986940
Epoch 44, Train Loss 0.064674, Valid_loss 4.043541
Epoch 45, Train Loss 0.066014, Valid_loss 4.039641
Epoch 46, Train Loss 0.062834, Valid_loss 4.055832
Epoch 47, Train Loss 0.067741, Valid_loss 4.108909
Epoch 48, Train Loss 0.063797, Valid_loss 4.159057
Epoch 49, Train Loss 0.063946, Valid_loss 4.239108
Epoch 50, Train Loss 0.058261, Valid_loss 4.329612
Epoch 51, Train Loss 0.077974, Valid_loss 2.507381
Epoch 52, Train Loss 0.069114, Valid_loss 4.000757
Epoch 53, Train Loss 0.061733, Valid_loss 3.950677
Epoch 54, Train Loss 0.048048, Valid_loss 4.004282
Epoch 55, Train Loss 0.047531, Valid_loss 4.031451
환자ID=P1422 -- true: [[1]] -- pred: tensor([[-2.4268,  1.4155, -0.2130]], device='cuda:0')
환자ID=P1437 -- true: [[2]] -- pred: tensor([[-2.5207,  1.4753, -0.2346]], device='cuda:0')
환자ID=P1447 -- true: [[1]] -- pred: tensor([[-2.5826,  1.5173, -0.4063]], device='cuda:0')
환자ID=P1472 -- true: [[2]] -- pred: tensor([[-2.5865,  1.5218, -0.2911]], device='cuda:0')
환자ID=P1561 -- true: [[0]] -- pred: tensor([[ 2.5223, -1.1855, -3.6869]], device='cuda:0')
환자ID=P1603 -- true: [[0]] -- pred: tensor([[ 2.5337, -1.2185, -3.6841]], device='cuda:0')
환자ID=P1622 -- true: [[0]] -- pred: tensor([[ 2.5138, -1.1719, -3.6853]], device='cuda:0')
환자ID=P1702 -- true: [[0]] -- pred: tensor([[ 2.5273, -1.2309, -3.6654]], device='cuda:0')
환자ID=P1726 -- true: [[1]] -- pred: tensor([[-2.5785,  1.5164, -0.2773]], device='cuda:0')
Best performance: Epoch 10, Loss 0.366947, Test ACC 0.777778, Test AUC 0.833333, Test Recall 0.666667, Test Precision 0.533333
Confusion Matrix:
 [[4 0 0]
 [0 3 0]
 [0 2 0]]
✅ Total valid splits used: 1
🔁 Repeat 0, Fold 1
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 459330, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 459330, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 8, 1: 12, 0: 13}
cell type :  CAACCAAAGACCCGCT-1-2          cardiac muscle cell
ACGGTTACATCGAACT-1-2          cardiac muscle cell
ACCCTCATCCGGCAGT-1-2          cardiac muscle cell
AACACACCACGGTCTG-1-2          cardiac muscle cell
AAACGCTTCACCGGGT-1-2          cardiac muscle cell
                                   ...           
TCATTGTCATACAGGG-1-70    cardiac endothelial cell
TCGTGCTTCTTGCGCT-1-70    cardiac endothelial cell
GACCAATAGGTCGTCC-1-70    cardiac endothelial cell
GAAGGGTTCAGGTAAA-1-70    cardiac endothelial cell
GGGTAGAAGTAGTCTC-1-70    cardiac endothelial cell
Name: manual_annotation, Length: 133359, dtype: string
cell type annotation :  CAACCAAAGACCCGCT-1-2          cardiac muscle cell
ACGGTTACATCGAACT-1-2          cardiac muscle cell
ACCCTCATCCGGCAGT-1-2          cardiac muscle cell
AACACACCACGGTCTG-1-2          cardiac muscle cell
AAACGCTTCACCGGGT-1-2          cardiac muscle cell
                                   ...           
TCATTGTCATACAGGG-1-70    cardiac endothelial cell
TCGTGCTTCTTGCGCT-1-70    cardiac endothelial cell
GACCAATAGGTCGTCC-1-70    cardiac endothelial cell
GAAGGGTTCAGGTAAA-1-70    cardiac endothelial cell
GGGTAGAAGTAGTCTC-1-70    cardiac endothelial cell
Name: manual_annotation, Length: 133359, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'vascular associated smooth muscle cell', 'macrophage', 'endocardial cell', 'endothelial cell of lymphatic vessel', 'cardiac endothelial cell', 'cardiac ventricle fibroblast', 'pericyte cell', 'cardiac neuron', 'lymphocyte', 'mast cell', 'mesothelial cell']
라벨별 그룹 개수 {2: 3, 1: 3, 0: 3}
🔍 Split #2
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 33
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 9
  → train 환자 ID: ['P1290', 'P1300', 'P1358', 'P1422', 'P1425', 'P1430', 'P1437', 'P1447', 'P1472', 'P1479', 'P1508', 'P1510', 'P1516', 'P1539', 'P1540', 'P1547', 'P1561', 'P1582', 'P1600', 'P1602', 'P1603', 'P1606', 'P1610', 'P1617', 'P1622', 'P1630', 'P1631', 'P1678', 'P1702', 'P1707', 'P1718', 'P1726', 'P1735']
  → test  환자 ID: ['P1304', 'P1371', 'P1462', 'P1504', 'P1515', 'P1549', 'P1558', 'P1685', 'P1722']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1358, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1304, Label: 2
    ID: P1371, Label: 2
    ID: P1462, Label: 1
    ID: P1504, Label: 2
    ID: P1515, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1685, Label: 1
    ID: P1722, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 33
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 33
기존 (train) label_stat 33
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 11
test_p_index 9
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1547, Label=0, 셀개수=8253
→ valid 환자 ID 및 라벨:
   총 개수: 11
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1622, Label=0, 셀개수=7210
→ test 환자 ID 및 라벨:
   총 개수: 9
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1722, Label=1, 셀개수=21432
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0              cardiac muscle cell
1              cardiac muscle cell
2              cardiac muscle cell
3              cardiac muscle cell
4              cardiac muscle cell
                    ...           
592684    cardiac endothelial cell
592685    cardiac endothelial cell
592686    cardiac endothelial cell
592687    cardiac endothelial cell
592688    cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:10,  9.03it/s]  2%|▏         | 2/100 [00:00<00:11,  8.81it/s]  3%|▎         | 3/100 [00:00<00:11,  8.75it/s]  4%|▍         | 4/100 [00:00<00:11,  8.49it/s]  5%|▌         | 5/100 [00:00<00:11,  8.55it/s]  6%|▌         | 6/100 [00:00<00:11,  8.47it/s]  7%|▋         | 7/100 [00:00<00:11,  8.36it/s]  8%|▊         | 8/100 [00:00<00:10,  8.45it/s]  9%|▉         | 9/100 [00:01<00:10,  8.47it/s] 10%|█         | 10/100 [00:01<00:10,  8.42it/s] 11%|█         | 11/100 [00:01<00:10,  8.63it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.67it/s] 13%|█▎        | 13/100 [00:01<00:10,  8.65it/s] 14%|█▍        | 14/100 [00:01<00:09,  8.68it/s] 15%|█▌        | 15/100 [00:01<00:09,  8.65it/s] 16%|█▌        | 16/100 [00:01<00:09,  8.73it/s] 17%|█▋        | 17/100 [00:01<00:09,  8.72it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.53it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.57it/s] 20%|██        | 20/100 [00:02<00:09,  8.50it/s] 21%|██        | 21/100 [00:02<00:09,  8.56it/s] 22%|██▏       | 22/100 [00:02<00:09,  8.48it/s] 23%|██▎       | 23/100 [00:02<00:08,  8.64it/s] 24%|██▍       | 24/100 [00:02<00:08,  8.76it/s] 25%|██▌       | 25/100 [00:02<00:08,  8.60it/s] 26%|██▌       | 26/100 [00:03<00:08,  8.63it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.57it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.61it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.60it/s] 30%|███       | 30/100 [00:03<00:08,  8.56it/s] 31%|███       | 31/100 [00:03<00:08,  8.52it/s] 32%|███▏      | 32/100 [00:03<00:08,  8.47it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.50it/s] 34%|███▍      | 34/100 [00:03<00:07,  8.47it/s] 35%|███▌      | 35/100 [00:04<00:07,  8.52it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.61it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.66it/s] 38%|███▊      | 38/100 [00:04<00:06,  8.91it/s] 39%|███▉      | 39/100 [00:04<00:06,  8.80it/s] 40%|████      | 40/100 [00:04<00:06,  8.69it/s] 41%|████      | 41/100 [00:04<00:06,  8.54it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.64it/s] 43%|████▎     | 43/100 [00:05<00:06,  8.41it/s] 44%|████▍     | 44/100 [00:05<00:06,  8.35it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.23it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.30it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.28it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.39it/s] 49%|████▉     | 49/100 [00:05<00:06,  8.37it/s] 50%|█████     | 50/100 [00:05<00:05,  8.35it/s] 51%|█████     | 51/100 [00:05<00:05,  8.39it/s] 52%|█████▏    | 52/100 [00:06<00:05,  8.49it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.56it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.44it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.53it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.43it/s] 57%|█████▋    | 57/100 [00:06<00:05,  8.42it/s] 58%|█████▊    | 58/100 [00:06<00:05,  8.33it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.35it/s] 60%|██████    | 60/100 [00:07<00:04,  8.28it/s] 61%|██████    | 61/100 [00:07<00:04,  8.31it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.29it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.27it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.34it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.31it/s] 66%|██████▌   | 66/100 [00:07<00:04,  8.24it/s] 67%|██████▋   | 67/100 [00:07<00:04,  8.11it/s] 68%|██████▊   | 68/100 [00:08<00:03,  8.24it/s] 69%|██████▉   | 69/100 [00:08<00:03,  8.22it/s] 70%|███████   | 70/100 [00:08<00:03,  8.23it/s] 71%|███████   | 71/100 [00:08<00:03,  8.14it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.10it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.18it/s] 74%|███████▍  | 74/100 [00:08<00:03,  8.25it/s] 75%|███████▌  | 75/100 [00:08<00:02,  8.46it/s] 76%|███████▌  | 76/100 [00:08<00:02,  8.42it/s] 77%|███████▋  | 77/100 [00:09<00:02,  8.32it/s] 78%|███████▊  | 78/100 [00:09<00:02,  8.32it/s] 79%|███████▉  | 79/100 [00:09<00:02,  8.37it/s] 80%|████████  | 80/100 [00:09<00:02,  8.42it/s] 81%|████████  | 81/100 [00:09<00:02,  8.10it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.13it/s] 83%|████████▎ | 83/100 [00:09<00:02,  7.99it/s] 84%|████████▍ | 84/100 [00:09<00:01,  8.14it/s] 85%|████████▌ | 85/100 [00:10<00:01,  8.15it/s] 86%|████████▌ | 86/100 [00:10<00:01,  8.13it/s] 87%|████████▋ | 87/100 [00:10<00:01,  8.10it/s] 88%|████████▊ | 88/100 [00:10<00:01,  8.11it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.13it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.13it/s] 91%|█████████ | 91/100 [00:10<00:01,  8.00it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.21it/s] 93%|█████████▎| 93/100 [00:11<00:00,  8.31it/s] 94%|█████████▍| 94/100 [00:11<00:00,  8.51it/s] 95%|█████████▌| 95/100 [00:11<00:00,  8.48it/s] 96%|█████████▌| 96/100 [00:11<00:00,  8.42it/s] 97%|█████████▋| 97/100 [00:11<00:00,  8.41it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.36it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.31it/s]100%|██████████| 100/100 [00:11<00:00,  8.26it/s]100%|██████████| 100/100 [00:11<00:00,  8.41it/s]
[I 2025-08-27 03:44:26,700] A new study created in memory with name: no-name-e8bc1bff-91e7-4f9b-a7be-67159dbc058d
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.025042, Valid_loss 1.390969
Epoch 2, Train Loss 0.939906, Valid_loss 1.499227
Epoch 3, Train Loss 0.958317, Valid_loss 1.378267
Epoch 4, Train Loss 0.943342, Valid_loss 1.296963
Epoch 5, Train Loss 0.898003, Valid_loss 1.238750
Epoch 6, Train Loss 0.885262, Valid_loss 1.295308
Epoch 7, Train Loss 0.876236, Valid_loss 1.403351
Epoch 8, Train Loss 0.875658, Valid_loss 1.527724
Epoch 9, Train Loss 0.883655, Valid_loss 1.360342
Epoch 10, Train Loss 0.889071, Valid_loss 1.247944
Epoch 11, Train Loss 0.880851, Valid_loss 1.222250
Epoch 12, Train Loss 0.880755, Valid_loss 1.322030
Epoch 13, Train Loss 0.869043, Valid_loss 1.255296
Epoch 14, Train Loss 0.861801, Valid_loss 2.077660
Epoch 15, Train Loss 0.871262, Valid_loss 1.261207
Epoch 16, Train Loss 0.862467, Valid_loss 1.319413
Epoch 17, Train Loss 0.852652, Valid_loss 1.302817
Epoch 18, Train Loss 0.849041, Valid_loss 1.344716
Epoch 19, Train Loss 0.861424, Valid_loss 1.229617
Epoch 20, Train Loss 0.859791, Valid_loss 1.292951
Epoch 21, Train Loss 0.856477, Valid_loss 1.277753
Epoch 22, Train Loss 0.856017, Valid_loss 1.291203
Epoch 23, Train Loss 0.850890, Valid_loss 1.312917
Epoch 24, Train Loss 0.850212, Valid_loss 1.345581
Epoch 25, Train Loss 0.868285, Valid_loss 1.292636
Epoch 26, Train Loss 0.853957, Valid_loss 1.289843
Epoch 27, Train Loss 0.850451, Valid_loss 1.335635
Epoch 28, Train Loss 0.855546, Valid_loss 1.310027
Epoch 29, Train Loss 0.851976, Valid_loss 1.324615
Epoch 30, Train Loss 0.854902, Valid_loss 1.318031
Epoch 31, Train Loss 0.848603, Valid_loss 1.350951
Epoch 32, Train Loss 0.854057, Valid_loss 1.323346
Epoch 33, Train Loss 0.854118, Valid_loss 1.331660
Epoch 34, Train Loss 0.853916, Valid_loss 1.324348
Epoch 35, Train Loss 0.852488, Valid_loss 1.325360
Epoch 36, Train Loss 0.850484, Valid_loss 1.322755
Epoch 37, Train Loss 0.853015, Valid_loss 1.334943
Epoch 38, Train Loss 0.851209, Valid_loss 1.345810
Epoch 39, Train Loss 0.854481, Valid_loss 1.323750
Epoch 40, Train Loss 0.868973, Valid_loss 1.332213
Epoch 41, Train Loss 0.852329, Valid_loss 1.329309
Epoch 42, Train Loss 0.851755, Valid_loss 1.339446
Epoch 43, Train Loss 0.851471, Valid_loss 1.332762
Epoch 44, Train Loss 0.851728, Valid_loss 1.343703
Epoch 45, Train Loss 0.852641, Valid_loss 1.341352
Epoch 46, Train Loss 0.853119, Valid_loss 1.339768
Epoch 47, Train Loss 0.850918, Valid_loss 1.335495
Epoch 48, Train Loss 0.854488, Valid_loss 1.343079
Epoch 49, Train Loss 0.851232, Valid_loss 1.355737
Epoch 50, Train Loss 0.850594, Valid_loss 1.345215
Epoch 51, Train Loss 0.848546, Valid_loss 1.349180
Epoch 52, Train Loss 0.849819, Valid_loss 1.342996
Epoch 53, Train Loss 0.849199, Valid_loss 1.342187
Epoch 54, Train Loss 0.848358, Valid_loss 1.448954
Epoch 55, Train Loss 0.871619, Valid_loss 1.336216
Epoch 56, Train Loss 0.849153, Valid_loss 1.336033
Epoch 57, Train Loss 0.848598, Valid_loss 1.339974
Epoch 58, Train Loss 0.849534, Valid_loss 1.339547
Epoch 59, Train Loss 0.848987, Valid_loss 1.347444
Epoch 60, Train Loss 0.848682, Valid_loss 1.341172
Epoch 61, Train Loss 0.849683, Valid_loss 1.340425
Epoch 62, Train Loss 0.849270, Valid_loss 1.342030
Epoch 63, Train Loss 0.848917, Valid_loss 1.349252
[I 2025-08-27 04:10:27,855] Trial 0 finished with value: 1.2222498926249417 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 1.2222498926249417.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.983010, Valid_loss 1.207688
Epoch 2, Train Loss 0.882153, Valid_loss 1.373330
Epoch 3, Train Loss 0.859104, Valid_loss 1.449844
Epoch 4, Train Loss 0.933415, Valid_loss 1.198085
Epoch 5, Train Loss 0.867861, Valid_loss 1.203137
Epoch 6, Train Loss 0.850710, Valid_loss 1.239629
Epoch 7, Train Loss 0.860778, Valid_loss 1.238317
Epoch 8, Train Loss 0.864685, Valid_loss 1.264293
Epoch 9, Train Loss 0.858176, Valid_loss 1.240207
Epoch 10, Train Loss 0.856166, Valid_loss 1.262195
Epoch 11, Train Loss 0.853710, Valid_loss 1.291302
Epoch 12, Train Loss 0.852818, Valid_loss 1.310108
Epoch 13, Train Loss 0.851648, Valid_loss 1.322325
Epoch 14, Train Loss 0.850525, Valid_loss 1.329262
Epoch 15, Train Loss 0.854425, Valid_loss 1.338185
Epoch 16, Train Loss 0.852323, Valid_loss 1.347745
Epoch 17, Train Loss 0.853472, Valid_loss 1.357798
Epoch 18, Train Loss 0.851924, Valid_loss 1.342853
Epoch 19, Train Loss 0.852391, Valid_loss 1.336513
Epoch 20, Train Loss 0.853617, Valid_loss 1.347203
Epoch 21, Train Loss 0.850138, Valid_loss 1.352323
Epoch 22, Train Loss 0.851037, Valid_loss 1.360186
Epoch 23, Train Loss 0.852702, Valid_loss 1.351118
Epoch 24, Train Loss 0.850571, Valid_loss 1.341342
Epoch 25, Train Loss 0.851033, Valid_loss 1.347782
Epoch 26, Train Loss 0.852346, Valid_loss 1.345216
Epoch 27, Train Loss 0.850663, Valid_loss 1.341118
Epoch 28, Train Loss 0.851164, Valid_loss 1.353071
Epoch 29, Train Loss 0.851482, Valid_loss 1.341928
Epoch 30, Train Loss 0.850943, Valid_loss 1.341515
Epoch 31, Train Loss 0.853252, Valid_loss 1.353419
Epoch 32, Train Loss 0.870386, Valid_loss 1.436977
Epoch 33, Train Loss 0.863561, Valid_loss 1.321548
Epoch 34, Train Loss 0.851658, Valid_loss 1.340389
Epoch 35, Train Loss 0.850172, Valid_loss 1.339242
Epoch 36, Train Loss 0.852175, Valid_loss 1.341406
Epoch 37, Train Loss 0.852204, Valid_loss 1.348381
Epoch 38, Train Loss 0.850398, Valid_loss 1.343196
Epoch 39, Train Loss 0.851590, Valid_loss 1.361916
Epoch 40, Train Loss 0.851068, Valid_loss 1.343711
Epoch 41, Train Loss 0.851797, Valid_loss 1.345440
Epoch 42, Train Loss 0.851610, Valid_loss 1.341349
Epoch 43, Train Loss 0.850418, Valid_loss 1.343284
Epoch 44, Train Loss 0.850168, Valid_loss 1.342973
Epoch 45, Train Loss 0.854895, Valid_loss 1.341985
Epoch 46, Train Loss 0.850446, Valid_loss 1.351966
Epoch 47, Train Loss 0.851554, Valid_loss 1.345871
Epoch 48, Train Loss 0.852318, Valid_loss 1.355318
Epoch 49, Train Loss 0.849905, Valid_loss 1.347018
Epoch 50, Train Loss 0.850906, Valid_loss 1.346044
Epoch 51, Train Loss 0.850072, Valid_loss 1.346025
Epoch 52, Train Loss 0.849223, Valid_loss 1.350440
Epoch 53, Train Loss 0.850916, Valid_loss 1.343757
Epoch 54, Train Loss 0.849086, Valid_loss 1.348572
Epoch 55, Train Loss 0.844110, Valid_loss 1.387477
[I 2025-08-27 04:42:47,258] Trial 1 finished with value: 1.1980847337029197 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 1.1980847337029197.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.986819, Valid_loss 1.250096
Epoch 2, Train Loss 0.867342, Valid_loss 1.537155
Epoch 3, Train Loss 0.902931, Valid_loss 1.447553
Epoch 4, Train Loss 0.893342, Valid_loss 1.264077
Epoch 5, Train Loss 0.853734, Valid_loss 1.361907
Epoch 6, Train Loss 0.890872, Valid_loss 1.312111
Epoch 7, Train Loss 0.867771, Valid_loss 1.202568
Epoch 8, Train Loss 0.878270, Valid_loss 1.198494
Epoch 9, Train Loss 0.852035, Valid_loss 1.183287
Epoch 10, Train Loss 0.873506, Valid_loss 1.153143
Epoch 11, Train Loss 0.860621, Valid_loss 1.133982
Epoch 12, Train Loss 0.852130, Valid_loss 1.119689
Epoch 13, Train Loss 0.880799, Valid_loss 1.180590
Epoch 14, Train Loss 0.843159, Valid_loss 1.229070
Epoch 15, Train Loss 0.864681, Valid_loss 1.139579
Epoch 16, Train Loss 0.830754, Valid_loss 1.145439
Epoch 17, Train Loss 0.850158, Valid_loss 1.125774
Epoch 18, Train Loss 0.849462, Valid_loss 1.135275
Epoch 19, Train Loss 0.839816, Valid_loss 1.141895
Epoch 20, Train Loss 0.864865, Valid_loss 1.206938
Epoch 21, Train Loss 0.842891, Valid_loss 1.144952
Epoch 22, Train Loss 0.852679, Valid_loss 1.142169
Epoch 23, Train Loss 0.843609, Valid_loss 1.145233
Epoch 24, Train Loss 0.810370, Valid_loss 1.154017
Epoch 25, Train Loss 0.852001, Valid_loss 1.137116
Epoch 26, Train Loss 0.830997, Valid_loss 1.133185
Epoch 27, Train Loss 0.841472, Valid_loss 1.128162
Epoch 28, Train Loss 0.855795, Valid_loss 1.156658
Epoch 29, Train Loss 0.847138, Valid_loss 1.164316
Epoch 30, Train Loss 0.842038, Valid_loss 1.157633
Epoch 31, Train Loss 0.845512, Valid_loss 1.163029
Epoch 32, Train Loss 0.825307, Valid_loss 1.147169
Epoch 33, Train Loss 0.839541, Valid_loss 1.144818
Epoch 34, Train Loss 0.852021, Valid_loss 1.162557
Epoch 35, Train Loss 0.850958, Valid_loss 1.160958
Epoch 36, Train Loss 0.890755, Valid_loss 1.437036
Epoch 37, Train Loss 0.873610, Valid_loss 1.258090
Epoch 38, Train Loss 0.856488, Valid_loss 1.244705
Epoch 39, Train Loss 0.851613, Valid_loss 1.217545
Epoch 40, Train Loss 0.843618, Valid_loss 1.239216
Epoch 41, Train Loss 0.861208, Valid_loss 1.230704
Epoch 42, Train Loss 0.859764, Valid_loss 1.235929
Epoch 43, Train Loss 0.851530, Valid_loss 1.261963
Epoch 44, Train Loss 0.843532, Valid_loss 1.261405
Epoch 45, Train Loss 0.840860, Valid_loss 1.253193
Epoch 46, Train Loss 0.847603, Valid_loss 1.255512
Epoch 47, Train Loss 0.839824, Valid_loss 1.255537
Epoch 48, Train Loss 0.854081, Valid_loss 1.283104
Epoch 49, Train Loss 0.856176, Valid_loss 1.309482
Epoch 50, Train Loss 0.852578, Valid_loss 1.325964
Epoch 51, Train Loss 0.849784, Valid_loss 1.329704
Epoch 52, Train Loss 0.849623, Valid_loss 1.324509
Epoch 53, Train Loss 0.848795, Valid_loss 1.334516
Epoch 54, Train Loss 0.849959, Valid_loss 1.327651
Epoch 55, Train Loss 0.849516, Valid_loss 1.330045
Epoch 56, Train Loss 0.848545, Valid_loss 1.339725
[I 2025-08-27 05:15:56,669] Trial 2 finished with value: 1.119689491662112 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 1.119689491662112.
선택된 trial params: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=9, batch_size=1 -> steps=9
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.991060, Valid_loss 1.147982
Epoch 2, Train Loss 0.926633, Valid_loss 1.188329
Epoch 3, Train Loss 0.892473, Valid_loss 1.341549
Epoch 4, Train Loss 0.867471, Valid_loss 1.455108
Epoch 5, Train Loss 0.881808, Valid_loss 1.358373
Epoch 6, Train Loss 0.868832, Valid_loss 1.294548
Epoch 7, Train Loss 0.853591, Valid_loss 1.325462
Epoch 8, Train Loss 0.882376, Valid_loss 1.133305
Epoch 9, Train Loss 0.864410, Valid_loss 1.320884
Epoch 10, Train Loss 0.876976, Valid_loss 1.213873
Epoch 11, Train Loss 0.858074, Valid_loss 1.218696
Epoch 12, Train Loss 0.894143, Valid_loss 1.227031
Epoch 13, Train Loss 0.850076, Valid_loss 1.204691
Epoch 14, Train Loss 0.853290, Valid_loss 1.219985
Epoch 15, Train Loss 0.835750, Valid_loss 1.386988
Epoch 16, Train Loss 0.857146, Valid_loss 1.156422
Epoch 17, Train Loss 0.880158, Valid_loss 1.184618
Epoch 18, Train Loss 0.855112, Valid_loss 1.268344
Epoch 19, Train Loss 0.851962, Valid_loss 1.222260
Epoch 20, Train Loss 0.833426, Valid_loss 1.219266
Epoch 21, Train Loss 0.844527, Valid_loss 1.252923
Epoch 22, Train Loss 0.858161, Valid_loss 1.256111
Epoch 23, Train Loss 0.871880, Valid_loss 1.235722
Epoch 24, Train Loss 0.865182, Valid_loss 1.268078
Epoch 25, Train Loss 0.852681, Valid_loss 1.285809
Epoch 26, Train Loss 0.852716, Valid_loss 1.295557
Epoch 27, Train Loss 0.850196, Valid_loss 1.300678
Epoch 28, Train Loss 0.849485, Valid_loss 1.329082
Epoch 29, Train Loss 0.840736, Valid_loss 1.287013
Epoch 30, Train Loss 0.855686, Valid_loss 1.316460
Epoch 31, Train Loss 0.852701, Valid_loss 1.331984
Epoch 32, Train Loss 0.852444, Valid_loss 1.342556
Epoch 33, Train Loss 0.849978, Valid_loss 1.331439
Epoch 34, Train Loss 0.851635, Valid_loss 1.339902
Epoch 35, Train Loss 0.850635, Valid_loss 1.346042
Epoch 36, Train Loss 0.851286, Valid_loss 1.348118
Epoch 37, Train Loss 0.850995, Valid_loss 1.340938
Epoch 38, Train Loss 0.849855, Valid_loss 1.344710
Epoch 39, Train Loss 0.850807, Valid_loss 1.344034
Epoch 40, Train Loss 0.854021, Valid_loss 1.346289
Epoch 41, Train Loss 0.851898, Valid_loss 1.359413
Epoch 42, Train Loss 0.852337, Valid_loss 1.337690
Epoch 43, Train Loss 0.853673, Valid_loss 1.350221
Epoch 44, Train Loss 0.853676, Valid_loss 1.346872
Epoch 45, Train Loss 0.852209, Valid_loss 1.346560
Epoch 46, Train Loss 0.849559, Valid_loss 1.354990
Epoch 47, Train Loss 0.851953, Valid_loss 1.352991
Epoch 48, Train Loss 0.854464, Valid_loss 1.346687
Epoch 49, Train Loss 0.853781, Valid_loss 1.340208
Epoch 50, Train Loss 0.849957, Valid_loss 1.332337
Epoch 51, Train Loss 0.850027, Valid_loss 1.338062
Epoch 52, Train Loss 0.848552, Valid_loss 1.339287
환자ID=P1304 -- true: [[2]] -- pred: tensor([[ 0.2755,  0.0677, -0.7764]], device='cuda:0')
환자ID=P1371 -- true: [[2]] -- pred: tensor([[ 0.2755,  0.0677, -0.7764]], device='cuda:0')
환자ID=P1462 -- true: [[1]] -- pred: tensor([[ 0.2755,  0.0677, -0.7764]], device='cuda:0')
환자ID=P1504 -- true: [[2]] -- pred: tensor([[ 0.2755,  0.0677, -0.7764]], device='cuda:0')
환자ID=P1515 -- true: [[0]] -- pred: tensor([[ 0.2755,  0.0677, -0.7764]], device='cuda:0')
환자ID=P1549 -- true: [[0]] -- pred: tensor([[ 0.2755,  0.0677, -0.7764]], device='cuda:0')
환자ID=P1558 -- true: [[0]] -- pred: tensor([[ 0.2755,  0.0677, -0.7764]], device='cuda:0')
환자ID=P1685 -- true: [[1]] -- pred: tensor([[ 0.2755,  0.0677, -0.7764]], device='cuda:0')
환자ID=P1722 -- true: [[1]] -- pred: tensor([[ 0.2755,  0.0677, -0.7764]], device='cuda:0')
Best performance: Epoch 8, Loss 0.882376, Test ACC 0.333333, Test AUC 0.592593, Test Recall 0.333333, Test Precision 0.111111
Confusion Matrix:
 [[3 0 0]
 [3 0 0]
 [3 0 0]]
✅ Total valid splits used: 2
🔁 Repeat 0, Fold 2
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 494461, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 494461, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  AGTTCCCTCTAGCCTC-1-5              cardiac muscle cell
CCTCAACTCCTCTGCA-1-5              cardiac muscle cell
CCATCACGTCCGACGT-1-5              cardiac muscle cell
GACCAATAGCTAATCC-1-5              cardiac muscle cell
CACGGGTTCTTGGTCC-1-5              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 98228, dtype: string
cell type annotation :  AGTTCCCTCTAGCCTC-1-5              cardiac muscle cell
CCTCAACTCCTCTGCA-1-5              cardiac muscle cell
CCATCACGTCCGACGT-1-5              cardiac muscle cell
GACCAATAGCTAATCC-1-5              cardiac muscle cell
CACGGGTTCTTGGTCC-1-5              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 98228, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'macrophage', 'fat cell', 'cardiac ventricle fibroblast', 'cardiac neuron', 'endocardial cell', 'endothelial cell of lymphatic vessel', 'cardiac endothelial cell', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 3}
🔍 Split #3
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1290', 'P1300', 'P1304', 'P1358', 'P1371', 'P1422', 'P1425', 'P1437', 'P1447', 'P1462', 'P1472', 'P1479', 'P1504', 'P1510', 'P1515', 'P1516', 'P1539', 'P1547', 'P1549', 'P1558', 'P1561', 'P1582', 'P1600', 'P1602', 'P1603', 'P1617', 'P1622', 'P1630', 'P1678', 'P1685', 'P1702', 'P1722', 'P1726', 'P1735']
  → test  환자 ID: ['P1430', 'P1508', 'P1540', 'P1606', 'P1610', 'P1631', 'P1707', 'P1718']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1722, Label: 1
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1430, Label: 2
    ID: P1508, Label: 1
    ID: P1540, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1631, Label: 1
    ID: P1707, Label: 1
    ID: P1718, Label: 0
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1516, Label=0, 셀개수=9361
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1582, Label=0, 셀개수=18855
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1718, Label=0, 셀개수=9278
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685        cardiac endothelial cell
592686    cardiac ventricle fibroblast
592687                   pericyte cell
592688        cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.87it/s]  2%|▏         | 2/100 [00:00<00:10,  9.06it/s]  3%|▎         | 3/100 [00:00<00:10,  9.10it/s]  4%|▍         | 4/100 [00:00<00:10,  9.16it/s]  5%|▌         | 5/100 [00:00<00:10,  9.23it/s]  6%|▌         | 6/100 [00:00<00:10,  9.10it/s]  7%|▋         | 7/100 [00:00<00:10,  8.92it/s]  8%|▊         | 8/100 [00:00<00:10,  8.99it/s]  9%|▉         | 9/100 [00:00<00:10,  9.01it/s] 10%|█         | 10/100 [00:01<00:10,  8.92it/s] 11%|█         | 11/100 [00:01<00:09,  8.95it/s] 12%|█▏        | 12/100 [00:01<00:09,  8.90it/s] 13%|█▎        | 13/100 [00:01<00:09,  8.82it/s] 14%|█▍        | 14/100 [00:01<00:09,  8.94it/s] 15%|█▌        | 15/100 [00:01<00:09,  8.95it/s] 16%|█▌        | 16/100 [00:01<00:09,  8.98it/s] 17%|█▋        | 17/100 [00:01<00:09,  9.10it/s] 18%|█▊        | 18/100 [00:01<00:09,  9.07it/s] 19%|█▉        | 19/100 [00:02<00:08,  9.03it/s] 20%|██        | 20/100 [00:02<00:08,  9.02it/s] 21%|██        | 21/100 [00:02<00:08,  8.95it/s] 22%|██▏       | 22/100 [00:02<00:08,  8.99it/s] 23%|██▎       | 23/100 [00:02<00:08,  8.90it/s] 24%|██▍       | 24/100 [00:02<00:08,  8.91it/s] 25%|██▌       | 25/100 [00:02<00:08,  9.03it/s] 26%|██▌       | 26/100 [00:02<00:08,  8.98it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.96it/s] 28%|██▊       | 28/100 [00:03<00:07,  9.05it/s] 29%|██▉       | 29/100 [00:03<00:07,  8.90it/s] 30%|███       | 30/100 [00:03<00:07,  8.92it/s] 31%|███       | 31/100 [00:03<00:07,  9.06it/s] 32%|███▏      | 32/100 [00:03<00:07,  8.94it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.80it/s] 34%|███▍      | 34/100 [00:03<00:07,  8.73it/s] 35%|███▌      | 35/100 [00:03<00:07,  8.75it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.96it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.86it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.83it/s] 39%|███▉      | 39/100 [00:04<00:06,  8.88it/s] 40%|████      | 40/100 [00:04<00:06,  8.93it/s] 41%|████      | 41/100 [00:04<00:06,  8.97it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.86it/s] 43%|████▎     | 43/100 [00:04<00:06,  8.84it/s] 44%|████▍     | 44/100 [00:04<00:06,  8.70it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.65it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.82it/s] 47%|████▋     | 47/100 [00:05<00:05,  8.90it/s] 48%|████▊     | 48/100 [00:05<00:05,  8.93it/s] 49%|████▉     | 49/100 [00:05<00:05,  8.76it/s] 50%|█████     | 50/100 [00:05<00:05,  8.81it/s] 51%|█████     | 51/100 [00:05<00:05,  8.72it/s] 52%|█████▏    | 52/100 [00:05<00:05,  8.76it/s] 53%|█████▎    | 53/100 [00:05<00:05,  8.78it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.83it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.83it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.77it/s] 57%|█████▋    | 57/100 [00:06<00:04,  8.71it/s] 58%|█████▊    | 58/100 [00:06<00:04,  8.55it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.73it/s] 60%|██████    | 60/100 [00:06<00:04,  8.79it/s] 61%|██████    | 61/100 [00:06<00:04,  8.81it/s] 62%|██████▏   | 62/100 [00:06<00:04,  8.66it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.60it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.57it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.60it/s] 66%|██████▌   | 66/100 [00:07<00:03,  8.64it/s] 67%|██████▋   | 67/100 [00:07<00:03,  8.72it/s] 68%|██████▊   | 68/100 [00:07<00:03,  8.73it/s] 69%|██████▉   | 69/100 [00:07<00:03,  8.66it/s] 70%|███████   | 70/100 [00:07<00:03,  8.74it/s] 71%|███████   | 71/100 [00:08<00:03,  8.71it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.61it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.67it/s] 74%|███████▍  | 74/100 [00:08<00:02,  8.76it/s] 75%|███████▌  | 75/100 [00:08<00:02,  8.75it/s] 76%|███████▌  | 76/100 [00:08<00:02,  8.60it/s] 77%|███████▋  | 77/100 [00:08<00:02,  8.68it/s] 78%|███████▊  | 78/100 [00:08<00:02,  8.51it/s] 79%|███████▉  | 79/100 [00:08<00:02,  8.47it/s] 80%|████████  | 80/100 [00:09<00:02,  8.63it/s] 81%|████████  | 81/100 [00:09<00:02,  8.56it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.47it/s] 83%|████████▎ | 83/100 [00:09<00:01,  8.71it/s] 84%|████████▍ | 84/100 [00:09<00:01,  8.80it/s] 85%|████████▌ | 85/100 [00:09<00:01,  8.80it/s] 86%|████████▌ | 86/100 [00:09<00:01,  8.74it/s] 87%|████████▋ | 87/100 [00:09<00:01,  8.72it/s] 88%|████████▊ | 88/100 [00:09<00:01,  8.65it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.49it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.64it/s] 91%|█████████ | 91/100 [00:10<00:01,  8.60it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.60it/s] 93%|█████████▎| 93/100 [00:10<00:00,  8.61it/s] 94%|█████████▍| 94/100 [00:10<00:00,  8.55it/s] 95%|█████████▌| 95/100 [00:10<00:00,  8.56it/s] 96%|█████████▌| 96/100 [00:10<00:00,  8.68it/s] 97%|█████████▋| 97/100 [00:11<00:00,  8.54it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.55it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.73it/s]100%|██████████| 100/100 [00:11<00:00,  8.63it/s]100%|██████████| 100/100 [00:11<00:00,  8.79it/s]
[I 2025-08-27 05:47:01,091] A new study created in memory with name: no-name-985d8420-0d10-46a3-add5-a601acfd3e5e
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.037440, Valid_loss 1.060038
Epoch 2, Train Loss 1.007250, Valid_loss 1.069869
Epoch 3, Train Loss 0.895673, Valid_loss 0.892128
Epoch 4, Train Loss 0.776685, Valid_loss 0.616062
Epoch 5, Train Loss 0.701486, Valid_loss 0.547166
Epoch 6, Train Loss 0.666238, Valid_loss 0.558410
Epoch 7, Train Loss 0.699601, Valid_loss 0.608858
Epoch 8, Train Loss 0.695536, Valid_loss 0.526212
Epoch 9, Train Loss 0.649464, Valid_loss 0.513322
Epoch 10, Train Loss 0.627811, Valid_loss 0.674817
Epoch 11, Train Loss 0.648573, Valid_loss 0.779432
Epoch 12, Train Loss 0.759149, Valid_loss 0.637496
Epoch 13, Train Loss 0.687936, Valid_loss 0.528682
Epoch 14, Train Loss 0.591753, Valid_loss 0.672821
Epoch 15, Train Loss 0.687070, Valid_loss 0.624931
Epoch 16, Train Loss 0.652199, Valid_loss 0.652455
Epoch 17, Train Loss 0.614173, Valid_loss 0.489259
Epoch 18, Train Loss 0.614976, Valid_loss 0.470339
Epoch 19, Train Loss 0.613082, Valid_loss 0.488695
Epoch 20, Train Loss 0.495300, Valid_loss 0.468008
Epoch 21, Train Loss 0.561313, Valid_loss 0.470054
Epoch 22, Train Loss 0.642287, Valid_loss 0.497810
Epoch 23, Train Loss 0.543627, Valid_loss 0.468686
Epoch 24, Train Loss 0.547888, Valid_loss 0.552186
Epoch 25, Train Loss 0.551199, Valid_loss 0.440305
Epoch 26, Train Loss 0.537193, Valid_loss 0.438399
Epoch 27, Train Loss 0.474670, Valid_loss 0.504186
Epoch 28, Train Loss 0.629218, Valid_loss 0.525713
Epoch 29, Train Loss 0.567450, Valid_loss 0.529945
Epoch 30, Train Loss 0.551920, Valid_loss 0.459199
Epoch 31, Train Loss 0.556851, Valid_loss 0.448203
Epoch 32, Train Loss 0.473360, Valid_loss 0.444560
Epoch 33, Train Loss 0.480594, Valid_loss 0.458098
Epoch 34, Train Loss 0.494747, Valid_loss 0.430563
Epoch 35, Train Loss 0.477993, Valid_loss 0.561432
Epoch 36, Train Loss 0.459537, Valid_loss 0.421683
Epoch 37, Train Loss 0.420177, Valid_loss 0.478059
Epoch 38, Train Loss 0.503783, Valid_loss 0.503919
Epoch 39, Train Loss 0.632257, Valid_loss 2.615734
Epoch 40, Train Loss 0.627671, Valid_loss 0.437315
Epoch 41, Train Loss 0.435581, Valid_loss 0.466236
Epoch 42, Train Loss 0.405018, Valid_loss 0.403018
Epoch 43, Train Loss 0.535140, Valid_loss 0.423818
Epoch 44, Train Loss 0.400299, Valid_loss 0.401484
Epoch 45, Train Loss 0.463044, Valid_loss 0.694826
Epoch 46, Train Loss 0.481334, Valid_loss 1.027003
Epoch 47, Train Loss 0.434036, Valid_loss 0.417933
Epoch 48, Train Loss 0.407685, Valid_loss 0.481453
Epoch 49, Train Loss 0.439548, Valid_loss 0.562852
Epoch 50, Train Loss 0.434017, Valid_loss 0.413655
Epoch 51, Train Loss 0.406385, Valid_loss 0.432067
Epoch 52, Train Loss 0.413572, Valid_loss 0.493881
[I 2025-08-27 06:16:27,862] Trial 0 finished with value: 0.4014835599809885 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.01, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.4014835599809885.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16883.20 MB
Memory Reserved: 16902.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 291.20 MB
Memory Reserved: 312.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16883.69 MB
Memory Reserved: 16904.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 291.20 MB
Memory Reserved: 312.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 06:16:29,489] Trial 1 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16883.69 MB
Memory Reserved: 16904.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16883.20 MB
Memory Reserved: 16904.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 291.20 MB
Memory Reserved: 312.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16883.69 MB
Memory Reserved: 16904.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 291.20 MB
Memory Reserved: 312.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 06:16:30,790] Trial 2 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16885.01 MB
Memory Reserved: 16906.00 MB
cuda
Epoch 1, Train Loss 1.123978, Valid_loss 1.049546
Epoch 2, Train Loss 1.061059, Valid_loss 0.972900
Epoch 3, Train Loss 0.888798, Valid_loss 0.662705
Epoch 4, Train Loss 0.756214, Valid_loss 0.570907
Epoch 5, Train Loss 0.679376, Valid_loss 0.526094
Epoch 6, Train Loss 0.686014, Valid_loss 0.527671
Epoch 7, Train Loss 0.650173, Valid_loss 0.561696
Epoch 8, Train Loss 0.611724, Valid_loss 0.478925
Epoch 9, Train Loss 0.648951, Valid_loss 0.491061
Epoch 10, Train Loss 0.537145, Valid_loss 0.458150
Epoch 11, Train Loss 0.560557, Valid_loss 0.617930
Epoch 12, Train Loss 0.568222, Valid_loss 0.442676
Epoch 13, Train Loss 0.653457, Valid_loss 0.463147
Epoch 14, Train Loss 0.684060, Valid_loss 1.779283
Epoch 15, Train Loss 0.659503, Valid_loss 0.789608
Epoch 16, Train Loss 0.604175, Valid_loss 0.495358
Epoch 17, Train Loss 0.527725, Valid_loss 0.755754
Epoch 18, Train Loss 0.556772, Valid_loss 0.436644
Epoch 19, Train Loss 0.552980, Valid_loss 0.437434
Epoch 20, Train Loss 0.561633, Valid_loss 0.429346
Epoch 21, Train Loss 0.525448, Valid_loss 1.166353
Epoch 22, Train Loss 0.504058, Valid_loss 0.554025
Epoch 23, Train Loss 0.502339, Valid_loss 0.611387
Epoch 24, Train Loss 0.502938, Valid_loss 0.737229
Epoch 25, Train Loss 0.503784, Valid_loss 0.697116
Epoch 26, Train Loss 0.513876, Valid_loss 1.983677
Epoch 27, Train Loss 0.485255, Valid_loss 0.798953
Epoch 28, Train Loss 0.488308, Valid_loss 0.512677
Epoch 29, Train Loss 0.438002, Valid_loss 0.663183
Epoch 30, Train Loss 0.426903, Valid_loss 0.557812
Epoch 31, Train Loss 0.465166, Valid_loss 0.750191
Epoch 32, Train Loss 0.448748, Valid_loss 0.511279
Epoch 33, Train Loss 0.646279, Valid_loss 0.695415
Epoch 34, Train Loss 0.420660, Valid_loss 0.598228
Epoch 35, Train Loss 0.446662, Valid_loss 0.752051
Epoch 36, Train Loss 0.458184, Valid_loss 0.841589
Epoch 37, Train Loss 0.448537, Valid_loss 0.593570
Epoch 38, Train Loss 0.395693, Valid_loss 0.585100
Epoch 39, Train Loss 0.378011, Valid_loss 0.841495
Epoch 40, Train Loss 0.388233, Valid_loss 1.149792
Epoch 41, Train Loss 0.535220, Valid_loss 0.622571
Epoch 42, Train Loss 0.339128, Valid_loss 0.787306
Epoch 43, Train Loss 0.410596, Valid_loss 0.678969
Epoch 44, Train Loss 0.371183, Valid_loss 0.508767
Epoch 45, Train Loss 0.363100, Valid_loss 0.656609
Epoch 46, Train Loss 0.352650, Valid_loss 0.956535
Epoch 47, Train Loss 0.346109, Valid_loss 0.831418
Epoch 48, Train Loss 0.454109, Valid_loss 0.827387
Epoch 49, Train Loss 0.350240, Valid_loss 1.344364
Epoch 50, Train Loss 0.321024, Valid_loss 0.925024
Epoch 51, Train Loss 0.311174, Valid_loss 0.807745
Epoch 52, Train Loss 0.306444, Valid_loss 1.246996
Epoch 53, Train Loss 0.373850, Valid_loss 1.070123
Epoch 54, Train Loss 0.277898, Valid_loss 1.081755
Epoch 55, Train Loss 0.307600, Valid_loss 0.768269
Epoch 56, Train Loss 0.280237, Valid_loss 1.017259
Epoch 57, Train Loss 0.279193, Valid_loss 1.170052
[I 2025-08-27 06:38:36,344] Trial 3 finished with value: 0.42934638261795044 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.4014835599809885.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.067500, Valid_loss 1.106621
Epoch 2, Train Loss 0.887852, Valid_loss 0.770326
Epoch 3, Train Loss 0.961341, Valid_loss 1.073266
Epoch 4, Train Loss 0.964949, Valid_loss 1.112300
Epoch 5, Train Loss 0.916447, Valid_loss 0.752604
Epoch 6, Train Loss 0.902699, Valid_loss 1.079772
Epoch 7, Train Loss 0.872207, Valid_loss 0.585283
Epoch 8, Train Loss 0.689122, Valid_loss 0.590400
Epoch 9, Train Loss 0.603379, Valid_loss 1.067084
Epoch 10, Train Loss 0.686409, Valid_loss 0.712058
Epoch 11, Train Loss 0.737304, Valid_loss 0.635345
Epoch 12, Train Loss 0.614349, Valid_loss 0.496194
Epoch 13, Train Loss 0.573774, Valid_loss 1.083719
Epoch 14, Train Loss 0.524539, Valid_loss 0.490899
Epoch 15, Train Loss 0.544574, Valid_loss 0.559239
Epoch 16, Train Loss 0.482802, Valid_loss 0.838877
Epoch 17, Train Loss 0.559446, Valid_loss 0.508396
Epoch 18, Train Loss 0.511440, Valid_loss 0.529311
Epoch 19, Train Loss 0.469814, Valid_loss 0.641863
Epoch 20, Train Loss 0.430325, Valid_loss 0.658777
Epoch 21, Train Loss 0.409701, Valid_loss 0.782250
Epoch 22, Train Loss 0.422061, Valid_loss 0.480195
Epoch 23, Train Loss 0.428672, Valid_loss 0.859216
Epoch 24, Train Loss 0.411014, Valid_loss 0.544412
Epoch 25, Train Loss 0.456531, Valid_loss 0.443521
Epoch 26, Train Loss 0.401244, Valid_loss 1.099740
Epoch 27, Train Loss 0.441256, Valid_loss 0.917632
Epoch 28, Train Loss 0.396493, Valid_loss 0.570974
Epoch 29, Train Loss 0.380410, Valid_loss 0.425602
Epoch 30, Train Loss 0.341863, Valid_loss 0.386840
Epoch 31, Train Loss 0.418428, Valid_loss 0.380070
Epoch 32, Train Loss 0.358745, Valid_loss 0.397101
Epoch 33, Train Loss 0.381611, Valid_loss 0.712218
Epoch 34, Train Loss 0.312114, Valid_loss 1.468682
Epoch 35, Train Loss 0.357197, Valid_loss 0.409650
Epoch 36, Train Loss 0.393172, Valid_loss 1.153142
Epoch 37, Train Loss 0.307800, Valid_loss 0.813074
Epoch 38, Train Loss 0.263404, Valid_loss 0.452464
Epoch 39, Train Loss 0.333217, Valid_loss 0.481109
Epoch 40, Train Loss 0.293252, Valid_loss 0.458884
Epoch 41, Train Loss 0.295449, Valid_loss 0.580539
Epoch 42, Train Loss 0.281806, Valid_loss 0.785257
Epoch 43, Train Loss 0.415944, Valid_loss 0.545822
Epoch 44, Train Loss 0.332783, Valid_loss 2.187314
Epoch 45, Train Loss 0.431845, Valid_loss 0.840371
Epoch 46, Train Loss 0.263499, Valid_loss 0.974935
Epoch 47, Train Loss 0.217305, Valid_loss 1.255476
Epoch 48, Train Loss 0.233511, Valid_loss 0.701000
Epoch 49, Train Loss 0.317921, Valid_loss 0.462290
Epoch 50, Train Loss 0.375826, Valid_loss 2.045367
Epoch 51, Train Loss 0.234428, Valid_loss 1.204437
Epoch 52, Train Loss 0.194383, Valid_loss 0.661338
Epoch 53, Train Loss 0.203852, Valid_loss 0.783589
Epoch 54, Train Loss 0.176314, Valid_loss 1.113366
[I 2025-08-27 06:58:23,811] Trial 4 finished with value: 0.38006998676185805 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 1, 'dropout': 0.0, 'weight_decay': 0.01, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 4 with value: 0.38006998676185805.
선택된 trial params: {'learning_rate': 0.001, 'epochs': 100, 'heads': 1, 'dropout': 0.0, 'weight_decay': 0.01, 'emb_dim': 64, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.094882, Valid_loss 1.091653
Epoch 2, Train Loss 1.029851, Valid_loss 1.142132
Epoch 3, Train Loss 0.925679, Valid_loss 0.618364
Epoch 4, Train Loss 0.755198, Valid_loss 0.933068
Epoch 5, Train Loss 0.657063, Valid_loss 0.562722
Epoch 6, Train Loss 0.637625, Valid_loss 0.514460
Epoch 7, Train Loss 0.719482, Valid_loss 0.529014
Epoch 8, Train Loss 0.589834, Valid_loss 0.492094
Epoch 9, Train Loss 0.606888, Valid_loss 0.527122
Epoch 10, Train Loss 0.752179, Valid_loss 0.542266
Epoch 11, Train Loss 0.732712, Valid_loss 0.576145
Epoch 12, Train Loss 0.624095, Valid_loss 0.484482
Epoch 13, Train Loss 0.544229, Valid_loss 0.556570
Epoch 14, Train Loss 0.521951, Valid_loss 0.633039
Epoch 15, Train Loss 0.639012, Valid_loss 0.827129
Epoch 16, Train Loss 0.498296, Valid_loss 0.496975
Epoch 17, Train Loss 0.506589, Valid_loss 0.453058
Epoch 18, Train Loss 0.600229, Valid_loss 0.525797
Epoch 19, Train Loss 0.496726, Valid_loss 0.733606
Epoch 20, Train Loss 0.497831, Valid_loss 0.651310
Epoch 21, Train Loss 0.579627, Valid_loss 0.461276
Epoch 22, Train Loss 0.472454, Valid_loss 0.602136
Epoch 23, Train Loss 0.478039, Valid_loss 0.850531
Epoch 24, Train Loss 0.440849, Valid_loss 0.582052
Epoch 25, Train Loss 0.452144, Valid_loss 0.449409
Epoch 26, Train Loss 0.448062, Valid_loss 0.964723
Epoch 27, Train Loss 0.398836, Valid_loss 0.463935
Epoch 28, Train Loss 0.388747, Valid_loss 0.631938
Epoch 29, Train Loss 0.401355, Valid_loss 0.980580
Epoch 30, Train Loss 0.561648, Valid_loss 0.957922
Epoch 31, Train Loss 0.414473, Valid_loss 0.958043
Epoch 32, Train Loss 0.396729, Valid_loss 0.550297
Epoch 33, Train Loss 0.330922, Valid_loss 0.725195
Epoch 34, Train Loss 0.340634, Valid_loss 0.771676
Epoch 35, Train Loss 0.344372, Valid_loss 0.628928
Epoch 36, Train Loss 0.380893, Valid_loss 1.032714
Epoch 37, Train Loss 0.348370, Valid_loss 0.897947
Epoch 38, Train Loss 0.313613, Valid_loss 0.727910
Epoch 39, Train Loss 0.343777, Valid_loss 1.289775
Epoch 40, Train Loss 0.335400, Valid_loss 0.893706
Epoch 41, Train Loss 0.309229, Valid_loss 0.769693
Epoch 42, Train Loss 0.349407, Valid_loss 0.794421
Epoch 43, Train Loss 0.299798, Valid_loss 1.986606
Epoch 44, Train Loss 0.372007, Valid_loss 0.767559
Epoch 45, Train Loss 0.322061, Valid_loss 0.673892
Epoch 46, Train Loss 0.302705, Valid_loss 0.844077
Epoch 47, Train Loss 0.254275, Valid_loss 0.577830
Epoch 48, Train Loss 0.325333, Valid_loss 0.815197
Epoch 49, Train Loss 0.360224, Valid_loss 1.292024
Epoch 50, Train Loss 0.294568, Valid_loss 0.741949
Epoch 51, Train Loss 0.261212, Valid_loss 0.902674
Epoch 52, Train Loss 0.255514, Valid_loss 0.947991
환자ID=P1430 -- true: [[2]] -- pred: tensor([[-2.0450,  0.3715,  1.1515]], device='cuda:0')
환자ID=P1508 -- true: [[1]] -- pred: tensor([[-1.0348,  1.4526, -0.9277]], device='cuda:0')
환자ID=P1540 -- true: [[0]] -- pred: tensor([[ 2.2014, -0.3817, -3.0025]], device='cuda:0')
환자ID=P1606 -- true: [[2]] -- pred: tensor([[-2.0807,  0.4117,  1.1312]], device='cuda:0')
환자ID=P1610 -- true: [[0]] -- pred: tensor([[ 1.5834,  0.1563, -2.8053]], device='cuda:0')
환자ID=P1631 -- true: [[1]] -- pred: tensor([[-0.6972,  1.3973, -1.2824]], device='cuda:0')
환자ID=P1707 -- true: [[1]] -- pred: tensor([[-2.1774,  0.7230,  0.8542]], device='cuda:0')
환자ID=P1718 -- true: [[0]] -- pred: tensor([[ 1.9945, -0.1761, -2.9655]], device='cuda:0')
Best performance: Epoch 25, Loss 0.452144, Test ACC 0.875000, Test AUC 1.000000, Test Recall 0.888889, Test Precision 0.888889
Confusion Matrix:
 [[3 0 0]
 [0 2 1]
 [0 0 2]]
✅ Total valid splits used: 3
🔁 Repeat 0, Fold 3
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 481329, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 481329, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  CCCTTAGCACCTGATA-1-9              cardiac muscle cell
TGCAGTAAGTCTAGAA-1-9              cardiac muscle cell
TGTCCCATCAGGACAG-1-9              cardiac muscle cell
CAGATTGTCCATTCAT-1-9              cardiac muscle cell
TCTATCACACGCTGAC-1-9              cardiac muscle cell
                                     ...             
AGAAGCGAGCGTCTGC-1-73        cardiac endothelial cell
TACTTCATCCCTTTGG-1-73        cardiac endothelial cell
ATATCCTGTTAGCGGA-1-73        cardiac endothelial cell
TACTTACCAAAGCACG-1-73        cardiac endothelial cell
GTCAGCGCAACACTAC-1-73    cardiac ventricle fibroblast
Name: manual_annotation, Length: 111360, dtype: string
cell type annotation :  CCCTTAGCACCTGATA-1-9              cardiac muscle cell
TGCAGTAAGTCTAGAA-1-9              cardiac muscle cell
TGTCCCATCAGGACAG-1-9              cardiac muscle cell
CAGATTGTCCATTCAT-1-9              cardiac muscle cell
TCTATCACACGCTGAC-1-9              cardiac muscle cell
                                     ...             
AGAAGCGAGCGTCTGC-1-73        cardiac endothelial cell
TACTTCATCCCTTTGG-1-73        cardiac endothelial cell
ATATCCTGTTAGCGGA-1-73        cardiac endothelial cell
TACTTACCAAAGCACG-1-73        cardiac endothelial cell
GTCAGCGCAACACTAC-1-73    cardiac ventricle fibroblast
Name: manual_annotation, Length: 111360, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endothelial cell of lymphatic vessel', 'endocardial cell', 'mesothelial cell', 'cardiac neuron', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'mast cell', 'vascular associated smooth muscle cell', 'lymphocyte', 'pericyte cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 3}
🔍 Split #4
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1304', 'P1358', 'P1371', 'P1422', 'P1425', 'P1430', 'P1437', 'P1447', 'P1462', 'P1472', 'P1504', 'P1508', 'P1515', 'P1516', 'P1540', 'P1549', 'P1558', 'P1561', 'P1600', 'P1602', 'P1603', 'P1606', 'P1610', 'P1617', 'P1622', 'P1631', 'P1678', 'P1685', 'P1702', 'P1707', 'P1718', 'P1722', 'P1726', 'P1735']
  → test  환자 ID: ['P1290', 'P1300', 'P1479', 'P1510', 'P1539', 'P1547', 'P1582', 'P1630']
  → train 환자 ID 및 라벨:
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1540, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1479, Label: 1
    ID: P1510, Label: 1
    ID: P1539, Label: 0
    ID: P1547, Label: 0
    ID: P1582, Label: 0
    ID: P1630, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1549, Label=0, 셀개수=11709
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1606, Label=2, 셀개수=8523
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1630, Label=1, 셀개수=17633
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685        cardiac endothelial cell
592686        cardiac endothelial cell
592687        cardiac endothelial cell
592688    cardiac ventricle fibroblast
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.70it/s]  2%|▏         | 2/100 [00:00<00:11,  8.88it/s]  3%|▎         | 3/100 [00:00<00:10,  9.07it/s]  4%|▍         | 4/100 [00:00<00:10,  9.20it/s]  5%|▌         | 5/100 [00:00<00:10,  9.23it/s]  6%|▌         | 6/100 [00:00<00:10,  9.39it/s]  7%|▋         | 7/100 [00:00<00:09,  9.44it/s]  8%|▊         | 8/100 [00:00<00:09,  9.44it/s]  9%|▉         | 9/100 [00:00<00:09,  9.44it/s] 10%|█         | 10/100 [00:01<00:09,  9.35it/s] 11%|█         | 11/100 [00:01<00:09,  9.15it/s] 12%|█▏        | 12/100 [00:01<00:09,  9.23it/s] 13%|█▎        | 13/100 [00:01<00:09,  9.28it/s] 14%|█▍        | 14/100 [00:01<00:09,  9.21it/s] 15%|█▌        | 15/100 [00:01<00:09,  9.20it/s] 16%|█▌        | 16/100 [00:01<00:09,  9.29it/s] 17%|█▋        | 17/100 [00:01<00:09,  9.19it/s] 18%|█▊        | 18/100 [00:01<00:09,  8.89it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.92it/s] 20%|██        | 20/100 [00:02<00:08,  9.03it/s] 21%|██        | 21/100 [00:02<00:08,  9.09it/s] 22%|██▏       | 22/100 [00:02<00:08,  9.22it/s] 23%|██▎       | 23/100 [00:02<00:08,  9.20it/s] 24%|██▍       | 24/100 [00:02<00:08,  9.12it/s] 25%|██▌       | 25/100 [00:02<00:08,  9.03it/s] 26%|██▌       | 26/100 [00:02<00:08,  9.04it/s] 27%|██▋       | 27/100 [00:02<00:08,  9.00it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.95it/s] 29%|██▉       | 29/100 [00:03<00:07,  8.96it/s] 30%|███       | 30/100 [00:03<00:07,  9.07it/s] 31%|███       | 31/100 [00:03<00:07,  8.87it/s] 32%|███▏      | 32/100 [00:03<00:07,  8.90it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.92it/s] 34%|███▍      | 34/100 [00:03<00:07,  8.82it/s] 35%|███▌      | 35/100 [00:03<00:07,  9.03it/s] 36%|███▌      | 36/100 [00:03<00:07,  8.95it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.92it/s] 38%|███▊      | 38/100 [00:04<00:06,  8.86it/s] 39%|███▉      | 39/100 [00:04<00:06,  8.91it/s] 40%|████      | 40/100 [00:04<00:06,  8.72it/s] 41%|████      | 41/100 [00:04<00:06,  8.79it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.78it/s] 43%|████▎     | 43/100 [00:04<00:06,  8.96it/s] 44%|████▍     | 44/100 [00:04<00:06,  8.97it/s] 45%|████▌     | 45/100 [00:04<00:06,  8.88it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.97it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.78it/s] 48%|████▊     | 48/100 [00:05<00:05,  8.86it/s] 49%|████▉     | 49/100 [00:05<00:05,  8.84it/s] 50%|█████     | 50/100 [00:05<00:05,  8.84it/s] 51%|█████     | 51/100 [00:05<00:05,  8.83it/s] 52%|█████▏    | 52/100 [00:05<00:05,  8.71it/s] 53%|█████▎    | 53/100 [00:05<00:05,  8.71it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.73it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.72it/s] 56%|█████▌    | 56/100 [00:06<00:04,  8.80it/s] 57%|█████▋    | 57/100 [00:06<00:04,  8.96it/s] 58%|█████▊    | 58/100 [00:06<00:04,  8.96it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.96it/s] 60%|██████    | 60/100 [00:06<00:04,  9.00it/s] 61%|██████    | 61/100 [00:06<00:04,  9.02it/s] 62%|██████▏   | 62/100 [00:06<00:04,  8.91it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.96it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.94it/s] 65%|██████▌   | 65/100 [00:07<00:03,  8.89it/s] 66%|██████▌   | 66/100 [00:07<00:03,  8.87it/s] 67%|██████▋   | 67/100 [00:07<00:03,  8.86it/s] 68%|██████▊   | 68/100 [00:07<00:03,  8.93it/s] 69%|██████▉   | 69/100 [00:07<00:03,  8.77it/s] 70%|███████   | 70/100 [00:07<00:03,  8.86it/s] 71%|███████   | 71/100 [00:07<00:03,  8.87it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.83it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.88it/s] 74%|███████▍  | 74/100 [00:08<00:02,  8.81it/s] 75%|███████▌  | 75/100 [00:08<00:02,  8.92it/s] 76%|███████▌  | 76/100 [00:08<00:02,  8.91it/s] 77%|███████▋  | 77/100 [00:08<00:02,  8.76it/s] 78%|███████▊  | 78/100 [00:08<00:02,  8.77it/s] 79%|███████▉  | 79/100 [00:08<00:02,  8.68it/s] 80%|████████  | 80/100 [00:08<00:02,  8.67it/s] 81%|████████  | 81/100 [00:09<00:02,  8.63it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.70it/s] 83%|████████▎ | 83/100 [00:09<00:01,  8.59it/s] 84%|████████▍ | 84/100 [00:09<00:01,  8.36it/s] 85%|████████▌ | 85/100 [00:09<00:01,  8.45it/s] 86%|████████▌ | 86/100 [00:09<00:01,  8.40it/s] 87%|████████▋ | 87/100 [00:09<00:01,  8.60it/s] 88%|████████▊ | 88/100 [00:09<00:01,  8.59it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.38it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.59it/s] 91%|█████████ | 91/100 [00:10<00:01,  8.53it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.52it/s] 93%|█████████▎| 93/100 [00:10<00:00,  8.59it/s] 94%|█████████▍| 94/100 [00:10<00:00,  8.69it/s] 95%|█████████▌| 95/100 [00:10<00:00,  8.77it/s] 96%|█████████▌| 96/100 [00:10<00:00,  8.77it/s] 97%|█████████▋| 97/100 [00:10<00:00,  8.79it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.72it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.72it/s]100%|██████████| 100/100 [00:11<00:00,  8.68it/s]100%|██████████| 100/100 [00:11<00:00,  8.88it/s]
[I 2025-08-27 07:18:10,615] A new study created in memory with name: no-name-a07756dc-23aa-41f7-96c4-eef83d806721
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.905813, Valid_loss 1.245736
Epoch 2, Train Loss 0.800331, Valid_loss 1.094687
Epoch 3, Train Loss 0.681047, Valid_loss 1.052318
Epoch 4, Train Loss 0.628447, Valid_loss 0.958657
Epoch 5, Train Loss 0.573975, Valid_loss 1.002746
Epoch 6, Train Loss 0.573988, Valid_loss 0.968924
Epoch 7, Train Loss 0.570590, Valid_loss 0.903485
Epoch 8, Train Loss 0.487607, Valid_loss 0.936683
Epoch 9, Train Loss 0.467825, Valid_loss 0.789910
Epoch 10, Train Loss 0.518012, Valid_loss 0.857693
Epoch 11, Train Loss 0.390477, Valid_loss 0.868383
Epoch 12, Train Loss 0.428336, Valid_loss 0.979750
Epoch 13, Train Loss 0.406695, Valid_loss 0.842754
Epoch 14, Train Loss 0.339979, Valid_loss 0.848755
Epoch 15, Train Loss 0.375581, Valid_loss 0.911493
Epoch 16, Train Loss 0.346643, Valid_loss 0.925553
Epoch 17, Train Loss 0.314499, Valid_loss 0.829015
Epoch 18, Train Loss 0.318313, Valid_loss 0.796322
Epoch 19, Train Loss 0.337423, Valid_loss 0.896318
Epoch 20, Train Loss 0.300146, Valid_loss 0.804831
Epoch 21, Train Loss 0.311566, Valid_loss 0.781650
Epoch 22, Train Loss 0.271273, Valid_loss 0.804864
Epoch 23, Train Loss 0.267993, Valid_loss 1.094396
Epoch 24, Train Loss 0.456886, Valid_loss 0.770368
Epoch 25, Train Loss 0.296327, Valid_loss 0.884727
Epoch 26, Train Loss 0.296335, Valid_loss 0.911944
Epoch 27, Train Loss 0.304633, Valid_loss 0.735090
Epoch 28, Train Loss 0.287773, Valid_loss 0.749767
Epoch 29, Train Loss 0.255698, Valid_loss 0.736387
Epoch 30, Train Loss 0.261095, Valid_loss 0.736543
Epoch 31, Train Loss 0.233089, Valid_loss 0.973358
Epoch 32, Train Loss 0.259957, Valid_loss 0.792915
Epoch 33, Train Loss 0.264116, Valid_loss 0.786468
Epoch 34, Train Loss 0.237049, Valid_loss 0.964669
Epoch 35, Train Loss 0.222557, Valid_loss 0.649832
Epoch 36, Train Loss 0.277584, Valid_loss 0.783153
Epoch 37, Train Loss 0.218612, Valid_loss 0.615242
Epoch 38, Train Loss 0.284485, Valid_loss 0.662118
Epoch 39, Train Loss 0.235262, Valid_loss 0.709440
Epoch 40, Train Loss 0.262475, Valid_loss 0.729681
Epoch 41, Train Loss 0.224352, Valid_loss 0.749884
Epoch 42, Train Loss 0.218782, Valid_loss 1.338072
Epoch 43, Train Loss 0.325832, Valid_loss 0.871221
Epoch 44, Train Loss 0.212132, Valid_loss 1.067061
Epoch 45, Train Loss 0.210168, Valid_loss 0.670467
Epoch 46, Train Loss 0.191561, Valid_loss 0.784208
Epoch 47, Train Loss 0.189805, Valid_loss 0.691103
Epoch 48, Train Loss 0.170161, Valid_loss 0.724476
Epoch 49, Train Loss 0.174822, Valid_loss 0.877856
Epoch 50, Train Loss 0.174127, Valid_loss 0.781004
Epoch 51, Train Loss 0.168104, Valid_loss 1.005783
Epoch 52, Train Loss 0.211432, Valid_loss 0.886790
Epoch 53, Train Loss 0.187186, Valid_loss 0.882147
Epoch 54, Train Loss 0.182084, Valid_loss 0.758148
Epoch 55, Train Loss 0.168390, Valid_loss 0.957573
Epoch 56, Train Loss 0.180623, Valid_loss 0.733370
Epoch 57, Train Loss 0.155699, Valid_loss 0.884221
Epoch 58, Train Loss 0.139824, Valid_loss 0.907224
[I 2025-08-27 07:48:06,720] Trial 0 finished with value: 0.6152416584081948 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.6152416584081948.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16510.75 MB
Memory Reserved: 16534.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 318.82 MB
Memory Reserved: 362.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 14710.85 MB
Memory Reserved: 14752.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 7514.82 MB
Memory Reserved: 7556.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 07:48:08,459] Trial 1 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 14707.68 MB
Memory Reserved: 14752.00 MB
cuda
Epoch 1, Train Loss 0.978935, Valid_loss 1.302044
Epoch 2, Train Loss 0.854139, Valid_loss 1.328233
Epoch 3, Train Loss 0.771041, Valid_loss 1.278062
Epoch 4, Train Loss 0.613847, Valid_loss 0.979340
Epoch 5, Train Loss 0.623537, Valid_loss 1.000834
Epoch 6, Train Loss 0.586869, Valid_loss 1.067739
Epoch 7, Train Loss 0.568653, Valid_loss 1.201462
Epoch 8, Train Loss 0.534349, Valid_loss 0.951837
Epoch 9, Train Loss 0.438957, Valid_loss 0.922638
Epoch 10, Train Loss 0.509210, Valid_loss 1.024352
Epoch 11, Train Loss 0.470344, Valid_loss 1.122972
Epoch 12, Train Loss 0.440693, Valid_loss 0.929537
Epoch 13, Train Loss 0.495566, Valid_loss 1.067863
Epoch 14, Train Loss 0.365656, Valid_loss 0.936744
Epoch 15, Train Loss 0.450973, Valid_loss 0.976183
Epoch 16, Train Loss 0.350807, Valid_loss 1.060429
Epoch 17, Train Loss 0.445519, Valid_loss 0.927318
Epoch 18, Train Loss 0.329690, Valid_loss 1.056326
Epoch 19, Train Loss 0.322529, Valid_loss 1.052967
Epoch 20, Train Loss 0.365033, Valid_loss 0.931040
Epoch 21, Train Loss 0.367057, Valid_loss 0.970402
Epoch 22, Train Loss 0.289312, Valid_loss 0.905004
Epoch 23, Train Loss 0.322048, Valid_loss 0.889799
Epoch 24, Train Loss 0.273348, Valid_loss 0.938365
Epoch 25, Train Loss 0.297067, Valid_loss 0.905511
Epoch 26, Train Loss 0.328882, Valid_loss 0.926447
Epoch 27, Train Loss 0.349139, Valid_loss 0.930945
Epoch 28, Train Loss 0.407731, Valid_loss 0.992916
Epoch 29, Train Loss 0.314743, Valid_loss 0.880078
Epoch 30, Train Loss 0.300244, Valid_loss 0.882439
Epoch 31, Train Loss 0.347202, Valid_loss 0.874282
Epoch 32, Train Loss 0.261823, Valid_loss 0.869503
Epoch 33, Train Loss 0.288052, Valid_loss 0.887793
Epoch 34, Train Loss 0.244799, Valid_loss 0.921918
Epoch 35, Train Loss 0.263604, Valid_loss 0.909999
Epoch 36, Train Loss 0.279222, Valid_loss 0.879892
Epoch 37, Train Loss 0.218640, Valid_loss 0.881417
Epoch 38, Train Loss 0.216254, Valid_loss 0.874569
Epoch 39, Train Loss 0.229755, Valid_loss 0.896584
Epoch 40, Train Loss 0.205182, Valid_loss 0.878956
Epoch 41, Train Loss 0.254991, Valid_loss 0.862130
Epoch 42, Train Loss 0.190239, Valid_loss 0.900724
Epoch 43, Train Loss 0.209827, Valid_loss 0.854357
Epoch 44, Train Loss 0.170466, Valid_loss 0.856635
Epoch 45, Train Loss 0.201021, Valid_loss 4.330629
Epoch 46, Train Loss 0.290110, Valid_loss 0.858598
Epoch 47, Train Loss 0.189744, Valid_loss 0.861811
Epoch 48, Train Loss 0.225334, Valid_loss 0.829385
Epoch 49, Train Loss 0.414075, Valid_loss 0.837399
Epoch 50, Train Loss 0.227358, Valid_loss 2.406885
Epoch 51, Train Loss 0.329125, Valid_loss 0.838402
Epoch 52, Train Loss 0.177459, Valid_loss 0.825261
Epoch 53, Train Loss 0.171964, Valid_loss 0.842855
Epoch 54, Train Loss 0.157478, Valid_loss 0.845125
[I 2025-08-27 08:15:57,924] Trial 2 finished with value: 0.825260774717511 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.6152416584081948.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16510.75 MB
Memory Reserved: 16534.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 318.82 MB
Memory Reserved: 362.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 14710.85 MB
Memory Reserved: 14752.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 7514.82 MB
Memory Reserved: 7556.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 08:15:59,631] Trial 3 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 14709.00 MB
Memory Reserved: 14754.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 7488.32 MB
Memory Reserved: 7542.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 14684.46 MB
Memory Reserved: 14706.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 7488.32 MB
Memory Reserved: 7530.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 14684.32 MB
Memory Reserved: 14706.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 08:16:00,942] Trial 4 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.830865, Valid_loss 1.595525
Epoch 2, Train Loss 0.774012, Valid_loss 1.602614
Epoch 3, Train Loss 0.622048, Valid_loss 1.518107
Epoch 4, Train Loss 0.569614, Valid_loss 1.488309
Epoch 5, Train Loss 0.548371, Valid_loss 1.109890
Epoch 6, Train Loss 0.547174, Valid_loss 1.306717
Epoch 7, Train Loss 0.410641, Valid_loss 1.234465
Epoch 8, Train Loss 0.409596, Valid_loss 1.274205
Epoch 9, Train Loss 0.372071, Valid_loss 1.070991
Epoch 10, Train Loss 0.419150, Valid_loss 1.002088
Epoch 11, Train Loss 0.316487, Valid_loss 1.079601
Epoch 12, Train Loss 0.398015, Valid_loss 1.056595
Epoch 13, Train Loss 0.344605, Valid_loss 1.100204
Epoch 14, Train Loss 0.349127, Valid_loss 0.893713
Epoch 15, Train Loss 0.334974, Valid_loss 1.272688
Epoch 16, Train Loss 0.303784, Valid_loss 0.840352
Epoch 17, Train Loss 0.337983, Valid_loss 1.140005
Epoch 18, Train Loss 0.339502, Valid_loss 0.982603
Epoch 19, Train Loss 0.286441, Valid_loss 0.959020
Epoch 20, Train Loss 0.300752, Valid_loss 0.858740
Epoch 21, Train Loss 0.257395, Valid_loss 1.399360
Epoch 22, Train Loss 0.291523, Valid_loss 0.891719
Epoch 23, Train Loss 0.425713, Valid_loss 1.196850
Epoch 24, Train Loss 0.295393, Valid_loss 1.111988
Epoch 25, Train Loss 0.254634, Valid_loss 0.989501
Epoch 26, Train Loss 0.254018, Valid_loss 1.314305
Epoch 27, Train Loss 0.268459, Valid_loss 1.305874
Epoch 28, Train Loss 0.234037, Valid_loss 1.088777
Epoch 29, Train Loss 0.235710, Valid_loss 1.114857
Epoch 30, Train Loss 0.241628, Valid_loss 1.561910
Epoch 31, Train Loss 0.197049, Valid_loss 1.529858
Epoch 32, Train Loss 0.199155, Valid_loss 1.207105
Epoch 33, Train Loss 0.209393, Valid_loss 1.255172
Epoch 34, Train Loss 0.167890, Valid_loss 0.869685
Epoch 35, Train Loss 0.429825, Valid_loss 0.876925
Epoch 36, Train Loss 0.231962, Valid_loss 1.058406
Epoch 37, Train Loss 0.213015, Valid_loss 1.140554
Epoch 38, Train Loss 0.217812, Valid_loss 1.244010
Epoch 39, Train Loss 0.227979, Valid_loss 0.796341
Epoch 40, Train Loss 0.258410, Valid_loss 0.610418
Epoch 41, Train Loss 0.271251, Valid_loss 1.120377
Epoch 42, Train Loss 0.193165, Valid_loss 0.572897
Epoch 43, Train Loss 0.207890, Valid_loss 1.215745
Epoch 44, Train Loss 0.167838, Valid_loss 1.052918
Epoch 45, Train Loss 0.172342, Valid_loss 1.388582
Epoch 46, Train Loss 0.184278, Valid_loss 0.772718
Epoch 47, Train Loss 0.169881, Valid_loss 1.281661
Epoch 48, Train Loss 0.193212, Valid_loss 1.027311
Epoch 49, Train Loss 0.151748, Valid_loss 0.809427
Epoch 50, Train Loss 0.138211, Valid_loss 2.415863
Epoch 51, Train Loss 0.176030, Valid_loss 0.995923
Epoch 52, Train Loss 0.131952, Valid_loss 1.063292
Epoch 53, Train Loss 0.128165, Valid_loss 1.023145
Epoch 54, Train Loss 0.128304, Valid_loss 0.852588
Epoch 55, Train Loss 0.121673, Valid_loss 0.843604
Epoch 56, Train Loss 0.097064, Valid_loss 1.055116
Epoch 57, Train Loss 0.121885, Valid_loss 1.251660
[I 2025-08-27 08:47:28,917] Trial 5 finished with value: 0.572896589563849 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 5 with value: 0.572896589563849.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.844491, Valid_loss 1.516439
Epoch 2, Train Loss 0.761309, Valid_loss 1.318041
Epoch 3, Train Loss 0.603368, Valid_loss 1.014169
Epoch 4, Train Loss 0.531964, Valid_loss 0.996003
Epoch 5, Train Loss 0.498227, Valid_loss 0.931476
Epoch 6, Train Loss 0.405756, Valid_loss 0.836163
Epoch 7, Train Loss 0.393778, Valid_loss 0.993638
Epoch 8, Train Loss 0.409622, Valid_loss 0.974901
Epoch 9, Train Loss 0.414158, Valid_loss 0.834033
Epoch 10, Train Loss 0.362112, Valid_loss 0.768917
Epoch 11, Train Loss 0.281742, Valid_loss 0.912662
Epoch 12, Train Loss 0.267997, Valid_loss 0.873995
Epoch 13, Train Loss 0.352546, Valid_loss 0.896456
Epoch 14, Train Loss 0.355420, Valid_loss 0.815706
Epoch 15, Train Loss 0.270574, Valid_loss 0.712451
Epoch 16, Train Loss 0.360395, Valid_loss 0.993242
Epoch 17, Train Loss 0.234527, Valid_loss 1.097474
Epoch 18, Train Loss 0.307980, Valid_loss 0.815735
Epoch 19, Train Loss 0.262539, Valid_loss 0.875734
Epoch 20, Train Loss 0.254858, Valid_loss 1.160678
Epoch 21, Train Loss 0.230151, Valid_loss 0.915203
Epoch 22, Train Loss 0.341888, Valid_loss 1.192145
Epoch 23, Train Loss 0.230225, Valid_loss 1.360635
Epoch 24, Train Loss 0.205293, Valid_loss 0.622483
Epoch 25, Train Loss 0.199476, Valid_loss 0.759579
Epoch 26, Train Loss 0.197324, Valid_loss 0.905388
Epoch 27, Train Loss 0.223566, Valid_loss 1.008998
Epoch 28, Train Loss 0.197989, Valid_loss 0.732721
Epoch 29, Train Loss 0.251275, Valid_loss 1.077483
Epoch 30, Train Loss 0.204500, Valid_loss 0.553101
Epoch 31, Train Loss 0.216110, Valid_loss 1.662560
Epoch 32, Train Loss 0.276649, Valid_loss 1.120474
Epoch 33, Train Loss 0.254760, Valid_loss 0.631484
Epoch 34, Train Loss 0.180071, Valid_loss 0.935415
Epoch 35, Train Loss 0.255419, Valid_loss 0.967780
Epoch 36, Train Loss 0.215932, Valid_loss 0.748016
Epoch 37, Train Loss 0.189856, Valid_loss 0.726761
Epoch 38, Train Loss 0.164998, Valid_loss 1.315637
Epoch 39, Train Loss 0.175542, Valid_loss 0.770831
Epoch 40, Train Loss 0.148511, Valid_loss 0.874084
Epoch 41, Train Loss 0.160836, Valid_loss 0.703493
Epoch 42, Train Loss 0.131740, Valid_loss 0.841261
Epoch 43, Train Loss 0.158782, Valid_loss 0.872600
Epoch 44, Train Loss 0.129675, Valid_loss 1.043282
Epoch 45, Train Loss 0.236732, Valid_loss 0.837946
Epoch 46, Train Loss 0.189361, Valid_loss 1.026368
Epoch 47, Train Loss 0.189249, Valid_loss 1.406089
Epoch 48, Train Loss 0.130022, Valid_loss 0.500572
Epoch 49, Train Loss 0.201440, Valid_loss 1.405324
Epoch 50, Train Loss 0.170192, Valid_loss 1.924159
Epoch 51, Train Loss 0.150658, Valid_loss 0.889863
Epoch 52, Train Loss 0.154013, Valid_loss 0.651635
Epoch 53, Train Loss 0.148006, Valid_loss 0.968819
Epoch 54, Train Loss 0.114864, Valid_loss 0.861331
Epoch 55, Train Loss 0.111802, Valid_loss 0.757228
Epoch 56, Train Loss 0.104113, Valid_loss 0.909004
Epoch 57, Train Loss 0.114249, Valid_loss 0.772348
Epoch 58, Train Loss 0.127319, Valid_loss 1.068112
Epoch 59, Train Loss 0.130177, Valid_loss 0.680612
Epoch 60, Train Loss 0.110127, Valid_loss 0.729896
Epoch 61, Train Loss 0.100527, Valid_loss 0.634898
Epoch 62, Train Loss 0.109238, Valid_loss 0.900420
Epoch 63, Train Loss 0.121398, Valid_loss 1.005560
환자ID=P1290 -- true: [[2]] -- pred: tensor([[-2.2227,  1.1296,  0.7442]], device='cuda:0')
환자ID=P1300 -- true: [[2]] -- pred: tensor([[-2.1622,  1.2792,  0.6120]], device='cuda:0')
환자ID=P1479 -- true: [[1]] -- pred: tensor([[ 1.1526,  0.3975, -3.0764]], device='cuda:0')
환자ID=P1510 -- true: [[1]] -- pred: tensor([[-2.0157,  1.4615,  0.3572]], device='cuda:0')
환자ID=P1539 -- true: [[0]] -- pred: tensor([[ 3.2031, -2.6622, -4.0380]], device='cuda:0')
환자ID=P1547 -- true: [[0]] -- pred: tensor([[ 3.1983, -2.6168, -4.0634]], device='cuda:0')
환자ID=P1582 -- true: [[0]] -- pred: tensor([[ 3.1954, -2.6501, -4.0386]], device='cuda:0')
환자ID=P1630 -- true: [[1]] -- pred: tensor([[-2.1600,  1.2573,  0.6144]], device='cuda:0')
Best performance: Epoch 48, Loss 0.130022, Test ACC 0.625000, Test AUC 0.888889, Test Recall 0.555556, Test Precision 0.416667
Confusion Matrix:
 [[3 0 0]
 [1 2 0]
 [0 2 0]]
✅ Total valid splits used: 4
🔁 Repeat 0, Fold 4
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 472424, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 472424, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  CACACAACAATCGTCA-1-7              cardiac muscle cell
TGCGATATCGTAGTCA-1-7              cardiac muscle cell
ATTCACTAGTTAGAAC-1-7              cardiac muscle cell
CGAAGTTGTGGTCAAG-1-7              cardiac muscle cell
AAACCCAGTGAACCGA-1-7              cardiac muscle cell
                                     ...             
GTTCTATTCCTTCTAA-1-77        cardiac endothelial cell
GAGTCATTCATGGATC-1-77        cardiac endothelial cell
GGTGTTACAAGACAAT-1-77    cardiac ventricle fibroblast
AGCGTCGTCCTCACTG-1-77        cardiac endothelial cell
GTGCTGGCATGATAGA-1-77        cardiac endothelial cell
Name: manual_annotation, Length: 120265, dtype: string
cell type annotation :  CACACAACAATCGTCA-1-7              cardiac muscle cell
TGCGATATCGTAGTCA-1-7              cardiac muscle cell
ATTCACTAGTTAGAAC-1-7              cardiac muscle cell
CGAAGTTGTGGTCAAG-1-7              cardiac muscle cell
AAACCCAGTGAACCGA-1-7              cardiac muscle cell
                                     ...             
GTTCTATTCCTTCTAA-1-77        cardiac endothelial cell
GAGTCATTCATGGATC-1-77        cardiac endothelial cell
GGTGTTACAAGACAAT-1-77    cardiac ventricle fibroblast
AGCGTCGTCCTCACTG-1-77        cardiac endothelial cell
GTGCTGGCATGATAGA-1-77        cardiac endothelial cell
Name: manual_annotation, Length: 120265, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'cardiac endothelial cell', 'endothelial cell of lymphatic vessel', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac neuron', 'mesothelial cell', 'macrophage', 'mast cell', 'vascular associated smooth muscle cell', 'pericyte cell', 'lymphocyte']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 3}
🔍 Split #5
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1290', 'P1300', 'P1304', 'P1371', 'P1422', 'P1430', 'P1437', 'P1447', 'P1462', 'P1472', 'P1479', 'P1504', 'P1508', 'P1510', 'P1515', 'P1539', 'P1540', 'P1547', 'P1549', 'P1558', 'P1561', 'P1582', 'P1603', 'P1606', 'P1610', 'P1622', 'P1630', 'P1631', 'P1685', 'P1702', 'P1707', 'P1718', 'P1722', 'P1726']
  → test  환자 ID: ['P1358', 'P1425', 'P1516', 'P1600', 'P1602', 'P1617', 'P1678', 'P1735']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1726, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1358, Label: 2
    ID: P1425, Label: 1
    ID: P1516, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1617, Label: 2
    ID: P1678, Label: 0
    ID: P1735, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1539, Label=0, 셀개수=11076
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1582, Label=0, 셀개수=18855
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1735, Label=1, 셀개수=12009
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685        cardiac endothelial cell
592686    cardiac ventricle fibroblast
592687        cardiac endothelial cell
592688        cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.43it/s]  2%|▏         | 2/100 [00:00<00:10,  8.92it/s]  3%|▎         | 3/100 [00:00<00:10,  8.83it/s]  4%|▍         | 4/100 [00:00<00:10,  8.95it/s]  5%|▌         | 5/100 [00:00<00:10,  9.05it/s]  6%|▌         | 6/100 [00:00<00:10,  9.11it/s]  7%|▋         | 7/100 [00:00<00:10,  9.18it/s]  8%|▊         | 8/100 [00:00<00:10,  9.08it/s]  9%|▉         | 9/100 [00:01<00:10,  8.99it/s] 10%|█         | 10/100 [00:01<00:10,  8.99it/s] 11%|█         | 11/100 [00:01<00:09,  8.92it/s] 12%|█▏        | 12/100 [00:01<00:09,  8.96it/s] 13%|█▎        | 13/100 [00:01<00:09,  8.96it/s] 14%|█▍        | 14/100 [00:01<00:09,  9.00it/s] 15%|█▌        | 15/100 [00:01<00:09,  9.07it/s] 16%|█▌        | 16/100 [00:01<00:09,  9.06it/s] 17%|█▋        | 17/100 [00:01<00:09,  8.94it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.87it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.99it/s] 20%|██        | 20/100 [00:02<00:08,  8.99it/s] 21%|██        | 21/100 [00:02<00:08,  8.98it/s] 22%|██▏       | 22/100 [00:02<00:08,  8.82it/s] 23%|██▎       | 23/100 [00:02<00:08,  8.83it/s] 24%|██▍       | 24/100 [00:02<00:08,  8.96it/s] 25%|██▌       | 25/100 [00:02<00:08,  8.96it/s] 26%|██▌       | 26/100 [00:02<00:08,  8.89it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.81it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.87it/s] 29%|██▉       | 29/100 [00:03<00:07,  8.91it/s] 30%|███       | 30/100 [00:03<00:07,  8.83it/s] 31%|███       | 31/100 [00:03<00:07,  8.82it/s] 32%|███▏      | 32/100 [00:03<00:07,  8.73it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.94it/s] 34%|███▍      | 34/100 [00:03<00:07,  8.71it/s] 35%|███▌      | 35/100 [00:03<00:07,  8.92it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.90it/s] 37%|███▋      | 37/100 [00:04<00:06,  9.01it/s] 38%|███▊      | 38/100 [00:04<00:06,  8.89it/s] 39%|███▉      | 39/100 [00:04<00:06,  8.90it/s] 40%|████      | 40/100 [00:04<00:06,  9.08it/s] 41%|████      | 41/100 [00:04<00:06,  9.00it/s] 42%|████▏     | 42/100 [00:04<00:06,  9.15it/s] 43%|████▎     | 43/100 [00:04<00:06,  8.82it/s] 44%|████▍     | 44/100 [00:04<00:06,  8.81it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.76it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.58it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.65it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.61it/s] 49%|████▉     | 49/100 [00:05<00:05,  8.75it/s] 50%|█████     | 50/100 [00:05<00:05,  8.72it/s] 51%|█████     | 51/100 [00:05<00:05,  8.56it/s] 52%|█████▏    | 52/100 [00:05<00:05,  8.62it/s] 53%|█████▎    | 53/100 [00:05<00:05,  8.68it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.57it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.67it/s] 56%|█████▌    | 56/100 [00:06<00:04,  8.89it/s] 57%|█████▋    | 57/100 [00:06<00:04,  8.94it/s] 58%|█████▊    | 58/100 [00:06<00:04,  8.96it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.80it/s] 60%|██████    | 60/100 [00:06<00:04,  8.83it/s] 61%|██████    | 61/100 [00:06<00:04,  8.61it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.57it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.49it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.67it/s] 65%|██████▌   | 65/100 [00:07<00:03,  8.83it/s] 66%|██████▌   | 66/100 [00:07<00:03,  8.73it/s] 67%|██████▋   | 67/100 [00:07<00:03,  8.72it/s] 68%|██████▊   | 68/100 [00:07<00:03,  8.77it/s] 69%|██████▉   | 69/100 [00:07<00:03,  8.62it/s] 70%|███████   | 70/100 [00:07<00:03,  8.64it/s] 71%|███████   | 71/100 [00:08<00:03,  8.65it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.85it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.72it/s] 74%|███████▍  | 74/100 [00:08<00:03,  8.58it/s] 75%|███████▌  | 75/100 [00:08<00:02,  8.55it/s] 76%|███████▌  | 76/100 [00:08<00:02,  8.57it/s] 77%|███████▋  | 77/100 [00:08<00:02,  8.56it/s] 78%|███████▊  | 78/100 [00:08<00:02,  8.50it/s] 79%|███████▉  | 79/100 [00:08<00:02,  8.40it/s] 80%|████████  | 80/100 [00:09<00:02,  8.44it/s] 81%|████████  | 81/100 [00:09<00:02,  8.50it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.58it/s] 83%|████████▎ | 83/100 [00:09<00:01,  8.65it/s] 84%|████████▍ | 84/100 [00:09<00:01,  8.59it/s] 85%|████████▌ | 85/100 [00:09<00:01,  8.56it/s] 86%|████████▌ | 86/100 [00:09<00:01,  8.59it/s] 87%|████████▋ | 87/100 [00:09<00:01,  8.64it/s] 88%|████████▊ | 88/100 [00:10<00:01,  8.46it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.55it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.54it/s] 91%|█████████ | 91/100 [00:10<00:01,  8.44it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.51it/s] 93%|█████████▎| 93/100 [00:10<00:00,  8.62it/s] 94%|█████████▍| 94/100 [00:10<00:00,  8.51it/s] 95%|█████████▌| 95/100 [00:10<00:00,  8.49it/s] 96%|█████████▌| 96/100 [00:10<00:00,  8.51it/s] 97%|█████████▋| 97/100 [00:11<00:00,  8.38it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.39it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.46it/s]100%|██████████| 100/100 [00:11<00:00,  8.40it/s]100%|██████████| 100/100 [00:11<00:00,  8.74it/s]
[I 2025-08-27 09:22:50,465] A new study created in memory with name: no-name-c57f89e0-70d2-4e94-bd21-707fab0748dc
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16934.53 MB
Memory Reserved: 16952.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 341.79 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.90 MB
Memory Reserved: 16960.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 342.12 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 09:22:51,811] Trial 0 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16931.43 MB
Memory Reserved: 16962.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16903.99 MB
Memory Reserved: 16922.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 313.89 MB
Memory Reserved: 350.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16903.99 MB
Memory Reserved: 16942.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 312.97 MB
Memory Reserved: 332.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 09:22:53,211] Trial 1 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16904.06 MB
Memory Reserved: 16944.00 MB
cuda
Epoch 1, Train Loss 0.944681, Valid_loss 1.557345
Epoch 2, Train Loss 0.847991, Valid_loss 1.429951
Epoch 3, Train Loss 0.685444, Valid_loss 1.163064
Epoch 4, Train Loss 0.556548, Valid_loss 0.886313
Epoch 5, Train Loss 0.488634, Valid_loss 1.521535
Epoch 6, Train Loss 0.408394, Valid_loss 0.907396
Epoch 7, Train Loss 0.433009, Valid_loss 0.865132
Epoch 8, Train Loss 0.462011, Valid_loss 0.768850
Epoch 9, Train Loss 0.473982, Valid_loss 0.766441
Epoch 10, Train Loss 0.373963, Valid_loss 1.097300
Epoch 11, Train Loss 0.356207, Valid_loss 0.960733
Epoch 12, Train Loss 0.462859, Valid_loss 0.899915
Epoch 13, Train Loss 0.382173, Valid_loss 0.939337
Epoch 14, Train Loss 0.410928, Valid_loss 0.616298
Epoch 15, Train Loss 0.423727, Valid_loss 0.835810
Epoch 16, Train Loss 0.354230, Valid_loss 1.013790
Epoch 17, Train Loss 0.383236, Valid_loss 1.075001
Epoch 18, Train Loss 0.364974, Valid_loss 0.769735
Epoch 19, Train Loss 0.279971, Valid_loss 0.888742
Epoch 20, Train Loss 0.352386, Valid_loss 0.680722
Epoch 21, Train Loss 0.369281, Valid_loss 0.599284
Epoch 22, Train Loss 0.268751, Valid_loss 1.002944
Epoch 23, Train Loss 0.305634, Valid_loss 1.380869
Epoch 24, Train Loss 0.355697, Valid_loss 1.086962
Epoch 25, Train Loss 0.274746, Valid_loss 1.320368
Epoch 26, Train Loss 0.293854, Valid_loss 1.120731
Epoch 27, Train Loss 0.263660, Valid_loss 1.226721
Epoch 28, Train Loss 0.306454, Valid_loss 1.268570
Epoch 29, Train Loss 0.250637, Valid_loss 0.572790
Epoch 30, Train Loss 0.301042, Valid_loss 0.498557
Epoch 31, Train Loss 0.358307, Valid_loss 1.150729
Epoch 32, Train Loss 0.219171, Valid_loss 1.073733
Epoch 33, Train Loss 0.147430, Valid_loss 1.115595
Epoch 34, Train Loss 0.219661, Valid_loss 0.820950
Epoch 35, Train Loss 0.184487, Valid_loss 1.317239
Epoch 36, Train Loss 0.175016, Valid_loss 1.044742
Epoch 37, Train Loss 0.188402, Valid_loss 0.662922
Epoch 38, Train Loss 0.336662, Valid_loss 2.346998
Epoch 39, Train Loss 0.246370, Valid_loss 0.750689
Epoch 40, Train Loss 0.166490, Valid_loss 1.377187
Epoch 41, Train Loss 0.252621, Valid_loss 1.426415
Epoch 42, Train Loss 0.257202, Valid_loss 1.866496
Epoch 43, Train Loss 0.237924, Valid_loss 1.082356
Epoch 44, Train Loss 0.189714, Valid_loss 0.569777
Epoch 45, Train Loss 0.173485, Valid_loss 1.077179
Epoch 46, Train Loss 0.275308, Valid_loss 0.673444
Epoch 47, Train Loss 0.140147, Valid_loss 1.270461
Epoch 48, Train Loss 0.110803, Valid_loss 2.019406
Epoch 49, Train Loss 0.160461, Valid_loss 0.707959
Epoch 50, Train Loss 0.157628, Valid_loss 1.699996
Epoch 51, Train Loss 0.161620, Valid_loss 1.338707
Epoch 52, Train Loss 0.200509, Valid_loss 0.799245
Epoch 53, Train Loss 0.120397, Valid_loss 0.664324
Epoch 54, Train Loss 0.144917, Valid_loss 0.769259
Epoch 55, Train Loss 0.127595, Valid_loss 1.340729
[I 2025-08-27 09:54:07,629] Trial 2 finished with value: 0.498557275296965 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.498557275296965.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.95 MB
Memory Reserved: 8626.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.97 MB
Memory Reserved: 8658.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.85 MB
Memory Reserved: 8624.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.97 MB
Memory Reserved: 8656.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 09:54:09,014] Trial 3 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8621.20 MB
Memory Reserved: 8626.00 MB
cuda
Epoch 1, Train Loss 0.939767, Valid_loss 1.380655
Epoch 2, Train Loss 0.785954, Valid_loss 1.184792
Epoch 3, Train Loss 0.650728, Valid_loss 1.100637
Epoch 4, Train Loss 0.527182, Valid_loss 1.248577
Epoch 5, Train Loss 0.583581, Valid_loss 1.157902
Epoch 6, Train Loss 0.497284, Valid_loss 1.063835
Epoch 7, Train Loss 0.473567, Valid_loss 0.926382
Epoch 8, Train Loss 0.441558, Valid_loss 0.814073
Epoch 9, Train Loss 0.424280, Valid_loss 1.080631
Epoch 10, Train Loss 0.467344, Valid_loss 1.201863
Epoch 11, Train Loss 0.397529, Valid_loss 1.133372
Epoch 12, Train Loss 0.560073, Valid_loss 0.923925
Epoch 13, Train Loss 0.372561, Valid_loss 0.696721
Epoch 14, Train Loss 0.397380, Valid_loss 0.925557
Epoch 15, Train Loss 0.403820, Valid_loss 1.098643
Epoch 16, Train Loss 0.361988, Valid_loss 0.677334
Epoch 17, Train Loss 0.424597, Valid_loss 1.088164
Epoch 18, Train Loss 0.327910, Valid_loss 1.205233
Epoch 19, Train Loss 0.376953, Valid_loss 1.140295
Epoch 20, Train Loss 0.323818, Valid_loss 1.040961
Epoch 21, Train Loss 0.386938, Valid_loss 1.655970
Epoch 22, Train Loss 0.399450, Valid_loss 1.851918
Epoch 23, Train Loss 0.434849, Valid_loss 1.214936
Epoch 24, Train Loss 0.312783, Valid_loss 1.425958
Epoch 25, Train Loss 0.325156, Valid_loss 1.360302
Epoch 26, Train Loss 0.389909, Valid_loss 1.037701
Epoch 27, Train Loss 0.283660, Valid_loss 1.373070
Epoch 28, Train Loss 0.218679, Valid_loss 1.230303
Epoch 29, Train Loss 0.294531, Valid_loss 1.365194
Epoch 30, Train Loss 0.311509, Valid_loss 1.499823
Epoch 31, Train Loss 0.296725, Valid_loss 1.621073
Epoch 32, Train Loss 0.251002, Valid_loss 1.381628
Epoch 33, Train Loss 0.320311, Valid_loss 1.786097
Epoch 34, Train Loss 0.322339, Valid_loss 1.411753
Epoch 35, Train Loss 0.237525, Valid_loss 1.373465
Epoch 36, Train Loss 0.248379, Valid_loss 1.579829
Epoch 37, Train Loss 0.341912, Valid_loss 1.480968
Epoch 38, Train Loss 0.272567, Valid_loss 1.100926
Epoch 39, Train Loss 0.237342, Valid_loss 1.297987
Epoch 40, Train Loss 0.192651, Valid_loss 1.085076
Epoch 41, Train Loss 0.238040, Valid_loss 1.920477
Epoch 42, Train Loss 0.278851, Valid_loss 1.073282
Epoch 43, Train Loss 0.238873, Valid_loss 1.911946
Epoch 44, Train Loss 0.211576, Valid_loss 1.513759
Epoch 45, Train Loss 0.154767, Valid_loss 1.842525
Epoch 46, Train Loss 0.235311, Valid_loss 0.933477
Epoch 47, Train Loss 0.214018, Valid_loss 1.531059
Epoch 48, Train Loss 0.179241, Valid_loss 1.340818
Epoch 49, Train Loss 0.219651, Valid_loss 1.131473
Epoch 50, Train Loss 0.134515, Valid_loss 0.783066
Epoch 51, Train Loss 0.146577, Valid_loss 1.508448
Epoch 52, Train Loss 0.198835, Valid_loss 1.758171
[I 2025-08-27 10:23:45,413] Trial 4 finished with value: 0.6773344224008421 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.498557275296965.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8600.90 MB
Memory Reserved: 8608.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8601.36 MB
Memory Reserved: 8628.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8600.95 MB
Memory Reserved: 8628.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8601.36 MB
Memory Reserved: 8628.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 10:23:46,795] Trial 5 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16934.53 MB
Memory Reserved: 16952.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 341.79 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.90 MB
Memory Reserved: 16960.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 342.12 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 10:23:48,390] Trial 6 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.51 MB
Memory Reserved: 16960.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 341.71 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.67 MB
Memory Reserved: 16960.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 341.71 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.67 MB
Memory Reserved: 16960.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 10:23:49,666] Trial 7 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16934.53 MB
Memory Reserved: 16952.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 341.79 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.90 MB
Memory Reserved: 16960.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 342.12 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 10:23:51,238] Trial 8 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.51 MB
Memory Reserved: 16960.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 4489.71 MB
Memory Reserved: 4528.00 MB
cuda
Epoch 1, Train Loss 1.032907, Valid_loss 1.321495
Epoch 2, Train Loss 0.976490, Valid_loss 1.438150
Epoch 3, Train Loss 0.933035, Valid_loss 1.465262
Epoch 4, Train Loss 0.928650, Valid_loss 1.240913
Epoch 5, Train Loss 0.939814, Valid_loss 1.803568
Epoch 6, Train Loss 0.917593, Valid_loss 1.375638
Epoch 7, Train Loss 0.910283, Valid_loss 1.595814
Epoch 8, Train Loss 0.923326, Valid_loss 1.612643
Epoch 9, Train Loss 0.905463, Valid_loss 1.790784
Epoch 10, Train Loss 0.912905, Valid_loss 1.823931
Epoch 11, Train Loss 0.926455, Valid_loss 1.532791
Epoch 12, Train Loss 0.911955, Valid_loss 1.644758
Epoch 13, Train Loss 0.934678, Valid_loss 1.387807
Epoch 14, Train Loss 0.913151, Valid_loss 1.539524
Epoch 15, Train Loss 0.923294, Valid_loss 1.566748
Epoch 16, Train Loss 0.912036, Valid_loss 1.396720
Epoch 17, Train Loss 0.910450, Valid_loss 1.468050
Epoch 18, Train Loss 0.907030, Valid_loss 1.456267
Epoch 19, Train Loss 0.899874, Valid_loss 1.507229
Epoch 20, Train Loss 0.913542, Valid_loss 1.535675
Epoch 21, Train Loss 0.901018, Valid_loss 1.549285
Epoch 22, Train Loss 0.920985, Valid_loss 1.555682
Epoch 23, Train Loss 0.903623, Valid_loss 1.512592
Epoch 24, Train Loss 0.897280, Valid_loss 1.509501
Epoch 25, Train Loss 0.901163, Valid_loss 1.497114
Epoch 26, Train Loss 0.897956, Valid_loss 1.526806
Epoch 27, Train Loss 0.898159, Valid_loss 1.527806
Epoch 28, Train Loss 0.897235, Valid_loss 1.553839
Epoch 29, Train Loss 0.908461, Valid_loss 1.534220
Epoch 30, Train Loss 0.910833, Valid_loss 1.538681
Epoch 31, Train Loss 0.895740, Valid_loss 1.524343
Epoch 32, Train Loss 0.918893, Valid_loss 1.530585
Epoch 33, Train Loss 0.906173, Valid_loss 1.506790
Epoch 34, Train Loss 0.896183, Valid_loss 1.525392
Epoch 35, Train Loss 0.894501, Valid_loss 1.545241
Epoch 36, Train Loss 0.898583, Valid_loss 1.540316
Epoch 37, Train Loss 0.898817, Valid_loss 1.776562
Epoch 38, Train Loss 0.900757, Valid_loss 1.518675
Epoch 39, Train Loss 0.908407, Valid_loss 1.489264
Epoch 40, Train Loss 0.896165, Valid_loss 1.493683
Epoch 41, Train Loss 0.897463, Valid_loss 1.495936
Epoch 42, Train Loss 0.897698, Valid_loss 1.529736
Epoch 43, Train Loss 0.894281, Valid_loss 1.525695
Epoch 44, Train Loss 0.902618, Valid_loss 1.516671
Epoch 45, Train Loss 0.894803, Valid_loss 1.508358
Epoch 46, Train Loss 0.895887, Valid_loss 1.538366
Epoch 47, Train Loss 0.895660, Valid_loss 1.520160
Epoch 48, Train Loss 0.893936, Valid_loss 1.447065
Epoch 49, Train Loss 0.904595, Valid_loss 1.594303
Epoch 50, Train Loss 0.899440, Valid_loss 1.533995
Epoch 51, Train Loss 0.892155, Valid_loss 1.527326
Epoch 52, Train Loss 0.892869, Valid_loss 1.539925
Epoch 53, Train Loss 0.892073, Valid_loss 1.530779
Epoch 54, Train Loss 0.893203, Valid_loss 1.538613
Epoch 55, Train Loss 0.893353, Valid_loss 1.522080
Epoch 56, Train Loss 0.892261, Valid_loss 1.528205
Epoch 57, Train Loss 0.891752, Valid_loss 1.530920
[I 2025-08-27 10:57:02,607] Trial 9 finished with value: 1.2409133662780125 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.01, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.498557275296965.
선택된 trial params: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 4487.87 MB
Memory Reserved: 4530.00 MB
cuda
Epoch 1, Train Loss 1.045511, Valid_loss 1.583492
Epoch 2, Train Loss 0.945068, Valid_loss 1.216130
Epoch 3, Train Loss 0.783753, Valid_loss 1.159869
Epoch 4, Train Loss 0.777418, Valid_loss 1.130709
Epoch 5, Train Loss 0.532880, Valid_loss 1.020357
Epoch 6, Train Loss 0.541848, Valid_loss 1.068480
Epoch 7, Train Loss 0.479842, Valid_loss 0.990947
Epoch 8, Train Loss 0.424885, Valid_loss 1.064940
Epoch 9, Train Loss 0.485963, Valid_loss 0.913520
Epoch 10, Train Loss 0.478873, Valid_loss 1.115628
Epoch 11, Train Loss 0.426903, Valid_loss 1.035736
Epoch 12, Train Loss 0.438862, Valid_loss 1.005621
Epoch 13, Train Loss 0.416635, Valid_loss 1.080899
Epoch 14, Train Loss 0.353251, Valid_loss 0.990077
Epoch 15, Train Loss 0.381193, Valid_loss 0.904163
Epoch 16, Train Loss 0.396317, Valid_loss 0.968351
Epoch 17, Train Loss 0.326099, Valid_loss 1.104933
Epoch 18, Train Loss 0.365205, Valid_loss 0.939159
Epoch 19, Train Loss 0.410260, Valid_loss 1.025414
Epoch 20, Train Loss 0.410704, Valid_loss 0.925974
Epoch 21, Train Loss 0.361711, Valid_loss 0.856882
Epoch 22, Train Loss 0.334429, Valid_loss 1.250777
Epoch 23, Train Loss 0.378365, Valid_loss 1.422390
Epoch 24, Train Loss 0.346669, Valid_loss 0.910976
Epoch 25, Train Loss 0.332746, Valid_loss 1.252389
Epoch 26, Train Loss 0.290110, Valid_loss 1.288709
Epoch 27, Train Loss 0.323233, Valid_loss 1.115006
Epoch 28, Train Loss 0.381151, Valid_loss 1.129730
Epoch 29, Train Loss 0.386065, Valid_loss 1.233410
Epoch 30, Train Loss 0.268428, Valid_loss 1.202547
Epoch 31, Train Loss 0.288783, Valid_loss 1.214003
Epoch 32, Train Loss 0.307455, Valid_loss 1.744627
Epoch 33, Train Loss 0.304534, Valid_loss 1.475728
Epoch 34, Train Loss 0.306037, Valid_loss 0.368813
Epoch 35, Train Loss 0.441573, Valid_loss 0.523418
Epoch 36, Train Loss 0.381689, Valid_loss 1.788215
Epoch 37, Train Loss 0.383873, Valid_loss 0.739225
Epoch 38, Train Loss 0.298022, Valid_loss 0.992396
Epoch 39, Train Loss 0.280562, Valid_loss 0.562699
Epoch 40, Train Loss 0.271196, Valid_loss 1.428659
Epoch 41, Train Loss 0.320492, Valid_loss 1.696390
Epoch 42, Train Loss 0.331182, Valid_loss 1.177555
Epoch 43, Train Loss 0.231698, Valid_loss 0.977679
Epoch 44, Train Loss 0.261324, Valid_loss 1.397568
Epoch 45, Train Loss 0.261388, Valid_loss 2.164420
Epoch 46, Train Loss 0.275675, Valid_loss 0.916767
Epoch 47, Train Loss 0.273835, Valid_loss 0.843588
Epoch 48, Train Loss 0.270144, Valid_loss 1.610653
Epoch 49, Train Loss 0.247766, Valid_loss 1.150134
Epoch 50, Train Loss 0.370797, Valid_loss 0.985261
Epoch 51, Train Loss 0.217872, Valid_loss 1.653605
Epoch 52, Train Loss 0.200784, Valid_loss 1.481893
Epoch 53, Train Loss 0.192712, Valid_loss 1.278792
Epoch 54, Train Loss 0.172770, Valid_loss 1.407752
Epoch 55, Train Loss 0.212696, Valid_loss 1.447840
환자ID=P1358 -- true: [[2]] -- pred: tensor([[-2.5051,  0.4211,  0.5005]], device='cuda:0')
환자ID=P1425 -- true: [[1]] -- pred: tensor([[-2.3495,  0.3140,  0.5127]], device='cuda:0')
환자ID=P1516 -- true: [[0]] -- pred: tensor([[ 4.3719, -1.7653, -5.7397]], device='cuda:0')
환자ID=P1600 -- true: [[0]] -- pred: tensor([[ 4.3596, -1.8083, -5.6633]], device='cuda:0')
환자ID=P1602 -- true: [[1]] -- pred: tensor([[-1.1682,  1.5576, -2.6030]], device='cuda:0')
환자ID=P1617 -- true: [[2]] -- pred: tensor([[-2.4249,  0.3587,  0.5104]], device='cuda:0')
환자ID=P1678 -- true: [[0]] -- pred: tensor([[ 4.3721, -1.8103, -5.6773]], device='cuda:0')
환자ID=P1735 -- true: [[1]] -- pred: tensor([[-2.3721,  0.3257,  0.5140]], device='cuda:0')
Best performance: Epoch 34, Loss 0.306037, Test ACC 0.750000, Test AUC 0.777778, Test Recall 0.777778, Test Precision 0.833333
Confusion Matrix:
 [[3 0 0]
 [0 1 2]
 [0 0 2]]
✅ Total valid splits used: 5

📌 Repeat 0: 평균 AUC = 0.8185, 표준편차 = 0.1348
Test ACC 평균 0.672222, Test Recall 평균 0.644444, Test Precision 평균 0.556667
fold_aucs = [0.8333333333333334, 0.5925925925925927, 1.0, 0.888888888888889, 0.7777777777777778]
NaN 개수: 0 / 전체 5개

🔁 Repeat 1, Fold 0
cell type :  ACAGCCGCAAGCGAGT-1-1          cardiac muscle cell
ATATCCTGTCCCTAAA-1-1          cardiac muscle cell
CAATGACCAGTTGTCA-1-1          cardiac muscle cell
CTAGACACAAGGTTGG-1-1          cardiac muscle cell
ATCGTCCGTATTTCTC-1-1          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 462466, dtype: string
cell type annotation :  ACAGCCGCAAGCGAGT-1-1          cardiac muscle cell
ATATCCTGTCCCTAAA-1-1          cardiac muscle cell
CAATGACCAGTTGTCA-1-1          cardiac muscle cell
CTAGACACAAGGTTGG-1-1          cardiac muscle cell
ATCGTCCGTATTTCTC-1-1          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 462466, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'mesothelial cell', 'macrophage', 'fat cell', 'endocardial cell', 'cardiac neuron', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'lymphocyte', 'mast cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 12}
cell type :  TTCTTCCGTTCAACGT-1-0                        cardiac muscle cell
CATCCACCATCTAACG-1-0                        cardiac muscle cell
ACCCAAACAGCTAACT-1-0                        cardiac muscle cell
AAGGAATCAACTGGTT-1-0                        cardiac muscle cell
TACCCGTAGCGTGCTC-1-0                        cardiac muscle cell
                                          ...                  
AAGTGAAGTGGCGTAA-1-71                  cardiac endothelial cell
CTTTCAAGTTTCACAG-1-71    vascular associated smooth muscle cell
GGGTGAATCATCGACA-1-71                                macrophage
CTGTGGGAGGAGGTTC-1-71                                macrophage
TGTTCATTCTGGCCGA-1-71                  cardiac endothelial cell
Name: manual_annotation, Length: 130223, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0                        cardiac muscle cell
CATCCACCATCTAACG-1-0                        cardiac muscle cell
ACCCAAACAGCTAACT-1-0                        cardiac muscle cell
AAGGAATCAACTGGTT-1-0                        cardiac muscle cell
TACCCGTAGCGTGCTC-1-0                        cardiac muscle cell
                                          ...                  
AAGTGAAGTGGCGTAA-1-71                  cardiac endothelial cell
CTTTCAAGTTTCACAG-1-71    vascular associated smooth muscle cell
GGGTGAATCATCGACA-1-71                                macrophage
CTGTGGGAGGAGGTTC-1-71                                macrophage
TGTTCATTCTGGCCGA-1-71                  cardiac endothelial cell
Name: manual_annotation, Length: 130223, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 4}
🔍 Split #1
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 33
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 9
  → train 환자 ID: ['P1290', 'P1300', 'P1358', 'P1371', 'P1422', 'P1425', 'P1430', 'P1447', 'P1462', 'P1472', 'P1479', 'P1504', 'P1515', 'P1516', 'P1539', 'P1540', 'P1547', 'P1549', 'P1558', 'P1561', 'P1582', 'P1600', 'P1602', 'P1603', 'P1606', 'P1617', 'P1631', 'P1685', 'P1702', 'P1707', 'P1722', 'P1726', 'P1735']
  → test  환자 ID: ['P1304', 'P1437', 'P1508', 'P1510', 'P1610', 'P1622', 'P1630', 'P1678', 'P1718']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1617, Label: 2
    ID: P1631, Label: 1
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1722, Label: 1
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1304, Label: 2
    ID: P1437, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1610, Label: 0
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1678, Label: 0
    ID: P1718, Label: 0
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 33
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 33
기존 (train) label_stat 33
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 11
test_p_index 9
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1540, Label=0, 셀개수=11638
→ valid 환자 ID 및 라벨:
   총 개수: 11
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1606, Label=2, 셀개수=8523
→ test 환자 ID 및 라벨:
   총 개수: 9
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1718, Label=0, 셀개수=9278
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                            cardiac muscle cell
1                            cardiac muscle cell
2                            cardiac muscle cell
3                            cardiac muscle cell
4                            cardiac muscle cell
                           ...                  
592684                  cardiac endothelial cell
592685    vascular associated smooth muscle cell
592686                                macrophage
592687                                macrophage
592688                  cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:12,  1.36it/s]  2%|▏         | 2/100 [00:00<00:37,  2.60it/s]  3%|▎         | 3/100 [00:01<00:26,  3.67it/s]  4%|▍         | 4/100 [00:01<00:20,  4.79it/s]  5%|▌         | 5/100 [00:01<00:16,  5.73it/s]  6%|▌         | 6/100 [00:01<00:14,  6.60it/s]  7%|▋         | 7/100 [00:01<00:12,  7.20it/s]  8%|▊         | 8/100 [00:01<00:12,  7.44it/s]  9%|▉         | 9/100 [00:01<00:11,  7.59it/s] 10%|█         | 10/100 [00:01<00:11,  8.05it/s] 11%|█         | 11/100 [00:01<00:10,  8.28it/s] 12%|█▏        | 12/100 [00:02<00:10,  8.31it/s] 13%|█▎        | 13/100 [00:02<00:10,  8.09it/s] 14%|█▍        | 14/100 [00:02<00:21,  3.93it/s] 15%|█▌        | 15/100 [00:02<00:17,  4.74it/s] 16%|█▌        | 16/100 [00:03<00:17,  4.87it/s] 17%|█▋        | 17/100 [00:03<00:14,  5.66it/s] 18%|█▊        | 18/100 [00:03<00:15,  5.41it/s] 19%|█▉        | 19/100 [00:04<00:29,  2.72it/s] 20%|██        | 20/100 [00:04<00:25,  3.18it/s] 21%|██        | 21/100 [00:04<00:25,  3.10it/s] 22%|██▏       | 22/100 [00:04<00:20,  3.84it/s] 23%|██▎       | 23/100 [00:04<00:16,  4.54it/s] 24%|██▍       | 24/100 [00:05<00:14,  5.23it/s] 25%|██▌       | 25/100 [00:05<00:12,  5.99it/s] 26%|██▌       | 26/100 [00:05<00:11,  6.72it/s] 27%|██▋       | 27/100 [00:05<00:10,  7.09it/s] 28%|██▊       | 28/100 [00:05<00:10,  6.83it/s] 29%|██▉       | 29/100 [00:06<00:30,  2.37it/s] 30%|███       | 30/100 [00:06<00:23,  3.02it/s] 31%|███       | 31/100 [00:06<00:20,  3.42it/s] 32%|███▏      | 32/100 [00:07<00:16,  4.07it/s] 33%|███▎      | 33/100 [00:07<00:14,  4.50it/s] 34%|███▍      | 34/100 [00:08<00:29,  2.21it/s] 35%|███▌      | 35/100 [00:08<00:23,  2.82it/s] 36%|███▌      | 36/100 [00:08<00:18,  3.54it/s] 37%|███▋      | 37/100 [00:08<00:14,  4.25it/s] 38%|███▊      | 38/100 [00:09<00:18,  3.30it/s] 39%|███▉      | 39/100 [00:09<00:15,  4.02it/s] 40%|████      | 40/100 [00:09<00:13,  4.46it/s] 41%|████      | 41/100 [00:10<00:23,  2.54it/s] 42%|████▏     | 42/100 [00:10<00:18,  3.17it/s] 43%|████▎     | 43/100 [00:10<00:15,  3.72it/s] 44%|████▍     | 44/100 [00:10<00:12,  4.46it/s] 45%|████▌     | 45/100 [00:10<00:11,  4.66it/s] 46%|████▌     | 46/100 [00:10<00:10,  5.24it/s] 47%|████▋     | 47/100 [00:11<00:11,  4.54it/s] 48%|████▊     | 48/100 [00:11<00:09,  5.31it/s] 49%|████▉     | 49/100 [00:11<00:08,  5.87it/s] 50%|█████     | 50/100 [00:11<00:07,  6.39it/s] 51%|█████     | 51/100 [00:11<00:07,  6.64it/s] 52%|█████▏    | 52/100 [00:11<00:07,  6.76it/s] 53%|█████▎    | 53/100 [00:11<00:06,  7.21it/s] 54%|█████▍    | 54/100 [00:12<00:06,  7.62it/s] 55%|█████▌    | 55/100 [00:12<00:05,  7.87it/s] 56%|█████▌    | 56/100 [00:12<00:05,  8.11it/s] 57%|█████▋    | 57/100 [00:12<00:05,  8.13it/s] 58%|█████▊    | 58/100 [00:13<00:15,  2.68it/s] 59%|█████▉    | 59/100 [00:13<00:12,  3.21it/s] 60%|██████    | 60/100 [00:13<00:10,  3.93it/s] 61%|██████    | 61/100 [00:13<00:10,  3.75it/s] 62%|██████▏   | 62/100 [00:14<00:09,  4.11it/s] 63%|██████▎   | 63/100 [00:14<00:07,  4.85it/s] 64%|██████▍   | 64/100 [00:14<00:06,  5.52it/s] 65%|██████▌   | 65/100 [00:14<00:05,  5.90it/s] 66%|██████▌   | 66/100 [00:14<00:05,  6.34it/s] 67%|██████▋   | 67/100 [00:14<00:05,  6.47it/s] 68%|██████▊   | 68/100 [00:15<00:08,  3.72it/s] 69%|██████▉   | 69/100 [00:15<00:06,  4.46it/s] 70%|███████   | 70/100 [00:15<00:05,  5.13it/s] 71%|███████   | 71/100 [00:15<00:05,  5.28it/s] 72%|███████▏  | 72/100 [00:16<00:12,  2.30it/s] 73%|███████▎  | 73/100 [00:16<00:09,  2.96it/s] 74%|███████▍  | 74/100 [00:17<00:09,  2.60it/s] 75%|███████▌  | 75/100 [00:17<00:08,  3.12it/s] 76%|███████▌  | 76/100 [00:17<00:06,  3.82it/s] 77%|███████▋  | 77/100 [00:17<00:05,  4.31it/s] 78%|███████▊  | 78/100 [00:17<00:04,  4.87it/s] 79%|███████▉  | 79/100 [00:19<00:13,  1.60it/s] 80%|████████  | 80/100 [00:19<00:10,  1.87it/s] 81%|████████  | 81/100 [00:20<00:08,  2.30it/s] 82%|████████▏ | 82/100 [00:20<00:06,  2.92it/s] 83%|████████▎ | 83/100 [00:20<00:04,  3.61it/s] 84%|████████▍ | 84/100 [00:20<00:03,  4.34it/s] 85%|████████▌ | 85/100 [00:20<00:02,  5.10it/s] 86%|████████▌ | 86/100 [00:20<00:02,  5.83it/s] 87%|████████▋ | 87/100 [00:20<00:02,  6.42it/s] 88%|████████▊ | 88/100 [00:20<00:01,  6.37it/s] 89%|████████▉ | 89/100 [00:21<00:01,  6.89it/s] 90%|█████████ | 90/100 [00:21<00:03,  3.13it/s] 91%|█████████ | 91/100 [00:21<00:02,  3.87it/s] 92%|█████████▏| 92/100 [00:22<00:01,  4.60it/s] 93%|█████████▎| 93/100 [00:22<00:01,  5.35it/s] 94%|█████████▍| 94/100 [00:22<00:01,  5.99it/s] 95%|█████████▌| 95/100 [00:22<00:00,  6.50it/s] 96%|█████████▌| 96/100 [00:22<00:00,  6.54it/s] 97%|█████████▋| 97/100 [00:22<00:00,  6.90it/s] 98%|█████████▊| 98/100 [00:22<00:00,  7.32it/s] 99%|█████████▉| 99/100 [00:22<00:00,  7.61it/s]100%|██████████| 100/100 [00:23<00:00,  7.94it/s]100%|██████████| 100/100 [00:23<00:00,  4.34it/s]
[I 2025-08-27 11:29:57,102] A new study created in memory with name: no-name-31cded88-233d-47bf-b4fd-f11e0639877b
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.033650, Valid_loss 1.371592
Epoch 2, Train Loss 0.911017, Valid_loss 1.426268
Epoch 3, Train Loss 0.721266, Valid_loss 1.551676
Epoch 4, Train Loss 0.628574, Valid_loss 1.097414
Epoch 5, Train Loss 0.527937, Valid_loss 1.393083
Epoch 6, Train Loss 0.493063, Valid_loss 1.241368
Epoch 7, Train Loss 0.474058, Valid_loss 1.159182
Epoch 8, Train Loss 0.472502, Valid_loss 1.090336
Epoch 9, Train Loss 0.397827, Valid_loss 1.387167
Epoch 10, Train Loss 0.469940, Valid_loss 1.226456
Epoch 11, Train Loss 0.442682, Valid_loss 1.182762
Epoch 12, Train Loss 0.409134, Valid_loss 1.111614
Epoch 13, Train Loss 0.436079, Valid_loss 1.364290
Epoch 14, Train Loss 0.438409, Valid_loss 1.098852
Epoch 15, Train Loss 0.350234, Valid_loss 1.452972
Epoch 16, Train Loss 0.362981, Valid_loss 1.093399
Epoch 17, Train Loss 0.347911, Valid_loss 1.472685
Epoch 18, Train Loss 0.443564, Valid_loss 1.406838
Epoch 19, Train Loss 0.401652, Valid_loss 0.849382
Epoch 20, Train Loss 0.369034, Valid_loss 0.904144
Epoch 21, Train Loss 0.308724, Valid_loss 1.289819
Epoch 22, Train Loss 0.343711, Valid_loss 1.479088
Epoch 23, Train Loss 0.294123, Valid_loss 0.955897
Epoch 24, Train Loss 0.354503, Valid_loss 0.815591
Epoch 25, Train Loss 0.347049, Valid_loss 0.766815
Epoch 26, Train Loss 0.355386, Valid_loss 1.472428
Epoch 27, Train Loss 0.254599, Valid_loss 1.400694
Epoch 28, Train Loss 0.335307, Valid_loss 1.322945
Epoch 29, Train Loss 0.411766, Valid_loss 1.614695
Epoch 30, Train Loss 0.245462, Valid_loss 1.088103
Epoch 31, Train Loss 0.298909, Valid_loss 1.017070
Epoch 32, Train Loss 0.307419, Valid_loss 1.188739
Epoch 33, Train Loss 0.340461, Valid_loss 1.001104
Epoch 34, Train Loss 0.279894, Valid_loss 1.243612
Epoch 35, Train Loss 0.277041, Valid_loss 1.106159
Epoch 36, Train Loss 0.262529, Valid_loss 0.897994
Epoch 37, Train Loss 0.225832, Valid_loss 1.006061
Epoch 38, Train Loss 0.252483, Valid_loss 1.067432
Epoch 39, Train Loss 0.284079, Valid_loss 1.458518
Epoch 40, Train Loss 0.220222, Valid_loss 0.732828
Epoch 41, Train Loss 0.317108, Valid_loss 1.570272
Epoch 42, Train Loss 0.212940, Valid_loss 1.510879
Epoch 43, Train Loss 0.216119, Valid_loss 1.254053
Epoch 44, Train Loss 0.203800, Valid_loss 1.692168
Epoch 45, Train Loss 0.290969, Valid_loss 1.545437
Epoch 46, Train Loss 0.227991, Valid_loss 1.593864
Epoch 47, Train Loss 0.215243, Valid_loss 1.069091
Epoch 48, Train Loss 0.210703, Valid_loss 2.142694
Epoch 49, Train Loss 0.204910, Valid_loss 0.868547
Epoch 50, Train Loss 0.340837, Valid_loss 1.621275
Epoch 51, Train Loss 0.244201, Valid_loss 1.573525
Epoch 52, Train Loss 0.178910, Valid_loss 1.342657
Epoch 53, Train Loss 0.170126, Valid_loss 1.441599
Epoch 54, Train Loss 0.167376, Valid_loss 1.425903
Epoch 55, Train Loss 0.176341, Valid_loss 1.812340
Epoch 56, Train Loss 0.186711, Valid_loss 1.599450
Epoch 57, Train Loss 0.168796, Valid_loss 1.681363
Epoch 58, Train Loss 0.158174, Valid_loss 1.037706
Epoch 59, Train Loss 0.196340, Valid_loss 1.602079
Epoch 60, Train Loss 0.146131, Valid_loss 1.711673
[I 2025-08-27 12:04:17,363] Trial 0 finished with value: 0.7328283615748991 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.7, 'weight_decay': 0.001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.7328283615748991.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.821730, Valid_loss 1.444445
Epoch 2, Train Loss 0.583297, Valid_loss 1.598261
Epoch 3, Train Loss 0.585932, Valid_loss 1.365101
Epoch 4, Train Loss 0.440302, Valid_loss 1.177210
Epoch 5, Train Loss 0.464887, Valid_loss 1.223554
Epoch 6, Train Loss 0.389662, Valid_loss 1.275864
Epoch 7, Train Loss 0.362008, Valid_loss 0.970442
Epoch 8, Train Loss 0.401663, Valid_loss 1.692294
Epoch 9, Train Loss 0.409774, Valid_loss 1.027637
Epoch 10, Train Loss 0.321132, Valid_loss 1.243173
Epoch 11, Train Loss 0.326083, Valid_loss 0.916178
Epoch 12, Train Loss 0.350646, Valid_loss 1.229638
Epoch 13, Train Loss 0.314413, Valid_loss 1.288356
Epoch 14, Train Loss 0.293012, Valid_loss 1.475607
Epoch 15, Train Loss 0.281263, Valid_loss 1.233006
Epoch 16, Train Loss 0.270958, Valid_loss 1.141827
Epoch 17, Train Loss 0.298981, Valid_loss 0.886986
Epoch 18, Train Loss 0.286444, Valid_loss 1.297636
Epoch 19, Train Loss 0.225814, Valid_loss 1.248338
Epoch 20, Train Loss 0.270301, Valid_loss 1.699681
Epoch 21, Train Loss 0.251010, Valid_loss 1.592527
Epoch 22, Train Loss 0.219703, Valid_loss 1.939439
Epoch 23, Train Loss 0.222505, Valid_loss 1.081407
Epoch 24, Train Loss 0.200874, Valid_loss 1.324907
Epoch 25, Train Loss 0.184813, Valid_loss 1.401441
Epoch 26, Train Loss 0.176200, Valid_loss 0.913027
Epoch 27, Train Loss 0.251899, Valid_loss 0.974805
Epoch 28, Train Loss 0.177821, Valid_loss 1.549515
Epoch 29, Train Loss 0.165849, Valid_loss 0.995470
Epoch 30, Train Loss 0.169795, Valid_loss 1.657641
Epoch 31, Train Loss 0.233913, Valid_loss 1.121577
Epoch 32, Train Loss 0.195027, Valid_loss 1.472367
Epoch 33, Train Loss 0.160873, Valid_loss 1.556164
Epoch 34, Train Loss 0.239935, Valid_loss 0.790863
Epoch 35, Train Loss 0.206234, Valid_loss 2.491142
Epoch 36, Train Loss 0.175788, Valid_loss 1.026653
Epoch 37, Train Loss 0.186933, Valid_loss 2.003196
Epoch 38, Train Loss 0.173408, Valid_loss 2.097807
Epoch 39, Train Loss 0.138427, Valid_loss 2.490724
Epoch 40, Train Loss 0.203266, Valid_loss 1.815965
Epoch 41, Train Loss 0.172437, Valid_loss 1.338108
Epoch 42, Train Loss 0.145446, Valid_loss 1.980047
Epoch 43, Train Loss 0.121285, Valid_loss 1.978885
Epoch 44, Train Loss 0.125803, Valid_loss 2.255275
Epoch 45, Train Loss 0.133198, Valid_loss 1.978694
Epoch 46, Train Loss 0.187099, Valid_loss 0.913334
Epoch 47, Train Loss 0.124775, Valid_loss 1.596461
Epoch 48, Train Loss 0.131490, Valid_loss 2.708237
Epoch 49, Train Loss 0.202459, Valid_loss 0.951925
Epoch 50, Train Loss 0.138924, Valid_loss 2.092150
Epoch 51, Train Loss 0.103067, Valid_loss 2.188132
Epoch 52, Train Loss 0.093392, Valid_loss 2.057516
Epoch 53, Train Loss 0.097298, Valid_loss 1.581496
Epoch 54, Train Loss 0.099435, Valid_loss 1.799516
Epoch 55, Train Loss 0.083574, Valid_loss 2.335864
[I 2025-08-27 12:35:34,679] Trial 1 finished with value: 0.7908626765182073 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.0001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.7328283615748991.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.936493, Valid_loss 1.750528
Epoch 2, Train Loss 0.847539, Valid_loss 1.529318
Epoch 3, Train Loss 0.865130, Valid_loss 1.539158
Epoch 4, Train Loss 0.846408, Valid_loss 2.117344
Epoch 5, Train Loss 0.858789, Valid_loss 2.163434
Epoch 6, Train Loss 0.848114, Valid_loss 1.825452
Epoch 7, Train Loss 0.859530, Valid_loss 1.841284
Epoch 8, Train Loss 0.845725, Valid_loss 1.974654
Epoch 9, Train Loss 0.837716, Valid_loss 2.083564
Epoch 10, Train Loss 0.840192, Valid_loss 1.560482
Epoch 11, Train Loss 0.850563, Valid_loss 2.035992
Epoch 12, Train Loss 0.853073, Valid_loss 1.880562
Epoch 13, Train Loss 0.846920, Valid_loss 2.194565
Epoch 14, Train Loss 0.842304, Valid_loss 1.921180
Epoch 15, Train Loss 0.848726, Valid_loss 1.933174
Epoch 16, Train Loss 0.845423, Valid_loss 2.097109
Epoch 17, Train Loss 0.837414, Valid_loss 2.062796
Epoch 18, Train Loss 0.851106, Valid_loss 2.327381
Epoch 19, Train Loss 0.850212, Valid_loss 2.052256
Epoch 20, Train Loss 0.846215, Valid_loss 1.991734
Epoch 21, Train Loss 0.842206, Valid_loss 1.923125
Epoch 22, Train Loss 0.848152, Valid_loss 1.928332
Epoch 23, Train Loss 0.852441, Valid_loss 1.819500
Epoch 24, Train Loss 0.847979, Valid_loss 2.129856
Epoch 25, Train Loss 0.848142, Valid_loss 2.037871
Epoch 26, Train Loss 0.845282, Valid_loss 1.936629
Epoch 27, Train Loss 0.841478, Valid_loss 1.958194
Epoch 28, Train Loss 0.843960, Valid_loss 2.116318
Epoch 29, Train Loss 0.848197, Valid_loss 2.053233
Epoch 30, Train Loss 0.853252, Valid_loss 1.927648
Epoch 31, Train Loss 0.838441, Valid_loss 1.967446
Epoch 32, Train Loss 0.838147, Valid_loss 1.880758
Epoch 33, Train Loss 0.844806, Valid_loss 2.108551
Epoch 34, Train Loss 0.850577, Valid_loss 1.767444
Epoch 35, Train Loss 0.841177, Valid_loss 1.951973
Epoch 36, Train Loss 0.841310, Valid_loss 2.057636
Epoch 37, Train Loss 0.840700, Valid_loss 2.086440
Epoch 38, Train Loss 0.847960, Valid_loss 2.076514
Epoch 39, Train Loss 0.857442, Valid_loss 2.085859
Epoch 40, Train Loss 0.838785, Valid_loss 1.936454
Epoch 41, Train Loss 0.844701, Valid_loss 1.898663
Epoch 42, Train Loss 0.841607, Valid_loss 1.779524
Epoch 43, Train Loss 0.844954, Valid_loss 2.019444
Epoch 44, Train Loss 0.840399, Valid_loss 1.900730
Epoch 45, Train Loss 0.844184, Valid_loss 2.111814
Epoch 46, Train Loss 0.845646, Valid_loss 1.882407
Epoch 47, Train Loss 0.847984, Valid_loss 2.256875
Epoch 48, Train Loss 0.850141, Valid_loss 2.002478
Epoch 49, Train Loss 0.840584, Valid_loss 1.981751
Epoch 50, Train Loss 0.845971, Valid_loss 2.019920
Epoch 51, Train Loss 0.842728, Valid_loss 1.831712
Epoch 52, Train Loss 0.835696, Valid_loss 1.947142
Epoch 53, Train Loss 0.837741, Valid_loss 2.010850
[I 2025-08-27 12:54:43,054] Trial 2 finished with value: 1.5293178829279812 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.0, 'weight_decay': 0.01, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.7328283615748991.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.7, 'weight_decay': 0.001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=9, batch_size=1 -> steps=9
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.976570, Valid_loss 1.499472
Epoch 2, Train Loss 0.751137, Valid_loss 1.463935
Epoch 3, Train Loss 0.749813, Valid_loss 1.107540
Epoch 4, Train Loss 0.590286, Valid_loss 1.161776
Epoch 5, Train Loss 0.550646, Valid_loss 1.337559
Epoch 6, Train Loss 0.492838, Valid_loss 1.234794
Epoch 7, Train Loss 0.512857, Valid_loss 1.161812
Epoch 8, Train Loss 0.503253, Valid_loss 1.254446
Epoch 9, Train Loss 0.461123, Valid_loss 1.125714
Epoch 10, Train Loss 0.466934, Valid_loss 1.154466
Epoch 11, Train Loss 0.562299, Valid_loss 1.260815
Epoch 12, Train Loss 0.390596, Valid_loss 1.107794
Epoch 13, Train Loss 0.422195, Valid_loss 1.109409
Epoch 14, Train Loss 0.408015, Valid_loss 1.174441
Epoch 15, Train Loss 0.389553, Valid_loss 1.120893
Epoch 16, Train Loss 0.409713, Valid_loss 1.094045
Epoch 17, Train Loss 0.361585, Valid_loss 0.956555
Epoch 18, Train Loss 0.377688, Valid_loss 0.944648
Epoch 19, Train Loss 0.399988, Valid_loss 1.324684
Epoch 20, Train Loss 0.319416, Valid_loss 1.282224
Epoch 21, Train Loss 0.371909, Valid_loss 1.589716
Epoch 22, Train Loss 0.367987, Valid_loss 0.837795
Epoch 23, Train Loss 0.380701, Valid_loss 1.127566
Epoch 24, Train Loss 0.412682, Valid_loss 1.050798
Epoch 25, Train Loss 0.353282, Valid_loss 0.836749
Epoch 26, Train Loss 0.295536, Valid_loss 0.970717
Epoch 27, Train Loss 0.387780, Valid_loss 1.012604
Epoch 28, Train Loss 0.322158, Valid_loss 0.890045
Epoch 29, Train Loss 0.330574, Valid_loss 1.033011
Epoch 30, Train Loss 0.282285, Valid_loss 1.144655
Epoch 31, Train Loss 0.291046, Valid_loss 1.156462
Epoch 32, Train Loss 0.286160, Valid_loss 0.867996
Epoch 33, Train Loss 0.233453, Valid_loss 1.307847
Epoch 34, Train Loss 0.271382, Valid_loss 1.242319
Epoch 35, Train Loss 0.259001, Valid_loss 1.426928
Epoch 36, Train Loss 0.298265, Valid_loss 0.783607
Epoch 37, Train Loss 0.266592, Valid_loss 0.932005
Epoch 38, Train Loss 0.219112, Valid_loss 1.064018
Epoch 39, Train Loss 0.249265, Valid_loss 1.607539
Epoch 40, Train Loss 0.226014, Valid_loss 0.872008
Epoch 41, Train Loss 0.218174, Valid_loss 1.145489
Epoch 42, Train Loss 0.218786, Valid_loss 1.476667
Epoch 43, Train Loss 0.290600, Valid_loss 1.686246
Epoch 44, Train Loss 0.198312, Valid_loss 1.515957
Epoch 45, Train Loss 0.212806, Valid_loss 1.040747
Epoch 46, Train Loss 0.257373, Valid_loss 1.927061
Epoch 47, Train Loss 0.239770, Valid_loss 2.019418
Epoch 48, Train Loss 0.289063, Valid_loss 0.765069
Epoch 49, Train Loss 0.213554, Valid_loss 1.423008
Epoch 50, Train Loss 0.232072, Valid_loss 1.728648
Epoch 51, Train Loss 0.160695, Valid_loss 1.834815
Epoch 52, Train Loss 0.168533, Valid_loss 1.260741
Epoch 53, Train Loss 0.179907, Valid_loss 1.173124
Epoch 54, Train Loss 0.235473, Valid_loss 1.307413
Epoch 55, Train Loss 0.207203, Valid_loss 1.438152
환자ID=P1304 -- true: [[2]] -- pred: tensor([[-1.0580,  2.0030, -0.7639]], device='cuda:0')
환자ID=P1437 -- true: [[2]] -- pred: tensor([[-1.5171,  0.5293,  1.0416]], device='cuda:0')
환자ID=P1508 -- true: [[1]] -- pred: tensor([[-0.2561,  2.0165, -1.3982]], device='cuda:0')
환자ID=P1510 -- true: [[1]] -- pred: tensor([[-0.6007,  2.0207, -1.1749]], device='cuda:0')
환자ID=P1610 -- true: [[0]] -- pred: tensor([[ 3.2193, -0.5519, -2.5538]], device='cuda:0')
환자ID=P1622 -- true: [[0]] -- pred: tensor([[ 3.3155, -0.7783, -2.5580]], device='cuda:0')
환자ID=P1630 -- true: [[1]] -- pred: tensor([[-1.5162,  1.2714,  0.2845]], device='cuda:0')
환자ID=P1678 -- true: [[0]] -- pred: tensor([[ 3.3241, -0.8454, -2.6147]], device='cuda:0')
환자ID=P1718 -- true: [[0]] -- pred: tensor([[ 3.2913, -0.7648, -2.6007]], device='cuda:0')
Best performance: Epoch 48, Loss 0.289063, Test ACC 0.888889, Test AUC 0.888889, Test Recall 0.833333, Test Precision 0.916667
Confusion Matrix:
 [[4 0 0]
 [0 3 0]
 [0 1 1]]
✅ Total valid splits used: 1
🔁 Repeat 1, Fold 1
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 478386, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 478386, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 8, 1: 12, 0: 13}
cell type :  CAACCAAAGACCCGCT-1-2              cardiac muscle cell
ACGGTTACATCGAACT-1-2              cardiac muscle cell
ACCCTCATCCGGCAGT-1-2              cardiac muscle cell
AACACACCACGGTCTG-1-2              cardiac muscle cell
AAACGCTTCACCGGGT-1-2              cardiac muscle cell
                                     ...             
AGAAGCGAGCGTCTGC-1-73        cardiac endothelial cell
TACTTCATCCCTTTGG-1-73        cardiac endothelial cell
ATATCCTGTTAGCGGA-1-73        cardiac endothelial cell
TACTTACCAAAGCACG-1-73        cardiac endothelial cell
GTCAGCGCAACACTAC-1-73    cardiac ventricle fibroblast
Name: manual_annotation, Length: 114303, dtype: string
cell type annotation :  CAACCAAAGACCCGCT-1-2              cardiac muscle cell
ACGGTTACATCGAACT-1-2              cardiac muscle cell
ACCCTCATCCGGCAGT-1-2              cardiac muscle cell
AACACACCACGGTCTG-1-2              cardiac muscle cell
AAACGCTTCACCGGGT-1-2              cardiac muscle cell
                                     ...             
AGAAGCGAGCGTCTGC-1-73        cardiac endothelial cell
TACTTCATCCCTTTGG-1-73        cardiac endothelial cell
ATATCCTGTTAGCGGA-1-73        cardiac endothelial cell
TACTTACCAAAGCACG-1-73        cardiac endothelial cell
GTCAGCGCAACACTAC-1-73    cardiac ventricle fibroblast
Name: manual_annotation, Length: 114303, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'vascular associated smooth muscle cell', 'macrophage', 'endocardial cell', 'endothelial cell of lymphatic vessel', 'cardiac endothelial cell', 'cardiac ventricle fibroblast', 'pericyte cell', 'cardiac neuron', 'lymphocyte', 'mast cell', 'mesothelial cell']
라벨별 그룹 개수 {2: 3, 0: 3, 1: 3}
🔍 Split #2
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 33
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 9
  → train 환자 ID: ['P1300', 'P1304', 'P1358', 'P1422', 'P1425', 'P1437', 'P1447', 'P1462', 'P1472', 'P1479', 'P1504', 'P1508', 'P1510', 'P1515', 'P1540', 'P1547', 'P1549', 'P1558', 'P1561', 'P1582', 'P1600', 'P1602', 'P1606', 'P1610', 'P1617', 'P1622', 'P1630', 'P1678', 'P1685', 'P1702', 'P1707', 'P1718', 'P1735']
  → test  환자 ID: ['P1290', 'P1371', 'P1430', 'P1516', 'P1539', 'P1603', 'P1631', 'P1722', 'P1726']
  → train 환자 ID 및 라벨:
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1371, Label: 2
    ID: P1430, Label: 2
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1603, Label: 0
    ID: P1631, Label: 1
    ID: P1722, Label: 1
    ID: P1726, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 33
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 33
기존 (train) label_stat 33
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 11
test_p_index 9
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1547, Label=0, 셀개수=8253
→ valid 환자 ID 및 라벨:
   총 개수: 11
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1617, Label=2, 셀개수=17986
→ test 환자 ID 및 라벨:
   총 개수: 9
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1726, Label=1, 셀개수=12389
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685        cardiac endothelial cell
592686        cardiac endothelial cell
592687        cardiac endothelial cell
592688    cardiac ventricle fibroblast
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.36it/s]  2%|▏         | 2/100 [00:00<00:11,  8.70it/s]  3%|▎         | 3/100 [00:00<00:11,  8.72it/s]  4%|▍         | 4/100 [00:00<00:11,  8.72it/s]  5%|▌         | 5/100 [00:00<00:11,  8.55it/s]  6%|▌         | 6/100 [00:00<00:10,  8.64it/s]  7%|▋         | 7/100 [00:00<00:10,  8.65it/s]  8%|▊         | 8/100 [00:00<00:10,  8.76it/s]  9%|▉         | 9/100 [00:01<00:10,  8.76it/s] 10%|█         | 10/100 [00:01<00:10,  8.89it/s] 11%|█         | 11/100 [00:01<00:10,  8.83it/s] 12%|█▏        | 12/100 [00:01<00:09,  8.83it/s] 13%|█▎        | 13/100 [00:01<00:09,  8.87it/s] 14%|█▍        | 14/100 [00:01<00:09,  8.88it/s] 15%|█▌        | 15/100 [00:01<00:09,  8.76it/s] 16%|█▌        | 16/100 [00:01<00:09,  8.65it/s] 17%|█▋        | 17/100 [00:01<00:09,  8.85it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.81it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.73it/s] 20%|██        | 20/100 [00:02<00:09,  8.73it/s] 21%|██        | 21/100 [00:02<00:09,  8.68it/s] 22%|██▏       | 22/100 [00:02<00:08,  8.84it/s] 23%|██▎       | 23/100 [00:02<00:08,  8.69it/s] 24%|██▍       | 24/100 [00:02<00:08,  8.84it/s] 25%|██▌       | 25/100 [00:02<00:08,  8.94it/s] 26%|██▌       | 26/100 [00:02<00:08,  8.89it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.82it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.79it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.82it/s] 30%|███       | 30/100 [00:03<00:07,  8.82it/s] 31%|███       | 31/100 [00:03<00:07,  8.90it/s] 32%|███▏      | 32/100 [00:03<00:07,  8.83it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.90it/s] 34%|███▍      | 34/100 [00:03<00:07,  8.91it/s] 35%|███▌      | 35/100 [00:03<00:07,  8.65it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.52it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.72it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.72it/s] 39%|███▉      | 39/100 [00:04<00:06,  8.82it/s] 40%|████      | 40/100 [00:04<00:06,  8.94it/s] 41%|████      | 41/100 [00:04<00:06,  8.84it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.71it/s] 43%|████▎     | 43/100 [00:04<00:06,  8.71it/s] 44%|████▍     | 44/100 [00:05<00:06,  8.70it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.76it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.67it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.73it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.63it/s] 49%|████▉     | 49/100 [00:05<00:05,  8.74it/s] 50%|█████     | 50/100 [00:05<00:05,  8.91it/s] 51%|█████     | 51/100 [00:05<00:05,  8.78it/s] 52%|█████▏    | 52/100 [00:05<00:05,  8.64it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.52it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.57it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.67it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.61it/s] 57%|█████▋    | 57/100 [00:06<00:04,  8.61it/s] 58%|█████▊    | 58/100 [00:06<00:04,  8.52it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.53it/s] 60%|██████    | 60/100 [00:06<00:04,  8.35it/s] 61%|██████    | 61/100 [00:07<00:04,  8.37it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.43it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.37it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.37it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.53it/s] 66%|██████▌   | 66/100 [00:07<00:03,  8.56it/s] 67%|██████▋   | 67/100 [00:07<00:03,  8.47it/s] 68%|██████▊   | 68/100 [00:07<00:03,  8.36it/s] 69%|██████▉   | 69/100 [00:07<00:03,  8.36it/s] 70%|███████   | 70/100 [00:08<00:03,  8.58it/s] 71%|███████   | 71/100 [00:08<00:03,  8.57it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.50it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.47it/s] 74%|███████▍  | 74/100 [00:08<00:03,  8.52it/s] 75%|███████▌  | 75/100 [00:08<00:02,  8.46it/s] 76%|███████▌  | 76/100 [00:08<00:02,  8.50it/s] 77%|███████▋  | 77/100 [00:08<00:02,  8.43it/s] 78%|███████▊  | 78/100 [00:08<00:02,  8.62it/s] 79%|███████▉  | 79/100 [00:09<00:02,  8.66it/s] 80%|████████  | 80/100 [00:09<00:02,  8.51it/s] 81%|████████  | 81/100 [00:09<00:02,  8.47it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.59it/s] 83%|████████▎ | 83/100 [00:09<00:02,  8.48it/s] 84%|████████▍ | 84/100 [00:09<00:01,  8.60it/s] 85%|████████▌ | 85/100 [00:09<00:01,  8.46it/s] 86%|████████▌ | 86/100 [00:09<00:01,  8.51it/s] 87%|████████▋ | 87/100 [00:10<00:01,  8.57it/s] 88%|████████▊ | 88/100 [00:10<00:01,  8.54it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.56it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.59it/s] 91%|█████████ | 91/100 [00:10<00:01,  8.53it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.36it/s] 93%|█████████▎| 93/100 [00:10<00:00,  8.46it/s] 94%|█████████▍| 94/100 [00:10<00:00,  8.48it/s] 95%|█████████▌| 95/100 [00:10<00:00,  8.60it/s] 96%|█████████▌| 96/100 [00:11<00:00,  8.47it/s] 97%|█████████▋| 97/100 [00:11<00:00,  8.53it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.50it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.29it/s]100%|██████████| 100/100 [00:11<00:00,  8.29it/s]100%|██████████| 100/100 [00:11<00:00,  8.62it/s]
[I 2025-08-27 13:26:49,485] A new study created in memory with name: no-name-6c5f5390-c21d-48c4-953c-af9a9a300c50
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.034717, Valid_loss 1.228122
Epoch 2, Train Loss 0.960854, Valid_loss 1.181003
Epoch 3, Train Loss 0.974241, Valid_loss 1.190977
Epoch 4, Train Loss 0.980997, Valid_loss 1.155961
Epoch 5, Train Loss 0.969448, Valid_loss 1.139040
Epoch 6, Train Loss 0.969437, Valid_loss 1.229915
Epoch 7, Train Loss 0.955926, Valid_loss 1.116065
Epoch 8, Train Loss 0.954982, Valid_loss 1.134278
Epoch 9, Train Loss 0.947118, Valid_loss 1.190267
Epoch 10, Train Loss 0.930387, Valid_loss 1.641309
Epoch 11, Train Loss 0.965123, Valid_loss 1.205733
Epoch 12, Train Loss 0.926086, Valid_loss 1.458073
Epoch 13, Train Loss 0.950262, Valid_loss 1.136333
Epoch 14, Train Loss 0.930761, Valid_loss 1.142172
Epoch 15, Train Loss 0.928207, Valid_loss 1.262874
Epoch 16, Train Loss 0.922406, Valid_loss 1.173994
Epoch 17, Train Loss 0.959241, Valid_loss 1.173544
Epoch 18, Train Loss 0.934963, Valid_loss 1.192015
Epoch 19, Train Loss 0.935001, Valid_loss 1.165952
Epoch 20, Train Loss 0.923837, Valid_loss 1.279017
Epoch 21, Train Loss 0.944607, Valid_loss 1.173443
Epoch 22, Train Loss 0.929233, Valid_loss 1.183361
Epoch 23, Train Loss 0.903756, Valid_loss 1.474828
Epoch 24, Train Loss 0.956974, Valid_loss 1.190330
Epoch 25, Train Loss 0.894134, Valid_loss 1.080046
Epoch 26, Train Loss 0.944218, Valid_loss 1.175504
Epoch 27, Train Loss 0.937529, Valid_loss 1.263437
Epoch 28, Train Loss 0.874787, Valid_loss 1.188067
Epoch 29, Train Loss 0.917778, Valid_loss 1.192727
Epoch 30, Train Loss 0.935456, Valid_loss 1.248164
Epoch 31, Train Loss 0.944128, Valid_loss 1.279236
Epoch 32, Train Loss 0.912242, Valid_loss 1.195767
Epoch 33, Train Loss 0.892006, Valid_loss 1.205607
Epoch 34, Train Loss 0.935282, Valid_loss 1.192402
Epoch 35, Train Loss 0.904432, Valid_loss 1.232882
Epoch 36, Train Loss 0.933136, Valid_loss 1.218580
Epoch 37, Train Loss 0.923516, Valid_loss 1.212300
Epoch 38, Train Loss 0.953011, Valid_loss 1.239431
Epoch 39, Train Loss 0.937378, Valid_loss 1.222824
Epoch 40, Train Loss 0.933908, Valid_loss 1.214784
Epoch 41, Train Loss 0.956398, Valid_loss 1.211099
Epoch 42, Train Loss 0.931211, Valid_loss 1.157386
Epoch 43, Train Loss 0.920691, Valid_loss 1.169908
Epoch 44, Train Loss 0.938221, Valid_loss 1.232679
Epoch 45, Train Loss 0.935494, Valid_loss 1.189249
Epoch 46, Train Loss 0.921408, Valid_loss 1.114321
Epoch 47, Train Loss 0.880698, Valid_loss 1.389448
Epoch 48, Train Loss 0.939079, Valid_loss 1.148016
Epoch 49, Train Loss 0.934028, Valid_loss 1.113932
Epoch 50, Train Loss 0.918764, Valid_loss 1.184189
Epoch 51, Train Loss 0.907085, Valid_loss 1.111453
Epoch 52, Train Loss 0.915982, Valid_loss 1.104996
Epoch 53, Train Loss 0.918540, Valid_loss 1.105654
Epoch 54, Train Loss 0.923735, Valid_loss 1.102749
Epoch 55, Train Loss 0.925538, Valid_loss 1.116316
Epoch 56, Train Loss 0.918132, Valid_loss 1.104231
Epoch 57, Train Loss 0.920450, Valid_loss 1.119306
Epoch 58, Train Loss 0.920510, Valid_loss 1.150603
[I 2025-08-27 13:50:24,132] Trial 0 finished with value: 1.0800459412011234 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.3, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 1.0800459412011234.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17906.54 MB
Memory Reserved: 17924.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 349.96 MB
Memory Reserved: 388.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17906.25 MB
Memory Reserved: 17932.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 350.37 MB
Memory Reserved: 388.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 13:50:26,033] Trial 1 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17904.00 MB
Memory Reserved: 17934.00 MB
cuda
Epoch 1, Train Loss 1.056642, Valid_loss 1.066671
Epoch 2, Train Loss 0.821941, Valid_loss 0.871724
Epoch 3, Train Loss 0.623127, Valid_loss 0.686068
Epoch 4, Train Loss 0.590705, Valid_loss 0.677195
Epoch 5, Train Loss 0.504112, Valid_loss 0.984496
Epoch 6, Train Loss 0.528277, Valid_loss 0.744367
Epoch 7, Train Loss 0.465541, Valid_loss 0.663002
Epoch 8, Train Loss 0.495394, Valid_loss 0.714875
Epoch 9, Train Loss 0.440249, Valid_loss 0.647751
Epoch 10, Train Loss 0.380490, Valid_loss 0.576882
Epoch 11, Train Loss 0.364935, Valid_loss 0.699305
Epoch 12, Train Loss 0.409848, Valid_loss 0.712246
Epoch 13, Train Loss 0.358980, Valid_loss 0.555805
Epoch 14, Train Loss 0.336894, Valid_loss 0.647486
Epoch 15, Train Loss 0.328414, Valid_loss 0.665013
Epoch 16, Train Loss 0.343482, Valid_loss 0.800487
Epoch 17, Train Loss 0.299161, Valid_loss 0.931262
Epoch 18, Train Loss 0.338849, Valid_loss 0.741853
Epoch 19, Train Loss 0.302451, Valid_loss 0.602773
Epoch 20, Train Loss 0.316785, Valid_loss 0.597577
Epoch 21, Train Loss 0.320007, Valid_loss 0.701051
Epoch 22, Train Loss 0.277384, Valid_loss 0.734564
Epoch 23, Train Loss 0.251193, Valid_loss 0.712779
Epoch 24, Train Loss 0.266016, Valid_loss 0.937406
Epoch 25, Train Loss 0.288299, Valid_loss 0.585971
Epoch 26, Train Loss 0.270519, Valid_loss 0.801204
Epoch 27, Train Loss 0.263947, Valid_loss 0.384847
Epoch 28, Train Loss 0.233534, Valid_loss 0.757287
Epoch 29, Train Loss 0.254689, Valid_loss 0.806885
Epoch 30, Train Loss 0.264679, Valid_loss 0.445878
Epoch 31, Train Loss 0.259945, Valid_loss 0.887471
Epoch 32, Train Loss 0.234583, Valid_loss 0.935346
Epoch 33, Train Loss 0.220161, Valid_loss 0.855060
Epoch 34, Train Loss 0.228249, Valid_loss 0.840948
Epoch 35, Train Loss 0.189585, Valid_loss 0.806300
Epoch 36, Train Loss 0.224324, Valid_loss 1.047679
Epoch 37, Train Loss 0.258849, Valid_loss 0.843852
Epoch 38, Train Loss 0.201540, Valid_loss 0.768581
Epoch 39, Train Loss 0.208387, Valid_loss 1.162870
Epoch 40, Train Loss 0.217729, Valid_loss 0.764623
Epoch 41, Train Loss 0.201046, Valid_loss 0.867446
Epoch 42, Train Loss 0.197270, Valid_loss 0.637695
Epoch 43, Train Loss 0.191026, Valid_loss 0.905491
Epoch 44, Train Loss 0.232795, Valid_loss 0.843589
Epoch 45, Train Loss 0.167735, Valid_loss 0.958026
Epoch 46, Train Loss 0.211618, Valid_loss 0.669104
Epoch 47, Train Loss 0.228994, Valid_loss 0.678230
Epoch 48, Train Loss 0.178095, Valid_loss 1.061238
Epoch 49, Train Loss 0.174574, Valid_loss 0.614082
Epoch 50, Train Loss 0.185793, Valid_loss 0.697779
Epoch 51, Train Loss 0.153262, Valid_loss 0.675841
Epoch 52, Train Loss 0.166065, Valid_loss 0.828864
Epoch 53, Train Loss 0.142801, Valid_loss 0.854507
[I 2025-08-27 14:10:57,772] Trial 2 finished with value: 0.3848465813154524 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.0, 'weight_decay': 0.01, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.3848465813154524.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.105659, Valid_loss 1.180979
Epoch 2, Train Loss 1.040158, Valid_loss 1.161086
Epoch 3, Train Loss 0.963375, Valid_loss 1.106436
Epoch 4, Train Loss 1.020689, Valid_loss 1.182837
Epoch 5, Train Loss 0.972207, Valid_loss 1.170407
Epoch 6, Train Loss 0.950744, Valid_loss 1.197736
Epoch 7, Train Loss 0.959180, Valid_loss 1.154392
Epoch 8, Train Loss 0.938982, Valid_loss 1.160585
Epoch 9, Train Loss 0.945296, Valid_loss 1.229692
Epoch 10, Train Loss 0.941689, Valid_loss 1.233496
Epoch 11, Train Loss 0.945335, Valid_loss 1.237062
Epoch 12, Train Loss 0.957736, Valid_loss 1.178607
Epoch 13, Train Loss 0.933390, Valid_loss 1.195052
Epoch 14, Train Loss 0.935793, Valid_loss 1.198986
Epoch 15, Train Loss 0.938724, Valid_loss 1.197624
Epoch 16, Train Loss 0.937501, Valid_loss 1.289773
Epoch 17, Train Loss 0.949596, Valid_loss 1.295758
Epoch 18, Train Loss 0.960097, Valid_loss 1.180599
Epoch 19, Train Loss 0.941273, Valid_loss 1.189951
Epoch 20, Train Loss 0.933436, Valid_loss 1.209118
Epoch 21, Train Loss 0.934753, Valid_loss 1.198962
Epoch 22, Train Loss 0.936927, Valid_loss 1.203403
Epoch 23, Train Loss 0.933755, Valid_loss 1.213151
Epoch 24, Train Loss 0.933466, Valid_loss 1.212192
Epoch 25, Train Loss 0.947428, Valid_loss 1.203936
Epoch 26, Train Loss 0.936710, Valid_loss 1.205017
Epoch 27, Train Loss 0.936151, Valid_loss 1.209531
Epoch 28, Train Loss 0.935309, Valid_loss 1.216415
Epoch 29, Train Loss 0.932681, Valid_loss 1.202831
Epoch 30, Train Loss 0.932748, Valid_loss 1.220251
Epoch 31, Train Loss 0.935366, Valid_loss 1.219388
Epoch 32, Train Loss 0.933787, Valid_loss 1.205635
Epoch 33, Train Loss 0.932984, Valid_loss 1.216869
Epoch 34, Train Loss 0.931958, Valid_loss 1.211680
Epoch 35, Train Loss 0.933805, Valid_loss 1.212662
Epoch 36, Train Loss 0.934372, Valid_loss 1.206162
Epoch 37, Train Loss 0.972267, Valid_loss 1.226011
Epoch 38, Train Loss 0.942066, Valid_loss 1.210503
Epoch 39, Train Loss 0.938363, Valid_loss 1.197507
Epoch 40, Train Loss 0.936901, Valid_loss 1.202532
Epoch 41, Train Loss 0.935769, Valid_loss 1.198516
Epoch 42, Train Loss 0.935116, Valid_loss 1.212900
Epoch 43, Train Loss 0.933012, Valid_loss 1.209256
Epoch 44, Train Loss 0.934227, Valid_loss 1.205721
Epoch 45, Train Loss 0.935378, Valid_loss 1.211390
Epoch 46, Train Loss 0.933648, Valid_loss 1.210713
Epoch 47, Train Loss 0.933190, Valid_loss 1.208309
Epoch 48, Train Loss 0.933480, Valid_loss 1.203898
Epoch 49, Train Loss 0.935372, Valid_loss 1.214581
Epoch 50, Train Loss 0.937884, Valid_loss 1.215107
Epoch 51, Train Loss 0.934268, Valid_loss 1.220513
Epoch 52, Train Loss 0.930684, Valid_loss 1.224162
[I 2025-08-27 14:33:14,531] Trial 3 finished with value: 1.1064355915242976 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.7, 'weight_decay': 0.01, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.3848465813154524.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.0, 'weight_decay': 0.01, 'emb_dim': 32, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=9, batch_size=1 -> steps=9
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.911707, Valid_loss 1.064958
Epoch 2, Train Loss 0.700024, Valid_loss 0.837682
Epoch 3, Train Loss 0.573670, Valid_loss 0.936827
Epoch 4, Train Loss 0.541218, Valid_loss 0.709723
Epoch 5, Train Loss 0.546488, Valid_loss 0.664481
Epoch 6, Train Loss 0.459902, Valid_loss 0.678937
Epoch 7, Train Loss 0.438530, Valid_loss 0.681121
Epoch 8, Train Loss 0.393866, Valid_loss 0.563611
Epoch 9, Train Loss 0.407104, Valid_loss 0.820652
Epoch 10, Train Loss 0.415142, Valid_loss 0.534132
Epoch 11, Train Loss 0.363501, Valid_loss 0.596424
Epoch 12, Train Loss 0.379308, Valid_loss 0.595054
Epoch 13, Train Loss 0.337629, Valid_loss 0.568337
Epoch 14, Train Loss 0.322707, Valid_loss 0.570287
Epoch 15, Train Loss 0.314787, Valid_loss 0.645368
Epoch 16, Train Loss 0.294457, Valid_loss 0.651765
Epoch 17, Train Loss 0.301672, Valid_loss 0.609751
Epoch 18, Train Loss 0.289223, Valid_loss 0.708906
Epoch 19, Train Loss 0.313444, Valid_loss 0.896710
Epoch 20, Train Loss 0.281603, Valid_loss 0.598387
Epoch 21, Train Loss 0.251651, Valid_loss 0.508735
Epoch 22, Train Loss 0.263417, Valid_loss 0.865174
Epoch 23, Train Loss 0.260843, Valid_loss 0.557636
Epoch 24, Train Loss 0.242833, Valid_loss 0.746715
Epoch 25, Train Loss 0.246031, Valid_loss 0.864226
Epoch 26, Train Loss 0.232093, Valid_loss 0.796925
Epoch 27, Train Loss 0.250079, Valid_loss 0.598989
Epoch 28, Train Loss 0.250488, Valid_loss 0.581914
Epoch 29, Train Loss 0.243234, Valid_loss 0.612909
Epoch 30, Train Loss 0.240309, Valid_loss 0.727089
Epoch 31, Train Loss 0.220702, Valid_loss 0.440226
Epoch 32, Train Loss 0.246490, Valid_loss 0.551278
Epoch 33, Train Loss 0.201642, Valid_loss 0.559678
Epoch 34, Train Loss 0.199556, Valid_loss 0.601464
Epoch 35, Train Loss 0.180221, Valid_loss 0.869739
Epoch 36, Train Loss 0.223804, Valid_loss 0.545580
Epoch 37, Train Loss 0.199837, Valid_loss 0.617144
Epoch 38, Train Loss 0.193463, Valid_loss 0.705261
Epoch 39, Train Loss 0.183653, Valid_loss 0.558919
Epoch 40, Train Loss 0.191409, Valid_loss 0.430327
Epoch 41, Train Loss 0.215900, Valid_loss 0.645182
Epoch 42, Train Loss 0.201585, Valid_loss 0.777984
Epoch 43, Train Loss 0.186403, Valid_loss 0.394490
Epoch 44, Train Loss 0.230632, Valid_loss 0.410696
Epoch 45, Train Loss 0.168648, Valid_loss 0.601227
Epoch 46, Train Loss 0.169822, Valid_loss 0.588784
Epoch 47, Train Loss 0.186081, Valid_loss 0.548801
Epoch 48, Train Loss 0.185652, Valid_loss 0.743369
Epoch 49, Train Loss 0.148740, Valid_loss 0.586178
Epoch 50, Train Loss 0.143175, Valid_loss 0.395950
Epoch 51, Train Loss 0.144396, Valid_loss 0.493392
Epoch 52, Train Loss 0.147946, Valid_loss 0.534799
환자ID=P1290 -- true: [[2]] -- pred: tensor([[-1.4418,  1.4236, -0.7409]], device='cuda:0')
환자ID=P1371 -- true: [[2]] -- pred: tensor([[-1.8820,  0.5309,  0.5112]], device='cuda:0')
환자ID=P1430 -- true: [[2]] -- pred: tensor([[-1.5731,  1.3216, -0.5784]], device='cuda:0')
환자ID=P1516 -- true: [[0]] -- pred: tensor([[ 0.9117, -0.3917, -2.3296]], device='cuda:0')
환자ID=P1539 -- true: [[0]] -- pred: tensor([[ 2.1337, -1.4913, -2.9092]], device='cuda:0')
환자ID=P1603 -- true: [[0]] -- pred: tensor([[ 1.3244, -0.9180, -2.4351]], device='cuda:0')
환자ID=P1631 -- true: [[1]] -- pred: tensor([[-1.0037,  1.7528, -1.3988]], device='cuda:0')
환자ID=P1722 -- true: [[1]] -- pred: tensor([[-1.6325,  1.1266, -0.3115]], device='cuda:0')
환자ID=P1726 -- true: [[1]] -- pred: tensor([[-1.7070,  0.9846, -0.1503]], device='cuda:0')
Best performance: Epoch 43, Loss 0.186403, Test ACC 0.666667, Test AUC 0.851852, Test Recall 0.666667, Test Precision 0.500000
Confusion Matrix:
 [[3 0 0]
 [0 3 0]
 [0 3 0]]
✅ Total valid splits used: 2
🔁 Repeat 1, Fold 2
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 469605, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 469605, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  ACAGCCGCAAGCGAGT-1-1          cardiac muscle cell
ATATCCTGTCCCTAAA-1-1          cardiac muscle cell
CAATGACCAGTTGTCA-1-1          cardiac muscle cell
CTAGACACAAGGTTGG-1-1          cardiac muscle cell
ATCGTCCGTATTTCTC-1-1          cardiac muscle cell
                                   ...           
GTCTCACGTGTCATGT-1-67                  macrophage
CGCGTGAAGGGCAGAG-1-67               pericyte cell
GTCTGTCTCATTCTTG-1-67    cardiac endothelial cell
AGCCAGCGTCGCTTGG-1-67    cardiac endothelial cell
CATCCACTCTACTGCC-1-67    cardiac endothelial cell
Name: manual_annotation, Length: 123084, dtype: string
cell type annotation :  ACAGCCGCAAGCGAGT-1-1          cardiac muscle cell
ATATCCTGTCCCTAAA-1-1          cardiac muscle cell
CAATGACCAGTTGTCA-1-1          cardiac muscle cell
CTAGACACAAGGTTGG-1-1          cardiac muscle cell
ATCGTCCGTATTTCTC-1-1          cardiac muscle cell
                                   ...           
GTCTCACGTGTCATGT-1-67                  macrophage
CGCGTGAAGGGCAGAG-1-67               pericyte cell
GTCTGTCTCATTCTTG-1-67    cardiac endothelial cell
AGCCAGCGTCGCTTGG-1-67    cardiac endothelial cell
CATCCACTCTACTGCC-1-67    cardiac endothelial cell
Name: manual_annotation, Length: 123084, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'mesothelial cell', 'macrophage', 'fat cell', 'endocardial cell', 'cardiac neuron', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'lymphocyte', 'mast cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 3}
🔍 Split #3
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1290', 'P1304', 'P1358', 'P1371', 'P1425', 'P1430', 'P1437', 'P1462', 'P1472', 'P1508', 'P1510', 'P1515', 'P1516', 'P1539', 'P1547', 'P1549', 'P1558', 'P1561', 'P1600', 'P1602', 'P1603', 'P1606', 'P1610', 'P1617', 'P1622', 'P1630', 'P1631', 'P1678', 'P1685', 'P1707', 'P1718', 'P1722', 'P1726', 'P1735']
  → test  환자 ID: ['P1300', 'P1422', 'P1447', 'P1479', 'P1504', 'P1540', 'P1582', 'P1702']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1300, Label: 2
    ID: P1422, Label: 1
    ID: P1447, Label: 1
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1540, Label: 0
    ID: P1582, Label: 0
    ID: P1702, Label: 0
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1549, Label=0, 셀개수=11709
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1606, Label=2, 셀개수=8523
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1702, Label=0, 셀개수=13550
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0              cardiac muscle cell
1              cardiac muscle cell
2              cardiac muscle cell
3              cardiac muscle cell
4              cardiac muscle cell
                    ...           
592684                  macrophage
592685               pericyte cell
592686    cardiac endothelial cell
592687    cardiac endothelial cell
592688    cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:12,  8.07it/s]  2%|▏         | 2/100 [00:00<00:11,  8.54it/s]  3%|▎         | 3/100 [00:00<00:11,  8.47it/s]  4%|▍         | 4/100 [00:00<00:11,  8.53it/s]  5%|▌         | 5/100 [00:00<00:11,  8.51it/s]  6%|▌         | 6/100 [00:00<00:11,  8.49it/s]  7%|▋         | 7/100 [00:00<00:10,  8.60it/s]  8%|▊         | 8/100 [00:00<00:10,  8.74it/s]  9%|▉         | 9/100 [00:01<00:10,  8.82it/s] 10%|█         | 10/100 [00:01<00:10,  8.87it/s] 11%|█         | 11/100 [00:01<00:10,  8.75it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.79it/s] 13%|█▎        | 13/100 [00:01<00:09,  8.71it/s] 14%|█▍        | 14/100 [00:01<00:09,  8.77it/s] 15%|█▌        | 15/100 [00:01<00:09,  8.61it/s] 16%|█▌        | 16/100 [00:01<00:09,  8.60it/s] 17%|█▋        | 17/100 [00:01<00:09,  8.64it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.64it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.60it/s] 20%|██        | 20/100 [00:02<00:09,  8.58it/s] 21%|██        | 21/100 [00:02<00:09,  8.58it/s] 22%|██▏       | 22/100 [00:02<00:08,  8.67it/s] 23%|██▎       | 23/100 [00:02<00:08,  8.63it/s] 24%|██▍       | 24/100 [00:02<00:08,  8.70it/s] 25%|██▌       | 25/100 [00:02<00:08,  8.69it/s] 26%|██▌       | 26/100 [00:03<00:08,  8.54it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.48it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.66it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.55it/s] 30%|███       | 30/100 [00:03<00:08,  8.60it/s] 31%|███       | 31/100 [00:03<00:08,  8.44it/s] 32%|███▏      | 32/100 [00:03<00:08,  8.45it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.53it/s] 34%|███▍      | 34/100 [00:03<00:07,  8.73it/s] 35%|███▌      | 35/100 [00:04<00:07,  8.54it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.53it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.61it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.46it/s] 39%|███▉      | 39/100 [00:04<00:07,  8.63it/s] 40%|████      | 40/100 [00:04<00:06,  8.63it/s] 41%|████      | 41/100 [00:04<00:06,  8.52it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.60it/s] 43%|████▎     | 43/100 [00:04<00:06,  8.59it/s] 44%|████▍     | 44/100 [00:05<00:06,  8.49it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.51it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.50it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.38it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.30it/s] 49%|████▉     | 49/100 [00:05<00:06,  8.39it/s] 50%|█████     | 50/100 [00:05<00:05,  8.35it/s] 51%|█████     | 51/100 [00:05<00:05,  8.30it/s] 52%|█████▏    | 52/100 [00:06<00:05,  8.19it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.33it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.30it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.36it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.38it/s] 57%|█████▋    | 57/100 [00:06<00:05,  8.39it/s] 58%|█████▊    | 58/100 [00:06<00:04,  8.44it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.35it/s] 60%|██████    | 60/100 [00:07<00:04,  8.36it/s] 61%|██████    | 61/100 [00:07<00:04,  8.29it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.39it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.58it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.55it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.54it/s] 66%|██████▌   | 66/100 [00:07<00:03,  8.50it/s] 67%|██████▋   | 67/100 [00:07<00:03,  8.54it/s] 68%|██████▊   | 68/100 [00:07<00:03,  8.63it/s] 69%|██████▉   | 69/100 [00:08<00:03,  8.72it/s] 70%|███████   | 70/100 [00:08<00:03,  8.55it/s] 71%|███████   | 71/100 [00:08<00:03,  8.53it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.54it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.51it/s] 74%|███████▍  | 74/100 [00:08<00:03,  8.59it/s] 75%|███████▌  | 75/100 [00:08<00:02,  8.63it/s] 76%|███████▌  | 76/100 [00:08<00:02,  8.53it/s] 77%|███████▋  | 77/100 [00:09<00:02,  8.23it/s] 78%|███████▊  | 78/100 [00:09<00:02,  8.22it/s] 79%|███████▉  | 79/100 [00:09<00:02,  8.20it/s] 80%|████████  | 80/100 [00:09<00:02,  8.12it/s] 81%|████████  | 81/100 [00:09<00:02,  8.22it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.33it/s] 83%|████████▎ | 83/100 [00:09<00:02,  8.31it/s] 84%|████████▍ | 84/100 [00:09<00:01,  8.27it/s] 85%|████████▌ | 85/100 [00:10<00:01,  8.26it/s] 86%|████████▌ | 86/100 [00:10<00:01,  8.30it/s] 87%|████████▋ | 87/100 [00:10<00:01,  8.27it/s] 88%|████████▊ | 88/100 [00:10<00:01,  8.12it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.02it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.19it/s] 91%|█████████ | 91/100 [00:10<00:01,  8.12it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.30it/s] 93%|█████████▎| 93/100 [00:10<00:00,  8.31it/s] 94%|█████████▍| 94/100 [00:11<00:00,  8.19it/s] 95%|█████████▌| 95/100 [00:11<00:00,  8.33it/s] 96%|█████████▌| 96/100 [00:11<00:00,  8.38it/s] 97%|█████████▋| 97/100 [00:11<00:00,  8.46it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.46it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.39it/s]100%|██████████| 100/100 [00:11<00:00,  8.36it/s]100%|██████████| 100/100 [00:11<00:00,  8.47it/s]
[I 2025-08-27 14:53:50,975] A new study created in memory with name: no-name-c4bbff18-250e-422a-aaa7-6cdcf88a785d
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.952944, Valid_loss 2.190633
Epoch 2, Train Loss 0.902022, Valid_loss 1.823703
Epoch 3, Train Loss 0.942905, Valid_loss 1.783906
Epoch 4, Train Loss 0.852611, Valid_loss 1.736104
Epoch 5, Train Loss 0.852690, Valid_loss 1.641257
Epoch 6, Train Loss 0.830238, Valid_loss 1.659247
Epoch 7, Train Loss 0.862217, Valid_loss 1.574460
Epoch 8, Train Loss 0.864854, Valid_loss 1.617952
Epoch 9, Train Loss 0.905244, Valid_loss 1.526478
Epoch 10, Train Loss 0.850298, Valid_loss 1.531662
Epoch 11, Train Loss 0.833101, Valid_loss 1.597977
Epoch 12, Train Loss 0.831344, Valid_loss 1.546829
Epoch 13, Train Loss 0.812140, Valid_loss 1.674621
Epoch 14, Train Loss 0.846099, Valid_loss 1.487614
Epoch 15, Train Loss 0.825702, Valid_loss 1.655792
Epoch 16, Train Loss 0.843018, Valid_loss 1.628738
Epoch 17, Train Loss 0.822730, Valid_loss 1.651247
Epoch 18, Train Loss 0.816979, Valid_loss 1.660157
Epoch 19, Train Loss 0.822165, Valid_loss 1.679986
Epoch 20, Train Loss 0.815660, Valid_loss 1.675096
Epoch 21, Train Loss 0.836663, Valid_loss 1.601771
Epoch 22, Train Loss 0.817773, Valid_loss 1.686544
Epoch 23, Train Loss 0.840046, Valid_loss 1.641775
Epoch 24, Train Loss 0.813483, Valid_loss 1.829085
Epoch 25, Train Loss 0.826868, Valid_loss 1.625122
Epoch 26, Train Loss 0.818009, Valid_loss 1.616759
Epoch 27, Train Loss 0.822519, Valid_loss 1.644296
Epoch 28, Train Loss 0.821887, Valid_loss 1.669329
Epoch 29, Train Loss 0.820396, Valid_loss 1.666289
Epoch 30, Train Loss 0.820585, Valid_loss 1.707662
Epoch 31, Train Loss 0.821516, Valid_loss 1.777459
Epoch 32, Train Loss 0.827936, Valid_loss 1.675129
Epoch 33, Train Loss 0.818192, Valid_loss 1.693812
Epoch 34, Train Loss 0.820841, Valid_loss 1.720074
Epoch 35, Train Loss 0.823850, Valid_loss 1.851356
Epoch 36, Train Loss 0.830000, Valid_loss 1.692581
Epoch 37, Train Loss 0.809627, Valid_loss 2.175963
Epoch 38, Train Loss 0.809757, Valid_loss 1.668001
Epoch 39, Train Loss 0.831588, Valid_loss 1.734422
Epoch 40, Train Loss 0.837548, Valid_loss 1.745197
Epoch 41, Train Loss 0.833205, Valid_loss 1.598370
Epoch 42, Train Loss 0.820823, Valid_loss 1.656389
Epoch 43, Train Loss 0.820594, Valid_loss 1.671667
Epoch 44, Train Loss 0.819521, Valid_loss 1.698101
Epoch 45, Train Loss 0.820593, Valid_loss 1.704818
Epoch 46, Train Loss 0.831408, Valid_loss 1.692458
Epoch 47, Train Loss 0.840282, Valid_loss 1.701035
Epoch 48, Train Loss 0.820370, Valid_loss 1.713370
Epoch 49, Train Loss 0.818955, Valid_loss 1.718571
Epoch 50, Train Loss 0.817327, Valid_loss 1.740930
Epoch 51, Train Loss 0.816834, Valid_loss 1.729484
Epoch 52, Train Loss 0.817293, Valid_loss 1.733062
Epoch 53, Train Loss 0.816133, Valid_loss 1.733768
[I 2025-08-27 15:29:09,567] Trial 0 finished with value: 1.4876143882671993 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 1.4876143882671993.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.233344, Valid_loss 1.150807
Epoch 2, Train Loss 1.003436, Valid_loss 1.132546
Epoch 3, Train Loss 0.918631, Valid_loss 1.067218
Epoch 4, Train Loss 0.852289, Valid_loss 1.062076
Epoch 5, Train Loss 0.795853, Valid_loss 0.936044
Epoch 6, Train Loss 0.750095, Valid_loss 0.917259
Epoch 7, Train Loss 0.728510, Valid_loss 0.875676
Epoch 8, Train Loss 0.688843, Valid_loss 0.880365
Epoch 9, Train Loss 0.651196, Valid_loss 0.904334
Epoch 10, Train Loss 0.623030, Valid_loss 0.849839
Epoch 11, Train Loss 0.607733, Valid_loss 0.840559
Epoch 12, Train Loss 0.614091, Valid_loss 0.817008
Epoch 13, Train Loss 0.559246, Valid_loss 0.805422
Epoch 14, Train Loss 0.548551, Valid_loss 0.813130
Epoch 15, Train Loss 0.555931, Valid_loss 0.796550
Epoch 16, Train Loss 0.535709, Valid_loss 0.794948
Epoch 17, Train Loss 0.511035, Valid_loss 0.812758
Epoch 18, Train Loss 0.485466, Valid_loss 0.773449
Epoch 19, Train Loss 0.503432, Valid_loss 0.771802
Epoch 20, Train Loss 0.477432, Valid_loss 0.783419
Epoch 21, Train Loss 0.459970, Valid_loss 0.775085
Epoch 22, Train Loss 0.452376, Valid_loss 0.767946
Epoch 23, Train Loss 0.441889, Valid_loss 0.769229
Epoch 24, Train Loss 0.421741, Valid_loss 0.750336
Epoch 25, Train Loss 0.413221, Valid_loss 0.763211
Epoch 26, Train Loss 0.409033, Valid_loss 0.779352
Epoch 27, Train Loss 0.389755, Valid_loss 0.779249
Epoch 28, Train Loss 0.396428, Valid_loss 0.752657
Epoch 29, Train Loss 0.385683, Valid_loss 0.747787
Epoch 30, Train Loss 0.404125, Valid_loss 0.794938
Epoch 31, Train Loss 0.372484, Valid_loss 0.784267
Epoch 32, Train Loss 0.370400, Valid_loss 0.839192
Epoch 33, Train Loss 0.368617, Valid_loss 0.763918
Epoch 34, Train Loss 0.349895, Valid_loss 0.747522
Epoch 35, Train Loss 0.351223, Valid_loss 0.739222
Epoch 36, Train Loss 0.338457, Valid_loss 0.801035
Epoch 37, Train Loss 0.347759, Valid_loss 0.796461
Epoch 38, Train Loss 0.331578, Valid_loss 1.127789
Epoch 39, Train Loss 0.338907, Valid_loss 0.817445
Epoch 40, Train Loss 0.309505, Valid_loss 0.736979
Epoch 41, Train Loss 0.311775, Valid_loss 0.799938
Epoch 42, Train Loss 0.344252, Valid_loss 0.767199
Epoch 43, Train Loss 0.325513, Valid_loss 0.820854
Epoch 44, Train Loss 0.319844, Valid_loss 0.779046
Epoch 45, Train Loss 0.278915, Valid_loss 0.743034
Epoch 46, Train Loss 0.290956, Valid_loss 0.758280
Epoch 47, Train Loss 0.291973, Valid_loss 0.799594
Epoch 48, Train Loss 0.292131, Valid_loss 0.808964
Epoch 49, Train Loss 0.273636, Valid_loss 0.795038
Epoch 50, Train Loss 0.271131, Valid_loss 0.811485
Epoch 51, Train Loss 0.262215, Valid_loss 0.745475
Epoch 52, Train Loss 0.258255, Valid_loss 0.808563
Epoch 53, Train Loss 0.254947, Valid_loss 0.755373
Epoch 54, Train Loss 0.246083, Valid_loss 0.755151
Epoch 55, Train Loss 0.242543, Valid_loss 0.826673
Epoch 56, Train Loss 0.236705, Valid_loss 0.807953
Epoch 57, Train Loss 0.232650, Valid_loss 0.759024
Epoch 58, Train Loss 0.231461, Valid_loss 0.761680
Epoch 59, Train Loss 0.233110, Valid_loss 0.761638
Epoch 60, Train Loss 0.225807, Valid_loss 0.777833
Epoch 61, Train Loss 0.223980, Valid_loss 0.718387
Epoch 62, Train Loss 0.243827, Valid_loss 0.760869
Epoch 63, Train Loss 0.221545, Valid_loss 0.775845
[I 2025-08-27 16:08:23,394] Trial 1 finished with value: 0.7183873488878211 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.0, 'weight_decay': 0.01, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 0.7183873488878211.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17855.37 MB
Memory Reserved: 17874.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 299.37 MB
Memory Reserved: 320.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17855.54 MB
Memory Reserved: 17876.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 299.37 MB
Memory Reserved: 320.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 16:08:33,746] Trial 2 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17856.86 MB
Memory Reserved: 17876.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 4713.41 MB
Memory Reserved: 4732.00 MB
cuda
Epoch 1, Train Loss 1.128065, Valid_loss 1.272088
Epoch 2, Train Loss 0.866180, Valid_loss 1.136785
Epoch 3, Train Loss 0.694786, Valid_loss 1.041670
Epoch 4, Train Loss 0.596538, Valid_loss 1.108680
Epoch 5, Train Loss 0.584353, Valid_loss 0.988817
Epoch 6, Train Loss 0.515317, Valid_loss 0.793498
Epoch 7, Train Loss 0.506177, Valid_loss 0.887173
Epoch 8, Train Loss 0.485953, Valid_loss 1.108297
Epoch 9, Train Loss 0.399673, Valid_loss 0.792774
Epoch 10, Train Loss 0.463238, Valid_loss 1.064738
Epoch 11, Train Loss 0.415330, Valid_loss 0.913160
Epoch 12, Train Loss 0.413980, Valid_loss 0.959816
Epoch 13, Train Loss 0.356770, Valid_loss 1.007824
Epoch 14, Train Loss 0.517517, Valid_loss 1.061620
Epoch 15, Train Loss 0.389243, Valid_loss 1.065416
Epoch 16, Train Loss 0.428898, Valid_loss 0.819664
Epoch 17, Train Loss 0.347998, Valid_loss 0.894838
Epoch 18, Train Loss 0.364134, Valid_loss 0.681947
Epoch 19, Train Loss 0.357777, Valid_loss 0.869511
Epoch 20, Train Loss 0.364481, Valid_loss 0.975812
Epoch 21, Train Loss 0.317511, Valid_loss 0.823296
Epoch 22, Train Loss 0.332667, Valid_loss 0.846386
Epoch 23, Train Loss 0.310903, Valid_loss 1.112556
Epoch 24, Train Loss 0.322416, Valid_loss 0.699251
Epoch 25, Train Loss 0.327636, Valid_loss 1.046802
Epoch 26, Train Loss 0.283013, Valid_loss 0.799208
Epoch 27, Train Loss 0.314998, Valid_loss 0.680345
Epoch 28, Train Loss 0.339728, Valid_loss 1.275789
Epoch 29, Train Loss 0.279925, Valid_loss 0.889773
Epoch 30, Train Loss 0.290185, Valid_loss 0.901342
Epoch 31, Train Loss 0.269600, Valid_loss 0.853231
Epoch 32, Train Loss 0.249541, Valid_loss 0.957327
Epoch 33, Train Loss 0.353275, Valid_loss 0.906271
Epoch 34, Train Loss 0.273091, Valid_loss 0.916460
Epoch 35, Train Loss 0.246472, Valid_loss 0.857749
Epoch 36, Train Loss 0.259374, Valid_loss 0.806183
Epoch 37, Train Loss 0.369211, Valid_loss 1.461798
Epoch 38, Train Loss 0.303721, Valid_loss 0.956292
Epoch 39, Train Loss 0.238827, Valid_loss 0.691478
Epoch 40, Train Loss 0.242485, Valid_loss 1.104730
Epoch 41, Train Loss 0.370839, Valid_loss 0.896357
Epoch 42, Train Loss 0.258187, Valid_loss 0.857209
Epoch 43, Train Loss 0.242705, Valid_loss 0.605088
Epoch 44, Train Loss 0.242927, Valid_loss 0.820876
Epoch 45, Train Loss 0.226518, Valid_loss 1.122133
Epoch 46, Train Loss 0.225592, Valid_loss 0.769453
Epoch 47, Train Loss 0.196343, Valid_loss 0.883282
Epoch 48, Train Loss 0.202469, Valid_loss 0.796592
Epoch 49, Train Loss 0.268108, Valid_loss 0.826754
Epoch 50, Train Loss 0.242962, Valid_loss 0.899411
Epoch 51, Train Loss 0.187750, Valid_loss 0.837082
Epoch 52, Train Loss 0.174200, Valid_loss 1.054527
Epoch 53, Train Loss 0.184919, Valid_loss 0.829517
Epoch 54, Train Loss 0.191032, Valid_loss 0.864183
Epoch 55, Train Loss 0.176349, Valid_loss 0.797174
Epoch 56, Train Loss 0.191250, Valid_loss 0.864360
Epoch 57, Train Loss 0.169053, Valid_loss 0.846872
Epoch 58, Train Loss 0.193859, Valid_loss 0.607831
Epoch 59, Train Loss 0.192322, Valid_loss 0.805381
Epoch 60, Train Loss 0.171602, Valid_loss 0.879575
[I 2025-08-27 16:36:55,792] Trial 3 finished with value: 0.6050877384841442 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.3, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 3 with value: 0.6050877384841442.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.3, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 4713.41 MB
Memory Reserved: 4732.00 MB
cuda
Epoch 1, Train Loss 0.880883, Valid_loss 1.293454
Epoch 2, Train Loss 0.783774, Valid_loss 1.257610
Epoch 3, Train Loss 0.648205, Valid_loss 1.142469
Epoch 4, Train Loss 0.558375, Valid_loss 1.062472
Epoch 5, Train Loss 0.529606, Valid_loss 1.070631
Epoch 6, Train Loss 0.467812, Valid_loss 1.048055
Epoch 7, Train Loss 0.501923, Valid_loss 1.131322
Epoch 8, Train Loss 0.420015, Valid_loss 1.019301
Epoch 9, Train Loss 0.454668, Valid_loss 0.844363
Epoch 10, Train Loss 0.470202, Valid_loss 0.917867
Epoch 11, Train Loss 0.412893, Valid_loss 0.975407
Epoch 12, Train Loss 0.392786, Valid_loss 0.994080
Epoch 13, Train Loss 0.366894, Valid_loss 0.839056
Epoch 14, Train Loss 0.442084, Valid_loss 0.883447
Epoch 15, Train Loss 0.353857, Valid_loss 0.980556
Epoch 16, Train Loss 0.340616, Valid_loss 0.810393
Epoch 17, Train Loss 0.358226, Valid_loss 1.043761
Epoch 18, Train Loss 0.350567, Valid_loss 0.979768
Epoch 19, Train Loss 0.319776, Valid_loss 1.080802
Epoch 20, Train Loss 0.341583, Valid_loss 0.708824
Epoch 21, Train Loss 0.309882, Valid_loss 0.683584
Epoch 22, Train Loss 0.302751, Valid_loss 0.963325
Epoch 23, Train Loss 0.340409, Valid_loss 0.858623
Epoch 24, Train Loss 0.309993, Valid_loss 0.969779
Epoch 25, Train Loss 0.272793, Valid_loss 1.037211
Epoch 26, Train Loss 0.330755, Valid_loss 0.816469
Epoch 27, Train Loss 0.257030, Valid_loss 0.757011
Epoch 28, Train Loss 0.303546, Valid_loss 0.855938
Epoch 29, Train Loss 0.287234, Valid_loss 0.954027
Epoch 30, Train Loss 0.292013, Valid_loss 0.818645
Epoch 31, Train Loss 0.256578, Valid_loss 1.080965
Epoch 32, Train Loss 0.289109, Valid_loss 0.930918
Epoch 33, Train Loss 0.250647, Valid_loss 1.102626
Epoch 34, Train Loss 0.299122, Valid_loss 0.655160
Epoch 35, Train Loss 0.259335, Valid_loss 1.033332
Epoch 36, Train Loss 0.222409, Valid_loss 0.773964
Epoch 37, Train Loss 0.270650, Valid_loss 1.027156
Epoch 38, Train Loss 0.214217, Valid_loss 0.822648
Epoch 39, Train Loss 0.239629, Valid_loss 1.318922
Epoch 40, Train Loss 0.205483, Valid_loss 0.759526
Epoch 41, Train Loss 0.199720, Valid_loss 1.031283
Epoch 42, Train Loss 0.227763, Valid_loss 0.960973
Epoch 43, Train Loss 0.195630, Valid_loss 0.880005
Epoch 44, Train Loss 0.237408, Valid_loss 0.871946
Epoch 45, Train Loss 0.186168, Valid_loss 0.773389
Epoch 46, Train Loss 0.172824, Valid_loss 0.867981
Epoch 47, Train Loss 0.183263, Valid_loss 0.872263
Epoch 48, Train Loss 0.229449, Valid_loss 1.042854
Epoch 49, Train Loss 0.198852, Valid_loss 0.977342
Epoch 50, Train Loss 0.171953, Valid_loss 1.023751
Epoch 51, Train Loss 0.154987, Valid_loss 1.033427
Epoch 52, Train Loss 0.177854, Valid_loss 1.258618
환자ID=P1300 -- true: [[2]] -- pred: tensor([[-1.3997,  1.0525,  0.2855]], device='cuda:0')
환자ID=P1422 -- true: [[1]] -- pred: tensor([[-1.2456,  0.9966,  0.2706]], device='cuda:0')
환자ID=P1447 -- true: [[1]] -- pred: tensor([[-0.8719,  1.3728, -0.0331]], device='cuda:0')
환자ID=P1479 -- true: [[1]] -- pred: tensor([[-1.1274,  1.2254,  0.1696]], device='cuda:0')
환자ID=P1504 -- true: [[2]] -- pred: tensor([[-1.4390,  1.0253,  0.3286]], device='cuda:0')
환자ID=P1540 -- true: [[0]] -- pred: tensor([[ 2.6301, -1.2260, -2.0212]], device='cuda:0')
환자ID=P1582 -- true: [[0]] -- pred: tensor([[ 2.5787, -1.1221, -1.9522]], device='cuda:0')
환자ID=P1702 -- true: [[0]] -- pred: tensor([[ 2.5977, -1.2309, -1.9205]], device='cuda:0')
Best performance: Epoch 34, Loss 0.299122, Test ACC 0.750000, Test AUC 0.916667, Test Recall 0.666667, Test Precision 0.533333
Confusion Matrix:
 [[3 0 0]
 [0 3 0]
 [0 2 0]]
✅ Total valid splits used: 3
🔁 Repeat 1, Fold 3
cell type :  TTCTTCCGTTCAACGT-1-0              cardiac muscle cell
CATCCACCATCTAACG-1-0              cardiac muscle cell
ACCCAAACAGCTAACT-1-0              cardiac muscle cell
AAGGAATCAACTGGTT-1-0              cardiac muscle cell
TACCCGTAGCGTGCTC-1-0              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 482823, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0              cardiac muscle cell
CATCCACCATCTAACG-1-0              cardiac muscle cell
ACCCAAACAGCTAACT-1-0              cardiac muscle cell
AAGGAATCAACTGGTT-1-0              cardiac muscle cell
TACCCGTAGCGTGCTC-1-0              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 482823, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  CACACAACAATCGTCA-1-7          cardiac muscle cell
TGCGATATCGTAGTCA-1-7          cardiac muscle cell
ATTCACTAGTTAGAAC-1-7          cardiac muscle cell
CGAAGTTGTGGTCAAG-1-7          cardiac muscle cell
AAACCCAGTGAACCGA-1-7          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 109866, dtype: string
cell type annotation :  CACACAACAATCGTCA-1-7          cardiac muscle cell
TGCGATATCGTAGTCA-1-7          cardiac muscle cell
ATTCACTAGTTAGAAC-1-7          cardiac muscle cell
CGAAGTTGTGGTCAAG-1-7          cardiac muscle cell
AAACCCAGTGAACCGA-1-7          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 109866, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'cardiac endothelial cell', 'endothelial cell of lymphatic vessel', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac neuron', 'mesothelial cell', 'macrophage', 'mast cell', 'vascular associated smooth muscle cell', 'pericyte cell', 'lymphocyte']
라벨별 그룹 개수 {2: 2, 0: 3, 1: 3}
🔍 Split #4
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1290', 'P1300', 'P1304', 'P1358', 'P1371', 'P1422', 'P1425', 'P1430', 'P1437', 'P1447', 'P1462', 'P1479', 'P1504', 'P1508', 'P1510', 'P1516', 'P1539', 'P1540', 'P1547', 'P1558', 'P1582', 'P1600', 'P1603', 'P1606', 'P1610', 'P1622', 'P1630', 'P1631', 'P1678', 'P1702', 'P1718', 'P1722', 'P1726', 'P1735']
  → test  환자 ID: ['P1472', 'P1515', 'P1549', 'P1561', 'P1602', 'P1617', 'P1685', 'P1707']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1558, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1702, Label: 0
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1472, Label: 2
    ID: P1515, Label: 0
    ID: P1549, Label: 0
    ID: P1561, Label: 0
    ID: P1602, Label: 1
    ID: P1617, Label: 2
    ID: P1685, Label: 1
    ID: P1707, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1516, Label=0, 셀개수=9361
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1600, Label=0, 셀개수=14882
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1707, Label=1, 셀개수=9517
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0              cardiac muscle cell
1              cardiac muscle cell
2              cardiac muscle cell
3              cardiac muscle cell
4              cardiac muscle cell
                    ...           
592684    cardiac endothelial cell
592685    cardiac endothelial cell
592686    cardiac endothelial cell
592687    cardiac endothelial cell
592688    cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:16,  5.99it/s]  2%|▏         | 2/100 [00:00<00:13,  7.25it/s]  3%|▎         | 3/100 [00:00<00:12,  7.68it/s]  4%|▍         | 4/100 [00:00<00:12,  7.97it/s]  5%|▌         | 5/100 [00:00<00:11,  8.15it/s]  6%|▌         | 6/100 [00:00<00:11,  8.40it/s]  7%|▋         | 7/100 [00:00<00:10,  8.55it/s]  8%|▊         | 8/100 [00:00<00:10,  8.51it/s]  9%|▉         | 9/100 [00:01<00:10,  8.58it/s] 10%|█         | 10/100 [00:01<00:10,  8.48it/s] 11%|█         | 11/100 [00:01<00:10,  8.51it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.39it/s] 13%|█▎        | 13/100 [00:01<00:10,  8.47it/s] 14%|█▍        | 14/100 [00:01<00:10,  8.17it/s] 15%|█▌        | 15/100 [00:01<00:10,  8.21it/s] 16%|█▌        | 16/100 [00:01<00:10,  8.30it/s] 17%|█▋        | 17/100 [00:02<00:30,  2.71it/s] 18%|█▊        | 18/100 [00:03<00:34,  2.36it/s] 19%|█▉        | 19/100 [00:03<00:32,  2.51it/s] 20%|██        | 20/100 [00:05<01:02,  1.28it/s] 21%|██        | 21/100 [00:05<00:48,  1.63it/s] 22%|██▏       | 22/100 [00:06<00:52,  1.50it/s] 23%|██▎       | 23/100 [00:07<00:51,  1.50it/s] 24%|██▍       | 24/100 [00:07<00:39,  1.90it/s] 25%|██▌       | 25/100 [00:07<00:32,  2.30it/s] 26%|██▌       | 26/100 [00:08<00:41,  1.79it/s] 27%|██▋       | 27/100 [00:08<00:31,  2.32it/s] 28%|██▊       | 28/100 [00:08<00:30,  2.38it/s] 29%|██▉       | 29/100 [00:09<00:23,  3.02it/s] 30%|███       | 30/100 [00:09<00:21,  3.20it/s] 31%|███       | 31/100 [00:09<00:21,  3.14it/s] 32%|███▏      | 32/100 [00:09<00:17,  3.84it/s] 33%|███▎      | 33/100 [00:11<00:39,  1.71it/s] 34%|███▍      | 34/100 [00:11<00:37,  1.78it/s] 35%|███▌      | 35/100 [00:13<00:56,  1.15it/s] 36%|███▌      | 36/100 [00:13<00:43,  1.47it/s] 37%|███▋      | 37/100 [00:13<00:38,  1.65it/s] 38%|███▊      | 38/100 [00:14<00:28,  2.17it/s] 39%|███▉      | 39/100 [00:14<00:28,  2.14it/s] 40%|████      | 40/100 [00:14<00:25,  2.34it/s] 41%|████      | 41/100 [00:15<00:33,  1.75it/s] 42%|████▏     | 42/100 [00:16<00:28,  2.01it/s] 43%|████▎     | 43/100 [00:16<00:26,  2.13it/s] 44%|████▍     | 44/100 [00:16<00:26,  2.08it/s] 45%|████▌     | 45/100 [00:17<00:24,  2.21it/s] 46%|████▌     | 46/100 [00:17<00:19,  2.78it/s] 47%|████▋     | 47/100 [00:18<00:24,  2.19it/s] 48%|████▊     | 48/100 [00:18<00:29,  1.78it/s] 49%|████▉     | 49/100 [00:19<00:25,  1.99it/s] 50%|█████     | 50/100 [00:19<00:25,  2.00it/s] 51%|█████     | 51/100 [00:20<00:20,  2.36it/s] 52%|█████▏    | 52/100 [00:20<00:22,  2.12it/s] 53%|█████▎    | 53/100 [00:21<00:20,  2.30it/s] 54%|█████▍    | 54/100 [00:21<00:26,  1.71it/s] 55%|█████▌    | 55/100 [00:22<00:20,  2.23it/s] 56%|█████▌    | 56/100 [00:22<00:16,  2.60it/s] 57%|█████▋    | 57/100 [00:22<00:15,  2.83it/s] 58%|█████▊    | 58/100 [00:23<00:18,  2.33it/s] 59%|█████▉    | 59/100 [00:23<00:16,  2.50it/s] 60%|██████    | 60/100 [00:23<00:13,  2.91it/s] 61%|██████    | 61/100 [00:24<00:17,  2.22it/s] 62%|██████▏   | 62/100 [00:25<00:22,  1.68it/s] 63%|██████▎   | 63/100 [00:25<00:18,  1.96it/s] 64%|██████▍   | 64/100 [00:26<00:17,  2.03it/s] 65%|██████▌   | 65/100 [00:26<00:13,  2.60it/s] 66%|██████▌   | 66/100 [00:27<00:23,  1.44it/s] 67%|██████▋   | 67/100 [00:28<00:19,  1.68it/s] 68%|██████▊   | 68/100 [00:28<00:15,  2.03it/s] 69%|██████▉   | 69/100 [00:28<00:13,  2.32it/s] 70%|███████   | 70/100 [00:28<00:12,  2.43it/s] 71%|███████   | 71/100 [00:30<00:24,  1.18it/s] 72%|███████▏  | 72/100 [00:31<00:19,  1.45it/s] 73%|███████▎  | 73/100 [00:31<00:14,  1.81it/s] 74%|███████▍  | 74/100 [00:31<00:12,  2.04it/s] 75%|███████▌  | 75/100 [00:33<00:19,  1.28it/s] 76%|███████▌  | 76/100 [00:33<00:15,  1.57it/s] 77%|███████▋  | 77/100 [00:33<00:12,  1.87it/s] 78%|███████▊  | 78/100 [00:34<00:09,  2.29it/s] 79%|███████▉  | 79/100 [00:34<00:08,  2.40it/s] 80%|████████  | 80/100 [00:34<00:08,  2.39it/s] 81%|████████  | 81/100 [00:34<00:06,  2.93it/s] 82%|████████▏ | 82/100 [00:35<00:06,  2.87it/s] 83%|████████▎ | 83/100 [00:35<00:05,  3.28it/s] 84%|████████▍ | 84/100 [00:35<00:05,  3.18it/s] 85%|████████▌ | 85/100 [00:36<00:05,  2.59it/s] 86%|████████▌ | 86/100 [00:36<00:04,  3.27it/s] 87%|████████▋ | 87/100 [00:36<00:03,  3.49it/s] 88%|████████▊ | 88/100 [00:37<00:03,  3.11it/s] 89%|████████▉ | 89/100 [00:37<00:04,  2.66it/s] 90%|█████████ | 90/100 [00:38<00:03,  2.68it/s] 91%|█████████ | 91/100 [00:38<00:03,  2.75it/s] 92%|█████████▏| 92/100 [00:39<00:04,  1.99it/s] 93%|█████████▎| 93/100 [00:39<00:02,  2.43it/s] 94%|█████████▍| 94/100 [00:39<00:02,  2.41it/s] 95%|█████████▌| 95/100 [00:40<00:02,  2.09it/s] 96%|█████████▌| 96/100 [00:41<00:02,  1.77it/s] 97%|█████████▋| 97/100 [00:41<00:01,  1.89it/s] 98%|█████████▊| 98/100 [00:42<00:01,  1.69it/s] 99%|█████████▉| 99/100 [00:42<00:00,  2.14it/s]100%|██████████| 100/100 [00:42<00:00,  2.71it/s]100%|██████████| 100/100 [00:42<00:00,  2.34it/s]
[I 2025-08-27 17:00:29,024] A new study created in memory with name: no-name-8a94243b-a5cd-44d3-b43a-153bf5154229
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.95 MB
Memory Reserved: 8626.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.97 MB
Memory Reserved: 8658.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.85 MB
Memory Reserved: 8624.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.97 MB
Memory Reserved: 8656.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 17:00:31,076] Trial 0 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8619.88 MB
Memory Reserved: 8624.00 MB
cuda
Epoch 1, Train Loss 0.990144, Valid_loss 1.154282
Epoch 2, Train Loss 0.951066, Valid_loss 1.223820
Epoch 3, Train Loss 0.981204, Valid_loss 1.150537
Epoch 4, Train Loss 0.957256, Valid_loss 1.191813
Epoch 5, Train Loss 0.949867, Valid_loss 1.182350
Epoch 6, Train Loss 0.975024, Valid_loss 1.199250
Epoch 7, Train Loss 0.962817, Valid_loss 1.144476
Epoch 8, Train Loss 0.973062, Valid_loss 1.206130
Epoch 9, Train Loss 0.959868, Valid_loss 1.198784
Epoch 10, Train Loss 0.958747, Valid_loss 1.193119
Epoch 11, Train Loss 0.954856, Valid_loss 1.206630
Epoch 12, Train Loss 0.957536, Valid_loss 1.188447
Epoch 13, Train Loss 0.955689, Valid_loss 1.200791
Epoch 14, Train Loss 0.954773, Valid_loss 1.191016
Epoch 15, Train Loss 0.955284, Valid_loss 1.203349
Epoch 16, Train Loss 0.954270, Valid_loss 1.204482
Epoch 17, Train Loss 0.954513, Valid_loss 1.196953
Epoch 18, Train Loss 0.954325, Valid_loss 1.200493
Epoch 19, Train Loss 0.954647, Valid_loss 1.198972
Epoch 20, Train Loss 0.955462, Valid_loss 1.199380
Epoch 21, Train Loss 0.956058, Valid_loss 1.197604
Epoch 22, Train Loss 0.955863, Valid_loss 1.203905
Epoch 23, Train Loss 0.956843, Valid_loss 1.210355
Epoch 24, Train Loss 0.975751, Valid_loss 1.203165
Epoch 25, Train Loss 0.956019, Valid_loss 1.206711
Epoch 26, Train Loss 0.993858, Valid_loss 1.225333
Epoch 27, Train Loss 0.958298, Valid_loss 1.188957
Epoch 28, Train Loss 0.954550, Valid_loss 1.202965
Epoch 29, Train Loss 0.954490, Valid_loss 1.222003
Epoch 30, Train Loss 0.955947, Valid_loss 1.211043
Epoch 31, Train Loss 0.954135, Valid_loss 1.213055
Epoch 32, Train Loss 0.954933, Valid_loss 1.208058
Epoch 33, Train Loss 0.955581, Valid_loss 1.196289
Epoch 34, Train Loss 0.953925, Valid_loss 1.193917
Epoch 35, Train Loss 0.954711, Valid_loss 1.194002
Epoch 36, Train Loss 0.954656, Valid_loss 1.203766
Epoch 37, Train Loss 0.958379, Valid_loss 1.208833
Epoch 38, Train Loss 0.954565, Valid_loss 1.210963
Epoch 39, Train Loss 0.954898, Valid_loss 1.208511
Epoch 40, Train Loss 0.957602, Valid_loss 1.206314
Epoch 41, Train Loss 0.956115, Valid_loss 1.209916
Epoch 42, Train Loss 0.956077, Valid_loss 1.191212
Epoch 43, Train Loss 0.956506, Valid_loss 1.203869
Epoch 44, Train Loss 0.955500, Valid_loss 1.209994
Epoch 45, Train Loss 1.034171, Valid_loss 1.181010
Epoch 46, Train Loss 0.956314, Valid_loss 1.204224
Epoch 47, Train Loss 0.953713, Valid_loss 1.201881
Epoch 48, Train Loss 0.955819, Valid_loss 1.208036
Epoch 49, Train Loss 0.954505, Valid_loss 1.204664
Epoch 50, Train Loss 0.955350, Valid_loss 1.213445
Epoch 51, Train Loss 0.952922, Valid_loss 1.214948
Epoch 52, Train Loss 0.952789, Valid_loss 1.213017
Epoch 53, Train Loss 0.952790, Valid_loss 1.200627
Epoch 54, Train Loss 0.951790, Valid_loss 1.207783
Epoch 55, Train Loss 0.952956, Valid_loss 1.203838
Epoch 56, Train Loss 0.951725, Valid_loss 1.208852
Epoch 57, Train Loss 0.953723, Valid_loss 1.208810
Epoch 58, Train Loss 0.953494, Valid_loss 1.203802
Epoch 59, Train Loss 0.954040, Valid_loss 1.207915
Epoch 60, Train Loss 0.952071, Valid_loss 1.205531
Epoch 61, Train Loss 0.952881, Valid_loss 1.207750
Epoch 62, Train Loss 0.952404, Valid_loss 1.207532
Epoch 63, Train Loss 0.952525, Valid_loss 1.204441
Epoch 64, Train Loss 0.952154, Valid_loss 1.202619
Epoch 65, Train Loss 0.953953, Valid_loss 1.198734
Epoch 66, Train Loss 0.953193, Valid_loss 1.201515
Epoch 67, Train Loss 0.954366, Valid_loss 1.207247
[I 2025-08-27 17:29:17,582] Trial 1 finished with value: 1.1444755345582962 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 1.1444755345582962.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.055779, Valid_loss 1.190316
Epoch 2, Train Loss 0.987604, Valid_loss 1.171712
Epoch 3, Train Loss 0.983206, Valid_loss 1.176231
Epoch 4, Train Loss 0.986368, Valid_loss 1.170256
Epoch 5, Train Loss 0.966868, Valid_loss 1.192858
Epoch 6, Train Loss 0.966923, Valid_loss 1.211989
Epoch 7, Train Loss 0.988555, Valid_loss 1.182122
Epoch 8, Train Loss 0.959067, Valid_loss 1.182690
Epoch 9, Train Loss 0.954814, Valid_loss 1.195704
Epoch 10, Train Loss 0.955723, Valid_loss 1.168045
Epoch 11, Train Loss 0.956133, Valid_loss 1.182935
Epoch 12, Train Loss 0.958729, Valid_loss 1.195946
Epoch 13, Train Loss 0.954785, Valid_loss 1.191921
Epoch 14, Train Loss 0.954837, Valid_loss 1.199564
Epoch 15, Train Loss 0.954713, Valid_loss 1.211968
Epoch 16, Train Loss 0.955886, Valid_loss 1.211944
Epoch 17, Train Loss 0.954580, Valid_loss 1.201531
Epoch 18, Train Loss 0.954418, Valid_loss 1.203222
Epoch 19, Train Loss 0.955484, Valid_loss 1.211412
Epoch 20, Train Loss 0.954579, Valid_loss 1.205687
Epoch 21, Train Loss 0.956582, Valid_loss 1.212310
Epoch 22, Train Loss 0.954104, Valid_loss 1.203539
Epoch 23, Train Loss 0.955851, Valid_loss 1.196735
Epoch 24, Train Loss 0.956195, Valid_loss 1.207384
Epoch 25, Train Loss 0.954128, Valid_loss 1.217158
Epoch 26, Train Loss 0.955958, Valid_loss 1.212865
Epoch 27, Train Loss 0.954596, Valid_loss 1.188894
Epoch 28, Train Loss 0.955788, Valid_loss 1.208631
Epoch 29, Train Loss 0.954362, Valid_loss 1.217642
Epoch 30, Train Loss 0.956121, Valid_loss 1.218065
Epoch 31, Train Loss 0.955790, Valid_loss 1.211475
Epoch 32, Train Loss 0.956619, Valid_loss 1.216712
Epoch 33, Train Loss 0.954370, Valid_loss 1.211026
Epoch 34, Train Loss 0.955003, Valid_loss 1.207677
Epoch 35, Train Loss 0.954104, Valid_loss 1.212373
Epoch 36, Train Loss 0.956177, Valid_loss 1.205515
Epoch 37, Train Loss 0.955362, Valid_loss 1.201740
Epoch 38, Train Loss 0.952824, Valid_loss 1.197095
Epoch 39, Train Loss 0.955179, Valid_loss 1.213797
Epoch 40, Train Loss 0.954729, Valid_loss 1.206264
Epoch 41, Train Loss 0.954509, Valid_loss 1.215862
Epoch 42, Train Loss 0.955029, Valid_loss 1.210344
Epoch 43, Train Loss 0.956634, Valid_loss 1.206971
Epoch 44, Train Loss 0.954654, Valid_loss 1.197506
Epoch 45, Train Loss 0.954350, Valid_loss 1.212949
Epoch 46, Train Loss 0.955183, Valid_loss 1.207910
Epoch 47, Train Loss 0.957829, Valid_loss 1.208401
Epoch 48, Train Loss 0.955485, Valid_loss 1.212557
Epoch 49, Train Loss 0.955271, Valid_loss 1.216732
Epoch 50, Train Loss 0.953190, Valid_loss 1.198919
Epoch 51, Train Loss 0.952132, Valid_loss 1.196286
Epoch 52, Train Loss 0.952429, Valid_loss 1.202363
Epoch 53, Train Loss 0.953249, Valid_loss 1.203288
[I 2025-08-27 18:03:05,047] Trial 2 finished with value: 1.1680452575286229 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 1.1444755345582962.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.166770, Valid_loss 1.354143
Epoch 2, Train Loss 1.051531, Valid_loss 1.067558
Epoch 3, Train Loss 1.032766, Valid_loss 1.152922
Epoch 4, Train Loss 1.029748, Valid_loss 1.126221
Epoch 5, Train Loss 0.993716, Valid_loss 1.264032
Epoch 6, Train Loss 0.988740, Valid_loss 1.182531
Epoch 7, Train Loss 0.982540, Valid_loss 1.183848
Epoch 8, Train Loss 0.959769, Valid_loss 1.230709
Epoch 9, Train Loss 0.991070, Valid_loss 1.140618
Epoch 10, Train Loss 0.984497, Valid_loss 1.180938
Epoch 11, Train Loss 0.959765, Valid_loss 1.212707
Epoch 12, Train Loss 0.965652, Valid_loss 1.203162
Epoch 13, Train Loss 0.966127, Valid_loss 1.279338
Epoch 14, Train Loss 0.989992, Valid_loss 1.155514
Epoch 15, Train Loss 0.966586, Valid_loss 1.177152
Epoch 16, Train Loss 0.968001, Valid_loss 1.167808
Epoch 17, Train Loss 0.953413, Valid_loss 1.201760
Epoch 18, Train Loss 0.956677, Valid_loss 1.202355
Epoch 19, Train Loss 0.967907, Valid_loss 1.194595
Epoch 20, Train Loss 0.954468, Valid_loss 1.193136
Epoch 21, Train Loss 0.956410, Valid_loss 1.208663
Epoch 22, Train Loss 0.966076, Valid_loss 1.182177
Epoch 23, Train Loss 0.963626, Valid_loss 1.198271
Epoch 24, Train Loss 0.956220, Valid_loss 1.197327
Epoch 25, Train Loss 0.955666, Valid_loss 1.197250
Epoch 26, Train Loss 0.956962, Valid_loss 1.211416
Epoch 27, Train Loss 0.955006, Valid_loss 1.210513
Epoch 28, Train Loss 0.958546, Valid_loss 1.196567
Epoch 29, Train Loss 0.953403, Valid_loss 1.207851
Epoch 30, Train Loss 0.953545, Valid_loss 1.211361
Epoch 31, Train Loss 0.961235, Valid_loss 1.213619
Epoch 32, Train Loss 0.955456, Valid_loss 1.197425
Epoch 33, Train Loss 0.955389, Valid_loss 1.186276
Epoch 34, Train Loss 0.956001, Valid_loss 1.197903
Epoch 35, Train Loss 0.954634, Valid_loss 1.209604
Epoch 36, Train Loss 0.954890, Valid_loss 1.209756
Epoch 37, Train Loss 0.955486, Valid_loss 1.211059
Epoch 38, Train Loss 0.953997, Valid_loss 1.219753
Epoch 39, Train Loss 0.955617, Valid_loss 1.215865
Epoch 40, Train Loss 0.956570, Valid_loss 1.219505
Epoch 41, Train Loss 0.957631, Valid_loss 1.239980
Epoch 42, Train Loss 0.962383, Valid_loss 1.228491
Epoch 43, Train Loss 0.955862, Valid_loss 1.220916
Epoch 44, Train Loss 0.955802, Valid_loss 1.197357
Epoch 45, Train Loss 0.955902, Valid_loss 1.209634
Epoch 46, Train Loss 0.953248, Valid_loss 1.212457
Epoch 47, Train Loss 0.957855, Valid_loss 1.213429
Epoch 48, Train Loss 0.956225, Valid_loss 1.214225
Epoch 49, Train Loss 0.954962, Valid_loss 1.202229
Epoch 50, Train Loss 0.955121, Valid_loss 1.213609
Epoch 51, Train Loss 0.952555, Valid_loss 1.207605
Epoch 52, Train Loss 0.952668, Valid_loss 1.204748
Epoch 53, Train Loss 0.952514, Valid_loss 1.212113
Epoch 54, Train Loss 0.952043, Valid_loss 1.212648
[I 2025-08-27 18:26:29,080] Trial 3 finished with value: 1.0675582587718964 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 3 with value: 1.0675582587718964.
선택된 trial params: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.125509, Valid_loss 1.472059
Epoch 2, Train Loss 1.061019, Valid_loss 1.550785
Epoch 3, Train Loss 1.031208, Valid_loss 1.080678
Epoch 4, Train Loss 0.989537, Valid_loss 1.143374
Epoch 5, Train Loss 0.982904, Valid_loss 1.193817
Epoch 6, Train Loss 0.983974, Valid_loss 1.171619
Epoch 7, Train Loss 0.970614, Valid_loss 1.263659
Epoch 8, Train Loss 0.992970, Valid_loss 1.238620
Epoch 9, Train Loss 0.984941, Valid_loss 1.172925
Epoch 10, Train Loss 0.983176, Valid_loss 1.226253
Epoch 11, Train Loss 0.970849, Valid_loss 1.184912
Epoch 12, Train Loss 0.962039, Valid_loss 1.168135
Epoch 13, Train Loss 0.954974, Valid_loss 1.233584
Epoch 14, Train Loss 0.975888, Valid_loss 1.187515
Epoch 15, Train Loss 0.964172, Valid_loss 1.217421
Epoch 16, Train Loss 0.959391, Valid_loss 1.198360
Epoch 17, Train Loss 0.954916, Valid_loss 1.212852
Epoch 18, Train Loss 0.940029, Valid_loss 1.235229
Epoch 19, Train Loss 0.987594, Valid_loss 1.437782
Epoch 20, Train Loss 1.005797, Valid_loss 1.189116
Epoch 21, Train Loss 0.957810, Valid_loss 1.201765
Epoch 22, Train Loss 0.967093, Valid_loss 1.210257
Epoch 23, Train Loss 0.957146, Valid_loss 1.205689
Epoch 24, Train Loss 0.958159, Valid_loss 1.199337
Epoch 25, Train Loss 0.954949, Valid_loss 1.191332
Epoch 26, Train Loss 0.956712, Valid_loss 1.195016
Epoch 27, Train Loss 0.956895, Valid_loss 1.199494
Epoch 28, Train Loss 0.956062, Valid_loss 1.209083
Epoch 29, Train Loss 0.955018, Valid_loss 1.198704
Epoch 30, Train Loss 0.957976, Valid_loss 1.205160
Epoch 31, Train Loss 0.955515, Valid_loss 1.196455
Epoch 32, Train Loss 0.957289, Valid_loss 1.197774
Epoch 33, Train Loss 0.954500, Valid_loss 1.209195
Epoch 34, Train Loss 0.956980, Valid_loss 1.200876
Epoch 35, Train Loss 0.955660, Valid_loss 1.222563
Epoch 36, Train Loss 0.955031, Valid_loss 1.199295
Epoch 37, Train Loss 0.954842, Valid_loss 1.207155
Epoch 38, Train Loss 0.954441, Valid_loss 1.197722
Epoch 39, Train Loss 0.956233, Valid_loss 1.211273
Epoch 40, Train Loss 0.955905, Valid_loss 1.197972
Epoch 41, Train Loss 0.955969, Valid_loss 1.208401
Epoch 42, Train Loss 0.990119, Valid_loss 1.284940
Epoch 43, Train Loss 0.971387, Valid_loss 1.195800
Epoch 44, Train Loss 0.954826, Valid_loss 1.208435
Epoch 45, Train Loss 0.956949, Valid_loss 1.197153
Epoch 46, Train Loss 0.954668, Valid_loss 1.196810
Epoch 47, Train Loss 0.955397, Valid_loss 1.194553
Epoch 48, Train Loss 0.956669, Valid_loss 1.205756
Epoch 49, Train Loss 0.956512, Valid_loss 1.218424
Epoch 50, Train Loss 0.955208, Valid_loss 1.200916
Epoch 51, Train Loss 0.952527, Valid_loss 1.207052
Epoch 52, Train Loss 0.953127, Valid_loss 1.207499
환자ID=P1472 -- true: [[2]] -- pred: tensor([[ 0.1137,  0.0838, -0.4593]], device='cuda:0')
환자ID=P1515 -- true: [[0]] -- pred: tensor([[ 0.1137,  0.0838, -0.4593]], device='cuda:0')
환자ID=P1549 -- true: [[0]] -- pred: tensor([[ 0.1137,  0.0838, -0.4593]], device='cuda:0')
환자ID=P1561 -- true: [[0]] -- pred: tensor([[ 0.1137,  0.0838, -0.4593]], device='cuda:0')
환자ID=P1602 -- true: [[1]] -- pred: tensor([[ 0.1137,  0.0838, -0.4593]], device='cuda:0')
환자ID=P1617 -- true: [[2]] -- pred: tensor([[ 0.1137,  0.0838, -0.4593]], device='cuda:0')
환자ID=P1685 -- true: [[1]] -- pred: tensor([[ 0.1137,  0.0838, -0.4593]], device='cuda:0')
환자ID=P1707 -- true: [[1]] -- pred: tensor([[ 0.1137,  0.0838, -0.4593]], device='cuda:0')
Best performance: Epoch 3, Loss 1.031208, Test ACC 0.375000, Test AUC 0.388889, Test Recall 0.333333, Test Precision 0.125000
Confusion Matrix:
 [[3 0 0]
 [3 0 0]
 [2 0 0]]
✅ Total valid splits used: 4
🔁 Repeat 1, Fold 4
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 477476, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 477476, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  CTGCTCAAGGCATCAG-1-3              cardiac muscle cell
TCATACTAGACTTCCA-1-3              cardiac muscle cell
GAGCCTGGTCGAGATG-1-3              cardiac muscle cell
CTTACCGCAGAACTCT-1-3              cardiac muscle cell
TTGACCCCATCTAACG-1-3              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 115213, dtype: string
cell type annotation :  CTGCTCAAGGCATCAG-1-3              cardiac muscle cell
TCATACTAGACTTCCA-1-3              cardiac muscle cell
GAGCCTGGTCGAGATG-1-3              cardiac muscle cell
CTTACCGCAGAACTCT-1-3              cardiac muscle cell
TTGACCCCATCTAACG-1-3              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 115213, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'endothelial cell of lymphatic vessel', 'fat cell', 'pericyte cell', 'vascular associated smooth muscle cell', 'lymphocyte', 'cardiac neuron', 'mast cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 3}
🔍 Split #5
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1290', 'P1300', 'P1304', 'P1371', 'P1422', 'P1430', 'P1437', 'P1447', 'P1472', 'P1479', 'P1504', 'P1508', 'P1510', 'P1515', 'P1516', 'P1539', 'P1540', 'P1549', 'P1561', 'P1582', 'P1602', 'P1603', 'P1610', 'P1617', 'P1622', 'P1630', 'P1631', 'P1678', 'P1685', 'P1702', 'P1707', 'P1718', 'P1722', 'P1726']
  → test  환자 ID: ['P1358', 'P1425', 'P1462', 'P1547', 'P1558', 'P1600', 'P1606', 'P1735']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1549, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1726, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1358, Label: 2
    ID: P1425, Label: 1
    ID: P1462, Label: 1
    ID: P1547, Label: 0
    ID: P1558, Label: 0
    ID: P1600, Label: 0
    ID: P1606, Label: 2
    ID: P1735, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1539, Label=0, 셀개수=11076
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1603, Label=0, 셀개수=10638
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1735, Label=1, 셀개수=12009
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685        cardiac endothelial cell
592686    cardiac ventricle fibroblast
592687                   pericyte cell
592688        cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:03<05:06,  3.10s/it]  2%|▏         | 2/100 [00:04<03:08,  1.93s/it]  3%|▎         | 3/100 [00:06<03:36,  2.23s/it]  4%|▍         | 4/100 [00:08<02:58,  1.86s/it]  5%|▌         | 5/100 [00:08<01:57,  1.24s/it]  6%|▌         | 6/100 [00:08<01:20,  1.16it/s]  7%|▋         | 7/100 [00:08<01:03,  1.46it/s]  8%|▊         | 8/100 [00:08<00:47,  1.95it/s]  9%|▉         | 9/100 [00:09<00:38,  2.35it/s] 10%|█         | 10/100 [00:09<00:30,  2.91it/s] 11%|█         | 11/100 [00:09<00:31,  2.82it/s] 12%|█▏        | 12/100 [00:09<00:30,  2.90it/s] 13%|█▎        | 13/100 [00:10<00:27,  3.20it/s] 14%|█▍        | 14/100 [00:10<00:22,  3.81it/s] 15%|█▌        | 15/100 [00:10<00:25,  3.28it/s] 16%|█▌        | 16/100 [00:10<00:22,  3.80it/s] 17%|█▋        | 17/100 [00:11<00:31,  2.60it/s] 18%|█▊        | 18/100 [00:11<00:30,  2.71it/s] 19%|█▉        | 19/100 [00:12<00:24,  3.24it/s] 20%|██        | 20/100 [00:12<00:30,  2.66it/s] 21%|██        | 21/100 [00:12<00:24,  3.22it/s] 22%|██▏       | 22/100 [00:13<00:31,  2.44it/s] 23%|██▎       | 23/100 [00:13<00:25,  3.03it/s] 24%|██▍       | 24/100 [00:13<00:25,  2.93it/s] 25%|██▌       | 25/100 [00:14<00:36,  2.07it/s] 26%|██▌       | 26/100 [00:18<01:40,  1.36s/it] 27%|██▋       | 27/100 [00:18<01:25,  1.17s/it] 28%|██▊       | 28/100 [00:18<01:02,  1.16it/s] 29%|██▉       | 29/100 [00:19<00:52,  1.34it/s] 30%|███       | 30/100 [00:19<00:39,  1.76it/s] 31%|███       | 31/100 [00:19<00:30,  2.27it/s] 32%|███▏      | 32/100 [00:19<00:23,  2.89it/s] 33%|███▎      | 33/100 [00:20<00:18,  3.57it/s] 34%|███▍      | 34/100 [00:20<00:21,  3.04it/s] 35%|███▌      | 35/100 [00:20<00:19,  3.37it/s] 36%|███▌      | 36/100 [00:20<00:16,  3.94it/s] 37%|███▋      | 37/100 [00:20<00:13,  4.64it/s] 38%|███▊      | 38/100 [00:23<00:54,  1.13it/s] 39%|███▉      | 39/100 [00:23<00:40,  1.50it/s] 40%|████      | 40/100 [00:23<00:30,  1.98it/s] 41%|████      | 41/100 [00:23<00:23,  2.53it/s] 42%|████▏     | 42/100 [00:23<00:18,  3.13it/s] 43%|████▎     | 43/100 [00:24<00:15,  3.77it/s] 44%|████▍     | 44/100 [00:24<00:12,  4.48it/s] 45%|████▌     | 45/100 [00:24<00:10,  5.12it/s] 46%|████▌     | 46/100 [00:24<00:09,  5.65it/s] 47%|████▋     | 47/100 [00:24<00:08,  6.13it/s] 48%|████▊     | 48/100 [00:24<00:07,  6.57it/s] 49%|████▉     | 49/100 [00:29<01:15,  1.48s/it] 50%|█████     | 50/100 [00:29<00:54,  1.09s/it] 51%|█████     | 51/100 [00:29<00:39,  1.24it/s] 52%|█████▏    | 52/100 [00:29<00:28,  1.66it/s] 53%|█████▎    | 53/100 [00:29<00:21,  2.15it/s] 54%|█████▍    | 54/100 [00:30<00:17,  2.68it/s] 55%|█████▌    | 55/100 [00:30<00:13,  3.29it/s] 56%|█████▌    | 56/100 [00:30<00:11,  3.95it/s] 57%|█████▋    | 57/100 [00:30<00:09,  4.56it/s] 58%|█████▊    | 58/100 [00:30<00:08,  5.20it/s] 59%|█████▉    | 59/100 [00:30<00:07,  5.68it/s] 60%|██████    | 60/100 [00:30<00:06,  6.03it/s] 61%|██████    | 61/100 [00:31<00:05,  6.50it/s] 62%|██████▏   | 62/100 [00:31<00:05,  6.79it/s] 63%|██████▎   | 63/100 [00:31<00:05,  7.04it/s] 64%|██████▍   | 64/100 [00:31<00:05,  7.16it/s] 65%|██████▌   | 65/100 [00:31<00:04,  7.38it/s] 66%|██████▌   | 66/100 [00:31<00:04,  7.43it/s] 67%|██████▋   | 67/100 [00:31<00:04,  7.07it/s] 68%|██████▊   | 68/100 [00:31<00:04,  7.14it/s] 69%|██████▉   | 69/100 [00:32<00:04,  7.27it/s] 70%|███████   | 70/100 [00:32<00:04,  7.44it/s] 71%|███████   | 71/100 [00:32<00:03,  7.33it/s] 72%|███████▏  | 72/100 [00:32<00:03,  7.22it/s] 73%|███████▎  | 73/100 [00:32<00:03,  7.34it/s] 74%|███████▍  | 74/100 [00:32<00:04,  5.66it/s] 75%|███████▌  | 75/100 [00:33<00:04,  5.88it/s] 76%|███████▌  | 76/100 [00:33<00:03,  6.35it/s] 77%|███████▋  | 77/100 [00:33<00:03,  6.74it/s] 78%|███████▊  | 78/100 [00:33<00:03,  6.74it/s] 79%|███████▉  | 79/100 [00:33<00:03,  6.79it/s] 80%|████████  | 80/100 [00:39<00:34,  1.73s/it] 81%|████████  | 81/100 [00:39<00:23,  1.25s/it] 82%|████████▏ | 82/100 [00:39<00:16,  1.10it/s] 83%|████████▎ | 83/100 [00:41<00:22,  1.30s/it] 84%|████████▍ | 84/100 [00:44<00:28,  1.77s/it] 85%|████████▌ | 85/100 [00:44<00:19,  1.28s/it] 86%|████████▌ | 86/100 [00:44<00:13,  1.07it/s] 87%|████████▋ | 87/100 [00:44<00:09,  1.44it/s] 88%|████████▊ | 88/100 [00:44<00:06,  1.89it/s] 89%|████████▉ | 89/100 [00:45<00:04,  2.43it/s] 90%|█████████ | 90/100 [00:45<00:03,  3.03it/s] 91%|█████████ | 91/100 [00:45<00:02,  3.69it/s] 92%|█████████▏| 92/100 [00:45<00:01,  4.36it/s] 93%|█████████▎| 93/100 [00:45<00:01,  5.00it/s] 94%|█████████▍| 94/100 [00:51<00:12,  2.02s/it] 95%|█████████▌| 95/100 [00:52<00:07,  1.54s/it] 96%|█████████▌| 96/100 [00:53<00:05,  1.30s/it] 97%|█████████▋| 97/100 [00:53<00:02,  1.05it/s] 98%|█████████▊| 98/100 [00:53<00:01,  1.42it/s] 99%|█████████▉| 99/100 [00:53<00:00,  1.87it/s]100%|██████████| 100/100 [00:53<00:00,  2.18it/s]100%|██████████| 100/100 [00:53<00:00,  1.86it/s]
[I 2025-08-27 18:49:56,477] A new study created in memory with name: no-name-fcd5e63d-6792-4545-9ab9-b678a28715f7
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16934.53 MB
Memory Reserved: 16952.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 341.79 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.90 MB
Memory Reserved: 16960.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 342.12 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 18:50:03,517] Trial 0 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.51 MB
Memory Reserved: 16960.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.51 MB
Memory Reserved: 16940.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 342.17 MB
Memory Reserved: 372.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16934.32 MB
Memory Reserved: 16960.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 341.71 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 18:50:04,909] Trial 1 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16931.59 MB
Memory Reserved: 16962.00 MB
cuda
Epoch 1, Train Loss 1.030528, Valid_loss 1.324856
Epoch 2, Train Loss 0.944697, Valid_loss 1.297069
Epoch 3, Train Loss 0.861154, Valid_loss 1.181663
Epoch 4, Train Loss 0.814920, Valid_loss 1.109191
Epoch 5, Train Loss 0.912976, Valid_loss 1.158928
Epoch 6, Train Loss 0.723874, Valid_loss 0.912215
Epoch 7, Train Loss 0.684489, Valid_loss 1.467578
Epoch 8, Train Loss 0.771148, Valid_loss 0.987272
Epoch 9, Train Loss 0.691228, Valid_loss 0.897612
Epoch 10, Train Loss 0.580462, Valid_loss 0.860990
Epoch 11, Train Loss 0.657764, Valid_loss 0.769914
Epoch 12, Train Loss 0.587048, Valid_loss 0.793299
Epoch 13, Train Loss 0.680843, Valid_loss 0.725440
Epoch 14, Train Loss 0.574430, Valid_loss 1.306147
Epoch 15, Train Loss 0.533923, Valid_loss 0.731825
Epoch 16, Train Loss 0.540388, Valid_loss 0.706304
Epoch 17, Train Loss 0.452175, Valid_loss 0.661129
Epoch 18, Train Loss 0.462066, Valid_loss 0.624362
Epoch 19, Train Loss 0.423067, Valid_loss 0.729289
Epoch 20, Train Loss 0.503830, Valid_loss 0.673669
Epoch 21, Train Loss 0.466241, Valid_loss 0.751383
Epoch 22, Train Loss 0.505516, Valid_loss 0.595749
Epoch 23, Train Loss 0.570834, Valid_loss 0.627900
Epoch 24, Train Loss 0.456426, Valid_loss 0.828689
Epoch 25, Train Loss 0.439973, Valid_loss 1.138091
Epoch 26, Train Loss 0.490404, Valid_loss 0.646973
Epoch 27, Train Loss 0.480674, Valid_loss 0.728394
Epoch 28, Train Loss 0.393710, Valid_loss 1.484301
Epoch 29, Train Loss 0.474478, Valid_loss 0.942574
Epoch 30, Train Loss 0.457223, Valid_loss 0.801270
Epoch 31, Train Loss 0.405442, Valid_loss 1.122844
Epoch 32, Train Loss 0.339145, Valid_loss 0.552884
Epoch 33, Train Loss 0.419425, Valid_loss 0.605970
Epoch 34, Train Loss 0.473406, Valid_loss 0.778910
Epoch 35, Train Loss 0.480732, Valid_loss 0.693878
Epoch 36, Train Loss 0.466510, Valid_loss 0.941453
Epoch 37, Train Loss 0.399918, Valid_loss 0.551438
Epoch 38, Train Loss 0.415804, Valid_loss 0.550404
Epoch 39, Train Loss 0.435445, Valid_loss 0.601156
Epoch 40, Train Loss 0.431876, Valid_loss 0.594572
Epoch 41, Train Loss 0.474091, Valid_loss 0.691497
Epoch 42, Train Loss 0.342023, Valid_loss 0.606308
Epoch 43, Train Loss 0.487212, Valid_loss 1.287464
Epoch 44, Train Loss 0.440028, Valid_loss 0.625382
Epoch 45, Train Loss 0.379296, Valid_loss 0.617846
Epoch 46, Train Loss 0.435937, Valid_loss 0.524520
Epoch 47, Train Loss 0.336240, Valid_loss 0.575905
Epoch 48, Train Loss 0.353039, Valid_loss 0.722897
Epoch 49, Train Loss 0.440264, Valid_loss 0.572573
Epoch 50, Train Loss 0.397967, Valid_loss 0.507281
Epoch 51, Train Loss 0.345453, Valid_loss 0.640116
Epoch 52, Train Loss 0.326540, Valid_loss 0.591997
Epoch 53, Train Loss 0.366133, Valid_loss 0.525680
Epoch 54, Train Loss 0.337277, Valid_loss 0.537401
Epoch 55, Train Loss 0.331389, Valid_loss 0.581581
[I 2025-08-27 19:23:07,728] Trial 2 finished with value: 0.507280642632395 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.01, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.507280642632395.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.975582, Valid_loss 1.516937
Epoch 2, Train Loss 0.931512, Valid_loss 1.343759
Epoch 3, Train Loss 0.897199, Valid_loss 1.577405
Epoch 4, Train Loss 0.896251, Valid_loss 1.285186
Epoch 5, Train Loss 0.884948, Valid_loss 1.375680
Epoch 6, Train Loss 0.909912, Valid_loss 1.420483
Epoch 7, Train Loss 0.877917, Valid_loss 1.303466
Epoch 8, Train Loss 0.862019, Valid_loss 1.515491
Epoch 9, Train Loss 0.892895, Valid_loss 1.333609
Epoch 10, Train Loss 0.888119, Valid_loss 1.290847
Epoch 11, Train Loss 0.882924, Valid_loss 1.324080
Epoch 12, Train Loss 0.862756, Valid_loss 1.687467
Epoch 13, Train Loss 0.891976, Valid_loss 1.408120
Epoch 14, Train Loss 0.883447, Valid_loss 1.374155
Epoch 15, Train Loss 0.872660, Valid_loss 1.385522
Epoch 16, Train Loss 0.883523, Valid_loss 1.396876
Epoch 17, Train Loss 0.881187, Valid_loss 1.345182
Epoch 18, Train Loss 0.890918, Valid_loss 1.373370
Epoch 19, Train Loss 0.879816, Valid_loss 1.456039
Epoch 20, Train Loss 0.881862, Valid_loss 1.428973
Epoch 21, Train Loss 0.877484, Valid_loss 1.418289
Epoch 22, Train Loss 0.883485, Valid_loss 1.388906
Epoch 23, Train Loss 0.878019, Valid_loss 1.399237
Epoch 24, Train Loss 0.872846, Valid_loss 1.451711
Epoch 25, Train Loss 0.884347, Valid_loss 1.437253
Epoch 26, Train Loss 0.877058, Valid_loss 1.399588
Epoch 27, Train Loss 0.875202, Valid_loss 1.428597
Epoch 28, Train Loss 0.874407, Valid_loss 1.471414
Epoch 29, Train Loss 0.883267, Valid_loss 1.425523
Epoch 30, Train Loss 0.874084, Valid_loss 1.418872
Epoch 31, Train Loss 0.882271, Valid_loss 1.416618
Epoch 32, Train Loss 0.876796, Valid_loss 1.414720
Epoch 33, Train Loss 0.878786, Valid_loss 1.418468
Epoch 34, Train Loss 0.875810, Valid_loss 1.443783
Epoch 35, Train Loss 0.875386, Valid_loss 1.429992
Epoch 36, Train Loss 0.872498, Valid_loss 1.455049
Epoch 37, Train Loss 0.875263, Valid_loss 1.435799
Epoch 38, Train Loss 0.873732, Valid_loss 1.438736
Epoch 39, Train Loss 0.873708, Valid_loss 1.438132
Epoch 40, Train Loss 0.874116, Valid_loss 1.420436
Epoch 41, Train Loss 0.875512, Valid_loss 1.417659
Epoch 42, Train Loss 0.875068, Valid_loss 1.429124
Epoch 43, Train Loss 0.875520, Valid_loss 1.457309
Epoch 44, Train Loss 0.880923, Valid_loss 1.421164
Epoch 45, Train Loss 0.874892, Valid_loss 1.405088
Epoch 46, Train Loss 0.874224, Valid_loss 1.437907
Epoch 47, Train Loss 0.874142, Valid_loss 1.432072
Epoch 48, Train Loss 0.874278, Valid_loss 1.432362
Epoch 49, Train Loss 0.910735, Valid_loss 1.436350
Epoch 50, Train Loss 0.878393, Valid_loss 1.418450
Epoch 51, Train Loss 0.879694, Valid_loss 1.457078
Epoch 52, Train Loss 0.873325, Valid_loss 1.418324
Epoch 53, Train Loss 0.872946, Valid_loss 1.417475
Epoch 54, Train Loss 0.872495, Valid_loss 1.420419
Epoch 55, Train Loss 0.872909, Valid_loss 1.422660
[I 2025-08-27 19:55:10,833] Trial 3 finished with value: 1.285186176498731 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.01, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.507280642632395.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.977793, Valid_loss 1.261347
Epoch 2, Train Loss 0.918574, Valid_loss 1.246361
Epoch 3, Train Loss 0.694358, Valid_loss 0.959832
Epoch 4, Train Loss 0.717972, Valid_loss 0.905408
Epoch 5, Train Loss 0.578772, Valid_loss 1.478997
Epoch 6, Train Loss 0.531078, Valid_loss 0.786508
Epoch 7, Train Loss 0.544402, Valid_loss 1.081075
Epoch 8, Train Loss 0.604717, Valid_loss 0.803563
Epoch 9, Train Loss 0.561127, Valid_loss 0.800271
Epoch 10, Train Loss 0.552078, Valid_loss 0.836776
Epoch 11, Train Loss 0.514744, Valid_loss 0.784388
Epoch 12, Train Loss 0.430423, Valid_loss 0.669986
Epoch 13, Train Loss 0.476061, Valid_loss 0.908981
Epoch 14, Train Loss 0.496664, Valid_loss 1.980891
Epoch 15, Train Loss 0.497998, Valid_loss 0.903571
Epoch 16, Train Loss 0.417830, Valid_loss 0.557027
Epoch 17, Train Loss 0.386305, Valid_loss 0.661410
Epoch 18, Train Loss 0.423447, Valid_loss 0.459203
Epoch 19, Train Loss 0.455179, Valid_loss 0.605681
Epoch 20, Train Loss 0.316294, Valid_loss 0.580965
Epoch 21, Train Loss 0.428685, Valid_loss 0.422758
Epoch 22, Train Loss 0.375152, Valid_loss 0.439028
Epoch 23, Train Loss 0.441771, Valid_loss 0.524153
Epoch 24, Train Loss 0.359067, Valid_loss 0.400498
Epoch 25, Train Loss 0.449733, Valid_loss 0.382405
Epoch 26, Train Loss 0.408873, Valid_loss 0.402727
Epoch 27, Train Loss 0.301787, Valid_loss 0.466770
Epoch 28, Train Loss 0.319408, Valid_loss 0.388405
Epoch 29, Train Loss 0.369061, Valid_loss 0.363983
Epoch 30, Train Loss 0.329621, Valid_loss 0.343957
Epoch 31, Train Loss 0.245719, Valid_loss 0.401420
Epoch 32, Train Loss 0.321849, Valid_loss 0.353427
Epoch 33, Train Loss 0.259748, Valid_loss 0.308752
Epoch 34, Train Loss 0.260673, Valid_loss 0.286147
Epoch 35, Train Loss 0.427593, Valid_loss 0.638471
Epoch 36, Train Loss 0.344830, Valid_loss 0.265267
Epoch 37, Train Loss 0.233661, Valid_loss 0.645177
Epoch 38, Train Loss 0.312529, Valid_loss 0.298581
Epoch 39, Train Loss 0.274237, Valid_loss 0.498318
Epoch 40, Train Loss 0.247659, Valid_loss 0.447840
Epoch 41, Train Loss 0.251920, Valid_loss 0.280000
Epoch 42, Train Loss 0.247151, Valid_loss 0.311687
Epoch 43, Train Loss 0.298074, Valid_loss 0.352030
Epoch 44, Train Loss 0.211485, Valid_loss 0.349215
Epoch 45, Train Loss 0.221651, Valid_loss 0.544549
Epoch 46, Train Loss 0.203250, Valid_loss 0.198540
Epoch 47, Train Loss 0.257132, Valid_loss 0.282471
Epoch 48, Train Loss 0.267736, Valid_loss 0.234751
Epoch 49, Train Loss 0.146544, Valid_loss 0.277586
Epoch 50, Train Loss 0.194510, Valid_loss 0.469955
Epoch 51, Train Loss 0.242687, Valid_loss 0.338451
Epoch 52, Train Loss 0.191134, Valid_loss 0.280519
Epoch 53, Train Loss 0.170670, Valid_loss 0.246974
Epoch 54, Train Loss 0.205119, Valid_loss 0.390191
Epoch 55, Train Loss 0.144973, Valid_loss 0.274047
Epoch 56, Train Loss 0.169706, Valid_loss 0.246170
Epoch 57, Train Loss 0.132170, Valid_loss 0.270623
Epoch 58, Train Loss 0.151889, Valid_loss 0.218162
Epoch 59, Train Loss 0.131645, Valid_loss 0.190392
Epoch 60, Train Loss 0.196172, Valid_loss 0.851028
Epoch 61, Train Loss 0.180872, Valid_loss 0.219609
Epoch 62, Train Loss 0.109030, Valid_loss 0.184414
Epoch 63, Train Loss 0.104857, Valid_loss 0.554322
Epoch 64, Train Loss 0.132555, Valid_loss 0.217902
Epoch 65, Train Loss 0.115670, Valid_loss 0.237118
Epoch 66, Train Loss 0.092760, Valid_loss 0.317589
[I 2025-08-27 20:34:05,983] Trial 4 finished with value: 0.18441420149792975 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 4 with value: 0.18441420149792975.
선택된 trial params: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.075808, Valid_loss 1.306167
Epoch 2, Train Loss 0.968852, Valid_loss 1.356199
Epoch 3, Train Loss 0.908686, Valid_loss 1.280750
Epoch 4, Train Loss 0.900231, Valid_loss 1.246564
Epoch 5, Train Loss 0.705203, Valid_loss 1.363761
Epoch 6, Train Loss 0.762054, Valid_loss 1.061157
Epoch 7, Train Loss 0.543829, Valid_loss 1.116948
Epoch 8, Train Loss 0.569865, Valid_loss 1.079202
Epoch 9, Train Loss 0.613758, Valid_loss 1.538245
Epoch 10, Train Loss 0.612347, Valid_loss 0.962227
Epoch 11, Train Loss 0.605648, Valid_loss 0.855008
Epoch 12, Train Loss 0.571221, Valid_loss 0.761837
Epoch 13, Train Loss 0.443734, Valid_loss 0.989787
Epoch 14, Train Loss 0.448707, Valid_loss 0.717611
Epoch 15, Train Loss 0.392789, Valid_loss 0.807467
Epoch 16, Train Loss 0.471414, Valid_loss 1.039534
Epoch 17, Train Loss 0.423616, Valid_loss 1.335599
Epoch 18, Train Loss 0.402205, Valid_loss 0.861796
Epoch 19, Train Loss 0.337738, Valid_loss 0.737145
Epoch 20, Train Loss 0.367596, Valid_loss 0.434648
Epoch 21, Train Loss 0.349780, Valid_loss 1.018621
Epoch 22, Train Loss 0.334355, Valid_loss 0.999064
Epoch 23, Train Loss 0.311514, Valid_loss 1.475029
Epoch 24, Train Loss 0.328853, Valid_loss 0.740532
Epoch 25, Train Loss 0.290721, Valid_loss 1.396618
Epoch 26, Train Loss 0.296334, Valid_loss 1.272189
Epoch 27, Train Loss 0.500331, Valid_loss 0.302319
Epoch 28, Train Loss 0.339680, Valid_loss 0.521089
Epoch 29, Train Loss 0.289943, Valid_loss 0.291319
Epoch 30, Train Loss 0.357174, Valid_loss 0.298235
Epoch 31, Train Loss 0.317277, Valid_loss 0.412641
Epoch 32, Train Loss 0.303525, Valid_loss 0.429629
Epoch 33, Train Loss 0.220635, Valid_loss 0.508385
Epoch 34, Train Loss 0.244569, Valid_loss 0.359916
Epoch 35, Train Loss 0.228052, Valid_loss 1.290856
Epoch 36, Train Loss 0.185601, Valid_loss 0.459543
Epoch 37, Train Loss 0.215201, Valid_loss 0.278808
Epoch 38, Train Loss 0.162292, Valid_loss 0.226900
Epoch 39, Train Loss 0.199694, Valid_loss 0.710242
Epoch 40, Train Loss 0.219387, Valid_loss 0.712840
Epoch 41, Train Loss 0.258919, Valid_loss 0.951976
Epoch 42, Train Loss 0.365422, Valid_loss 0.533952
Epoch 43, Train Loss 0.233806, Valid_loss 0.346607
Epoch 44, Train Loss 0.288307, Valid_loss 0.283896
Epoch 45, Train Loss 0.155931, Valid_loss 0.188415
Epoch 46, Train Loss 0.154986, Valid_loss 0.398624
Epoch 47, Train Loss 0.151432, Valid_loss 0.670391
Epoch 48, Train Loss 0.243708, Valid_loss 0.295640
Epoch 49, Train Loss 0.218742, Valid_loss 0.338945
Epoch 50, Train Loss 0.129892, Valid_loss 0.265021
Epoch 51, Train Loss 0.123656, Valid_loss 0.210384
Epoch 52, Train Loss 0.109707, Valid_loss 0.533783
Epoch 53, Train Loss 0.140436, Valid_loss 0.194607
Epoch 54, Train Loss 0.123590, Valid_loss 0.205593
Epoch 55, Train Loss 0.137511, Valid_loss 0.195895
Epoch 56, Train Loss 0.095568, Valid_loss 0.197593
Epoch 57, Train Loss 0.122648, Valid_loss 0.207931
환자ID=P1358 -- true: [[2]] -- pred: tensor([[-3.4124,  1.5813,  0.2064]], device='cuda:0')
환자ID=P1425 -- true: [[1]] -- pred: tensor([[-3.9099,  0.8556,  1.0707]], device='cuda:0')
환자ID=P1462 -- true: [[1]] -- pred: tensor([[-3.5247,  1.3996,  0.4098]], device='cuda:0')
환자ID=P1547 -- true: [[0]] -- pred: tensor([[ 3.0319, -1.9601, -6.6941]], device='cuda:0')
환자ID=P1558 -- true: [[0]] -- pred: tensor([[ 3.0468, -1.9333, -6.7199]], device='cuda:0')
환자ID=P1600 -- true: [[0]] -- pred: tensor([[ 3.0395, -1.9493, -6.7075]], device='cuda:0')
환자ID=P1606 -- true: [[2]] -- pred: tensor([[-3.6412,  1.2815,  0.6067]], device='cuda:0')
환자ID=P1735 -- true: [[1]] -- pred: tensor([[-3.6825,  1.2027,  0.6955]], device='cuda:0')
Best performance: Epoch 45, Loss 0.155931, Test ACC 0.625000, Test AUC 0.722222, Test Recall 0.555556, Test Precision 0.500000
Confusion Matrix:
 [[3 0 0]
 [0 2 1]
 [0 2 0]]
✅ Total valid splits used: 5

📌 Repeat 1: 평균 AUC = 0.7537, 표준편차 = 0.1942
Test ACC 평균 0.661111, Test Recall 평균 0.611111, Test Precision 평균 0.515000
fold_aucs = [0.888888888888889, 0.8518518518518517, 0.9166666666666666, 0.3888888888888889, 0.7222222222222222]
NaN 개수: 0 / 전체 5개

🔁 Repeat 2, Fold 0
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 464096, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 464096, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 12}
cell type :  CTCCCAAGTGGCACTC-1-6              cardiac muscle cell
CTGCCTAAGCCTCAAT-1-6              cardiac muscle cell
TCCTGCAAGGCTCTAT-1-6              cardiac muscle cell
ACGTACAGTGGACCAA-1-6              cardiac muscle cell
TCCTCCCCAACATACC-1-6              cardiac muscle cell
                                     ...             
GTTCTATTCCTTCTAA-1-77        cardiac endothelial cell
GAGTCATTCATGGATC-1-77        cardiac endothelial cell
GGTGTTACAAGACAAT-1-77    cardiac ventricle fibroblast
AGCGTCGTCCTCACTG-1-77        cardiac endothelial cell
GTGCTGGCATGATAGA-1-77        cardiac endothelial cell
Name: manual_annotation, Length: 128593, dtype: string
cell type annotation :  CTCCCAAGTGGCACTC-1-6              cardiac muscle cell
CTGCCTAAGCCTCAAT-1-6              cardiac muscle cell
TCCTGCAAGGCTCTAT-1-6              cardiac muscle cell
ACGTACAGTGGACCAA-1-6              cardiac muscle cell
TCCTCCCCAACATACC-1-6              cardiac muscle cell
                                     ...             
GTTCTATTCCTTCTAA-1-77        cardiac endothelial cell
GAGTCATTCATGGATC-1-77        cardiac endothelial cell
GGTGTTACAAGACAAT-1-77    cardiac ventricle fibroblast
AGCGTCGTCCTCACTG-1-77        cardiac endothelial cell
GTGCTGGCATGATAGA-1-77        cardiac endothelial cell
Name: manual_annotation, Length: 128593, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'endocardial cell', 'cardiac ventricle fibroblast', 'macrophage', 'endothelial cell of lymphatic vessel', 'pericyte cell', 'cardiac neuron', 'cardiac endothelial cell', 'vascular associated smooth muscle cell', 'lymphocyte', 'mast cell', 'mesothelial cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 4}
🔍 Split #1
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 33
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 9
  → train 환자 ID: ['P1290', 'P1300', 'P1358', 'P1371', 'P1422', 'P1425', 'P1430', 'P1462', 'P1472', 'P1479', 'P1504', 'P1508', 'P1516', 'P1539', 'P1540', 'P1547', 'P1549', 'P1558', 'P1561', 'P1582', 'P1606', 'P1610', 'P1617', 'P1622', 'P1630', 'P1631', 'P1678', 'P1685', 'P1702', 'P1707', 'P1722', 'P1726', 'P1735']
  → test  환자 ID: ['P1304', 'P1437', 'P1447', 'P1510', 'P1515', 'P1600', 'P1602', 'P1603', 'P1718']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1722, Label: 1
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1304, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1718, Label: 0
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 33
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 33
기존 (train) label_stat 33
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 11
test_p_index 9
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1547, Label=0, 셀개수=8253
→ valid 환자 ID 및 라벨:
   총 개수: 11
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1630, Label=1, 셀개수=17633
→ test 환자 ID 및 라벨:
   총 개수: 9
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1718, Label=0, 셀개수=9278
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685        cardiac endothelial cell
592686    cardiac ventricle fibroblast
592687        cardiac endothelial cell
592688        cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:16,  6.10it/s]  2%|▏         | 2/100 [00:00<00:13,  7.02it/s]  3%|▎         | 3/100 [00:00<00:12,  7.66it/s]  4%|▍         | 4/100 [00:00<00:11,  8.01it/s]  5%|▌         | 5/100 [00:00<00:11,  8.40it/s]  6%|▌         | 6/100 [00:00<00:10,  8.60it/s]  7%|▋         | 7/100 [00:00<00:10,  8.85it/s]  8%|▊         | 8/100 [00:00<00:10,  8.71it/s]  9%|▉         | 9/100 [00:01<00:10,  8.77it/s] 10%|█         | 10/100 [00:01<00:10,  8.63it/s] 11%|█         | 11/100 [00:01<00:10,  8.71it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.77it/s] 13%|█▎        | 13/100 [00:01<00:10,  8.57it/s] 14%|█▍        | 14/100 [00:01<00:10,  8.45it/s] 15%|█▌        | 15/100 [00:01<00:10,  8.38it/s] 16%|█▌        | 16/100 [00:01<00:10,  8.24it/s] 17%|█▋        | 17/100 [00:02<00:09,  8.40it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.49it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.52it/s] 20%|██        | 20/100 [00:02<00:09,  8.66it/s] 21%|██        | 21/100 [00:02<00:09,  8.54it/s] 22%|██▏       | 22/100 [00:02<00:09,  8.50it/s] 23%|██▎       | 23/100 [00:02<00:08,  8.66it/s] 24%|██▍       | 24/100 [00:02<00:08,  8.69it/s] 25%|██▌       | 25/100 [00:02<00:08,  8.54it/s] 26%|██▌       | 26/100 [00:03<00:08,  8.55it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.49it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.43it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.38it/s] 30%|███       | 30/100 [00:03<00:08,  8.59it/s] 31%|███       | 31/100 [00:03<00:08,  8.45it/s] 32%|███▏      | 32/100 [00:03<00:07,  8.66it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.53it/s] 34%|███▍      | 34/100 [00:04<00:07,  8.47it/s] 35%|███▌      | 35/100 [00:04<00:07,  8.42it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.46it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.43it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.38it/s] 39%|███▉      | 39/100 [00:04<00:07,  8.36it/s] 40%|████      | 40/100 [00:04<00:07,  8.49it/s] 41%|████      | 41/100 [00:04<00:07,  8.42it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.38it/s] 43%|████▎     | 43/100 [00:05<00:06,  8.20it/s] 44%|████▍     | 44/100 [00:05<00:06,  8.44it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.45it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.47it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.36it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.41it/s] 49%|████▉     | 49/100 [00:05<00:06,  8.48it/s] 50%|█████     | 50/100 [00:05<00:06,  8.27it/s] 51%|█████     | 51/100 [00:06<00:05,  8.31it/s] 52%|█████▏    | 52/100 [00:06<00:05,  8.32it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.51it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.65it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.68it/s] 56%|█████▌    | 56/100 [00:06<00:05,  7.73it/s] 57%|█████▋    | 57/100 [00:07<00:10,  4.30it/s] 58%|█████▊    | 58/100 [00:07<00:08,  4.86it/s] 59%|█████▉    | 59/100 [00:08<00:16,  2.42it/s] 60%|██████    | 60/100 [00:08<00:15,  2.61it/s] 61%|██████    | 61/100 [00:09<00:22,  1.73it/s] 62%|██████▏   | 62/100 [00:09<00:17,  2.22it/s] 63%|██████▎   | 63/100 [00:09<00:13,  2.69it/s] 64%|██████▍   | 64/100 [00:10<00:10,  3.29it/s] 65%|██████▌   | 65/100 [00:10<00:08,  3.98it/s] 66%|██████▌   | 66/100 [00:10<00:07,  4.69it/s] 67%|██████▋   | 67/100 [00:10<00:06,  5.32it/s] 68%|██████▊   | 68/100 [00:10<00:05,  5.98it/s] 69%|██████▉   | 69/100 [00:10<00:07,  4.36it/s] 70%|███████   | 70/100 [00:11<00:11,  2.69it/s] 71%|███████   | 71/100 [00:11<00:09,  3.03it/s] 72%|███████▏  | 72/100 [00:11<00:07,  3.75it/s] 73%|███████▎  | 73/100 [00:12<00:07,  3.50it/s] 74%|███████▍  | 74/100 [00:12<00:06,  4.20it/s] 75%|███████▌  | 75/100 [00:12<00:05,  4.94it/s] 76%|███████▌  | 76/100 [00:12<00:05,  4.43it/s] 77%|███████▋  | 77/100 [00:12<00:04,  5.13it/s] 78%|███████▊  | 78/100 [00:13<00:05,  3.78it/s] 79%|███████▉  | 79/100 [00:13<00:06,  3.09it/s] 80%|████████  | 80/100 [00:14<00:06,  2.97it/s] 81%|████████  | 81/100 [00:14<00:05,  3.33it/s] 82%|████████▏ | 82/100 [00:14<00:04,  4.07it/s] 83%|████████▎ | 83/100 [00:14<00:03,  4.81it/s] 84%|████████▍ | 84/100 [00:14<00:02,  5.44it/s] 85%|████████▌ | 85/100 [00:14<00:02,  6.08it/s] 86%|████████▌ | 86/100 [00:15<00:02,  6.60it/s] 87%|████████▋ | 87/100 [00:16<00:05,  2.45it/s] 88%|████████▊ | 88/100 [00:16<00:04,  2.63it/s] 89%|████████▉ | 89/100 [00:16<00:03,  3.27it/s] 90%|█████████ | 90/100 [00:17<00:04,  2.16it/s] 91%|█████████ | 91/100 [00:17<00:03,  2.44it/s] 92%|█████████▏| 92/100 [00:17<00:02,  3.10it/s] 93%|█████████▎| 93/100 [00:17<00:01,  3.81it/s] 94%|█████████▍| 94/100 [00:17<00:01,  4.16it/s] 95%|█████████▌| 95/100 [00:18<00:01,  4.85it/s] 96%|█████████▌| 96/100 [00:18<00:00,  5.53it/s] 97%|█████████▋| 97/100 [00:18<00:00,  6.12it/s] 98%|█████████▊| 98/100 [00:18<00:00,  6.60it/s] 99%|█████████▉| 99/100 [00:18<00:00,  4.54it/s]100%|██████████| 100/100 [00:19<00:00,  3.12it/s]100%|██████████| 100/100 [00:19<00:00,  5.15it/s]
[I 2025-08-27 21:07:51,359] A new study created in memory with name: no-name-04abd919-a47d-49a4-b770-dfd3593ade9f
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17876.68 MB
Memory Reserved: 17896.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 321.01 MB
Memory Reserved: 360.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17877.65 MB
Memory Reserved: 17896.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 320.84 MB
Memory Reserved: 360.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 21:07:54,042] Trial 0 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17876.84 MB
Memory Reserved: 17896.00 MB
cuda
Epoch 1, Train Loss 1.064891, Valid_loss 1.483124
Epoch 2, Train Loss 0.955841, Valid_loss 1.676238
Epoch 3, Train Loss 0.942335, Valid_loss 1.883543
Epoch 4, Train Loss 0.950677, Valid_loss 1.519175
Epoch 5, Train Loss 0.937548, Valid_loss 1.335031
Epoch 6, Train Loss 0.928646, Valid_loss 1.372671
Epoch 7, Train Loss 0.935032, Valid_loss 1.321300
Epoch 8, Train Loss 0.910098, Valid_loss 1.377449
Epoch 9, Train Loss 0.920844, Valid_loss 1.357736
Epoch 10, Train Loss 0.902623, Valid_loss 1.421850
Epoch 11, Train Loss 0.889904, Valid_loss 1.451002
Epoch 12, Train Loss 0.897554, Valid_loss 1.424685
Epoch 13, Train Loss 0.899646, Valid_loss 1.466422
Epoch 14, Train Loss 0.899169, Valid_loss 1.419184
Epoch 15, Train Loss 0.902491, Valid_loss 1.437715
Epoch 16, Train Loss 0.895174, Valid_loss 1.434978
Epoch 17, Train Loss 0.894289, Valid_loss 1.443689
Epoch 18, Train Loss 0.894033, Valid_loss 1.447900
Epoch 19, Train Loss 0.892177, Valid_loss 1.461494
Epoch 20, Train Loss 0.895297, Valid_loss 1.464525
Epoch 21, Train Loss 0.892079, Valid_loss 1.472160
Epoch 22, Train Loss 0.895828, Valid_loss 1.472674
Epoch 23, Train Loss 0.890958, Valid_loss 1.432897
Epoch 24, Train Loss 0.896273, Valid_loss 1.482363
Epoch 25, Train Loss 0.891980, Valid_loss 1.489819
Epoch 26, Train Loss 0.896321, Valid_loss 1.476818
Epoch 27, Train Loss 0.892503, Valid_loss 1.470467
Epoch 28, Train Loss 0.893620, Valid_loss 1.474531
Epoch 29, Train Loss 0.892734, Valid_loss 1.466896
Epoch 30, Train Loss 0.892969, Valid_loss 1.461785
Epoch 31, Train Loss 0.898315, Valid_loss 1.467566
Epoch 32, Train Loss 0.896835, Valid_loss 1.555683
Epoch 33, Train Loss 0.903640, Valid_loss 1.470730
Epoch 34, Train Loss 0.912873, Valid_loss 1.471047
Epoch 35, Train Loss 0.894469, Valid_loss 1.473892
Epoch 36, Train Loss 0.894499, Valid_loss 1.478283
Epoch 37, Train Loss 0.894407, Valid_loss 1.474357
Epoch 38, Train Loss 0.891844, Valid_loss 1.479807
Epoch 39, Train Loss 0.897211, Valid_loss 1.472584
Epoch 40, Train Loss 0.895642, Valid_loss 1.467424
Epoch 41, Train Loss 0.893827, Valid_loss 1.462641
Epoch 42, Train Loss 0.894990, Valid_loss 1.460415
Epoch 43, Train Loss 0.894236, Valid_loss 1.461386
Epoch 44, Train Loss 0.902623, Valid_loss 1.482655
Epoch 45, Train Loss 0.896941, Valid_loss 1.473554
Epoch 46, Train Loss 0.889532, Valid_loss 1.488467
Epoch 47, Train Loss 0.895916, Valid_loss 1.492030
Epoch 48, Train Loss 0.894140, Valid_loss 1.470550
Epoch 49, Train Loss 0.894102, Valid_loss 1.473260
Epoch 50, Train Loss 0.892550, Valid_loss 1.456857
Epoch 51, Train Loss 0.892185, Valid_loss 1.435253
Epoch 52, Train Loss 0.890282, Valid_loss 1.431991
Epoch 53, Train Loss 0.890866, Valid_loss 1.416077
Epoch 54, Train Loss 0.889874, Valid_loss 1.401063
Epoch 55, Train Loss 0.890150, Valid_loss 1.401727
Epoch 56, Train Loss 0.891409, Valid_loss 1.421066
[I 2025-08-27 21:40:24,174] Trial 1 finished with value: 1.321299742568623 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.7, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 1.321299742568623.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17876.68 MB
Memory Reserved: 17896.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 321.01 MB
Memory Reserved: 360.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17877.65 MB
Memory Reserved: 17896.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 320.84 MB
Memory Reserved: 360.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 21:40:25,904] Trial 2 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17878.92 MB
Memory Reserved: 17896.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17906.78 MB
Memory Reserved: 17926.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 350.82 MB
Memory Reserved: 382.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17906.93 MB
Memory Reserved: 17926.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 351.63 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 21:40:27,276] Trial 3 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17905.84 MB
Memory Reserved: 17932.00 MB
cuda
Epoch 1, Train Loss 0.984987, Valid_loss 1.395818
Epoch 2, Train Loss 0.902971, Valid_loss 1.363281
Epoch 3, Train Loss 0.818322, Valid_loss 1.012225
Epoch 4, Train Loss 0.734068, Valid_loss 1.083653
Epoch 5, Train Loss 0.667114, Valid_loss 0.772934
Epoch 6, Train Loss 0.629790, Valid_loss 0.794896
Epoch 7, Train Loss 0.581092, Valid_loss 0.826855
Epoch 8, Train Loss 0.567343, Valid_loss 0.738687
Epoch 9, Train Loss 0.532945, Valid_loss 1.269641
Epoch 10, Train Loss 0.525553, Valid_loss 0.956941
Epoch 11, Train Loss 0.459693, Valid_loss 2.081982
Epoch 12, Train Loss 0.449307, Valid_loss 0.977727
Epoch 13, Train Loss 0.484939, Valid_loss 0.688210
Epoch 14, Train Loss 0.687367, Valid_loss 0.893375
Epoch 15, Train Loss 0.559004, Valid_loss 0.965799
Epoch 16, Train Loss 0.460023, Valid_loss 0.963838
Epoch 17, Train Loss 0.458940, Valid_loss 1.103889
Epoch 18, Train Loss 0.468726, Valid_loss 1.068206
Epoch 19, Train Loss 0.444616, Valid_loss 0.862349
Epoch 20, Train Loss 0.337287, Valid_loss 0.958041
Epoch 21, Train Loss 0.371768, Valid_loss 0.682396
Epoch 22, Train Loss 0.364212, Valid_loss 0.697488
Epoch 23, Train Loss 0.354629, Valid_loss 0.916810
Epoch 24, Train Loss 0.319676, Valid_loss 0.631803
Epoch 25, Train Loss 0.339569, Valid_loss 0.949899
Epoch 26, Train Loss 0.266718, Valid_loss 0.704343
Epoch 27, Train Loss 0.267911, Valid_loss 1.099145
Epoch 28, Train Loss 0.294878, Valid_loss 2.013648
Epoch 29, Train Loss 0.360917, Valid_loss 1.023299
Epoch 30, Train Loss 0.270736, Valid_loss 1.300355
Epoch 31, Train Loss 0.253054, Valid_loss 1.283993
Epoch 32, Train Loss 0.209915, Valid_loss 1.505813
Epoch 33, Train Loss 0.201534, Valid_loss 1.001911
Epoch 34, Train Loss 0.262869, Valid_loss 1.281633
Epoch 35, Train Loss 0.239475, Valid_loss 1.167507
Epoch 36, Train Loss 0.200365, Valid_loss 1.318541
Epoch 37, Train Loss 0.215299, Valid_loss 1.210019
Epoch 38, Train Loss 0.167406, Valid_loss 1.118267
Epoch 39, Train Loss 0.153693, Valid_loss 1.103704
Epoch 40, Train Loss 0.157203, Valid_loss 0.971392
Epoch 41, Train Loss 0.182702, Valid_loss 1.158401
Epoch 42, Train Loss 0.187789, Valid_loss 1.004327
Epoch 43, Train Loss 0.128583, Valid_loss 1.009154
Epoch 44, Train Loss 0.153805, Valid_loss 1.187106
Epoch 45, Train Loss 0.136277, Valid_loss 1.248802
Epoch 46, Train Loss 0.143529, Valid_loss 1.027808
Epoch 47, Train Loss 0.228856, Valid_loss 1.479648
Epoch 48, Train Loss 0.125068, Valid_loss 1.011604
Epoch 49, Train Loss 0.134355, Valid_loss 1.267832
Epoch 50, Train Loss 0.162478, Valid_loss 0.962101
Epoch 51, Train Loss 0.069718, Valid_loss 1.080755
Epoch 52, Train Loss 0.115189, Valid_loss 1.151534
[I 2025-08-27 22:01:24,100] Trial 4 finished with value: 0.6318026286740364 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 1, 'dropout': 0.3, 'weight_decay': 0.0001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 4 with value: 0.6318026286740364.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17876.68 MB
Memory Reserved: 17896.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 321.01 MB
Memory Reserved: 360.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17877.65 MB
Memory Reserved: 17896.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 320.84 MB
Memory Reserved: 360.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 22:01:25,855] Trial 5 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17878.92 MB
Memory Reserved: 17896.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 335.73 MB
Memory Reserved: 370.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9113.59 MB
Memory Reserved: 9128.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9113.97 MB
Memory Reserved: 9128.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9113.97 MB
Memory Reserved: 9128.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 22:01:27,369] Trial 6 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.053134, Valid_loss 1.264195
Epoch 2, Train Loss 0.939941, Valid_loss 1.462117
Epoch 3, Train Loss 0.942347, Valid_loss 1.431051
Epoch 4, Train Loss 0.943278, Valid_loss 1.561680
Epoch 5, Train Loss 0.926915, Valid_loss 1.371971
Epoch 6, Train Loss 0.916247, Valid_loss 1.517408
Epoch 7, Train Loss 0.941494, Valid_loss 1.248835
Epoch 8, Train Loss 0.894483, Valid_loss 1.302299
Epoch 9, Train Loss 0.907597, Valid_loss 1.303048
Epoch 10, Train Loss 0.912070, Valid_loss 1.291687
Epoch 11, Train Loss 0.886224, Valid_loss 1.389725
Epoch 12, Train Loss 0.900502, Valid_loss 1.301711
Epoch 13, Train Loss 0.907533, Valid_loss 1.259294
Epoch 14, Train Loss 0.875546, Valid_loss 1.351106
Epoch 15, Train Loss 0.917909, Valid_loss 1.336505
Epoch 16, Train Loss 0.899210, Valid_loss 1.297479
Epoch 17, Train Loss 0.900130, Valid_loss 1.345426
Epoch 18, Train Loss 0.897748, Valid_loss 1.334028
Epoch 19, Train Loss 0.915179, Valid_loss 1.312114
Epoch 20, Train Loss 0.896084, Valid_loss 1.370050
Epoch 21, Train Loss 0.892529, Valid_loss 1.318065
Epoch 22, Train Loss 0.899171, Valid_loss 1.377947
Epoch 23, Train Loss 0.892232, Valid_loss 1.360367
Epoch 24, Train Loss 0.898184, Valid_loss 1.405217
Epoch 25, Train Loss 0.893516, Valid_loss 1.349388
Epoch 26, Train Loss 0.895400, Valid_loss 1.330911
Epoch 27, Train Loss 0.893615, Valid_loss 1.329962
Epoch 28, Train Loss 0.881654, Valid_loss 1.613654
Epoch 29, Train Loss 0.890479, Valid_loss 1.436936
Epoch 30, Train Loss 0.887408, Valid_loss 1.391659
Epoch 31, Train Loss 0.890448, Valid_loss 1.333117
Epoch 32, Train Loss 0.882425, Valid_loss 1.315427
Epoch 33, Train Loss 0.885400, Valid_loss 1.337138
Epoch 34, Train Loss 0.891811, Valid_loss 1.450055
Epoch 35, Train Loss 0.888042, Valid_loss 1.242457
Epoch 36, Train Loss 0.879165, Valid_loss 1.646449
Epoch 37, Train Loss 0.903823, Valid_loss 1.370465
Epoch 38, Train Loss 0.894183, Valid_loss 1.386952
Epoch 39, Train Loss 0.889156, Valid_loss 1.377491
Epoch 40, Train Loss 0.894503, Valid_loss 1.391340
Epoch 41, Train Loss 0.891223, Valid_loss 1.395406
Epoch 42, Train Loss 0.899420, Valid_loss 1.370196
Epoch 43, Train Loss 0.889929, Valid_loss 1.356459
Epoch 44, Train Loss 0.900061, Valid_loss 1.374929
Epoch 45, Train Loss 0.891032, Valid_loss 1.361960
Epoch 46, Train Loss 0.894350, Valid_loss 1.378056
Epoch 47, Train Loss 0.895167, Valid_loss 1.391868
Epoch 48, Train Loss 0.892188, Valid_loss 1.388891
Epoch 49, Train Loss 0.893978, Valid_loss 1.385400
Epoch 50, Train Loss 0.897972, Valid_loss 1.403767
Epoch 51, Train Loss 0.894362, Valid_loss 1.415949
Epoch 52, Train Loss 0.891168, Valid_loss 1.407895
Epoch 53, Train Loss 0.887142, Valid_loss 1.411403
Epoch 54, Train Loss 0.890530, Valid_loss 1.405747
Epoch 55, Train Loss 0.892158, Valid_loss 1.404627
Epoch 56, Train Loss 0.893193, Valid_loss 1.406698
Epoch 57, Train Loss 0.892563, Valid_loss 1.410202
[I 2025-08-27 22:34:26,383] Trial 7 finished with value: 1.2424565011804753 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 4 with value: 0.6318026286740364.
선택된 trial params: {'learning_rate': 0.001, 'epochs': 100, 'heads': 1, 'dropout': 0.3, 'weight_decay': 0.0001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=9, batch_size=1 -> steps=9
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.985823, Valid_loss 1.434148
Epoch 2, Train Loss 0.935274, Valid_loss 1.522996
Epoch 3, Train Loss 0.925116, Valid_loss 1.253203
Epoch 4, Train Loss 0.714400, Valid_loss 1.089902
Epoch 5, Train Loss 0.761251, Valid_loss 1.617611
Epoch 6, Train Loss 0.700823, Valid_loss 1.120658
Epoch 7, Train Loss 0.614623, Valid_loss 0.977225
Epoch 8, Train Loss 0.553983, Valid_loss 0.869089
Epoch 9, Train Loss 0.569430, Valid_loss 0.885043
Epoch 10, Train Loss 0.563140, Valid_loss 0.934314
Epoch 11, Train Loss 0.551014, Valid_loss 0.824387
Epoch 12, Train Loss 0.554157, Valid_loss 0.841250
Epoch 13, Train Loss 0.575310, Valid_loss 0.663919
Epoch 14, Train Loss 0.527884, Valid_loss 0.896416
Epoch 15, Train Loss 0.553208, Valid_loss 0.733196
Epoch 16, Train Loss 0.525934, Valid_loss 0.637550
Epoch 17, Train Loss 0.462490, Valid_loss 0.749195
Epoch 18, Train Loss 0.469118, Valid_loss 1.178998
Epoch 19, Train Loss 0.456836, Valid_loss 0.649753
Epoch 20, Train Loss 0.437443, Valid_loss 1.597850
Epoch 21, Train Loss 0.352020, Valid_loss 0.664355
Epoch 22, Train Loss 0.412897, Valid_loss 1.278489
Epoch 23, Train Loss 0.348911, Valid_loss 1.748845
Epoch 24, Train Loss 0.389183, Valid_loss 0.775471
Epoch 25, Train Loss 0.335848, Valid_loss 0.908872
Epoch 26, Train Loss 0.343633, Valid_loss 2.008331
Epoch 27, Train Loss 0.425847, Valid_loss 1.046993
Epoch 28, Train Loss 0.321084, Valid_loss 1.672033
Epoch 29, Train Loss 0.304467, Valid_loss 1.020177
Epoch 30, Train Loss 0.320602, Valid_loss 1.622633
Epoch 31, Train Loss 0.329236, Valid_loss 1.590091
Epoch 32, Train Loss 0.295593, Valid_loss 1.047251
Epoch 33, Train Loss 0.363328, Valid_loss 2.734823
Epoch 34, Train Loss 0.249793, Valid_loss 2.100701
Epoch 35, Train Loss 0.241531, Valid_loss 1.818756
Epoch 36, Train Loss 0.324345, Valid_loss 2.290152
Epoch 37, Train Loss 0.221358, Valid_loss 3.092288
Epoch 38, Train Loss 0.268004, Valid_loss 2.331829
Epoch 39, Train Loss 0.267938, Valid_loss 1.691526
Epoch 40, Train Loss 0.216320, Valid_loss 1.099629
Epoch 41, Train Loss 0.237296, Valid_loss 3.439337
Epoch 42, Train Loss 0.265308, Valid_loss 2.338676
Epoch 43, Train Loss 0.229541, Valid_loss 0.547314
Epoch 44, Train Loss 0.416469, Valid_loss 1.270768
Epoch 45, Train Loss 0.174805, Valid_loss 1.197631
Epoch 46, Train Loss 0.214066, Valid_loss 1.288108
Epoch 47, Train Loss 0.308139, Valid_loss 0.932042
Epoch 48, Train Loss 0.222528, Valid_loss 1.306187
Epoch 49, Train Loss 0.200558, Valid_loss 1.418033
Epoch 50, Train Loss 0.231980, Valid_loss 0.929688
Epoch 51, Train Loss 0.345046, Valid_loss 1.279834
Epoch 52, Train Loss 0.174622, Valid_loss 2.135750
환자ID=P1304 -- true: [[2]] -- pred: tensor([[-5.7489,  0.5589,  1.8032]], device='cuda:0')
환자ID=P1437 -- true: [[2]] -- pred: tensor([[-5.6844,  0.3679,  2.0759]], device='cuda:0')
환자ID=P1447 -- true: [[1]] -- pred: tensor([[-5.7267,  0.4689,  1.9469]], device='cuda:0')
환자ID=P1510 -- true: [[1]] -- pred: tensor([[-5.7298,  0.6722,  1.5887]], device='cuda:0')
환자ID=P1515 -- true: [[0]] -- pred: tensor([[ 3.7795, -1.4763, -6.7174]], device='cuda:0')
환자ID=P1600 -- true: [[0]] -- pred: tensor([[ 3.8108, -1.5034, -6.7145]], device='cuda:0')
환자ID=P1602 -- true: [[1]] -- pred: tensor([[-4.0135,  1.5966, -2.0458]], device='cuda:0')
환자ID=P1603 -- true: [[0]] -- pred: tensor([[ 3.4276, -1.1860, -6.7011]], device='cuda:0')
환자ID=P1718 -- true: [[0]] -- pred: tensor([[ 3.6882, -1.3969, -6.7160]], device='cuda:0')
Best performance: Epoch 43, Loss 0.229541, Test ACC 0.777778, Test AUC 0.944444, Test Recall 0.777778, Test Precision 0.833333
Confusion Matrix:
 [[4 0 0]
 [0 1 2]
 [0 0 2]]
✅ Total valid splits used: 1
🔁 Repeat 2, Fold 1
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 473950, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 473950, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 8, 1: 12, 0: 13}
cell type :  AACCTGAGTGTACATC-1-4              cardiac muscle cell
CTCCAACTCCGAGATT-1-4              cardiac muscle cell
CATCGTCCACCCGTAG-1-4              cardiac muscle cell
AAAGGGCCACTAGTAC-1-4              cardiac muscle cell
ATTTCTGGTGAATGAT-1-4              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 118739, dtype: string
cell type annotation :  AACCTGAGTGTACATC-1-4              cardiac muscle cell
CTCCAACTCCGAGATT-1-4              cardiac muscle cell
CATCGTCCACCCGTAG-1-4              cardiac muscle cell
AAAGGGCCACTAGTAC-1-4              cardiac muscle cell
ATTTCTGGTGAATGAT-1-4              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 118739, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'endocardial cell', 'macrophage', 'cardiac neuron', 'cardiac ventricle fibroblast', 'endothelial cell of lymphatic vessel', 'cardiac endothelial cell', 'vascular associated smooth muscle cell', 'pericyte cell', 'lymphocyte', 'mast cell', 'mesothelial cell']
라벨별 그룹 개수 {2: 3, 1: 3, 0: 3}
🔍 Split #2
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 33
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 9
  → train 환자 ID: ['P1290', 'P1300', 'P1304', 'P1371', 'P1422', 'P1425', 'P1430', 'P1437', 'P1447', 'P1462', 'P1472', 'P1479', 'P1510', 'P1515', 'P1516', 'P1539', 'P1547', 'P1549', 'P1561', 'P1582', 'P1600', 'P1602', 'P1603', 'P1610', 'P1617', 'P1622', 'P1630', 'P1631', 'P1678', 'P1685', 'P1718', 'P1722', 'P1735']
  → test  환자 ID: ['P1358', 'P1504', 'P1508', 'P1540', 'P1558', 'P1606', 'P1702', 'P1707', 'P1726']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1358, Label: 2
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1540, Label: 0
    ID: P1558, Label: 0
    ID: P1606, Label: 2
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1726, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 33
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 33
기존 (train) label_stat 33
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 11
test_p_index 9
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1539, Label=0, 셀개수=11076
→ valid 환자 ID 및 라벨:
   총 개수: 11
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1617, Label=2, 셀개수=17986
→ test 환자 ID 및 라벨:
   총 개수: 9
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1726, Label=1, 셀개수=12389
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685        cardiac endothelial cell
592686    cardiac ventricle fibroblast
592687                   pericyte cell
592688        cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:12,  7.93it/s]  2%|▏         | 2/100 [00:00<00:11,  8.26it/s]  3%|▎         | 3/100 [00:00<00:11,  8.27it/s]  4%|▍         | 4/100 [00:00<00:11,  8.47it/s]  5%|▌         | 5/100 [00:00<00:11,  8.34it/s]  6%|▌         | 6/100 [00:00<00:10,  8.61it/s]  7%|▋         | 7/100 [00:00<00:10,  8.54it/s]  8%|▊         | 8/100 [00:00<00:10,  8.39it/s]  9%|▉         | 9/100 [00:01<00:10,  8.36it/s] 10%|█         | 10/100 [00:01<00:10,  8.33it/s] 11%|█         | 11/100 [00:01<00:10,  8.40it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.28it/s] 13%|█▎        | 13/100 [00:01<00:10,  8.19it/s] 14%|█▍        | 14/100 [00:01<00:10,  8.29it/s] 15%|█▌        | 15/100 [00:01<00:10,  8.46it/s] 16%|█▌        | 16/100 [00:01<00:09,  8.55it/s] 17%|█▋        | 17/100 [00:02<00:09,  8.53it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.42it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.38it/s] 20%|██        | 20/100 [00:02<00:09,  8.23it/s] 21%|██        | 21/100 [00:02<00:09,  8.15it/s] 22%|██▏       | 22/100 [00:02<00:09,  8.10it/s] 23%|██▎       | 23/100 [00:02<00:09,  8.16it/s] 24%|██▍       | 24/100 [00:02<00:09,  8.10it/s] 25%|██▌       | 25/100 [00:03<00:09,  8.22it/s] 26%|██▌       | 26/100 [00:03<00:09,  8.15it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.26it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.16it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.20it/s] 30%|███       | 30/100 [00:03<00:08,  8.29it/s] 31%|███       | 31/100 [00:03<00:08,  8.34it/s] 32%|███▏      | 32/100 [00:03<00:08,  8.34it/s] 33%|███▎      | 33/100 [00:03<00:08,  8.29it/s] 34%|███▍      | 34/100 [00:04<00:08,  8.23it/s] 35%|███▌      | 35/100 [00:04<00:07,  8.28it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.17it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.25it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.08it/s] 39%|███▉      | 39/100 [00:04<00:07,  8.14it/s] 40%|████      | 40/100 [00:04<00:07,  8.13it/s] 41%|████      | 41/100 [00:04<00:07,  8.20it/s] 42%|████▏     | 42/100 [00:05<00:07,  7.93it/s] 43%|████▎     | 43/100 [00:05<00:07,  8.12it/s] 44%|████▍     | 44/100 [00:05<00:06,  8.04it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.04it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.01it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.14it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.11it/s] 49%|████▉     | 49/100 [00:05<00:06,  8.24it/s] 50%|█████     | 50/100 [00:06<00:06,  8.05it/s] 51%|█████     | 51/100 [00:06<00:06,  8.05it/s] 52%|█████▏    | 52/100 [00:06<00:06,  7.95it/s] 53%|█████▎    | 53/100 [00:06<00:05,  7.96it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.05it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.03it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.11it/s] 57%|█████▋    | 57/100 [00:06<00:05,  8.18it/s] 58%|█████▊    | 58/100 [00:07<00:05,  8.12it/s] 59%|█████▉    | 59/100 [00:07<00:05,  8.06it/s] 60%|██████    | 60/100 [00:07<00:04,  8.00it/s] 61%|██████    | 61/100 [00:07<00:04,  8.03it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.12it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.23it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.03it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.07it/s] 66%|██████▌   | 66/100 [00:08<00:04,  8.20it/s] 67%|██████▋   | 67/100 [00:08<00:04,  8.16it/s] 68%|██████▊   | 68/100 [00:08<00:03,  8.13it/s] 69%|██████▉   | 69/100 [00:08<00:03,  8.22it/s] 70%|███████   | 70/100 [00:08<00:03,  8.33it/s] 71%|███████   | 71/100 [00:08<00:03,  8.46it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.29it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.30it/s] 74%|███████▍  | 74/100 [00:09<00:03,  8.21it/s] 75%|███████▌  | 75/100 [00:09<00:03,  8.11it/s] 76%|███████▌  | 76/100 [00:09<00:02,  8.17it/s] 77%|███████▋  | 77/100 [00:09<00:02,  8.39it/s] 78%|███████▊  | 78/100 [00:09<00:02,  8.18it/s] 79%|███████▉  | 79/100 [00:09<00:02,  8.05it/s] 80%|████████  | 80/100 [00:09<00:02,  7.94it/s] 81%|████████  | 81/100 [00:09<00:02,  7.94it/s] 82%|████████▏ | 82/100 [00:10<00:02,  7.84it/s] 83%|████████▎ | 83/100 [00:10<00:02,  7.88it/s] 84%|████████▍ | 84/100 [00:10<00:02,  7.98it/s] 85%|████████▌ | 85/100 [00:10<00:01,  8.02it/s] 86%|████████▌ | 86/100 [00:10<00:01,  7.87it/s] 87%|████████▋ | 87/100 [00:10<00:01,  7.82it/s] 88%|████████▊ | 88/100 [00:10<00:01,  7.94it/s] 89%|████████▉ | 89/100 [00:10<00:01,  7.98it/s] 90%|█████████ | 90/100 [00:11<00:01,  7.99it/s] 91%|█████████ | 91/100 [00:11<00:01,  7.98it/s] 92%|█████████▏| 92/100 [00:11<00:01,  7.89it/s] 93%|█████████▎| 93/100 [00:11<00:00,  7.99it/s] 94%|█████████▍| 94/100 [00:11<00:00,  7.82it/s] 95%|█████████▌| 95/100 [00:11<00:00,  7.86it/s] 96%|█████████▌| 96/100 [00:11<00:00,  7.90it/s] 97%|█████████▋| 97/100 [00:11<00:00,  7.89it/s] 98%|█████████▊| 98/100 [00:12<00:00,  8.01it/s] 99%|█████████▉| 99/100 [00:12<00:00,  8.06it/s]100%|██████████| 100/100 [00:12<00:00,  7.99it/s]100%|██████████| 100/100 [00:12<00:00,  8.14it/s]
[I 2025-08-27 22:55:58,452] A new study created in memory with name: no-name-5b0963fc-696f-41da-9065-6793a805d537
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.926352, Valid_loss 1.793061
Epoch 2, Train Loss 0.860912, Valid_loss 2.020885
Epoch 3, Train Loss 0.888867, Valid_loss 1.377844
Epoch 4, Train Loss 0.881215, Valid_loss 1.233906
Epoch 5, Train Loss 0.862831, Valid_loss 1.570575
Epoch 6, Train Loss 0.858001, Valid_loss 1.713946
Epoch 7, Train Loss 0.885274, Valid_loss 1.295471
Epoch 8, Train Loss 0.846411, Valid_loss 1.489920
Epoch 9, Train Loss 0.845570, Valid_loss 1.841072
Epoch 10, Train Loss 0.836050, Valid_loss 1.718861
Epoch 11, Train Loss 0.866462, Valid_loss 1.380158
Epoch 12, Train Loss 0.853826, Valid_loss 1.326864
Epoch 13, Train Loss 0.847136, Valid_loss 1.578380
Epoch 14, Train Loss 0.862900, Valid_loss 1.848723
Epoch 15, Train Loss 0.849259, Valid_loss 1.550637
Epoch 16, Train Loss 0.864613, Valid_loss 1.434167
Epoch 17, Train Loss 0.850001, Valid_loss 1.463833
Epoch 18, Train Loss 0.863105, Valid_loss 1.501358
Epoch 19, Train Loss 0.850029, Valid_loss 1.491613
Epoch 20, Train Loss 0.841810, Valid_loss 1.403693
Epoch 21, Train Loss 0.865715, Valid_loss 1.445198
Epoch 22, Train Loss 0.851850, Valid_loss 1.731465
Epoch 23, Train Loss 0.862789, Valid_loss 1.615414
Epoch 24, Train Loss 0.851121, Valid_loss 1.584894
Epoch 25, Train Loss 0.865469, Valid_loss 1.491856
Epoch 26, Train Loss 0.846771, Valid_loss 1.566674
Epoch 27, Train Loss 0.854063, Valid_loss 1.563684
Epoch 28, Train Loss 0.855096, Valid_loss 1.591043
Epoch 29, Train Loss 0.852665, Valid_loss 1.635295
Epoch 30, Train Loss 0.847279, Valid_loss 1.692368
Epoch 31, Train Loss 0.846787, Valid_loss 1.651352
Epoch 32, Train Loss 0.857105, Valid_loss 1.638767
Epoch 33, Train Loss 0.853294, Valid_loss 1.555773
Epoch 34, Train Loss 0.847659, Valid_loss 1.596640
Epoch 35, Train Loss 0.859450, Valid_loss 1.619590
Epoch 36, Train Loss 0.844278, Valid_loss 1.624233
Epoch 37, Train Loss 0.843769, Valid_loss 1.655579
Epoch 38, Train Loss 0.843591, Valid_loss 1.647368
Epoch 39, Train Loss 0.847171, Valid_loss 1.629766
Epoch 40, Train Loss 0.846411, Valid_loss 1.632064
Epoch 41, Train Loss 0.844402, Valid_loss 1.638980
Epoch 42, Train Loss 0.844317, Valid_loss 1.654853
Epoch 43, Train Loss 0.845210, Valid_loss 1.656465
Epoch 44, Train Loss 0.847351, Valid_loss 1.637158
Epoch 45, Train Loss 0.853253, Valid_loss 1.687946
Epoch 46, Train Loss 0.846658, Valid_loss 1.630501
Epoch 47, Train Loss 0.844468, Valid_loss 1.639174
Epoch 48, Train Loss 0.844003, Valid_loss 1.638886
Epoch 49, Train Loss 0.845454, Valid_loss 1.633992
Epoch 50, Train Loss 0.845153, Valid_loss 1.638976
Epoch 51, Train Loss 0.842492, Valid_loss 1.644166
Epoch 52, Train Loss 0.842169, Valid_loss 1.634563
Epoch 53, Train Loss 0.841588, Valid_loss 1.638986
Epoch 54, Train Loss 0.842441, Valid_loss 1.636143
Epoch 55, Train Loss 0.842662, Valid_loss 1.639606
Epoch 56, Train Loss 0.842365, Valid_loss 1.644430
[I 2025-08-27 23:27:46,477] Trial 0 finished with value: 1.2339055429805408 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.01, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 1.2339055429805408.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.95 MB
Memory Reserved: 8626.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.97 MB
Memory Reserved: 8658.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.85 MB
Memory Reserved: 8624.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.97 MB
Memory Reserved: 8656.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 23:27:47,904] Trial 1 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.85 MB
Memory Reserved: 8624.00 MB
cuda
Epoch 1, Train Loss 1.049597, Valid_loss 1.384746
Epoch 2, Train Loss 0.859674, Valid_loss 1.332065
Epoch 3, Train Loss 0.728851, Valid_loss 1.162951
Epoch 4, Train Loss 0.580067, Valid_loss 1.121147
Epoch 5, Train Loss 0.572917, Valid_loss 1.155635
Epoch 6, Train Loss 0.563838, Valid_loss 1.061226
Epoch 7, Train Loss 0.555645, Valid_loss 1.007168
Epoch 8, Train Loss 0.502772, Valid_loss 0.946064
Epoch 9, Train Loss 0.497307, Valid_loss 0.977286
Epoch 10, Train Loss 0.422449, Valid_loss 1.036666
Epoch 11, Train Loss 0.514915, Valid_loss 0.865994
Epoch 12, Train Loss 0.428395, Valid_loss 0.970931
Epoch 13, Train Loss 0.399382, Valid_loss 1.060403
Epoch 14, Train Loss 0.365004, Valid_loss 0.958455
Epoch 15, Train Loss 0.427988, Valid_loss 1.051650
Epoch 16, Train Loss 0.425303, Valid_loss 0.822286
Epoch 17, Train Loss 0.315960, Valid_loss 1.122128
Epoch 18, Train Loss 0.374339, Valid_loss 0.959730
Epoch 19, Train Loss 0.412485, Valid_loss 1.356509
Epoch 20, Train Loss 0.355385, Valid_loss 0.923902
Epoch 21, Train Loss 0.302388, Valid_loss 1.062847
Epoch 22, Train Loss 0.326703, Valid_loss 1.351927
Epoch 23, Train Loss 0.287902, Valid_loss 0.990062
Epoch 24, Train Loss 0.287543, Valid_loss 0.858746
Epoch 25, Train Loss 0.309172, Valid_loss 1.227204
Epoch 26, Train Loss 0.262298, Valid_loss 1.301692
Epoch 27, Train Loss 0.302549, Valid_loss 1.203451
Epoch 28, Train Loss 0.229541, Valid_loss 1.250369
Epoch 29, Train Loss 0.303174, Valid_loss 1.205572
Epoch 30, Train Loss 0.282867, Valid_loss 1.326083
Epoch 31, Train Loss 0.229263, Valid_loss 1.379314
Epoch 32, Train Loss 0.246104, Valid_loss 1.180701
Epoch 33, Train Loss 0.256411, Valid_loss 1.457019
Epoch 34, Train Loss 0.207352, Valid_loss 1.518343
Epoch 35, Train Loss 0.279107, Valid_loss 1.294767
Epoch 36, Train Loss 0.266412, Valid_loss 1.129459
Epoch 37, Train Loss 0.220223, Valid_loss 1.307889
Epoch 38, Train Loss 0.220242, Valid_loss 1.199782
Epoch 39, Train Loss 0.250845, Valid_loss 1.671139
Epoch 40, Train Loss 0.194467, Valid_loss 1.251655
Epoch 41, Train Loss 0.194726, Valid_loss 1.252059
Epoch 42, Train Loss 0.181230, Valid_loss 1.189325
Epoch 43, Train Loss 0.187920, Valid_loss 0.925681
Epoch 44, Train Loss 0.254782, Valid_loss 1.370127
Epoch 45, Train Loss 0.162983, Valid_loss 1.474839
Epoch 46, Train Loss 0.165606, Valid_loss 1.404241
Epoch 47, Train Loss 0.249196, Valid_loss 1.714619
Epoch 48, Train Loss 0.145231, Valid_loss 1.296233
Epoch 49, Train Loss 0.156264, Valid_loss 1.721851
Epoch 50, Train Loss 0.209986, Valid_loss 1.755204
Epoch 51, Train Loss 0.201179, Valid_loss 1.406228
Epoch 52, Train Loss 0.190005, Valid_loss 1.575580
Epoch 53, Train Loss 0.132702, Valid_loss 1.809760
[I 2025-08-27 23:58:00,276] Trial 2 finished with value: 0.8222864845936949 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.7, 'weight_decay': 0.0001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.8222864845936949.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16934.53 MB
Memory Reserved: 16952.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 341.79 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.90 MB
Memory Reserved: 16960.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 342.12 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 23:58:01,935] Trial 3 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16931.43 MB
Memory Reserved: 16962.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 312.71 MB
Memory Reserved: 352.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16904.06 MB
Memory Reserved: 16944.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 312.06 MB
Memory Reserved: 352.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16904.48 MB
Memory Reserved: 16944.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-27 23:58:03,186] Trial 4 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.950968, Valid_loss 1.858656
Epoch 2, Train Loss 0.857286, Valid_loss 2.167157
Epoch 3, Train Loss 0.880703, Valid_loss 2.240018
Epoch 4, Train Loss 0.874390, Valid_loss 1.815841
Epoch 5, Train Loss 0.861334, Valid_loss 1.654426
Epoch 6, Train Loss 0.858605, Valid_loss 1.703767
Epoch 7, Train Loss 0.850252, Valid_loss 2.042008
Epoch 8, Train Loss 0.873280, Valid_loss 1.445543
Epoch 9, Train Loss 0.843401, Valid_loss 1.340354
Epoch 10, Train Loss 0.853634, Valid_loss 1.724315
Epoch 11, Train Loss 0.844493, Valid_loss 2.021801
Epoch 12, Train Loss 0.861383, Valid_loss 1.418508
Epoch 13, Train Loss 0.871480, Valid_loss 1.554116
Epoch 14, Train Loss 0.860475, Valid_loss 1.784876
Epoch 15, Train Loss 0.873752, Valid_loss 1.800602
Epoch 16, Train Loss 0.869505, Valid_loss 1.588924
Epoch 17, Train Loss 0.840113, Valid_loss 1.746758
Epoch 18, Train Loss 0.855563, Valid_loss 1.338284
Epoch 19, Train Loss 0.849301, Valid_loss 1.334083
Epoch 20, Train Loss 0.870238, Valid_loss 2.504533
Epoch 21, Train Loss 0.882207, Valid_loss 1.496573
Epoch 22, Train Loss 0.843361, Valid_loss 1.680520
Epoch 23, Train Loss 0.851556, Valid_loss 1.540311
Epoch 24, Train Loss 0.861768, Valid_loss 1.466491
Epoch 25, Train Loss 0.851966, Valid_loss 1.412258
Epoch 26, Train Loss 0.832537, Valid_loss 1.722767
Epoch 27, Train Loss 0.861000, Valid_loss 1.565481
Epoch 28, Train Loss 0.849188, Valid_loss 1.478795
Epoch 29, Train Loss 0.850838, Valid_loss 1.458900
Epoch 30, Train Loss 0.838345, Valid_loss 1.707790
Epoch 31, Train Loss 0.848189, Valid_loss 1.502615
Epoch 32, Train Loss 0.847094, Valid_loss 1.546725
Epoch 33, Train Loss 0.855425, Valid_loss 1.530167
Epoch 34, Train Loss 0.858749, Valid_loss 1.470515
Epoch 35, Train Loss 0.839920, Valid_loss 1.799581
Epoch 36, Train Loss 0.863486, Valid_loss 1.636687
Epoch 37, Train Loss 0.852901, Valid_loss 1.764843
Epoch 38, Train Loss 0.837839, Valid_loss 1.766566
Epoch 39, Train Loss 0.860993, Valid_loss 1.417409
Epoch 40, Train Loss 0.853848, Valid_loss 1.634532
Epoch 41, Train Loss 0.852413, Valid_loss 1.540772
Epoch 42, Train Loss 0.853573, Valid_loss 1.384735
Epoch 43, Train Loss 0.851457, Valid_loss 1.578513
Epoch 44, Train Loss 0.852400, Valid_loss 1.709483
Epoch 45, Train Loss 0.882627, Valid_loss 1.692635
Epoch 46, Train Loss 0.848988, Valid_loss 1.598003
Epoch 47, Train Loss 0.851526, Valid_loss 1.630728
Epoch 48, Train Loss 0.850465, Valid_loss 1.691916
Epoch 49, Train Loss 0.843115, Valid_loss 1.735723
Epoch 50, Train Loss 0.879658, Valid_loss 1.521953
Epoch 51, Train Loss 0.847484, Valid_loss 1.486048
Epoch 52, Train Loss 0.835390, Valid_loss 1.679437
Epoch 53, Train Loss 0.840870, Valid_loss 1.494022
Epoch 54, Train Loss 0.837781, Valid_loss 1.544307
Epoch 55, Train Loss 0.833002, Valid_loss 1.647366
[I 2025-08-28 00:18:20,570] Trial 5 finished with value: 1.334082755175504 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.0, 'weight_decay': 0.01, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.8222864845936949.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.7, 'weight_decay': 0.0001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=9, batch_size=1 -> steps=9
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.934463, Valid_loss 1.525893
Epoch 2, Train Loss 0.882944, Valid_loss 1.393770
Epoch 3, Train Loss 0.719440, Valid_loss 1.434347
Epoch 4, Train Loss 0.714329, Valid_loss 1.145194
Epoch 5, Train Loss 0.614089, Valid_loss 1.103088
Epoch 6, Train Loss 0.533687, Valid_loss 1.187933
Epoch 7, Train Loss 0.500834, Valid_loss 1.062381
Epoch 8, Train Loss 0.436597, Valid_loss 1.147635
Epoch 9, Train Loss 0.488333, Valid_loss 1.194981
Epoch 10, Train Loss 0.406882, Valid_loss 1.178929
Epoch 11, Train Loss 0.474144, Valid_loss 0.964492
Epoch 12, Train Loss 0.513784, Valid_loss 1.094554
Epoch 13, Train Loss 0.398578, Valid_loss 1.058335
Epoch 14, Train Loss 0.359094, Valid_loss 1.047122
Epoch 15, Train Loss 0.349737, Valid_loss 1.064038
Epoch 16, Train Loss 0.314806, Valid_loss 1.392435
Epoch 17, Train Loss 0.344586, Valid_loss 1.000832
Epoch 18, Train Loss 0.387677, Valid_loss 1.419071
Epoch 19, Train Loss 0.381606, Valid_loss 1.045392
Epoch 20, Train Loss 0.346221, Valid_loss 1.035022
Epoch 21, Train Loss 0.306185, Valid_loss 1.070682
Epoch 22, Train Loss 0.315223, Valid_loss 1.194252
Epoch 23, Train Loss 0.281229, Valid_loss 1.701406
Epoch 24, Train Loss 0.392706, Valid_loss 1.024241
Epoch 25, Train Loss 0.266965, Valid_loss 1.293773
Epoch 26, Train Loss 0.291781, Valid_loss 1.335209
Epoch 27, Train Loss 0.274278, Valid_loss 1.595807
Epoch 28, Train Loss 0.350461, Valid_loss 1.282746
Epoch 29, Train Loss 0.284598, Valid_loss 0.842629
Epoch 30, Train Loss 0.268829, Valid_loss 0.821685
Epoch 31, Train Loss 0.267975, Valid_loss 1.142937
Epoch 32, Train Loss 0.265996, Valid_loss 1.246505
Epoch 33, Train Loss 0.312446, Valid_loss 0.853077
Epoch 34, Train Loss 0.221010, Valid_loss 1.440104
Epoch 35, Train Loss 0.230740, Valid_loss 1.283099
Epoch 36, Train Loss 0.258759, Valid_loss 1.171735
Epoch 37, Train Loss 0.255955, Valid_loss 1.433998
Epoch 38, Train Loss 0.256418, Valid_loss 1.300828
Epoch 39, Train Loss 0.242185, Valid_loss 1.738558
Epoch 40, Train Loss 0.234407, Valid_loss 1.648071
Epoch 41, Train Loss 0.295532, Valid_loss 0.828458
Epoch 42, Train Loss 0.242437, Valid_loss 1.688683
Epoch 43, Train Loss 0.203193, Valid_loss 1.550034
Epoch 44, Train Loss 0.195767, Valid_loss 1.449900
Epoch 45, Train Loss 0.264673, Valid_loss 1.501818
Epoch 46, Train Loss 0.176759, Valid_loss 1.380295
Epoch 47, Train Loss 0.222333, Valid_loss 1.220358
Epoch 48, Train Loss 0.271949, Valid_loss 1.365464
Epoch 49, Train Loss 0.138549, Valid_loss 1.312721
Epoch 50, Train Loss 0.176447, Valid_loss 1.247300
Epoch 51, Train Loss 0.125876, Valid_loss 1.496465
Epoch 52, Train Loss 0.151791, Valid_loss 1.890978
환자ID=P1358 -- true: [[2]] -- pred: tensor([[-1.2766,  0.8645, -0.0833]], device='cuda:0')
환자ID=P1504 -- true: [[2]] -- pred: tensor([[-1.3532,  1.0301, -0.0973]], device='cuda:0')
환자ID=P1508 -- true: [[1]] -- pred: tensor([[-0.6684,  1.2384, -1.4404]], device='cuda:0')
환자ID=P1540 -- true: [[0]] -- pred: tensor([[ 2.5022, -1.5296, -2.5951]], device='cuda:0')
환자ID=P1558 -- true: [[0]] -- pred: tensor([[ 2.5303, -1.6455, -2.5497]], device='cuda:0')
환자ID=P1606 -- true: [[2]] -- pred: tensor([[-1.2824,  0.8527, -0.0451]], device='cuda:0')
환자ID=P1702 -- true: [[0]] -- pred: tensor([[ 2.5178, -1.5671, -2.5876]], device='cuda:0')
환자ID=P1707 -- true: [[1]] -- pred: tensor([[-1.4401,  1.2802, -0.3364]], device='cuda:0')
환자ID=P1726 -- true: [[1]] -- pred: tensor([[-1.4346,  1.3034, -0.4812]], device='cuda:0')
Best performance: Epoch 30, Loss 0.268829, Test ACC 0.666667, Test AUC 1.000000, Test Recall 0.666667, Test Precision 0.500000
Confusion Matrix:
 [[3 0 0]
 [0 3 0]
 [0 3 0]]
✅ Total valid splits used: 2
🔁 Repeat 2, Fold 2
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 480471, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 480471, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  CCCTTAGCACCTGATA-1-9          cardiac muscle cell
TGCAGTAAGTCTAGAA-1-9          cardiac muscle cell
TGTCCCATCAGGACAG-1-9          cardiac muscle cell
CAGATTGTCCATTCAT-1-9          cardiac muscle cell
TCTATCACACGCTGAC-1-9          cardiac muscle cell
                                   ...           
CTACTATGTACGAGCA-1-75    cardiac endothelial cell
GTCGCGAGTCGTGGTC-1-75    cardiac endothelial cell
CTGTCGTGTCATCCGG-1-75    cardiac endothelial cell
CTTTCGGAGACCGCCT-1-75    cardiac endothelial cell
GTCGTTCAGGCACTAG-1-75    cardiac endothelial cell
Name: manual_annotation, Length: 112218, dtype: string
cell type annotation :  CCCTTAGCACCTGATA-1-9          cardiac muscle cell
TGCAGTAAGTCTAGAA-1-9          cardiac muscle cell
TGTCCCATCAGGACAG-1-9          cardiac muscle cell
CAGATTGTCCATTCAT-1-9          cardiac muscle cell
TCTATCACACGCTGAC-1-9          cardiac muscle cell
                                   ...           
CTACTATGTACGAGCA-1-75    cardiac endothelial cell
GTCGCGAGTCGTGGTC-1-75    cardiac endothelial cell
CTGTCGTGTCATCCGG-1-75    cardiac endothelial cell
CTTTCGGAGACCGCCT-1-75    cardiac endothelial cell
GTCGTTCAGGCACTAG-1-75    cardiac endothelial cell
Name: manual_annotation, Length: 112218, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endothelial cell of lymphatic vessel', 'endocardial cell', 'mesothelial cell', 'cardiac neuron', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'mast cell', 'vascular associated smooth muscle cell', 'lymphocyte', 'pericyte cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 3}
🔍 Split #3
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1290', 'P1304', 'P1358', 'P1371', 'P1422', 'P1430', 'P1437', 'P1447', 'P1462', 'P1479', 'P1504', 'P1508', 'P1510', 'P1515', 'P1540', 'P1549', 'P1558', 'P1561', 'P1582', 'P1600', 'P1602', 'P1603', 'P1606', 'P1610', 'P1617', 'P1622', 'P1678', 'P1685', 'P1702', 'P1707', 'P1718', 'P1722', 'P1726', 'P1735']
  → test  환자 ID: ['P1300', 'P1425', 'P1472', 'P1516', 'P1539', 'P1547', 'P1630', 'P1631']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1540, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1300, Label: 2
    ID: P1425, Label: 1
    ID: P1472, Label: 2
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1547, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1549, Label=0, 셀개수=11709
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1603, Label=0, 셀개수=10638
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1631, Label=1, 셀개수=13686
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0              cardiac muscle cell
1              cardiac muscle cell
2              cardiac muscle cell
3              cardiac muscle cell
4              cardiac muscle cell
                    ...           
592684    cardiac endothelial cell
592685    cardiac endothelial cell
592686    cardiac endothelial cell
592687    cardiac endothelial cell
592688    cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.35it/s]  2%|▏         | 2/100 [00:00<00:11,  8.42it/s]  3%|▎         | 3/100 [00:00<00:11,  8.27it/s]  4%|▍         | 4/100 [00:00<00:11,  8.40it/s]  5%|▌         | 5/100 [00:00<00:11,  8.44it/s]  6%|▌         | 6/100 [00:00<00:11,  8.53it/s]  7%|▋         | 7/100 [00:00<00:10,  8.51it/s]  8%|▊         | 8/100 [00:00<00:10,  8.39it/s]  9%|▉         | 9/100 [00:01<00:10,  8.55it/s] 10%|█         | 10/100 [00:01<00:10,  8.55it/s] 11%|█         | 11/100 [00:01<00:10,  8.47it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.49it/s] 13%|█▎        | 13/100 [00:01<00:10,  8.51it/s] 14%|█▍        | 14/100 [00:01<00:10,  8.45it/s] 15%|█▌        | 15/100 [00:01<00:10,  8.40it/s] 16%|█▌        | 16/100 [00:01<00:10,  8.39it/s] 17%|█▋        | 17/100 [00:02<00:09,  8.42it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.46it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.51it/s] 20%|██        | 20/100 [00:02<00:09,  8.31it/s] 21%|██        | 21/100 [00:02<00:09,  8.49it/s] 22%|██▏       | 22/100 [00:02<00:09,  8.53it/s] 23%|██▎       | 23/100 [00:02<00:09,  8.46it/s] 24%|██▍       | 24/100 [00:02<00:09,  8.42it/s] 25%|██▌       | 25/100 [00:02<00:08,  8.46it/s] 26%|██▌       | 26/100 [00:03<00:08,  8.40it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.57it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.56it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.46it/s] 30%|███       | 30/100 [00:03<00:08,  8.44it/s] 31%|███       | 31/100 [00:03<00:08,  8.50it/s] 32%|███▏      | 32/100 [00:03<00:07,  8.65it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.59it/s] 34%|███▍      | 34/100 [00:04<00:07,  8.51it/s] 35%|███▌      | 35/100 [00:04<00:07,  8.60it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.55it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.44it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.36it/s] 39%|███▉      | 39/100 [00:04<00:07,  8.55it/s] 40%|████      | 40/100 [00:04<00:07,  8.47it/s] 41%|████      | 41/100 [00:04<00:06,  8.46it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.51it/s] 43%|████▎     | 43/100 [00:05<00:06,  8.37it/s] 44%|████▍     | 44/100 [00:05<00:06,  8.38it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.43it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.32it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.26it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.21it/s] 49%|████▉     | 49/100 [00:05<00:06,  8.29it/s] 50%|█████     | 50/100 [00:05<00:06,  8.20it/s] 51%|█████     | 51/100 [00:06<00:05,  8.40it/s] 52%|█████▏    | 52/100 [00:06<00:05,  8.40it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.29it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.26it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.16it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.18it/s] 57%|█████▋    | 57/100 [00:06<00:05,  8.24it/s] 58%|█████▊    | 58/100 [00:06<00:05,  8.27it/s] 59%|█████▉    | 59/100 [00:07<00:04,  8.40it/s] 60%|██████    | 60/100 [00:07<00:04,  8.54it/s] 61%|██████    | 61/100 [00:07<00:04,  8.48it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.36it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.48it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.27it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.19it/s] 66%|██████▌   | 66/100 [00:07<00:04,  8.07it/s] 67%|██████▋   | 67/100 [00:07<00:04,  8.17it/s] 68%|██████▊   | 68/100 [00:08<00:03,  8.02it/s] 69%|██████▉   | 69/100 [00:08<00:03,  8.22it/s] 70%|███████   | 70/100 [00:08<00:03,  8.04it/s] 71%|███████   | 71/100 [00:08<00:03,  8.09it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.14it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.21it/s] 74%|███████▍  | 74/100 [00:08<00:03,  8.18it/s] 75%|███████▌  | 75/100 [00:08<00:03,  8.23it/s] 76%|███████▌  | 76/100 [00:09<00:02,  8.22it/s] 77%|███████▋  | 77/100 [00:09<00:02,  8.23it/s] 78%|███████▊  | 78/100 [00:09<00:02,  8.27it/s] 79%|███████▉  | 79/100 [00:09<00:02,  8.20it/s] 80%|████████  | 80/100 [00:09<00:02,  7.92it/s] 81%|████████  | 81/100 [00:09<00:02,  8.02it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.02it/s] 83%|████████▎ | 83/100 [00:09<00:02,  7.89it/s] 84%|████████▍ | 84/100 [00:10<00:01,  8.02it/s] 85%|████████▌ | 85/100 [00:10<00:01,  8.14it/s] 86%|████████▌ | 86/100 [00:10<00:01,  8.21it/s] 87%|████████▋ | 87/100 [00:10<00:01,  8.19it/s] 88%|████████▊ | 88/100 [00:10<00:01,  8.27it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.09it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.11it/s] 91%|█████████ | 91/100 [00:10<00:01,  7.95it/s] 92%|█████████▏| 92/100 [00:11<00:01,  7.96it/s] 93%|█████████▎| 93/100 [00:11<00:00,  7.82it/s] 94%|█████████▍| 94/100 [00:11<00:00,  7.87it/s] 95%|█████████▌| 95/100 [00:11<00:00,  7.98it/s] 96%|█████████▌| 96/100 [00:11<00:00,  8.12it/s] 97%|█████████▋| 97/100 [00:11<00:00,  8.14it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.06it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.08it/s]100%|██████████| 100/100 [00:12<00:00,  8.06it/s]100%|██████████| 100/100 [00:12<00:00,  8.29it/s]
[I 2025-08-28 00:48:54,925] A new study created in memory with name: no-name-109acdfd-f217-4184-aadd-a03af9f05ab8
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17906.54 MB
Memory Reserved: 17924.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 349.96 MB
Memory Reserved: 388.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17906.25 MB
Memory Reserved: 17932.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 350.37 MB
Memory Reserved: 388.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 00:48:56,318] Trial 0 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17906.81 MB
Memory Reserved: 17932.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17906.61 MB
Memory Reserved: 17914.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 350.65 MB
Memory Reserved: 400.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17906.00 MB
Memory Reserved: 17912.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 350.42 MB
Memory Reserved: 400.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 00:48:57,743] Trial 1 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17904.16 MB
Memory Reserved: 17914.00 MB
cuda
Epoch 1, Train Loss 1.063906, Valid_loss 1.474150
Epoch 2, Train Loss 0.985721, Valid_loss 1.659299
Epoch 3, Train Loss 0.885873, Valid_loss 1.713991
Epoch 4, Train Loss 0.935909, Valid_loss 1.601092
Epoch 5, Train Loss 0.934747, Valid_loss 1.456135
Epoch 6, Train Loss 0.906470, Valid_loss 1.447746
Epoch 7, Train Loss 0.893024, Valid_loss 1.545490
Epoch 8, Train Loss 0.901873, Valid_loss 1.456036
Epoch 9, Train Loss 0.897757, Valid_loss 1.432832
Epoch 10, Train Loss 0.874414, Valid_loss 1.526971
Epoch 11, Train Loss 0.894923, Valid_loss 1.473277
Epoch 12, Train Loss 0.883526, Valid_loss 1.504017
Epoch 13, Train Loss 0.877606, Valid_loss 1.533984
Epoch 14, Train Loss 0.879967, Valid_loss 1.522507
Epoch 15, Train Loss 0.874980, Valid_loss 1.556474
Epoch 16, Train Loss 0.899226, Valid_loss 1.522769
Epoch 17, Train Loss 0.879319, Valid_loss 1.535201
Epoch 18, Train Loss 0.877841, Valid_loss 1.548857
Epoch 19, Train Loss 0.904448, Valid_loss 1.536002
Epoch 20, Train Loss 0.882618, Valid_loss 1.559375
Epoch 21, Train Loss 0.877077, Valid_loss 1.637847
Epoch 22, Train Loss 0.890901, Valid_loss 1.537452
Epoch 23, Train Loss 0.878574, Valid_loss 1.531709
Epoch 24, Train Loss 0.876783, Valid_loss 1.553976
Epoch 25, Train Loss 0.879314, Valid_loss 1.532793
Epoch 26, Train Loss 0.877728, Valid_loss 1.545761
Epoch 27, Train Loss 0.877804, Valid_loss 1.540272
Epoch 28, Train Loss 0.878111, Valid_loss 1.544053
Epoch 29, Train Loss 0.877684, Valid_loss 1.535541
Epoch 30, Train Loss 0.876284, Valid_loss 1.545775
Epoch 31, Train Loss 0.960592, Valid_loss 1.548946
Epoch 32, Train Loss 0.876877, Valid_loss 1.551566
Epoch 33, Train Loss 0.876579, Valid_loss 1.543383
Epoch 34, Train Loss 0.877670, Valid_loss 1.536045
Epoch 35, Train Loss 0.877749, Valid_loss 1.540169
Epoch 36, Train Loss 0.876688, Valid_loss 1.552875
Epoch 37, Train Loss 0.876116, Valid_loss 1.563590
Epoch 38, Train Loss 0.878082, Valid_loss 1.552884
Epoch 39, Train Loss 0.880147, Valid_loss 1.552005
Epoch 40, Train Loss 0.918904, Valid_loss 1.575447
Epoch 41, Train Loss 0.878225, Valid_loss 1.533401
Epoch 42, Train Loss 0.878530, Valid_loss 1.543707
Epoch 43, Train Loss 0.875877, Valid_loss 1.532430
Epoch 44, Train Loss 0.876199, Valid_loss 1.559502
Epoch 45, Train Loss 0.892184, Valid_loss 1.530352
Epoch 46, Train Loss 0.988513, Valid_loss 1.558216
Epoch 47, Train Loss 0.876440, Valid_loss 1.563343
Epoch 48, Train Loss 0.880502, Valid_loss 1.554732
Epoch 49, Train Loss 0.874407, Valid_loss 1.583649
Epoch 50, Train Loss 0.876530, Valid_loss 1.569506
Epoch 51, Train Loss 0.875225, Valid_loss 1.555707
Epoch 52, Train Loss 0.876927, Valid_loss 1.553840
Epoch 53, Train Loss 0.875211, Valid_loss 1.552463
Epoch 54, Train Loss 0.876282, Valid_loss 1.548493
Epoch 55, Train Loss 0.873254, Valid_loss 1.551336
Epoch 56, Train Loss 0.876652, Valid_loss 1.549863
Epoch 57, Train Loss 0.874218, Valid_loss 1.560318
Epoch 58, Train Loss 0.876619, Valid_loss 1.539698
Epoch 59, Train Loss 0.878600, Valid_loss 1.532530
Epoch 60, Train Loss 0.876287, Valid_loss 1.545349
Epoch 61, Train Loss 0.875443, Valid_loss 1.544175
Epoch 62, Train Loss 0.875110, Valid_loss 1.542823
Epoch 63, Train Loss 0.876758, Valid_loss 1.545474
Epoch 64, Train Loss 0.875237, Valid_loss 1.545370
Epoch 65, Train Loss 0.875427, Valid_loss 1.550244
Epoch 66, Train Loss 0.875448, Valid_loss 1.545635
Epoch 67, Train Loss 0.875553, Valid_loss 1.540168
Epoch 68, Train Loss 0.874626, Valid_loss 1.542737
Epoch 69, Train Loss 0.875993, Valid_loss 1.543507
[I 2025-08-28 01:17:22,489] Trial 2 finished with value: 1.4328317840894063 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.7, 'weight_decay': 0.01, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 1.4328317840894063.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.993378, Valid_loss 1.464327
Epoch 2, Train Loss 0.941269, Valid_loss 1.442290
Epoch 3, Train Loss 0.911834, Valid_loss 1.413684
Epoch 4, Train Loss 0.897928, Valid_loss 1.475706
Epoch 5, Train Loss 0.895687, Valid_loss 1.445627
Epoch 6, Train Loss 0.878107, Valid_loss 1.534434
Epoch 7, Train Loss 0.880456, Valid_loss 1.540079
Epoch 8, Train Loss 0.880218, Valid_loss 1.643621
Epoch 9, Train Loss 0.884797, Valid_loss 1.596006
Epoch 10, Train Loss 0.879472, Valid_loss 1.616160
Epoch 11, Train Loss 0.877256, Valid_loss 1.586835
Epoch 12, Train Loss 0.879354, Valid_loss 1.583880
Epoch 13, Train Loss 0.877430, Valid_loss 1.600372
Epoch 14, Train Loss 0.877197, Valid_loss 1.603860
Epoch 15, Train Loss 0.873946, Valid_loss 1.603327
Epoch 16, Train Loss 0.875346, Valid_loss 1.630544
Epoch 17, Train Loss 0.881194, Valid_loss 1.618418
Epoch 18, Train Loss 0.873616, Valid_loss 1.623989
Epoch 19, Train Loss 0.876256, Valid_loss 1.626661
Epoch 20, Train Loss 0.878661, Valid_loss 1.622836
Epoch 21, Train Loss 0.876094, Valid_loss 1.620579
Epoch 22, Train Loss 0.874610, Valid_loss 1.616108
Epoch 23, Train Loss 0.875588, Valid_loss 1.639366
Epoch 24, Train Loss 0.874252, Valid_loss 1.614919
Epoch 25, Train Loss 0.875601, Valid_loss 1.616158
Epoch 26, Train Loss 0.875039, Valid_loss 1.613388
Epoch 27, Train Loss 0.875383, Valid_loss 1.630193
Epoch 28, Train Loss 0.875925, Valid_loss 1.624065
Epoch 29, Train Loss 0.875447, Valid_loss 1.633496
Epoch 30, Train Loss 0.876584, Valid_loss 1.642290
Epoch 31, Train Loss 0.877349, Valid_loss 1.614376
Epoch 32, Train Loss 0.874616, Valid_loss 1.620952
Epoch 33, Train Loss 0.875281, Valid_loss 1.633818
Epoch 34, Train Loss 0.876414, Valid_loss 1.619709
Epoch 35, Train Loss 0.875115, Valid_loss 1.616481
Epoch 36, Train Loss 0.876432, Valid_loss 1.623285
Epoch 37, Train Loss 0.881641, Valid_loss 1.623049
Epoch 38, Train Loss 0.870783, Valid_loss 1.802151
Epoch 39, Train Loss 0.883816, Valid_loss 1.600705
Epoch 40, Train Loss 0.875724, Valid_loss 1.605148
Epoch 41, Train Loss 0.876436, Valid_loss 1.623146
Epoch 42, Train Loss 0.874500, Valid_loss 1.600833
Epoch 43, Train Loss 0.876048, Valid_loss 1.623516
Epoch 44, Train Loss 0.876969, Valid_loss 1.626573
Epoch 45, Train Loss 0.876315, Valid_loss 1.617452
Epoch 46, Train Loss 0.877275, Valid_loss 1.641699
Epoch 47, Train Loss 0.874441, Valid_loss 1.622763
Epoch 48, Train Loss 0.875029, Valid_loss 1.622061
Epoch 49, Train Loss 0.875626, Valid_loss 1.633083
Epoch 50, Train Loss 0.876229, Valid_loss 1.624203
Epoch 51, Train Loss 0.873070, Valid_loss 1.627553
Epoch 52, Train Loss 0.872690, Valid_loss 1.631262
[I 2025-08-28 01:38:39,419] Trial 3 finished with value: 1.4136840303738911 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.7, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 3 with value: 1.4136840303738911.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17906.54 MB
Memory Reserved: 17924.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 349.96 MB
Memory Reserved: 388.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17906.25 MB
Memory Reserved: 17932.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 350.37 MB
Memory Reserved: 388.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 01:38:41,196] Trial 4 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17904.00 MB
Memory Reserved: 17934.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 313.52 MB
Memory Reserved: 360.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9091.39 MB
Memory Reserved: 9118.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9091.36 MB
Memory Reserved: 9118.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9091.52 MB
Memory Reserved: 9118.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 01:38:42,512] Trial 5 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.956491, Valid_loss 1.973872
Epoch 2, Train Loss 0.914577, Valid_loss 1.708329
Epoch 3, Train Loss 0.914230, Valid_loss 1.889711
Epoch 4, Train Loss 0.890900, Valid_loss 1.394456
Epoch 5, Train Loss 0.908238, Valid_loss 1.388971
Epoch 6, Train Loss 0.889734, Valid_loss 1.798850
Epoch 7, Train Loss 0.888052, Valid_loss 1.548064
Epoch 8, Train Loss 0.898052, Valid_loss 1.443914
Epoch 9, Train Loss 0.886596, Valid_loss 1.502236
Epoch 10, Train Loss 0.877701, Valid_loss 1.754250
Epoch 11, Train Loss 0.889399, Valid_loss 1.301433
Epoch 12, Train Loss 0.876546, Valid_loss 1.416881
Epoch 13, Train Loss 0.891427, Valid_loss 1.393587
Epoch 14, Train Loss 0.888657, Valid_loss 1.244951
Epoch 15, Train Loss 0.894096, Valid_loss 1.372548
Epoch 16, Train Loss 0.885789, Valid_loss 1.318986
Epoch 17, Train Loss 0.878870, Valid_loss 1.310692
Epoch 18, Train Loss 0.880098, Valid_loss 1.288320
Epoch 19, Train Loss 0.881860, Valid_loss 1.438621
Epoch 20, Train Loss 0.893010, Valid_loss 1.411149
Epoch 21, Train Loss 0.890466, Valid_loss 1.513490
Epoch 22, Train Loss 0.887189, Valid_loss 1.447778
Epoch 23, Train Loss 0.887951, Valid_loss 1.477889
Epoch 24, Train Loss 0.881106, Valid_loss 1.448467
Epoch 25, Train Loss 0.878585, Valid_loss 1.381592
Epoch 26, Train Loss 0.879656, Valid_loss 1.492637
Epoch 27, Train Loss 0.880146, Valid_loss 1.397723
Epoch 28, Train Loss 0.872407, Valid_loss 1.389426
Epoch 29, Train Loss 0.880610, Valid_loss 1.395189
Epoch 30, Train Loss 0.879758, Valid_loss 1.414408
Epoch 31, Train Loss 0.875830, Valid_loss 1.430444
Epoch 32, Train Loss 0.881395, Valid_loss 1.452366
Epoch 33, Train Loss 0.879458, Valid_loss 1.505469
Epoch 34, Train Loss 0.876301, Valid_loss 1.492950
Epoch 35, Train Loss 0.881883, Valid_loss 1.501209
Epoch 36, Train Loss 0.883266, Valid_loss 1.512204
Epoch 37, Train Loss 0.877019, Valid_loss 1.480436
Epoch 38, Train Loss 0.881425, Valid_loss 1.522689
Epoch 39, Train Loss 0.875496, Valid_loss 1.505446
Epoch 40, Train Loss 0.871815, Valid_loss 1.482537
Epoch 41, Train Loss 0.876889, Valid_loss 1.614383
Epoch 42, Train Loss 0.882997, Valid_loss 1.548037
Epoch 43, Train Loss 0.877327, Valid_loss 1.484531
Epoch 44, Train Loss 0.881086, Valid_loss 1.532456
Epoch 45, Train Loss 0.876244, Valid_loss 1.568458
Epoch 46, Train Loss 0.877174, Valid_loss 1.572459
Epoch 47, Train Loss 0.875724, Valid_loss 1.586592
Epoch 48, Train Loss 0.876895, Valid_loss 1.606051
Epoch 49, Train Loss 0.875770, Valid_loss 1.608600
Epoch 50, Train Loss 0.875965, Valid_loss 1.604858
Epoch 51, Train Loss 0.874086, Valid_loss 1.610512
Epoch 52, Train Loss 0.880410, Valid_loss 1.616863
[I 2025-08-28 02:07:56,940] Trial 6 finished with value: 1.244950955112775 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.0, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 6 with value: 1.244950955112775.
선택된 trial params: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.0, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.959361, Valid_loss 1.700805
Epoch 2, Train Loss 0.907523, Valid_loss 1.555327
Epoch 3, Train Loss 0.941416, Valid_loss 1.725875
Epoch 4, Train Loss 0.920286, Valid_loss 1.550561
Epoch 5, Train Loss 0.896042, Valid_loss 1.395089
Epoch 6, Train Loss 0.892971, Valid_loss 1.263919
Epoch 7, Train Loss 0.901006, Valid_loss 1.422851
Epoch 8, Train Loss 0.927139, Valid_loss 1.322216
Epoch 9, Train Loss 0.904403, Valid_loss 1.593180
Epoch 10, Train Loss 0.901975, Valid_loss 1.299180
Epoch 11, Train Loss 0.888240, Valid_loss 1.530882
Epoch 12, Train Loss 0.886202, Valid_loss 1.250515
Epoch 13, Train Loss 0.889575, Valid_loss 1.249959
Epoch 14, Train Loss 0.888605, Valid_loss 1.277563
Epoch 15, Train Loss 0.881516, Valid_loss 1.438478
Epoch 16, Train Loss 0.883557, Valid_loss 1.341075
Epoch 17, Train Loss 0.875814, Valid_loss 1.331310
Epoch 18, Train Loss 0.872703, Valid_loss 1.415179
Epoch 19, Train Loss 0.879528, Valid_loss 1.348092
Epoch 20, Train Loss 0.878379, Valid_loss 1.430955
Epoch 21, Train Loss 0.876754, Valid_loss 1.472975
Epoch 22, Train Loss 0.888396, Valid_loss 1.450792
Epoch 23, Train Loss 0.918951, Valid_loss 1.356599
Epoch 24, Train Loss 0.906891, Valid_loss 1.535861
Epoch 25, Train Loss 0.881694, Valid_loss 1.500599
Epoch 26, Train Loss 0.872897, Valid_loss 1.780884
Epoch 27, Train Loss 0.910650, Valid_loss 1.408903
Epoch 28, Train Loss 0.886882, Valid_loss 1.425904
Epoch 29, Train Loss 0.875551, Valid_loss 1.468250
Epoch 30, Train Loss 0.877108, Valid_loss 1.475324
Epoch 31, Train Loss 0.877312, Valid_loss 1.517750
Epoch 32, Train Loss 0.879565, Valid_loss 1.707406
Epoch 33, Train Loss 0.881920, Valid_loss 1.564705
Epoch 34, Train Loss 0.877570, Valid_loss 1.538751
Epoch 35, Train Loss 0.883620, Valid_loss 1.628308
Epoch 36, Train Loss 0.883384, Valid_loss 1.738404
Epoch 37, Train Loss 0.883994, Valid_loss 1.517781
Epoch 38, Train Loss 0.878832, Valid_loss 1.476622
Epoch 39, Train Loss 0.876307, Valid_loss 1.452239
Epoch 40, Train Loss 0.880115, Valid_loss 1.442055
Epoch 41, Train Loss 0.877271, Valid_loss 1.566027
Epoch 42, Train Loss 0.878330, Valid_loss 1.463750
Epoch 43, Train Loss 0.883114, Valid_loss 1.500534
Epoch 44, Train Loss 0.879915, Valid_loss 1.619690
Epoch 45, Train Loss 0.877546, Valid_loss 1.549768
Epoch 46, Train Loss 0.872283, Valid_loss 1.554069
Epoch 47, Train Loss 0.875968, Valid_loss 1.534581
Epoch 48, Train Loss 0.877684, Valid_loss 1.532305
Epoch 49, Train Loss 0.877319, Valid_loss 1.636464
Epoch 50, Train Loss 0.877479, Valid_loss 1.524897
Epoch 51, Train Loss 0.875428, Valid_loss 1.529832
Epoch 52, Train Loss 0.873630, Valid_loss 1.529722
Epoch 53, Train Loss 0.870843, Valid_loss 1.555149
Epoch 54, Train Loss 0.875292, Valid_loss 1.534963
Epoch 55, Train Loss 0.872653, Valid_loss 1.547388
Epoch 56, Train Loss 0.873846, Valid_loss 1.537693
Epoch 57, Train Loss 0.872700, Valid_loss 1.508643
Epoch 58, Train Loss 0.877343, Valid_loss 1.682115
Epoch 59, Train Loss 0.875237, Valid_loss 1.540927
Epoch 60, Train Loss 0.871017, Valid_loss 1.511823
Epoch 61, Train Loss 0.861592, Valid_loss 1.506144
Epoch 62, Train Loss 0.840370, Valid_loss 1.487259
Epoch 63, Train Loss 0.856443, Valid_loss 1.524701
Epoch 64, Train Loss 0.881946, Valid_loss 1.536067
환자ID=P1300 -- true: [[2]] -- pred: tensor([[ 0.1656,  0.0975, -0.7649]], device='cuda:0')
환자ID=P1425 -- true: [[1]] -- pred: tensor([[ 0.1656,  0.0975, -0.7649]], device='cuda:0')
환자ID=P1472 -- true: [[2]] -- pred: tensor([[ 0.1656,  0.0975, -0.7649]], device='cuda:0')
환자ID=P1516 -- true: [[0]] -- pred: tensor([[ 0.1656,  0.0975, -0.7649]], device='cuda:0')
환자ID=P1539 -- true: [[0]] -- pred: tensor([[ 0.1656,  0.0975, -0.7649]], device='cuda:0')
환자ID=P1547 -- true: [[0]] -- pred: tensor([[ 0.1656,  0.0975, -0.7649]], device='cuda:0')
환자ID=P1630 -- true: [[1]] -- pred: tensor([[ 0.1656,  0.0975, -0.7649]], device='cuda:0')
환자ID=P1631 -- true: [[1]] -- pred: tensor([[ 0.1656,  0.0975, -0.7649]], device='cuda:0')
Best performance: Epoch 13, Loss 0.889575, Test ACC 0.375000, Test AUC 0.666667, Test Recall 0.333333, Test Precision 0.125000
Confusion Matrix:
 [[3 0 0]
 [3 0 0]
 [2 0 0]]
✅ Total valid splits used: 3
🔁 Repeat 2, Fold 3
cell type :  CTGCTCAAGGCATCAG-1-3          cardiac muscle cell
TCATACTAGACTTCCA-1-3          cardiac muscle cell
GAGCCTGGTCGAGATG-1-3          cardiac muscle cell
CTTACCGCAGAACTCT-1-3          cardiac muscle cell
TTGACCCCATCTAACG-1-3          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 465304, dtype: string
cell type annotation :  CTGCTCAAGGCATCAG-1-3          cardiac muscle cell
TCATACTAGACTTCCA-1-3          cardiac muscle cell
GAGCCTGGTCGAGATG-1-3          cardiac muscle cell
CTTACCGCAGAACTCT-1-3          cardiac muscle cell
TTGACCCCATCTAACG-1-3          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 465304, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'endothelial cell of lymphatic vessel', 'fat cell', 'pericyte cell', 'vascular associated smooth muscle cell', 'lymphocyte', 'cardiac neuron', 'mast cell', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTCCTTCCAGGTTTAC-1-64    cardiac endothelial cell
GGGTCACAGTCTAGAA-1-64    cardiac endothelial cell
GTTCCGTGTACAAGTA-1-64    cardiac endothelial cell
TTCTTCCGTGTGTCGC-1-64    cardiac endothelial cell
TGTTGGACAGAGACTG-1-64               pericyte cell
Name: manual_annotation, Length: 127385, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTCCTTCCAGGTTTAC-1-64    cardiac endothelial cell
GGGTCACAGTCTAGAA-1-64    cardiac endothelial cell
GTTCCGTGTACAAGTA-1-64    cardiac endothelial cell
TTCTTCCGTGTGTCGC-1-64    cardiac endothelial cell
TGTTGGACAGAGACTG-1-64               pericyte cell
Name: manual_annotation, Length: 127385, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 3}
🔍 Split #4
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1290', 'P1300', 'P1304', 'P1358', 'P1425', 'P1437', 'P1447', 'P1462', 'P1472', 'P1504', 'P1508', 'P1510', 'P1515', 'P1516', 'P1539', 'P1540', 'P1547', 'P1549', 'P1558', 'P1561', 'P1600', 'P1602', 'P1603', 'P1606', 'P1610', 'P1617', 'P1630', 'P1631', 'P1685', 'P1702', 'P1707', 'P1718', 'P1726', 'P1735']
  → test  환자 ID: ['P1371', 'P1422', 'P1430', 'P1479', 'P1582', 'P1622', 'P1678', 'P1722']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1425, Label: 1
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1430, Label: 2
    ID: P1479, Label: 1
    ID: P1582, Label: 0
    ID: P1622, Label: 0
    ID: P1678, Label: 0
    ID: P1722, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1540, Label=0, 셀개수=11638
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1602, Label=1, 셀개수=16580
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1722, Label=1, 셀개수=21432
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0              cardiac muscle cell
1              cardiac muscle cell
2              cardiac muscle cell
3              cardiac muscle cell
4              cardiac muscle cell
                    ...           
592684    cardiac endothelial cell
592685    cardiac endothelial cell
592686    cardiac endothelial cell
592687    cardiac endothelial cell
592688               pericyte cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<02:05,  1.26s/it]  2%|▏         | 2/100 [00:01<01:06,  1.46it/s]  3%|▎         | 3/100 [00:01<00:42,  2.30it/s]  4%|▍         | 4/100 [00:01<00:29,  3.20it/s]  5%|▌         | 5/100 [00:01<00:23,  4.08it/s]  6%|▌         | 6/100 [00:02<00:19,  4.85it/s]  7%|▋         | 7/100 [00:02<00:19,  4.72it/s]  8%|▊         | 8/100 [00:02<00:16,  5.43it/s]  9%|▉         | 9/100 [00:02<00:14,  6.13it/s] 10%|█         | 10/100 [00:02<00:13,  6.55it/s] 11%|█         | 11/100 [00:02<00:12,  7.04it/s] 12%|█▏        | 12/100 [00:02<00:11,  7.48it/s] 13%|█▎        | 13/100 [00:03<00:11,  7.66it/s] 14%|█▍        | 14/100 [00:04<00:43,  1.97it/s] 15%|█▌        | 15/100 [00:04<00:35,  2.37it/s] 16%|█▌        | 16/100 [00:05<00:40,  2.06it/s] 17%|█▋        | 17/100 [00:05<00:34,  2.39it/s] 18%|█▊        | 18/100 [00:05<00:27,  2.98it/s] 19%|█▉        | 19/100 [00:05<00:22,  3.57it/s] 20%|██        | 20/100 [00:05<00:18,  4.25it/s] 21%|██        | 21/100 [00:06<00:18,  4.33it/s] 22%|██▏       | 22/100 [00:06<00:15,  5.03it/s] 23%|██▎       | 23/100 [00:06<00:13,  5.65it/s] 24%|██▍       | 24/100 [00:06<00:15,  4.90it/s] 25%|██▌       | 25/100 [00:06<00:13,  5.54it/s] 26%|██▌       | 26/100 [00:07<00:16,  4.41it/s] 27%|██▋       | 27/100 [00:08<00:32,  2.25it/s] 28%|██▊       | 28/100 [00:08<00:25,  2.86it/s] 29%|██▉       | 29/100 [00:08<00:20,  3.52it/s] 30%|███       | 30/100 [00:08<00:16,  4.23it/s] 31%|███       | 31/100 [00:08<00:14,  4.90it/s] 32%|███▏      | 32/100 [00:08<00:14,  4.63it/s] 33%|███▎      | 33/100 [00:08<00:12,  5.34it/s] 34%|███▍      | 34/100 [00:09<00:10,  6.07it/s] 35%|███▌      | 35/100 [00:09<00:09,  6.51it/s] 36%|███▌      | 36/100 [00:09<00:17,  3.66it/s] 37%|███▋      | 37/100 [00:10<00:17,  3.65it/s] 38%|███▊      | 38/100 [00:10<00:14,  4.34it/s] 39%|███▉      | 39/100 [00:10<00:12,  5.01it/s] 40%|████      | 40/100 [00:10<00:10,  5.58it/s] 41%|████      | 41/100 [00:10<00:11,  5.24it/s] 42%|████▏     | 42/100 [00:10<00:09,  5.90it/s] 43%|████▎     | 43/100 [00:11<00:13,  4.14it/s] 44%|████▍     | 44/100 [00:11<00:11,  4.75it/s] 45%|████▌     | 45/100 [00:12<00:20,  2.65it/s] 46%|████▌     | 46/100 [00:12<00:18,  2.96it/s] 47%|████▋     | 47/100 [00:12<00:14,  3.66it/s] 48%|████▊     | 48/100 [00:12<00:11,  4.39it/s] 49%|████▉     | 49/100 [00:12<00:10,  5.02it/s] 50%|█████     | 50/100 [00:14<00:27,  1.83it/s] 51%|█████     | 51/100 [00:14<00:20,  2.36it/s] 52%|█████▏    | 52/100 [00:14<00:16,  2.97it/s] 53%|█████▎    | 53/100 [00:14<00:12,  3.63it/s] 54%|█████▍    | 54/100 [00:14<00:11,  4.17it/s] 55%|█████▌    | 55/100 [00:14<00:10,  4.24it/s] 56%|█████▌    | 56/100 [00:14<00:08,  4.92it/s] 57%|█████▋    | 57/100 [00:15<00:07,  5.52it/s] 58%|█████▊    | 58/100 [00:16<00:20,  2.06it/s] 59%|█████▉    | 59/100 [00:16<00:15,  2.64it/s] 60%|██████    | 60/100 [00:16<00:12,  3.23it/s] 61%|██████    | 61/100 [00:16<00:10,  3.89it/s] 62%|██████▏   | 62/100 [00:16<00:08,  4.59it/s] 63%|██████▎   | 63/100 [00:17<00:08,  4.34it/s] 64%|██████▍   | 64/100 [00:17<00:07,  5.09it/s] 65%|██████▌   | 65/100 [00:17<00:06,  5.66it/s] 66%|██████▌   | 66/100 [00:17<00:05,  6.19it/s] 67%|██████▋   | 67/100 [00:18<00:16,  2.05it/s] 68%|██████▊   | 68/100 [00:18<00:12,  2.65it/s] 69%|██████▉   | 69/100 [00:18<00:09,  3.27it/s] 70%|███████   | 70/100 [00:19<00:07,  3.96it/s] 71%|███████   | 71/100 [00:19<00:06,  4.34it/s] 72%|███████▏  | 72/100 [00:19<00:05,  4.76it/s] 73%|███████▎  | 73/100 [00:19<00:05,  5.37it/s] 74%|███████▍  | 74/100 [00:19<00:04,  5.92it/s] 75%|███████▌  | 75/100 [00:20<00:08,  3.07it/s] 76%|███████▌  | 76/100 [00:20<00:06,  3.79it/s] 77%|███████▋  | 77/100 [00:20<00:05,  4.49it/s] 78%|███████▊  | 78/100 [00:20<00:04,  5.00it/s] 79%|███████▉  | 79/100 [00:21<00:04,  4.67it/s] 80%|████████  | 80/100 [00:21<00:03,  5.21it/s] 81%|████████  | 81/100 [00:21<00:03,  5.39it/s] 82%|████████▏ | 82/100 [00:21<00:03,  4.76it/s] 83%|████████▎ | 83/100 [00:21<00:03,  5.31it/s] 84%|████████▍ | 84/100 [00:21<00:02,  5.84it/s] 85%|████████▌ | 85/100 [00:23<00:07,  1.99it/s] 86%|████████▌ | 86/100 [00:23<00:05,  2.54it/s] 87%|████████▋ | 87/100 [00:23<00:04,  3.16it/s] 88%|████████▊ | 88/100 [00:23<00:03,  3.74it/s] 89%|████████▉ | 89/100 [00:23<00:02,  4.47it/s] 90%|█████████ | 90/100 [00:24<00:02,  3.85it/s] 91%|█████████ | 91/100 [00:24<00:01,  4.58it/s] 92%|█████████▏| 92/100 [00:24<00:01,  5.29it/s] 93%|█████████▎| 93/100 [00:24<00:01,  5.86it/s] 94%|█████████▍| 94/100 [00:24<00:00,  6.31it/s] 95%|█████████▌| 95/100 [00:25<00:01,  3.58it/s] 96%|█████████▌| 96/100 [00:26<00:01,  2.10it/s] 97%|█████████▋| 97/100 [00:26<00:01,  2.45it/s] 98%|█████████▊| 98/100 [00:26<00:00,  3.10it/s] 99%|█████████▉| 99/100 [00:26<00:00,  3.80it/s]100%|██████████| 100/100 [00:27<00:00,  2.25it/s]100%|██████████| 100/100 [00:27<00:00,  3.65it/s]
[I 2025-08-28 02:44:31,229] A new study created in memory with name: no-name-d349a270-1b92-4d28-80a3-721f4f0ebc27
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.987416, Valid_loss 1.125161
Epoch 2, Train Loss 0.888257, Valid_loss 1.075770
Epoch 3, Train Loss 0.751082, Valid_loss 0.854269
Epoch 4, Train Loss 0.699244, Valid_loss 0.949610
Epoch 5, Train Loss 0.659764, Valid_loss 1.042259
Epoch 6, Train Loss 0.598779, Valid_loss 0.716863
Epoch 7, Train Loss 0.646123, Valid_loss 0.991474
Epoch 8, Train Loss 0.603766, Valid_loss 0.727419
Epoch 9, Train Loss 0.594969, Valid_loss 0.801317
Epoch 10, Train Loss 0.542903, Valid_loss 0.835539
Epoch 11, Train Loss 0.526587, Valid_loss 0.785313
Epoch 12, Train Loss 0.548838, Valid_loss 1.360370
Epoch 13, Train Loss 0.544797, Valid_loss 0.861056
Epoch 14, Train Loss 0.483315, Valid_loss 1.389887
Epoch 15, Train Loss 0.523266, Valid_loss 0.657016
Epoch 16, Train Loss 0.574578, Valid_loss 0.820480
Epoch 17, Train Loss 0.487021, Valid_loss 0.793317
Epoch 18, Train Loss 0.459358, Valid_loss 0.980774
Epoch 19, Train Loss 0.421049, Valid_loss 0.627256
Epoch 20, Train Loss 0.433042, Valid_loss 1.358494
Epoch 21, Train Loss 0.370163, Valid_loss 0.806763
Epoch 22, Train Loss 0.340563, Valid_loss 0.623376
Epoch 23, Train Loss 0.318050, Valid_loss 0.628828
Epoch 24, Train Loss 0.297829, Valid_loss 0.748081
Epoch 25, Train Loss 0.286838, Valid_loss 0.651584
Epoch 26, Train Loss 0.291658, Valid_loss 0.672790
Epoch 27, Train Loss 0.254724, Valid_loss 0.335573
Epoch 28, Train Loss 0.305448, Valid_loss 0.675735
Epoch 29, Train Loss 0.253320, Valid_loss 0.465600
Epoch 30, Train Loss 0.258030, Valid_loss 0.450673
Epoch 31, Train Loss 0.234317, Valid_loss 0.693920
Epoch 32, Train Loss 0.269853, Valid_loss 0.410494
Epoch 33, Train Loss 0.225810, Valid_loss 0.582468
Epoch 34, Train Loss 0.191952, Valid_loss 0.371671
Epoch 35, Train Loss 0.249509, Valid_loss 0.482602
Epoch 36, Train Loss 0.189590, Valid_loss 1.471907
Epoch 37, Train Loss 0.266210, Valid_loss 0.424613
Epoch 38, Train Loss 0.232756, Valid_loss 0.564752
Epoch 39, Train Loss 0.175450, Valid_loss 1.133186
Epoch 40, Train Loss 0.173864, Valid_loss 0.622191
Epoch 41, Train Loss 0.154982, Valid_loss 0.812366
Epoch 42, Train Loss 0.198715, Valid_loss 0.644210
Epoch 43, Train Loss 0.196726, Valid_loss 0.821991
Epoch 44, Train Loss 0.150585, Valid_loss 0.936032
Epoch 45, Train Loss 0.147545, Valid_loss 0.473098
Epoch 46, Train Loss 0.143276, Valid_loss 0.938082
Epoch 47, Train Loss 0.147389, Valid_loss 0.728464
Epoch 48, Train Loss 0.200763, Valid_loss 1.010286
Epoch 49, Train Loss 0.121426, Valid_loss 1.129043
Epoch 50, Train Loss 0.148012, Valid_loss 0.788165
Epoch 51, Train Loss 0.118073, Valid_loss 0.846332
Epoch 52, Train Loss 0.107903, Valid_loss 0.599147
Epoch 53, Train Loss 0.144135, Valid_loss 0.786899
Epoch 54, Train Loss 0.094036, Valid_loss 0.838230
[I 2025-08-28 03:10:03,501] Trial 0 finished with value: 0.3355725226768603 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.0, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.3355725226768603.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.036623, Valid_loss 1.438257
Epoch 2, Train Loss 1.017113, Valid_loss 1.464608
Epoch 3, Train Loss 1.010512, Valid_loss 1.219965
Epoch 4, Train Loss 0.992540, Valid_loss 1.098307
Epoch 5, Train Loss 1.007317, Valid_loss 1.306313
Epoch 6, Train Loss 0.997771, Valid_loss 1.401329
Epoch 7, Train Loss 0.985056, Valid_loss 1.487976
Epoch 8, Train Loss 0.991013, Valid_loss 1.223430
Epoch 9, Train Loss 0.979757, Valid_loss 1.263016
Epoch 10, Train Loss 0.982063, Valid_loss 1.241773
Epoch 11, Train Loss 0.979479, Valid_loss 1.234251
Epoch 12, Train Loss 0.980523, Valid_loss 1.213129
Epoch 13, Train Loss 0.978941, Valid_loss 1.210619
Epoch 14, Train Loss 0.977846, Valid_loss 1.238185
Epoch 15, Train Loss 0.996601, Valid_loss 1.236873
Epoch 16, Train Loss 0.970743, Valid_loss 1.292612
Epoch 17, Train Loss 0.979134, Valid_loss 1.256972
Epoch 18, Train Loss 0.984200, Valid_loss 1.208828
Epoch 19, Train Loss 0.976936, Valid_loss 1.218666
Epoch 20, Train Loss 0.976853, Valid_loss 1.230919
Epoch 21, Train Loss 0.976059, Valid_loss 1.233924
Epoch 22, Train Loss 0.972544, Valid_loss 1.236721
Epoch 23, Train Loss 0.980251, Valid_loss 1.251724
Epoch 24, Train Loss 0.974413, Valid_loss 1.232355
Epoch 25, Train Loss 0.976943, Valid_loss 1.237004
Epoch 26, Train Loss 0.976757, Valid_loss 1.247764
Epoch 27, Train Loss 0.980868, Valid_loss 1.247016
Epoch 28, Train Loss 0.977439, Valid_loss 1.243712
Epoch 29, Train Loss 0.974310, Valid_loss 1.252130
Epoch 30, Train Loss 0.974310, Valid_loss 1.261918
Epoch 31, Train Loss 0.973549, Valid_loss 1.256311
Epoch 32, Train Loss 0.972943, Valid_loss 1.261605
Epoch 33, Train Loss 0.974433, Valid_loss 1.255886
Epoch 34, Train Loss 0.974437, Valid_loss 1.271756
Epoch 35, Train Loss 0.973131, Valid_loss 1.256630
Epoch 36, Train Loss 0.975178, Valid_loss 1.266291
Epoch 37, Train Loss 0.975058, Valid_loss 1.260278
Epoch 38, Train Loss 0.974927, Valid_loss 1.267819
Epoch 39, Train Loss 0.975178, Valid_loss 1.248284
Epoch 40, Train Loss 0.973131, Valid_loss 1.257476
Epoch 41, Train Loss 0.975398, Valid_loss 1.254120
Epoch 42, Train Loss 0.974538, Valid_loss 1.249531
Epoch 43, Train Loss 0.972741, Valid_loss 1.258611
Epoch 44, Train Loss 0.973104, Valid_loss 1.260669
Epoch 45, Train Loss 0.972600, Valid_loss 1.250837
Epoch 46, Train Loss 0.975047, Valid_loss 1.268705
Epoch 47, Train Loss 0.972145, Valid_loss 1.249226
Epoch 48, Train Loss 0.982119, Valid_loss 1.256334
Epoch 49, Train Loss 0.973260, Valid_loss 1.250588
Epoch 50, Train Loss 0.975353, Valid_loss 1.263854
Epoch 51, Train Loss 0.970928, Valid_loss 1.262662
Epoch 52, Train Loss 0.971416, Valid_loss 1.258782
Epoch 53, Train Loss 0.971897, Valid_loss 1.257250
Epoch 54, Train Loss 0.970402, Valid_loss 1.258316
Epoch 55, Train Loss 0.970738, Valid_loss 1.256559
Epoch 56, Train Loss 0.971177, Valid_loss 1.252957
Epoch 57, Train Loss 0.970606, Valid_loss 1.257355
Epoch 58, Train Loss 0.971504, Valid_loss 1.254391
Epoch 59, Train Loss 0.971334, Valid_loss 1.258486
Epoch 60, Train Loss 0.970556, Valid_loss 1.254002
Epoch 61, Train Loss 0.972031, Valid_loss 1.253686
Epoch 62, Train Loss 0.971030, Valid_loss 1.253766
Epoch 63, Train Loss 0.971043, Valid_loss 1.255155
[I 2025-08-28 03:32:38,538] Trial 1 finished with value: 1.098306655883789 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.3, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.3355725226768603.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.115461, Valid_loss 1.345133
Epoch 2, Train Loss 1.025159, Valid_loss 1.439094
Epoch 3, Train Loss 1.026823, Valid_loss 1.293683
Epoch 4, Train Loss 1.008431, Valid_loss 1.235281
Epoch 5, Train Loss 1.003154, Valid_loss 1.197182
Epoch 6, Train Loss 0.992427, Valid_loss 1.184400
Epoch 7, Train Loss 0.986792, Valid_loss 1.199556
Epoch 8, Train Loss 0.985488, Valid_loss 1.213494
Epoch 9, Train Loss 0.974392, Valid_loss 1.231448
Epoch 10, Train Loss 0.979311, Valid_loss 1.237769
Epoch 11, Train Loss 0.976579, Valid_loss 1.231151
Epoch 12, Train Loss 0.995521, Valid_loss 1.244747
Epoch 13, Train Loss 0.978895, Valid_loss 1.241640
Epoch 14, Train Loss 0.973502, Valid_loss 1.251787
Epoch 15, Train Loss 0.975928, Valid_loss 1.253714
Epoch 16, Train Loss 0.974765, Valid_loss 1.252208
Epoch 17, Train Loss 0.973367, Valid_loss 1.250649
Epoch 18, Train Loss 0.973339, Valid_loss 1.259613
Epoch 19, Train Loss 0.977494, Valid_loss 1.253485
Epoch 20, Train Loss 0.973490, Valid_loss 1.250659
Epoch 21, Train Loss 0.973068, Valid_loss 1.249136
Epoch 22, Train Loss 0.974013, Valid_loss 1.254849
Epoch 23, Train Loss 0.973488, Valid_loss 1.256819
Epoch 24, Train Loss 0.975872, Valid_loss 1.251088
Epoch 25, Train Loss 0.973850, Valid_loss 1.254830
Epoch 26, Train Loss 0.972921, Valid_loss 1.266501
Epoch 27, Train Loss 0.972586, Valid_loss 1.259836
Epoch 28, Train Loss 1.010945, Valid_loss 1.347219
Epoch 29, Train Loss 0.980400, Valid_loss 1.261365
Epoch 30, Train Loss 0.974547, Valid_loss 1.255497
Epoch 31, Train Loss 0.974916, Valid_loss 1.256380
Epoch 32, Train Loss 0.973693, Valid_loss 1.261575
Epoch 33, Train Loss 0.975594, Valid_loss 1.250305
Epoch 34, Train Loss 0.972139, Valid_loss 1.264568
Epoch 35, Train Loss 0.972703, Valid_loss 1.256059
Epoch 36, Train Loss 0.974094, Valid_loss 1.251872
Epoch 37, Train Loss 0.972718, Valid_loss 1.256176
Epoch 38, Train Loss 0.974185, Valid_loss 1.247405
Epoch 39, Train Loss 0.976769, Valid_loss 1.241612
Epoch 40, Train Loss 0.974104, Valid_loss 1.248455
Epoch 41, Train Loss 0.972254, Valid_loss 1.253499
Epoch 42, Train Loss 0.974333, Valid_loss 1.251247
Epoch 43, Train Loss 0.973674, Valid_loss 1.261227
Epoch 44, Train Loss 0.972665, Valid_loss 1.258416
Epoch 45, Train Loss 0.974401, Valid_loss 1.248990
Epoch 46, Train Loss 0.974880, Valid_loss 1.251306
Epoch 47, Train Loss 0.972525, Valid_loss 1.255895
Epoch 48, Train Loss 0.975311, Valid_loss 1.255585
Epoch 49, Train Loss 0.975785, Valid_loss 1.255882
Epoch 50, Train Loss 0.974782, Valid_loss 1.253267
Epoch 51, Train Loss 0.971771, Valid_loss 1.252813
Epoch 52, Train Loss 0.970688, Valid_loss 1.252721
Epoch 53, Train Loss 0.970624, Valid_loss 1.252112
Epoch 54, Train Loss 0.971307, Valid_loss 1.252204
Epoch 55, Train Loss 0.973591, Valid_loss 1.263711
[I 2025-08-28 04:00:54,993] Trial 2 finished with value: 1.1843996594349544 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.7, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.3355725226768603.
선택된 trial params: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.0, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.013750, Valid_loss 1.182910
Epoch 2, Train Loss 0.946032, Valid_loss 1.035911
Epoch 3, Train Loss 0.775585, Valid_loss 0.997748
Epoch 4, Train Loss 0.709509, Valid_loss 0.828798
Epoch 5, Train Loss 0.683126, Valid_loss 0.806895
Epoch 6, Train Loss 0.633220, Valid_loss 0.728175
Epoch 7, Train Loss 0.619941, Valid_loss 0.719810
Epoch 8, Train Loss 0.629687, Valid_loss 0.733781
Epoch 9, Train Loss 0.633723, Valid_loss 0.745964
Epoch 10, Train Loss 0.558905, Valid_loss 0.692661
Epoch 11, Train Loss 0.510300, Valid_loss 0.701383
Epoch 12, Train Loss 0.596553, Valid_loss 0.678801
Epoch 13, Train Loss 0.604165, Valid_loss 0.684818
Epoch 14, Train Loss 0.526948, Valid_loss 0.673584
Epoch 15, Train Loss 0.507700, Valid_loss 0.747338
Epoch 16, Train Loss 0.519921, Valid_loss 0.648433
Epoch 17, Train Loss 0.481080, Valid_loss 0.709857
Epoch 18, Train Loss 0.477521, Valid_loss 0.637191
Epoch 19, Train Loss 0.416171, Valid_loss 0.587275
Epoch 20, Train Loss 0.434156, Valid_loss 0.683095
Epoch 21, Train Loss 0.404180, Valid_loss 0.608391
Epoch 22, Train Loss 0.445452, Valid_loss 0.590013
Epoch 23, Train Loss 0.351557, Valid_loss 0.595809
Epoch 24, Train Loss 0.387246, Valid_loss 0.633810
Epoch 25, Train Loss 0.353812, Valid_loss 0.550661
Epoch 26, Train Loss 0.314179, Valid_loss 0.551152
Epoch 27, Train Loss 0.284001, Valid_loss 0.427010
Epoch 28, Train Loss 0.201650, Valid_loss 0.335235
Epoch 29, Train Loss 0.189120, Valid_loss 0.446263
Epoch 30, Train Loss 0.169455, Valid_loss 0.424037
Epoch 31, Train Loss 0.175322, Valid_loss 0.426181
Epoch 32, Train Loss 0.171439, Valid_loss 0.735425
Epoch 33, Train Loss 0.133258, Valid_loss 0.604106
Epoch 34, Train Loss 0.126785, Valid_loss 0.865891
Epoch 35, Train Loss 0.114647, Valid_loss 0.899609
Epoch 36, Train Loss 0.134485, Valid_loss 0.609389
Epoch 37, Train Loss 0.092053, Valid_loss 1.076150
Epoch 38, Train Loss 0.150307, Valid_loss 0.753258
Epoch 39, Train Loss 0.117573, Valid_loss 0.733450
Epoch 40, Train Loss 0.061707, Valid_loss 1.046471
Epoch 41, Train Loss 0.069448, Valid_loss 1.113297
Epoch 42, Train Loss 0.061875, Valid_loss 1.813254
Epoch 43, Train Loss 0.172127, Valid_loss 0.766063
Epoch 44, Train Loss 0.046550, Valid_loss 0.727745
Epoch 45, Train Loss 0.073262, Valid_loss 0.702493
Epoch 46, Train Loss 0.052502, Valid_loss 1.643449
Epoch 47, Train Loss 0.029512, Valid_loss 0.864232
Epoch 48, Train Loss 0.017201, Valid_loss 1.659740
Epoch 49, Train Loss 0.040038, Valid_loss 0.824866
Epoch 50, Train Loss 0.037921, Valid_loss 0.660406
Epoch 51, Train Loss 0.038635, Valid_loss 1.362993
Epoch 52, Train Loss 0.012271, Valid_loss 1.097016
Epoch 53, Train Loss 0.009461, Valid_loss 0.971683
Epoch 54, Train Loss 0.008961, Valid_loss 1.027094
Epoch 55, Train Loss 0.007848, Valid_loss 0.966751
Epoch 56, Train Loss 0.007582, Valid_loss 1.041051
Epoch 57, Train Loss 0.006974, Valid_loss 1.050823
환자ID=P1371 -- true: [[2]] -- pred: tensor([[-3.0752,  0.0577,  0.4582]], device='cuda:0')
환자ID=P1422 -- true: [[1]] -- pred: tensor([[-2.9955,  0.4204,  0.3176]], device='cuda:0')
환자ID=P1430 -- true: [[2]] -- pred: tensor([[-3.0418,  0.3354,  0.3575]], device='cuda:0')
환자ID=P1479 -- true: [[1]] -- pred: tensor([[ 0.5542,  0.7318, -2.8745]], device='cuda:0')
환자ID=P1582 -- true: [[0]] -- pred: tensor([[ 3.0981, -1.8592, -4.7175]], device='cuda:0')
환자ID=P1622 -- true: [[0]] -- pred: tensor([[ 3.2021, -1.8557, -4.8661]], device='cuda:0')
환자ID=P1678 -- true: [[0]] -- pred: tensor([[ 3.1029, -1.8589, -4.7238]], device='cuda:0')
환자ID=P1722 -- true: [[1]] -- pred: tensor([[-2.9821,  0.4874,  0.2915]], device='cuda:0')
Best performance: Epoch 28, Loss 0.201650, Test ACC 1.000000, Test AUC 1.000000, Test Recall 1.000000, Test Precision 1.000000
Confusion Matrix:
 [[3 0 0]
 [0 3 0]
 [0 0 2]]
✅ Total valid splits used: 4
🔁 Repeat 2, Fold 4
cell type :  TTCTTCCGTTCAACGT-1-0              cardiac muscle cell
CATCCACCATCTAACG-1-0              cardiac muscle cell
ACCCAAACAGCTAACT-1-0              cardiac muscle cell
AAGGAATCAACTGGTT-1-0              cardiac muscle cell
TACCCGTAGCGTGCTC-1-0              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 486935, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0              cardiac muscle cell
CATCCACCATCTAACG-1-0              cardiac muscle cell
ACCCAAACAGCTAACT-1-0              cardiac muscle cell
AAGGAATCAACTGGTT-1-0              cardiac muscle cell
TACCCGTAGCGTGCTC-1-0              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 486935, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  CTGCTCAAGGCATCAG-1-3          cardiac muscle cell
TCATACTAGACTTCCA-1-3          cardiac muscle cell
GAGCCTGGTCGAGATG-1-3          cardiac muscle cell
CTTACCGCAGAACTCT-1-3          cardiac muscle cell
TTGACCCCATCTAACG-1-3          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 105754, dtype: string
cell type annotation :  CTGCTCAAGGCATCAG-1-3          cardiac muscle cell
TCATACTAGACTTCCA-1-3          cardiac muscle cell
GAGCCTGGTCGAGATG-1-3          cardiac muscle cell
CTTACCGCAGAACTCT-1-3          cardiac muscle cell
TTGACCCCATCTAACG-1-3          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 105754, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'endothelial cell of lymphatic vessel', 'fat cell', 'pericyte cell', 'vascular associated smooth muscle cell', 'lymphocyte', 'cardiac neuron', 'mast cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 3}
🔍 Split #5
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1300', 'P1304', 'P1358', 'P1371', 'P1422', 'P1425', 'P1430', 'P1437', 'P1447', 'P1472', 'P1479', 'P1504', 'P1508', 'P1510', 'P1515', 'P1516', 'P1539', 'P1540', 'P1547', 'P1558', 'P1582', 'P1600', 'P1602', 'P1603', 'P1606', 'P1622', 'P1630', 'P1631', 'P1678', 'P1702', 'P1707', 'P1718', 'P1722', 'P1726']
  → test  환자 ID: ['P1290', 'P1462', 'P1549', 'P1561', 'P1610', 'P1617', 'P1685', 'P1735']
  → train 환자 ID 및 라벨:
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1558, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1726, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1462, Label: 1
    ID: P1549, Label: 0
    ID: P1561, Label: 0
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1685, Label: 1
    ID: P1735, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1516, Label=0, 셀개수=9361
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1600, Label=0, 셀개수=14882
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1735, Label=1, 셀개수=12009
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0              cardiac muscle cell
1              cardiac muscle cell
2              cardiac muscle cell
3              cardiac muscle cell
4              cardiac muscle cell
                    ...           
592684    cardiac endothelial cell
592685    cardiac endothelial cell
592686    cardiac endothelial cell
592687    cardiac endothelial cell
592688    cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:19,  5.06it/s]  2%|▏         | 2/100 [00:00<00:15,  6.45it/s]  3%|▎         | 3/100 [00:00<00:14,  6.79it/s]  4%|▍         | 4/100 [00:00<00:12,  7.44it/s]  5%|▌         | 5/100 [00:00<00:12,  7.88it/s]  6%|▌         | 6/100 [00:00<00:11,  8.27it/s]  7%|▋         | 7/100 [00:01<00:14,  6.44it/s]  8%|▊         | 8/100 [00:01<00:26,  3.53it/s]  9%|▉         | 9/100 [00:01<00:21,  4.33it/s] 10%|█         | 10/100 [00:01<00:17,  5.11it/s] 11%|█         | 11/100 [00:01<00:15,  5.86it/s] 12%|█▏        | 12/100 [00:02<00:13,  6.36it/s] 13%|█▎        | 13/100 [00:02<00:12,  6.77it/s] 14%|█▍        | 14/100 [00:02<00:12,  6.96it/s] 15%|█▌        | 15/100 [00:02<00:11,  7.28it/s] 16%|█▌        | 16/100 [00:02<00:11,  7.63it/s] 17%|█▋        | 17/100 [00:02<00:10,  7.92it/s] 18%|█▊        | 18/100 [00:03<00:18,  4.54it/s] 19%|█▉        | 19/100 [00:03<00:15,  5.28it/s] 20%|██        | 20/100 [00:03<00:19,  4.00it/s] 21%|██        | 21/100 [00:03<00:16,  4.73it/s] 22%|██▏       | 22/100 [00:03<00:14,  5.40it/s] 23%|██▎       | 23/100 [00:04<00:19,  3.97it/s] 24%|██▍       | 24/100 [00:04<00:28,  2.65it/s] 25%|██▌       | 25/100 [00:05<00:23,  3.19it/s] 26%|██▌       | 26/100 [00:05<00:21,  3.51it/s] 27%|██▋       | 27/100 [00:05<00:17,  4.29it/s] 28%|██▊       | 28/100 [00:05<00:14,  5.12it/s] 29%|██▉       | 29/100 [00:06<00:26,  2.69it/s] 30%|███       | 30/100 [00:07<00:32,  2.14it/s] 31%|███       | 31/100 [00:07<00:25,  2.70it/s] 32%|███▏      | 32/100 [00:07<00:20,  3.28it/s] 33%|███▎      | 33/100 [00:07<00:19,  3.45it/s] 34%|███▍      | 34/100 [00:07<00:16,  4.08it/s] 35%|███▌      | 35/100 [00:07<00:13,  4.79it/s] 36%|███▌      | 36/100 [00:07<00:11,  5.48it/s] 37%|███▋      | 37/100 [00:08<00:10,  6.14it/s] 38%|███▊      | 38/100 [00:08<00:09,  6.68it/s] 39%|███▉      | 39/100 [00:08<00:08,  7.15it/s] 40%|████      | 40/100 [00:08<00:08,  7.49it/s] 41%|████      | 41/100 [00:09<00:16,  3.56it/s] 42%|████▏     | 42/100 [00:09<00:15,  3.63it/s] 43%|████▎     | 43/100 [00:09<00:20,  2.81it/s] 44%|████▍     | 44/100 [00:09<00:15,  3.53it/s] 45%|████▌     | 45/100 [00:10<00:13,  4.14it/s] 46%|████▌     | 46/100 [00:10<00:11,  4.56it/s] 47%|████▋     | 47/100 [00:10<00:10,  5.17it/s] 48%|████▊     | 48/100 [00:10<00:08,  5.83it/s] 49%|████▉     | 49/100 [00:10<00:07,  6.41it/s] 50%|█████     | 50/100 [00:12<00:27,  1.81it/s] 51%|█████     | 51/100 [00:12<00:20,  2.34it/s] 52%|█████▏    | 52/100 [00:12<00:16,  2.91it/s] 53%|█████▎    | 53/100 [00:12<00:13,  3.57it/s] 54%|█████▍    | 54/100 [00:12<00:10,  4.32it/s] 55%|█████▌    | 55/100 [00:12<00:08,  5.16it/s] 56%|█████▌    | 56/100 [00:12<00:07,  5.60it/s] 57%|█████▋    | 57/100 [00:13<00:06,  6.17it/s] 58%|█████▊    | 58/100 [00:13<00:06,  6.74it/s] 59%|█████▉    | 59/100 [00:13<00:05,  7.07it/s] 60%|██████    | 60/100 [00:14<00:15,  2.54it/s] 61%|██████    | 61/100 [00:14<00:16,  2.38it/s] 62%|██████▏   | 62/100 [00:14<00:13,  2.90it/s] 63%|██████▎   | 63/100 [00:15<00:10,  3.59it/s] 64%|██████▍   | 64/100 [00:15<00:08,  4.37it/s] 65%|██████▌   | 65/100 [00:15<00:06,  5.07it/s] 66%|██████▌   | 66/100 [00:15<00:05,  5.68it/s] 67%|██████▋   | 67/100 [00:15<00:05,  6.29it/s] 68%|██████▊   | 68/100 [00:15<00:04,  6.76it/s] 69%|██████▉   | 69/100 [00:15<00:04,  7.15it/s] 70%|███████   | 70/100 [00:15<00:04,  7.49it/s] 71%|███████   | 71/100 [00:16<00:03,  7.57it/s] 72%|███████▏  | 72/100 [00:17<00:12,  2.30it/s] 73%|███████▎  | 73/100 [00:17<00:10,  2.50it/s] 74%|███████▍  | 74/100 [00:17<00:08,  3.17it/s] 75%|███████▌  | 75/100 [00:17<00:07,  3.14it/s] 76%|███████▌  | 76/100 [00:18<00:08,  2.93it/s] 77%|███████▋  | 77/100 [00:18<00:06,  3.64it/s] 78%|███████▊  | 78/100 [00:18<00:05,  4.38it/s] 79%|███████▉  | 79/100 [00:18<00:04,  4.93it/s] 80%|████████  | 80/100 [00:18<00:03,  5.64it/s] 81%|████████  | 81/100 [00:18<00:03,  5.87it/s] 82%|████████▏ | 82/100 [00:19<00:02,  6.44it/s] 83%|████████▎ | 83/100 [00:19<00:03,  4.25it/s] 84%|████████▍ | 84/100 [00:19<00:03,  4.98it/s] 85%|████████▌ | 85/100 [00:20<00:05,  2.87it/s] 86%|████████▌ | 86/100 [00:20<00:05,  2.49it/s] 87%|████████▋ | 87/100 [00:21<00:04,  2.64it/s] 88%|████████▊ | 88/100 [00:21<00:03,  3.31it/s] 89%|████████▉ | 89/100 [00:21<00:02,  3.87it/s] 90%|█████████ | 90/100 [00:21<00:02,  4.37it/s] 91%|█████████ | 91/100 [00:21<00:01,  4.77it/s] 92%|█████████▏| 92/100 [00:21<00:01,  5.34it/s] 93%|█████████▎| 93/100 [00:22<00:01,  5.48it/s] 94%|█████████▍| 94/100 [00:22<00:00,  6.13it/s] 95%|█████████▌| 95/100 [00:23<00:02,  2.00it/s] 96%|█████████▌| 96/100 [00:23<00:01,  2.52it/s] 97%|█████████▋| 97/100 [00:23<00:01,  3.00it/s] 98%|█████████▊| 98/100 [00:23<00:00,  3.70it/s] 99%|█████████▉| 99/100 [00:24<00:00,  4.36it/s]100%|██████████| 100/100 [00:24<00:00,  4.96it/s]100%|██████████| 100/100 [00:24<00:00,  4.13it/s]
[I 2025-08-28 04:33:30,257] A new study created in memory with name: no-name-3efaa26c-64a8-46f2-a44e-c0f71f222b7b
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9091.39 MB
Memory Reserved: 9098.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9091.52 MB
Memory Reserved: 9118.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9091.36 MB
Memory Reserved: 9098.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9091.52 MB
Memory Reserved: 9118.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 04:33:31,590] Trial 0 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9090.04 MB
Memory Reserved: 9098.00 MB
cuda
Epoch 1, Train Loss 0.862214, Valid_loss 1.920421
Epoch 2, Train Loss 0.799701, Valid_loss 2.161629
Epoch 3, Train Loss 0.799587, Valid_loss 2.159569
Epoch 4, Train Loss 0.814419, Valid_loss 1.485096
Epoch 5, Train Loss 0.787476, Valid_loss 1.531063
Epoch 6, Train Loss 0.799896, Valid_loss 1.641381
Epoch 7, Train Loss 0.802492, Valid_loss 1.945182
Epoch 8, Train Loss 0.808230, Valid_loss 1.732546
Epoch 9, Train Loss 0.803665, Valid_loss 1.694085
Epoch 10, Train Loss 0.783931, Valid_loss 1.758703
Epoch 11, Train Loss 0.786156, Valid_loss 1.896612
Epoch 12, Train Loss 0.794204, Valid_loss 1.505899
Epoch 13, Train Loss 0.792496, Valid_loss 1.353202
Epoch 14, Train Loss 0.776784, Valid_loss 1.328748
Epoch 15, Train Loss 0.778300, Valid_loss 1.320649
Epoch 16, Train Loss 0.779383, Valid_loss 1.355360
Epoch 17, Train Loss 0.771297, Valid_loss 1.421435
Epoch 18, Train Loss 0.780213, Valid_loss 1.383823
Epoch 19, Train Loss 0.774820, Valid_loss 1.335911
Epoch 20, Train Loss 0.775386, Valid_loss 1.385562
Epoch 21, Train Loss 0.772239, Valid_loss 1.378188
Epoch 22, Train Loss 0.763279, Valid_loss 1.697488
Epoch 23, Train Loss 0.776899, Valid_loss 1.367085
Epoch 24, Train Loss 0.766174, Valid_loss 1.386980
Epoch 25, Train Loss 0.798482, Valid_loss 2.359595
Epoch 26, Train Loss 0.793412, Valid_loss 1.815811
Epoch 27, Train Loss 0.779371, Valid_loss 1.363607
Epoch 28, Train Loss 0.773053, Valid_loss 1.756475
Epoch 29, Train Loss 0.787298, Valid_loss 1.367210
Epoch 30, Train Loss 0.800780, Valid_loss 1.526686
Epoch 31, Train Loss 0.770228, Valid_loss 1.410802
Epoch 32, Train Loss 0.783561, Valid_loss 1.571815
Epoch 33, Train Loss 0.764163, Valid_loss 1.392042
Epoch 34, Train Loss 0.769437, Valid_loss 1.381842
Epoch 35, Train Loss 0.768796, Valid_loss 1.353679
Epoch 36, Train Loss 0.770022, Valid_loss 1.392166
Epoch 37, Train Loss 0.786168, Valid_loss 1.409361
Epoch 38, Train Loss 0.763778, Valid_loss 1.397252
Epoch 39, Train Loss 0.765149, Valid_loss 1.476332
Epoch 40, Train Loss 0.768365, Valid_loss 1.400473
Epoch 41, Train Loss 0.765501, Valid_loss 1.403015
Epoch 42, Train Loss 0.764933, Valid_loss 1.441293
Epoch 43, Train Loss 0.764280, Valid_loss 1.443627
Epoch 44, Train Loss 0.769150, Valid_loss 1.403350
Epoch 45, Train Loss 0.776865, Valid_loss 1.416774
Epoch 46, Train Loss 0.757583, Valid_loss 1.420769
Epoch 47, Train Loss 0.769823, Valid_loss 1.387318
Epoch 48, Train Loss 0.764418, Valid_loss 1.368453
Epoch 49, Train Loss 0.763351, Valid_loss 1.460350
Epoch 50, Train Loss 0.779857, Valid_loss 1.385570
Epoch 51, Train Loss 0.761040, Valid_loss 1.374004
Epoch 52, Train Loss 0.755562, Valid_loss 1.361683
Epoch 53, Train Loss 0.758470, Valid_loss 1.371438
Epoch 54, Train Loss 0.753658, Valid_loss 1.359325
Epoch 55, Train Loss 0.755873, Valid_loss 1.370985
Epoch 56, Train Loss 0.759097, Valid_loss 1.362408
Epoch 57, Train Loss 0.758716, Valid_loss 1.349319
Epoch 58, Train Loss 0.757105, Valid_loss 1.349824
Epoch 59, Train Loss 0.755012, Valid_loss 1.336392
Epoch 60, Train Loss 0.763998, Valid_loss 1.337535
Epoch 61, Train Loss 0.756200, Valid_loss 1.365542
[I 2025-08-28 04:57:15,799] Trial 1 finished with value: 1.3206489086151123 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.0, 'weight_decay': 0.001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 1.3206489086151123.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.042756, Valid_loss 1.609162
Epoch 2, Train Loss 0.826118, Valid_loss 1.820264
Epoch 3, Train Loss 0.721425, Valid_loss 1.587387
Epoch 4, Train Loss 0.897426, Valid_loss 1.801272
Epoch 5, Train Loss 0.817829, Valid_loss 1.981894
Epoch 6, Train Loss 0.712961, Valid_loss 1.742859
Epoch 7, Train Loss 0.532288, Valid_loss 1.649826
Epoch 8, Train Loss 0.518692, Valid_loss 1.663718
Epoch 9, Train Loss 0.494694, Valid_loss 1.768303
Epoch 10, Train Loss 0.376745, Valid_loss 1.659035
Epoch 11, Train Loss 0.361007, Valid_loss 1.646849
Epoch 12, Train Loss 0.379173, Valid_loss 1.632007
Epoch 13, Train Loss 0.380921, Valid_loss 1.604628
Epoch 14, Train Loss 0.328679, Valid_loss 1.559226
Epoch 15, Train Loss 0.319084, Valid_loss 1.486120
Epoch 16, Train Loss 0.287559, Valid_loss 1.559820
Epoch 17, Train Loss 0.333934, Valid_loss 1.580528
Epoch 18, Train Loss 0.354742, Valid_loss 1.695073
Epoch 19, Train Loss 0.314499, Valid_loss 1.492859
Epoch 20, Train Loss 0.280490, Valid_loss 1.952395
Epoch 21, Train Loss 0.369213, Valid_loss 1.782277
Epoch 22, Train Loss 0.257998, Valid_loss 1.529108
Epoch 23, Train Loss 0.193402, Valid_loss 1.552098
Epoch 24, Train Loss 0.286967, Valid_loss 1.431816
Epoch 25, Train Loss 0.289454, Valid_loss 1.436713
Epoch 26, Train Loss 0.295200, Valid_loss 1.377400
Epoch 27, Train Loss 0.235180, Valid_loss 1.428849
Epoch 28, Train Loss 0.372960, Valid_loss 2.242583
Epoch 29, Train Loss 0.244105, Valid_loss 1.326887
Epoch 30, Train Loss 0.299286, Valid_loss 1.324737
Epoch 31, Train Loss 0.353534, Valid_loss 1.262364
Epoch 32, Train Loss 0.229741, Valid_loss 1.274467
Epoch 33, Train Loss 0.222995, Valid_loss 1.409914
Epoch 34, Train Loss 0.343861, Valid_loss 1.697645
Epoch 35, Train Loss 0.198219, Valid_loss 1.317172
Epoch 36, Train Loss 0.253291, Valid_loss 1.417532
Epoch 37, Train Loss 0.207821, Valid_loss 1.328587
Epoch 38, Train Loss 0.189173, Valid_loss 1.450952
Epoch 39, Train Loss 0.358831, Valid_loss 1.274645
Epoch 40, Train Loss 0.345881, Valid_loss 1.243272
Epoch 41, Train Loss 0.225419, Valid_loss 1.303243
Epoch 42, Train Loss 0.285151, Valid_loss 1.235532
Epoch 43, Train Loss 0.305774, Valid_loss 1.246387
Epoch 44, Train Loss 0.294212, Valid_loss 1.219635
Epoch 45, Train Loss 0.213473, Valid_loss 1.111109
Epoch 46, Train Loss 0.279144, Valid_loss 1.200408
Epoch 47, Train Loss 0.228933, Valid_loss 1.329102
Epoch 48, Train Loss 0.142090, Valid_loss 1.232497
Epoch 49, Train Loss 0.323627, Valid_loss 1.099224
Epoch 50, Train Loss 0.312711, Valid_loss 1.152726
Epoch 51, Train Loss 0.274230, Valid_loss 2.256163
Epoch 52, Train Loss 0.270311, Valid_loss 1.163565
Epoch 53, Train Loss 0.267314, Valid_loss 1.114280
Epoch 54, Train Loss 0.204009, Valid_loss 1.136245
Epoch 55, Train Loss 0.187645, Valid_loss 1.161007
[I 2025-08-28 05:19:55,570] Trial 2 finished with value: 1.0992240339692216 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 1.0992240339692216.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.014069, Valid_loss 1.224364
Epoch 2, Train Loss 0.950737, Valid_loss 1.110772
Epoch 3, Train Loss 0.877199, Valid_loss 1.098235
Epoch 4, Train Loss 0.798666, Valid_loss 1.031934
Epoch 5, Train Loss 0.753468, Valid_loss 1.197837
Epoch 6, Train Loss 0.749774, Valid_loss 1.033867
Epoch 7, Train Loss 0.726725, Valid_loss 1.019097
Epoch 8, Train Loss 0.660126, Valid_loss 0.996119
Epoch 9, Train Loss 0.672056, Valid_loss 1.006802
Epoch 10, Train Loss 0.633390, Valid_loss 0.995915
Epoch 11, Train Loss 0.631385, Valid_loss 0.993161
Epoch 12, Train Loss 0.621628, Valid_loss 1.004201
Epoch 13, Train Loss 0.639287, Valid_loss 1.007190
Epoch 14, Train Loss 0.573819, Valid_loss 1.022835
Epoch 15, Train Loss 0.557478, Valid_loss 1.017371
Epoch 16, Train Loss 0.526940, Valid_loss 1.013025
Epoch 17, Train Loss 0.513109, Valid_loss 0.998276
Epoch 18, Train Loss 0.561896, Valid_loss 1.039123
Epoch 19, Train Loss 0.484620, Valid_loss 1.033847
Epoch 20, Train Loss 0.505834, Valid_loss 1.010151
Epoch 21, Train Loss 0.463586, Valid_loss 1.032154
Epoch 22, Train Loss 0.558962, Valid_loss 1.008010
Epoch 23, Train Loss 0.435368, Valid_loss 1.048300
Epoch 24, Train Loss 0.440978, Valid_loss 1.032191
Epoch 25, Train Loss 0.433016, Valid_loss 1.131536
Epoch 26, Train Loss 0.456964, Valid_loss 1.015509
Epoch 27, Train Loss 0.381613, Valid_loss 1.004432
Epoch 28, Train Loss 0.413524, Valid_loss 0.994041
Epoch 29, Train Loss 0.404742, Valid_loss 0.994209
Epoch 30, Train Loss 0.368403, Valid_loss 1.047890
Epoch 31, Train Loss 0.439731, Valid_loss 1.036668
Epoch 32, Train Loss 0.379434, Valid_loss 1.047884
Epoch 33, Train Loss 0.384053, Valid_loss 1.065480
Epoch 34, Train Loss 0.439018, Valid_loss 1.110664
Epoch 35, Train Loss 0.407035, Valid_loss 1.084495
Epoch 36, Train Loss 0.355790, Valid_loss 1.032330
Epoch 37, Train Loss 0.366786, Valid_loss 1.010811
Epoch 38, Train Loss 0.410587, Valid_loss 0.998999
Epoch 39, Train Loss 0.339342, Valid_loss 1.065054
Epoch 40, Train Loss 0.378327, Valid_loss 1.046311
Epoch 41, Train Loss 0.385820, Valid_loss 1.071329
Epoch 42, Train Loss 0.349839, Valid_loss 1.069811
Epoch 43, Train Loss 0.316611, Valid_loss 1.098340
Epoch 44, Train Loss 0.349845, Valid_loss 1.070933
Epoch 45, Train Loss 0.340882, Valid_loss 1.077631
Epoch 46, Train Loss 0.326167, Valid_loss 1.069611
Epoch 47, Train Loss 0.317076, Valid_loss 1.082918
Epoch 48, Train Loss 0.367521, Valid_loss 1.118363
Epoch 49, Train Loss 0.306740, Valid_loss 1.089281
Epoch 50, Train Loss 0.409589, Valid_loss 1.119788
Epoch 51, Train Loss 0.340806, Valid_loss 1.093668
Epoch 52, Train Loss 0.278213, Valid_loss 1.048817
Epoch 53, Train Loss 0.281530, Valid_loss 1.066798
Epoch 54, Train Loss 0.289486, Valid_loss 1.068072
[I 2025-08-28 05:43:46,714] Trial 3 finished with value: 0.9931608885526657 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.3, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 3 with value: 0.9931608885526657.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.3, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.993357, Valid_loss 1.309197
Epoch 2, Train Loss 0.943711, Valid_loss 1.292070
Epoch 3, Train Loss 0.918358, Valid_loss 1.234777
Epoch 4, Train Loss 0.867706, Valid_loss 1.116522
Epoch 5, Train Loss 0.814396, Valid_loss 1.017648
Epoch 6, Train Loss 0.783751, Valid_loss 0.991450
Epoch 7, Train Loss 0.775033, Valid_loss 0.920918
Epoch 8, Train Loss 0.735870, Valid_loss 0.924665
Epoch 9, Train Loss 0.712594, Valid_loss 0.910051
Epoch 10, Train Loss 0.653277, Valid_loss 0.888446
Epoch 11, Train Loss 0.675412, Valid_loss 0.926965
Epoch 12, Train Loss 0.663711, Valid_loss 0.889708
Epoch 13, Train Loss 0.643458, Valid_loss 0.946046
Epoch 14, Train Loss 0.625059, Valid_loss 0.910257
Epoch 15, Train Loss 0.598471, Valid_loss 0.876043
Epoch 16, Train Loss 0.577747, Valid_loss 0.877623
Epoch 17, Train Loss 0.559664, Valid_loss 0.904184
Epoch 18, Train Loss 0.534353, Valid_loss 0.941973
Epoch 19, Train Loss 0.556443, Valid_loss 0.873896
Epoch 20, Train Loss 0.568678, Valid_loss 1.006311
Epoch 21, Train Loss 0.485548, Valid_loss 0.863722
Epoch 22, Train Loss 0.474223, Valid_loss 0.878609
Epoch 23, Train Loss 0.502088, Valid_loss 0.852375
Epoch 24, Train Loss 0.472716, Valid_loss 0.876871
Epoch 25, Train Loss 0.458179, Valid_loss 0.867274
Epoch 26, Train Loss 0.519801, Valid_loss 0.871720
Epoch 27, Train Loss 0.463340, Valid_loss 0.876235
Epoch 28, Train Loss 0.474637, Valid_loss 0.899042
Epoch 29, Train Loss 0.432979, Valid_loss 0.927732
Epoch 30, Train Loss 0.449620, Valid_loss 0.867225
Epoch 31, Train Loss 0.484604, Valid_loss 0.906061
Epoch 32, Train Loss 0.466876, Valid_loss 0.868004
Epoch 33, Train Loss 0.487147, Valid_loss 0.874923
Epoch 34, Train Loss 0.375475, Valid_loss 0.890986
Epoch 35, Train Loss 0.456191, Valid_loss 0.941281
Epoch 36, Train Loss 0.420270, Valid_loss 0.899883
Epoch 37, Train Loss 0.441472, Valid_loss 0.905966
Epoch 38, Train Loss 0.410301, Valid_loss 0.877230
Epoch 39, Train Loss 0.348933, Valid_loss 0.868856
Epoch 40, Train Loss 0.340463, Valid_loss 0.900510
Epoch 41, Train Loss 0.366460, Valid_loss 0.875602
Epoch 42, Train Loss 0.336037, Valid_loss 0.869566
Epoch 43, Train Loss 0.410828, Valid_loss 0.882762
Epoch 44, Train Loss 0.470230, Valid_loss 0.917981
Epoch 45, Train Loss 0.306320, Valid_loss 0.875926
Epoch 46, Train Loss 0.352111, Valid_loss 0.904249
Epoch 47, Train Loss 0.331474, Valid_loss 0.871869
Epoch 48, Train Loss 0.401323, Valid_loss 0.932641
Epoch 49, Train Loss 0.299644, Valid_loss 0.900312
Epoch 50, Train Loss 0.336779, Valid_loss 0.947000
Epoch 51, Train Loss 0.336675, Valid_loss 0.917092
Epoch 52, Train Loss 0.336042, Valid_loss 0.908311
Epoch 53, Train Loss 0.277862, Valid_loss 0.887069
Epoch 54, Train Loss 0.283903, Valid_loss 0.897298
Epoch 55, Train Loss 0.323442, Valid_loss 0.885305
Epoch 56, Train Loss 0.299417, Valid_loss 0.884106
Epoch 57, Train Loss 0.326354, Valid_loss 0.885618
Epoch 58, Train Loss 0.274672, Valid_loss 0.902457
환자ID=P1290 -- true: [[2]] -- pred: tensor([[-0.4587, -0.0543, -0.3236]], device='cuda:0')
환자ID=P1462 -- true: [[1]] -- pred: tensor([[-0.5120,  0.0068, -0.3048]], device='cuda:0')
환자ID=P1549 -- true: [[0]] -- pred: tensor([[ 1.3211, -0.2910, -0.2866]], device='cuda:0')
환자ID=P1561 -- true: [[0]] -- pred: tensor([[ 1.3503, -0.2820, -0.2887]], device='cuda:0')
환자ID=P1610 -- true: [[0]] -- pred: tensor([[ 1.2273, -0.3328, -0.2723]], device='cuda:0')
환자ID=P1617 -- true: [[2]] -- pred: tensor([[-0.6650,  0.3413, -0.3813]], device='cuda:0')
환자ID=P1685 -- true: [[1]] -- pred: tensor([[-0.6240,  0.1558, -0.3611]], device='cuda:0')
환자ID=P1735 -- true: [[1]] -- pred: tensor([[-0.5980,  0.7632, -0.3180]], device='cuda:0')
Best performance: Epoch 23, Loss 0.502088, Test ACC 0.750000, Test AUC 0.861111, Test Recall 0.666667, Test Precision 0.533333
Confusion Matrix:
 [[3 0 0]
 [0 3 0]
 [0 2 0]]
✅ Total valid splits used: 5

📌 Repeat 2: 평균 AUC = 0.8944, 표준편차 = 0.1247
Test ACC 평균 0.713889, Test Recall 평균 0.688889, Test Precision 평균 0.598333
fold_aucs = [0.9444444444444443, 1.0, 0.6666666666666666, 1.0, 0.861111111111111]
NaN 개수: 0 / 전체 5개

🔁 Repeat 3, Fold 0
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 454224, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 454224, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 12}
cell type :  CTCCCAAGTGGCACTC-1-6              cardiac muscle cell
CTGCCTAAGCCTCAAT-1-6              cardiac muscle cell
TCCTGCAAGGCTCTAT-1-6              cardiac muscle cell
ACGTACAGTGGACCAA-1-6              cardiac muscle cell
TCCTCCCCAACATACC-1-6              cardiac muscle cell
                                     ...             
GTGTCCTCACCCTTGT-1-74        cardiac endothelial cell
TATTGCTGTGACACGA-1-74    cardiac ventricle fibroblast
TCGTGCTTCGAAGGAC-1-74        cardiac endothelial cell
TGTGTGAAGGTAACTA-1-74    cardiac ventricle fibroblast
GTCGTAACACACCTTC-1-74    cardiac ventricle fibroblast
Name: manual_annotation, Length: 138465, dtype: string
cell type annotation :  CTCCCAAGTGGCACTC-1-6              cardiac muscle cell
CTGCCTAAGCCTCAAT-1-6              cardiac muscle cell
TCCTGCAAGGCTCTAT-1-6              cardiac muscle cell
ACGTACAGTGGACCAA-1-6              cardiac muscle cell
TCCTCCCCAACATACC-1-6              cardiac muscle cell
                                     ...             
GTGTCCTCACCCTTGT-1-74        cardiac endothelial cell
TATTGCTGTGACACGA-1-74    cardiac ventricle fibroblast
TCGTGCTTCGAAGGAC-1-74        cardiac endothelial cell
TGTGTGAAGGTAACTA-1-74    cardiac ventricle fibroblast
GTCGTAACACACCTTC-1-74    cardiac ventricle fibroblast
Name: manual_annotation, Length: 138465, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'endocardial cell', 'cardiac ventricle fibroblast', 'macrophage', 'endothelial cell of lymphatic vessel', 'pericyte cell', 'cardiac neuron', 'cardiac endothelial cell', 'vascular associated smooth muscle cell', 'lymphocyte', 'mast cell', 'mesothelial cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 4}
🔍 Split #1
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 33
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 9
  → train 환자 ID: ['P1290', 'P1300', 'P1304', 'P1371', 'P1422', 'P1430', 'P1437', 'P1447', 'P1462', 'P1472', 'P1504', 'P1508', 'P1516', 'P1539', 'P1540', 'P1547', 'P1549', 'P1558', 'P1561', 'P1582', 'P1600', 'P1602', 'P1603', 'P1606', 'P1622', 'P1630', 'P1631', 'P1678', 'P1685', 'P1707', 'P1722', 'P1726', 'P1735']
  → test  환자 ID: ['P1358', 'P1425', 'P1479', 'P1510', 'P1515', 'P1610', 'P1617', 'P1702', 'P1718']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1707, Label: 1
    ID: P1722, Label: 1
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1358, Label: 2
    ID: P1425, Label: 1
    ID: P1479, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1702, Label: 0
    ID: P1718, Label: 0
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 33
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 33
기존 (train) label_stat 33
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 11
test_p_index 9
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1547, Label=0, 셀개수=8253
→ valid 환자 ID 및 라벨:
   총 개수: 11
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1622, Label=0, 셀개수=7210
→ test 환자 ID 및 라벨:
   총 개수: 9
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1718, Label=0, 셀개수=9278
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685    cardiac ventricle fibroblast
592686        cardiac endothelial cell
592687    cardiac ventricle fibroblast
592688    cardiac ventricle fibroblast
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:12,  8.10it/s]  2%|▏         | 2/100 [00:00<00:11,  8.23it/s]  3%|▎         | 3/100 [00:00<00:11,  8.34it/s]  4%|▍         | 4/100 [00:00<00:11,  8.31it/s]  5%|▌         | 5/100 [00:00<00:11,  8.21it/s]  6%|▌         | 6/100 [00:00<00:11,  8.38it/s]  7%|▋         | 7/100 [00:00<00:11,  8.43it/s]  8%|▊         | 8/100 [00:00<00:11,  8.35it/s]  9%|▉         | 9/100 [00:01<00:10,  8.42it/s] 10%|█         | 10/100 [00:01<00:10,  8.38it/s] 11%|█         | 11/100 [00:01<00:10,  8.40it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.58it/s] 13%|█▎        | 13/100 [00:01<00:10,  8.44it/s] 14%|█▍        | 14/100 [00:01<00:10,  8.10it/s] 15%|█▌        | 15/100 [00:01<00:10,  8.19it/s] 16%|█▌        | 16/100 [00:01<00:10,  8.35it/s] 17%|█▋        | 17/100 [00:02<00:09,  8.45it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.36it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.30it/s] 20%|██        | 20/100 [00:02<00:09,  8.18it/s] 21%|██        | 21/100 [00:02<00:09,  8.24it/s] 22%|██▏       | 22/100 [00:02<00:09,  8.26it/s] 23%|██▎       | 23/100 [00:02<00:09,  8.07it/s] 24%|██▍       | 24/100 [00:02<00:09,  8.11it/s] 25%|██▌       | 25/100 [00:03<00:09,  8.13it/s] 26%|██▌       | 26/100 [00:03<00:09,  8.04it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.24it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.28it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.18it/s] 30%|███       | 30/100 [00:03<00:08,  8.16it/s] 31%|███       | 31/100 [00:03<00:08,  7.99it/s] 32%|███▏      | 32/100 [00:03<00:08,  7.94it/s] 33%|███▎      | 33/100 [00:04<00:08,  8.04it/s] 34%|███▍      | 34/100 [00:04<00:08,  8.13it/s] 35%|███▌      | 35/100 [00:04<00:08,  8.10it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.14it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.25it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.43it/s] 39%|███▉      | 39/100 [00:04<00:07,  8.32it/s] 40%|████      | 40/100 [00:04<00:07,  8.27it/s] 41%|████      | 41/100 [00:04<00:07,  8.07it/s] 42%|████▏     | 42/100 [00:05<00:07,  8.02it/s] 43%|████▎     | 43/100 [00:05<00:07,  8.05it/s] 44%|████▍     | 44/100 [00:05<00:07,  7.95it/s] 45%|████▌     | 45/100 [00:05<00:06,  7.98it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.06it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.15it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.05it/s] 49%|████▉     | 49/100 [00:05<00:06,  8.00it/s] 50%|█████     | 50/100 [00:06<00:06,  7.86it/s] 51%|█████     | 51/100 [00:06<00:06,  7.83it/s] 52%|█████▏    | 52/100 [00:06<00:05,  8.00it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.01it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.02it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.16it/s] 56%|█████▌    | 56/100 [00:06<00:05,  7.97it/s] 57%|█████▋    | 57/100 [00:06<00:05,  8.04it/s] 58%|█████▊    | 58/100 [00:07<00:05,  8.09it/s] 59%|█████▉    | 59/100 [00:07<00:05,  8.01it/s] 60%|██████    | 60/100 [00:07<00:05,  7.98it/s] 61%|██████    | 61/100 [00:07<00:04,  8.05it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.12it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.09it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.07it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.04it/s] 66%|██████▌   | 66/100 [00:08<00:04,  8.06it/s] 67%|██████▋   | 67/100 [00:08<00:04,  8.17it/s] 68%|██████▊   | 68/100 [00:08<00:03,  8.17it/s] 69%|██████▉   | 69/100 [00:08<00:03,  8.27it/s] 70%|███████   | 70/100 [00:08<00:03,  8.18it/s] 71%|███████   | 71/100 [00:08<00:03,  8.19it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.16it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.26it/s] 74%|███████▍  | 74/100 [00:09<00:03,  8.19it/s] 75%|███████▌  | 75/100 [00:09<00:03,  8.04it/s] 76%|███████▌  | 76/100 [00:09<00:02,  8.08it/s] 77%|███████▋  | 77/100 [00:09<00:02,  7.97it/s] 78%|███████▊  | 78/100 [00:09<00:02,  8.07it/s] 79%|███████▉  | 79/100 [00:09<00:02,  8.12it/s] 80%|████████  | 80/100 [00:09<00:02,  7.88it/s] 81%|████████  | 81/100 [00:09<00:02,  7.99it/s] 82%|████████▏ | 82/100 [00:10<00:02,  7.99it/s] 83%|████████▎ | 83/100 [00:10<00:02,  8.00it/s] 84%|████████▍ | 84/100 [00:10<00:01,  8.01it/s] 85%|████████▌ | 85/100 [00:10<00:01,  7.94it/s] 86%|████████▌ | 86/100 [00:10<00:01,  7.97it/s] 87%|████████▋ | 87/100 [00:10<00:01,  8.09it/s] 88%|████████▊ | 88/100 [00:10<00:01,  7.78it/s] 89%|████████▉ | 89/100 [00:10<00:01,  7.84it/s] 90%|█████████ | 90/100 [00:11<00:01,  7.98it/s] 91%|█████████ | 91/100 [00:11<00:01,  7.89it/s] 92%|█████████▏| 92/100 [00:11<00:01,  7.68it/s] 93%|█████████▎| 93/100 [00:11<00:00,  7.81it/s] 94%|█████████▍| 94/100 [00:11<00:00,  7.75it/s] 95%|█████████▌| 95/100 [00:11<00:00,  7.80it/s] 96%|█████████▌| 96/100 [00:11<00:00,  7.66it/s] 97%|█████████▋| 97/100 [00:11<00:00,  7.69it/s] 98%|█████████▊| 98/100 [00:12<00:00,  7.57it/s] 99%|█████████▉| 99/100 [00:12<00:00,  7.67it/s]100%|██████████| 100/100 [00:12<00:00,  7.71it/s]100%|██████████| 100/100 [00:12<00:00,  8.07it/s]
[I 2025-08-28 06:09:51,321] A new study created in memory with name: no-name-d9b6e5e4-c855-4638-a98b-fd8271eb6d97
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16934.53 MB
Memory Reserved: 16952.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 341.79 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.90 MB
Memory Reserved: 16960.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 342.12 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 06:09:52,815] Trial 0 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16931.43 MB
Memory Reserved: 16962.00 MB
cuda
Epoch 1, Train Loss 0.953178, Valid_loss 1.251657
Epoch 2, Train Loss 0.882394, Valid_loss 1.392475
Epoch 3, Train Loss 0.757360, Valid_loss 1.305127
Epoch 4, Train Loss 0.660082, Valid_loss 1.412071
Epoch 5, Train Loss 0.656898, Valid_loss 1.188044
Epoch 6, Train Loss 0.590830, Valid_loss 1.344028
Epoch 7, Train Loss 0.623405, Valid_loss 1.130758
Epoch 8, Train Loss 0.583651, Valid_loss 1.002139
Epoch 9, Train Loss 0.532718, Valid_loss 1.124962
Epoch 10, Train Loss 0.555386, Valid_loss 1.045403
Epoch 11, Train Loss 0.543235, Valid_loss 1.116716
Epoch 12, Train Loss 0.511168, Valid_loss 1.127885
Epoch 13, Train Loss 0.450200, Valid_loss 1.007282
Epoch 14, Train Loss 0.518409, Valid_loss 1.148972
Epoch 15, Train Loss 0.468855, Valid_loss 1.325966
Epoch 16, Train Loss 0.475984, Valid_loss 1.296969
Epoch 17, Train Loss 0.478631, Valid_loss 1.134425
Epoch 18, Train Loss 0.459668, Valid_loss 1.275432
Epoch 19, Train Loss 0.440444, Valid_loss 1.045519
Epoch 20, Train Loss 0.480399, Valid_loss 1.622343
Epoch 21, Train Loss 0.384673, Valid_loss 1.021991
Epoch 22, Train Loss 0.502793, Valid_loss 1.291589
Epoch 23, Train Loss 0.341977, Valid_loss 1.417928
Epoch 24, Train Loss 0.424718, Valid_loss 1.185809
Epoch 25, Train Loss 0.400747, Valid_loss 1.158036
Epoch 26, Train Loss 0.397753, Valid_loss 0.884579
Epoch 27, Train Loss 0.686701, Valid_loss 0.946882
Epoch 28, Train Loss 0.353116, Valid_loss 1.167972
Epoch 29, Train Loss 0.374486, Valid_loss 0.979579
Epoch 30, Train Loss 0.407012, Valid_loss 1.030077
Epoch 31, Train Loss 0.381329, Valid_loss 1.325282
Epoch 32, Train Loss 0.363340, Valid_loss 1.345274
Epoch 33, Train Loss 0.362623, Valid_loss 1.182656
Epoch 34, Train Loss 0.334918, Valid_loss 1.454550
Epoch 35, Train Loss 0.365624, Valid_loss 1.469905
Epoch 36, Train Loss 0.349704, Valid_loss 1.362260
Epoch 37, Train Loss 0.400140, Valid_loss 1.232836
Epoch 38, Train Loss 0.339938, Valid_loss 1.352027
Epoch 39, Train Loss 0.282008, Valid_loss 0.889429
Epoch 40, Train Loss 0.318165, Valid_loss 1.021508
Epoch 41, Train Loss 0.276749, Valid_loss 1.912144
Epoch 42, Train Loss 0.357939, Valid_loss 1.322888
Epoch 43, Train Loss 0.255987, Valid_loss 1.154666
Epoch 44, Train Loss 0.270285, Valid_loss 0.888662
Epoch 45, Train Loss 0.366116, Valid_loss 1.375336
Epoch 46, Train Loss 0.366121, Valid_loss 1.113788
Epoch 47, Train Loss 0.269832, Valid_loss 1.524611
Epoch 48, Train Loss 0.276735, Valid_loss 1.835192
Epoch 49, Train Loss 0.370179, Valid_loss 1.071421
Epoch 50, Train Loss 0.281502, Valid_loss 0.684467
Epoch 51, Train Loss 0.294433, Valid_loss 1.414035
Epoch 52, Train Loss 0.246280, Valid_loss 1.258293
Epoch 53, Train Loss 0.209569, Valid_loss 1.379461
Epoch 54, Train Loss 0.235880, Valid_loss 1.351252
Epoch 55, Train Loss 0.235806, Valid_loss 1.473559
Epoch 56, Train Loss 0.220846, Valid_loss 1.312713
Epoch 57, Train Loss 0.201273, Valid_loss 1.401300
Epoch 58, Train Loss 0.206314, Valid_loss 1.382360
Epoch 59, Train Loss 0.177008, Valid_loss 1.520820
Epoch 60, Train Loss 0.212956, Valid_loss 1.494771
Epoch 61, Train Loss 0.194374, Valid_loss 1.902034
Epoch 62, Train Loss 0.194377, Valid_loss 1.871806
Epoch 63, Train Loss 0.208449, Valid_loss 1.791436
Epoch 64, Train Loss 0.242215, Valid_loss 1.314857
Epoch 65, Train Loss 0.201605, Valid_loss 1.166352
Epoch 66, Train Loss 0.193635, Valid_loss 1.399259
Epoch 67, Train Loss 0.159618, Valid_loss 1.408315
[I 2025-08-28 06:36:37,236] Trial 1 finished with value: 0.6844667179340665 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 0.6844667179340665.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16934.53 MB
Memory Reserved: 16952.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 341.79 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.90 MB
Memory Reserved: 16960.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 342.12 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 06:36:38,916] Trial 2 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16930.11 MB
Memory Reserved: 16960.00 MB
cuda
Epoch 1, Train Loss 0.927234, Valid_loss 1.532707
Epoch 2, Train Loss 0.852477, Valid_loss 1.440364
Epoch 3, Train Loss 0.728825, Valid_loss 1.227939
Epoch 4, Train Loss 0.681523, Valid_loss 1.409236
Epoch 5, Train Loss 0.687879, Valid_loss 1.279948
Epoch 6, Train Loss 0.641646, Valid_loss 1.440153
Epoch 7, Train Loss 0.527668, Valid_loss 1.283188
Epoch 8, Train Loss 0.515522, Valid_loss 1.291887
Epoch 9, Train Loss 0.502774, Valid_loss 1.839967
Epoch 10, Train Loss 0.516407, Valid_loss 1.250823
Epoch 11, Train Loss 0.463022, Valid_loss 1.381598
Epoch 12, Train Loss 0.456907, Valid_loss 1.160073
Epoch 13, Train Loss 0.460876, Valid_loss 1.383961
Epoch 14, Train Loss 0.420735, Valid_loss 1.492808
Epoch 15, Train Loss 0.403951, Valid_loss 1.107352
Epoch 16, Train Loss 0.409740, Valid_loss 1.128476
Epoch 17, Train Loss 0.326791, Valid_loss 0.979637
Epoch 18, Train Loss 0.426108, Valid_loss 2.046782
Epoch 19, Train Loss 0.376897, Valid_loss 1.275641
Epoch 20, Train Loss 0.346698, Valid_loss 1.402300
Epoch 21, Train Loss 0.377515, Valid_loss 2.219502
Epoch 22, Train Loss 0.382723, Valid_loss 1.158460
Epoch 23, Train Loss 0.473672, Valid_loss 1.390469
Epoch 24, Train Loss 0.316367, Valid_loss 1.344527
Epoch 25, Train Loss 0.329019, Valid_loss 1.279316
Epoch 26, Train Loss 0.289452, Valid_loss 1.567941
Epoch 27, Train Loss 0.373057, Valid_loss 1.546610
Epoch 28, Train Loss 0.306978, Valid_loss 1.206461
Epoch 29, Train Loss 0.313169, Valid_loss 1.132283
Epoch 30, Train Loss 0.361289, Valid_loss 1.705171
Epoch 31, Train Loss 0.288181, Valid_loss 1.027955
Epoch 32, Train Loss 0.295021, Valid_loss 1.334138
Epoch 33, Train Loss 0.417604, Valid_loss 1.004505
Epoch 34, Train Loss 0.409208, Valid_loss 1.243353
Epoch 35, Train Loss 0.270919, Valid_loss 1.361317
Epoch 36, Train Loss 0.302675, Valid_loss 1.063165
Epoch 37, Train Loss 0.353059, Valid_loss 1.012484
Epoch 38, Train Loss 0.288717, Valid_loss 1.131935
Epoch 39, Train Loss 0.304244, Valid_loss 1.402786
Epoch 40, Train Loss 0.288702, Valid_loss 1.373719
Epoch 41, Train Loss 0.255422, Valid_loss 0.997342
Epoch 42, Train Loss 0.276339, Valid_loss 1.851710
Epoch 43, Train Loss 0.307865, Valid_loss 1.087586
Epoch 44, Train Loss 0.246315, Valid_loss 1.061097
Epoch 45, Train Loss 0.302198, Valid_loss 0.989658
Epoch 46, Train Loss 0.267619, Valid_loss 1.156174
Epoch 47, Train Loss 0.253396, Valid_loss 0.992159
Epoch 48, Train Loss 0.250757, Valid_loss 1.141752
Epoch 49, Train Loss 0.312555, Valid_loss 1.340532
Epoch 50, Train Loss 0.252880, Valid_loss 1.554718
Epoch 51, Train Loss 0.208054, Valid_loss 0.979949
Epoch 52, Train Loss 0.181264, Valid_loss 1.277686
Epoch 53, Train Loss 0.174012, Valid_loss 1.021021
Epoch 54, Train Loss 0.201642, Valid_loss 1.099590
Epoch 55, Train Loss 0.207901, Valid_loss 1.248779
[I 2025-08-28 07:05:17,336] Trial 3 finished with value: 0.9796365936371413 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.0, 'weight_decay': 0.01, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 0.6844667179340665.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16903.99 MB
Memory Reserved: 16924.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 312.97 MB
Memory Reserved: 352.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16903.99 MB
Memory Reserved: 16924.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 312.55 MB
Memory Reserved: 352.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 07:05:19,042] Trial 4 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16903.99 MB
Memory Reserved: 16944.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 4460.55 MB
Memory Reserved: 4500.00 MB
cuda
Epoch 1, Train Loss 1.144301, Valid_loss 1.163153
Epoch 2, Train Loss 0.932264, Valid_loss 1.116286
Epoch 3, Train Loss 0.853333, Valid_loss 1.110149
Epoch 4, Train Loss 0.664526, Valid_loss 1.080392
Epoch 5, Train Loss 0.659434, Valid_loss 1.024415
Epoch 6, Train Loss 0.623152, Valid_loss 1.026687
Epoch 7, Train Loss 0.556342, Valid_loss 1.005468
Epoch 8, Train Loss 0.608873, Valid_loss 0.995163
Epoch 9, Train Loss 0.562252, Valid_loss 1.005062
Epoch 10, Train Loss 0.540694, Valid_loss 0.962355
Epoch 11, Train Loss 0.552593, Valid_loss 1.020313
Epoch 12, Train Loss 0.510627, Valid_loss 0.960181
Epoch 13, Train Loss 0.548808, Valid_loss 0.955732
Epoch 14, Train Loss 0.542742, Valid_loss 0.961677
Epoch 15, Train Loss 0.476252, Valid_loss 0.971630
Epoch 16, Train Loss 0.468003, Valid_loss 0.983591
Epoch 17, Train Loss 0.408475, Valid_loss 0.998155
Epoch 18, Train Loss 0.562335, Valid_loss 1.045852
Epoch 19, Train Loss 0.480470, Valid_loss 1.077925
Epoch 20, Train Loss 0.498714, Valid_loss 0.983580
Epoch 21, Train Loss 0.432592, Valid_loss 0.996312
Epoch 22, Train Loss 0.488605, Valid_loss 1.068825
Epoch 23, Train Loss 0.455762, Valid_loss 1.007896
Epoch 24, Train Loss 0.421267, Valid_loss 1.252525
Epoch 25, Train Loss 0.463417, Valid_loss 1.114256
Epoch 26, Train Loss 0.353093, Valid_loss 1.068797
Epoch 27, Train Loss 0.366482, Valid_loss 1.035172
Epoch 28, Train Loss 0.418757, Valid_loss 1.064714
Epoch 29, Train Loss 0.398833, Valid_loss 0.944304
Epoch 30, Train Loss 0.382515, Valid_loss 1.342974
Epoch 31, Train Loss 0.348644, Valid_loss 1.039169
Epoch 32, Train Loss 0.338519, Valid_loss 1.314236
Epoch 33, Train Loss 0.394241, Valid_loss 1.063542
Epoch 34, Train Loss 0.405571, Valid_loss 0.952074
Epoch 35, Train Loss 0.343425, Valid_loss 1.048663
Epoch 36, Train Loss 0.336356, Valid_loss 1.027731
Epoch 37, Train Loss 0.406607, Valid_loss 1.055539
Epoch 38, Train Loss 0.339596, Valid_loss 1.216301
Epoch 39, Train Loss 0.365672, Valid_loss 1.080288
Epoch 40, Train Loss 0.361507, Valid_loss 1.264508
Epoch 41, Train Loss 0.372304, Valid_loss 1.272848
Epoch 42, Train Loss 0.305585, Valid_loss 1.124168
Epoch 43, Train Loss 0.354412, Valid_loss 1.010458
Epoch 44, Train Loss 0.292086, Valid_loss 1.075885
Epoch 45, Train Loss 0.399744, Valid_loss 0.980333
Epoch 46, Train Loss 0.267110, Valid_loss 1.209270
Epoch 47, Train Loss 0.265343, Valid_loss 1.234522
Epoch 48, Train Loss 0.281590, Valid_loss 1.126618
Epoch 49, Train Loss 0.384284, Valid_loss 1.076223
Epoch 50, Train Loss 0.279888, Valid_loss 1.004247
Epoch 51, Train Loss 0.312491, Valid_loss 1.139119
Epoch 52, Train Loss 0.251288, Valid_loss 1.234959
[I 2025-08-28 07:25:31,279] Trial 5 finished with value: 0.9443041302941062 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.01, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 0.6844667179340665.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=9, batch_size=1 -> steps=9
Memory Allocated: 4460.55 MB
Memory Reserved: 4500.00 MB
cuda
Epoch 1, Train Loss 0.951669, Valid_loss 1.423064
Epoch 2, Train Loss 0.862250, Valid_loss 1.452263
Epoch 3, Train Loss 0.733193, Valid_loss 1.289792
Epoch 4, Train Loss 0.691437, Valid_loss 1.237589
Epoch 5, Train Loss 0.654499, Valid_loss 1.267012
Epoch 6, Train Loss 0.674622, Valid_loss 1.170956
Epoch 7, Train Loss 0.600974, Valid_loss 0.938972
Epoch 8, Train Loss 0.609288, Valid_loss 1.179481
Epoch 9, Train Loss 0.528437, Valid_loss 1.132096
Epoch 10, Train Loss 0.553599, Valid_loss 1.122202
Epoch 11, Train Loss 0.479626, Valid_loss 1.170800
Epoch 12, Train Loss 0.486180, Valid_loss 1.023944
Epoch 13, Train Loss 0.499590, Valid_loss 1.261494
Epoch 14, Train Loss 0.494492, Valid_loss 1.100290
Epoch 15, Train Loss 0.460507, Valid_loss 1.120500
Epoch 16, Train Loss 0.436512, Valid_loss 0.998821
Epoch 17, Train Loss 0.508366, Valid_loss 1.170947
Epoch 18, Train Loss 0.511099, Valid_loss 1.450877
Epoch 19, Train Loss 0.474634, Valid_loss 1.218120
Epoch 20, Train Loss 0.418725, Valid_loss 1.174230
Epoch 21, Train Loss 0.398986, Valid_loss 1.013901
Epoch 22, Train Loss 0.337540, Valid_loss 1.154462
Epoch 23, Train Loss 0.371371, Valid_loss 1.316867
Epoch 24, Train Loss 0.335902, Valid_loss 1.241129
Epoch 25, Train Loss 0.428440, Valid_loss 1.084932
Epoch 26, Train Loss 0.317287, Valid_loss 1.046010
Epoch 27, Train Loss 0.331059, Valid_loss 1.024098
Epoch 28, Train Loss 0.273035, Valid_loss 1.483231
Epoch 29, Train Loss 0.319929, Valid_loss 1.206717
Epoch 30, Train Loss 0.334259, Valid_loss 1.048282
Epoch 31, Train Loss 0.301233, Valid_loss 0.852948
Epoch 32, Train Loss 0.338388, Valid_loss 1.215954
Epoch 33, Train Loss 0.301653, Valid_loss 1.263748
Epoch 34, Train Loss 0.374969, Valid_loss 1.276293
Epoch 35, Train Loss 0.278880, Valid_loss 1.402810
Epoch 36, Train Loss 0.229112, Valid_loss 1.109323
Epoch 37, Train Loss 0.408348, Valid_loss 1.014588
Epoch 38, Train Loss 0.403747, Valid_loss 1.040788
Epoch 39, Train Loss 0.284808, Valid_loss 1.441716
Epoch 40, Train Loss 0.239904, Valid_loss 1.254914
Epoch 41, Train Loss 0.256388, Valid_loss 1.146960
Epoch 42, Train Loss 0.270141, Valid_loss 1.335569
Epoch 43, Train Loss 0.293095, Valid_loss 1.254454
Epoch 44, Train Loss 0.284504, Valid_loss 0.912010
Epoch 45, Train Loss 0.363773, Valid_loss 0.980413
Epoch 46, Train Loss 0.281835, Valid_loss 1.162545
Epoch 47, Train Loss 0.248863, Valid_loss 1.136784
Epoch 48, Train Loss 0.220066, Valid_loss 1.274171
Epoch 49, Train Loss 0.218189, Valid_loss 1.364565
Epoch 50, Train Loss 0.267814, Valid_loss 1.632433
Epoch 51, Train Loss 0.241694, Valid_loss 1.372961
Epoch 52, Train Loss 0.230528, Valid_loss 1.121054
Epoch 53, Train Loss 0.204093, Valid_loss 1.233271
Epoch 54, Train Loss 0.171964, Valid_loss 1.220006
Epoch 55, Train Loss 0.177690, Valid_loss 1.131215
Epoch 56, Train Loss 0.195653, Valid_loss 1.012098
Epoch 57, Train Loss 0.204381, Valid_loss 1.286003
Epoch 58, Train Loss 0.187046, Valid_loss 1.206713
Epoch 59, Train Loss 0.188943, Valid_loss 1.286703
Epoch 60, Train Loss 0.172711, Valid_loss 1.077075
Epoch 61, Train Loss 0.183584, Valid_loss 1.076915
Epoch 62, Train Loss 0.179032, Valid_loss 1.266272
Epoch 63, Train Loss 0.205183, Valid_loss 1.306249
환자ID=P1358 -- true: [[2]] -- pred: tensor([[-1.9032,  0.6092, -0.5854]], device='cuda:0')
환자ID=P1425 -- true: [[1]] -- pred: tensor([[-1.9371,  0.4487, -0.3556]], device='cuda:0')
환자ID=P1479 -- true: [[1]] -- pred: tensor([[-1.5597,  0.7266, -0.8601]], device='cuda:0')
환자ID=P1510 -- true: [[1]] -- pred: tensor([[-1.6843,  0.7875, -0.7980]], device='cuda:0')
환자ID=P1515 -- true: [[0]] -- pred: tensor([[ 2.1969, -0.4643, -1.8081]], device='cuda:0')
환자ID=P1610 -- true: [[0]] -- pred: tensor([[ 1.9922, -0.3602, -1.8385]], device='cuda:0')
환자ID=P1617 -- true: [[2]] -- pred: tensor([[-1.9304,  0.5262, -0.4722]], device='cuda:0')
환자ID=P1702 -- true: [[0]] -- pred: tensor([[ 2.1530, -0.4585, -1.7918]], device='cuda:0')
환자ID=P1718 -- true: [[0]] -- pred: tensor([[ 2.0345, -0.3789, -1.8265]], device='cuda:0')
Best performance: Epoch 31, Loss 0.301233, Test ACC 0.777778, Test AUC 0.888889, Test Recall 0.666667, Test Precision 0.533333
Confusion Matrix:
 [[4 0 0]
 [0 3 0]
 [0 2 0]]
✅ Total valid splits used: 1
🔁 Repeat 3, Fold 1
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 484018, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 484018, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 8, 1: 12, 0: 13}
cell type :  ACAGCCGCAAGCGAGT-1-1              cardiac muscle cell
ATATCCTGTCCCTAAA-1-1              cardiac muscle cell
CAATGACCAGTTGTCA-1-1              cardiac muscle cell
CTAGACACAAGGTTGG-1-1              cardiac muscle cell
ATCGTCCGTATTTCTC-1-1              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 108671, dtype: string
cell type annotation :  ACAGCCGCAAGCGAGT-1-1              cardiac muscle cell
ATATCCTGTCCCTAAA-1-1              cardiac muscle cell
CAATGACCAGTTGTCA-1-1              cardiac muscle cell
CTAGACACAAGGTTGG-1-1              cardiac muscle cell
ATCGTCCGTATTTCTC-1-1              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 108671, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'mesothelial cell', 'macrophage', 'fat cell', 'endocardial cell', 'cardiac neuron', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'lymphocyte', 'mast cell']
라벨별 그룹 개수 {2: 3, 1: 3, 0: 3}
🔍 Split #2
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 33
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 9
  → train 환자 ID: ['P1304', 'P1358', 'P1371', 'P1425', 'P1430', 'P1437', 'P1447', 'P1462', 'P1472', 'P1479', 'P1504', 'P1508', 'P1510', 'P1515', 'P1539', 'P1549', 'P1558', 'P1561', 'P1582', 'P1600', 'P1602', 'P1603', 'P1610', 'P1617', 'P1622', 'P1630', 'P1631', 'P1678', 'P1685', 'P1702', 'P1718', 'P1722', 'P1735']
  → test  환자 ID: ['P1290', 'P1300', 'P1422', 'P1516', 'P1540', 'P1547', 'P1606', 'P1707', 'P1726']
  → train 환자 ID 및 라벨:
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1539, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1422, Label: 1
    ID: P1516, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1606, Label: 2
    ID: P1707, Label: 1
    ID: P1726, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 33
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 33
기존 (train) label_stat 33
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 11
test_p_index 9
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1549, Label=0, 셀개수=11709
→ valid 환자 ID 및 라벨:
   총 개수: 11
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1622, Label=0, 셀개수=7210
→ test 환자 ID 및 라벨:
   총 개수: 9
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1726, Label=1, 셀개수=12389
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685        cardiac endothelial cell
592686    cardiac ventricle fibroblast
592687                   pericyte cell
592688        cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:12,  8.14it/s]  2%|▏         | 2/100 [00:00<00:11,  8.19it/s]  3%|▎         | 3/100 [00:00<00:11,  8.15it/s]  4%|▍         | 4/100 [00:00<00:11,  8.16it/s]  5%|▌         | 5/100 [00:00<00:11,  8.21it/s]  6%|▌         | 6/100 [00:00<00:11,  8.24it/s]  7%|▋         | 7/100 [00:00<00:11,  8.30it/s]  8%|▊         | 8/100 [00:00<00:11,  8.28it/s]  9%|▉         | 9/100 [00:01<00:10,  8.47it/s] 10%|█         | 10/100 [00:01<00:10,  8.50it/s] 11%|█         | 11/100 [00:01<00:10,  8.47it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.54it/s] 13%|█▎        | 13/100 [00:01<00:10,  8.56it/s] 14%|█▍        | 14/100 [00:01<00:09,  8.60it/s] 15%|█▌        | 15/100 [00:01<00:10,  8.48it/s] 16%|█▌        | 16/100 [00:01<00:09,  8.42it/s] 17%|█▋        | 17/100 [00:02<00:09,  8.43it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.24it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.32it/s] 20%|██        | 20/100 [00:02<00:09,  8.44it/s] 21%|██        | 21/100 [00:02<00:09,  8.37it/s] 22%|██▏       | 22/100 [00:02<00:09,  8.28it/s] 23%|██▎       | 23/100 [00:02<00:09,  8.45it/s] 24%|██▍       | 24/100 [00:02<00:08,  8.47it/s] 25%|██▌       | 25/100 [00:02<00:08,  8.37it/s] 26%|██▌       | 26/100 [00:03<00:08,  8.28it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.25it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.19it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.11it/s] 30%|███       | 30/100 [00:03<00:08,  8.16it/s] 31%|███       | 31/100 [00:03<00:08,  8.14it/s] 32%|███▏      | 32/100 [00:03<00:08,  8.11it/s] 33%|███▎      | 33/100 [00:03<00:08,  8.16it/s] 34%|███▍      | 34/100 [00:04<00:08,  8.10it/s] 35%|███▌      | 35/100 [00:04<00:07,  8.16it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.13it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.24it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.18it/s] 39%|███▉      | 39/100 [00:04<00:07,  8.19it/s] 40%|████      | 40/100 [00:04<00:07,  8.24it/s] 41%|████      | 41/100 [00:04<00:07,  8.07it/s] 42%|████▏     | 42/100 [00:05<00:07,  8.10it/s] 43%|████▎     | 43/100 [00:05<00:07,  8.12it/s] 44%|████▍     | 44/100 [00:05<00:06,  8.27it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.37it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.40it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.40it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.28it/s] 49%|████▉     | 49/100 [00:05<00:06,  8.20it/s] 50%|█████     | 50/100 [00:06<00:06,  8.20it/s] 51%|█████     | 51/100 [00:06<00:06,  8.11it/s] 52%|█████▏    | 52/100 [00:06<00:05,  8.19it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.04it/s] 54%|█████▍    | 54/100 [00:06<00:05,  7.96it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.08it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.10it/s] 57%|█████▋    | 57/100 [00:06<00:05,  8.11it/s] 58%|█████▊    | 58/100 [00:07<00:05,  8.21it/s] 59%|█████▉    | 59/100 [00:07<00:04,  8.36it/s] 60%|██████    | 60/100 [00:07<00:04,  8.21it/s] 61%|██████    | 61/100 [00:07<00:04,  8.17it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.07it/s] 63%|██████▎   | 63/100 [00:08<00:11,  3.14it/s] 64%|██████▍   | 64/100 [00:08<00:09,  3.84it/s] 65%|██████▌   | 65/100 [00:08<00:07,  4.58it/s] 66%|██████▌   | 66/100 [00:08<00:06,  5.27it/s] 67%|██████▋   | 67/100 [00:08<00:06,  5.14it/s] 68%|██████▊   | 68/100 [00:09<00:05,  5.55it/s] 69%|██████▉   | 69/100 [00:09<00:05,  6.03it/s] 70%|███████   | 70/100 [00:10<00:17,  1.68it/s] 71%|███████   | 71/100 [00:10<00:13,  2.19it/s] 72%|███████▏  | 72/100 [00:11<00:10,  2.77it/s] 73%|███████▎  | 73/100 [00:11<00:07,  3.40it/s] 74%|███████▍  | 74/100 [00:11<00:06,  4.02it/s] 75%|███████▌  | 75/100 [00:11<00:05,  4.70it/s] 76%|███████▌  | 76/100 [00:11<00:04,  5.32it/s] 77%|███████▋  | 77/100 [00:11<00:03,  6.00it/s] 78%|███████▊  | 78/100 [00:12<00:05,  4.23it/s] 79%|███████▉  | 79/100 [00:12<00:04,  4.91it/s] 80%|████████  | 80/100 [00:12<00:03,  5.31it/s] 81%|████████  | 81/100 [00:12<00:03,  5.87it/s] 82%|████████▏ | 82/100 [00:12<00:02,  6.35it/s] 83%|████████▎ | 83/100 [00:12<00:02,  6.61it/s] 84%|████████▍ | 84/100 [00:12<00:02,  6.89it/s] 85%|████████▌ | 85/100 [00:13<00:02,  7.07it/s] 86%|████████▌ | 86/100 [00:13<00:01,  7.20it/s] 87%|████████▋ | 87/100 [00:13<00:01,  7.31it/s] 88%|████████▊ | 88/100 [00:13<00:01,  7.41it/s] 89%|████████▉ | 89/100 [00:13<00:01,  7.48it/s] 90%|█████████ | 90/100 [00:13<00:01,  7.61it/s] 91%|█████████ | 91/100 [00:13<00:01,  7.66it/s] 92%|█████████▏| 92/100 [00:13<00:01,  7.57it/s] 93%|█████████▎| 93/100 [00:14<00:00,  7.72it/s] 94%|█████████▍| 94/100 [00:14<00:00,  6.72it/s] 95%|█████████▌| 95/100 [00:14<00:00,  6.99it/s] 96%|█████████▌| 96/100 [00:14<00:00,  7.23it/s] 97%|█████████▋| 97/100 [00:14<00:00,  7.33it/s] 98%|█████████▊| 98/100 [00:14<00:00,  7.39it/s] 99%|█████████▉| 99/100 [00:14<00:00,  7.40it/s]100%|██████████| 100/100 [00:15<00:00,  7.57it/s]100%|██████████| 100/100 [00:15<00:00,  6.66it/s]
[I 2025-08-28 07:51:09,857] A new study created in memory with name: no-name-d294e8a3-280e-45a4-9510-7ddaa13a6912
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.033963, Valid_loss 1.021094
Epoch 2, Train Loss 1.052499, Valid_loss 0.998062
Epoch 3, Train Loss 0.912259, Valid_loss 0.854385
Epoch 4, Train Loss 0.857307, Valid_loss 0.782186
Epoch 5, Train Loss 0.820709, Valid_loss 0.740093
Epoch 6, Train Loss 0.796087, Valid_loss 0.725595
Epoch 7, Train Loss 0.792690, Valid_loss 0.708955
Epoch 8, Train Loss 0.755989, Valid_loss 0.671840
Epoch 9, Train Loss 0.602819, Valid_loss 0.640549
Epoch 10, Train Loss 0.685021, Valid_loss 0.711723
Epoch 11, Train Loss 0.648597, Valid_loss 0.636080
Epoch 12, Train Loss 0.627088, Valid_loss 0.573737
Epoch 13, Train Loss 0.635995, Valid_loss 0.574640
Epoch 14, Train Loss 0.663387, Valid_loss 0.592141
Epoch 15, Train Loss 0.628096, Valid_loss 0.563480
Epoch 16, Train Loss 0.627052, Valid_loss 0.550568
Epoch 17, Train Loss 0.615725, Valid_loss 0.636709
Epoch 18, Train Loss 0.527113, Valid_loss 0.521754
Epoch 19, Train Loss 0.571635, Valid_loss 0.577399
Epoch 20, Train Loss 0.625715, Valid_loss 0.537695
Epoch 21, Train Loss 0.568246, Valid_loss 0.508168
Epoch 22, Train Loss 0.524322, Valid_loss 0.514731
Epoch 23, Train Loss 0.532187, Valid_loss 0.488574
Epoch 24, Train Loss 0.488382, Valid_loss 0.541420
Epoch 25, Train Loss 0.539783, Valid_loss 0.515624
Epoch 26, Train Loss 0.531299, Valid_loss 0.488256
Epoch 27, Train Loss 0.537005, Valid_loss 0.512290
Epoch 28, Train Loss 0.565720, Valid_loss 0.592689
Epoch 29, Train Loss 0.499901, Valid_loss 0.490749
Epoch 30, Train Loss 0.471307, Valid_loss 0.465429
Epoch 31, Train Loss 0.511815, Valid_loss 0.560257
Epoch 32, Train Loss 0.537754, Valid_loss 0.564580
Epoch 33, Train Loss 0.478937, Valid_loss 0.457581
Epoch 34, Train Loss 0.513217, Valid_loss 0.521593
Epoch 35, Train Loss 0.504007, Valid_loss 0.445648
Epoch 36, Train Loss 0.484099, Valid_loss 0.477963
Epoch 37, Train Loss 0.480004, Valid_loss 0.421981
Epoch 38, Train Loss 0.391128, Valid_loss 0.477284
Epoch 39, Train Loss 0.366066, Valid_loss 0.411159
Epoch 40, Train Loss 0.439212, Valid_loss 0.427684
Epoch 41, Train Loss 0.420593, Valid_loss 0.424720
Epoch 42, Train Loss 0.366022, Valid_loss 0.413934
Epoch 43, Train Loss 0.358770, Valid_loss 0.479482
Epoch 44, Train Loss 0.367257, Valid_loss 0.500594
Epoch 45, Train Loss 0.530148, Valid_loss 0.480223
Epoch 46, Train Loss 0.354025, Valid_loss 0.414951
Epoch 47, Train Loss 0.374380, Valid_loss 0.426536
Epoch 48, Train Loss 0.386233, Valid_loss 0.387677
Epoch 49, Train Loss 0.320512, Valid_loss 0.461554
Epoch 50, Train Loss 0.463460, Valid_loss 0.405870
Epoch 51, Train Loss 0.348614, Valid_loss 0.454831
Epoch 52, Train Loss 0.389026, Valid_loss 0.395243
Epoch 53, Train Loss 0.279815, Valid_loss 0.465152
Epoch 54, Train Loss 0.313859, Valid_loss 0.573982
[I 2025-08-28 08:10:55,728] Trial 0 finished with value: 0.3876771798188036 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.7, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.3876771798188036.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.179743, Valid_loss 1.063375
Epoch 2, Train Loss 1.092289, Valid_loss 1.057406
Epoch 3, Train Loss 0.991543, Valid_loss 1.140804
Epoch 4, Train Loss 0.990480, Valid_loss 1.098633
Epoch 5, Train Loss 1.021482, Valid_loss 1.073078
Epoch 6, Train Loss 0.976414, Valid_loss 1.069203
Epoch 7, Train Loss 0.933225, Valid_loss 1.088392
Epoch 8, Train Loss 0.958500, Valid_loss 1.073209
Epoch 9, Train Loss 0.954424, Valid_loss 1.078007
Epoch 10, Train Loss 0.955437, Valid_loss 1.103634
Epoch 11, Train Loss 0.977774, Valid_loss 1.075678
Epoch 12, Train Loss 0.954120, Valid_loss 1.090151
Epoch 13, Train Loss 0.948381, Valid_loss 1.081926
Epoch 14, Train Loss 0.918672, Valid_loss 1.115640
Epoch 15, Train Loss 0.949312, Valid_loss 1.107700
Epoch 16, Train Loss 0.947807, Valid_loss 1.074528
Epoch 17, Train Loss 0.953080, Valid_loss 1.082644
Epoch 18, Train Loss 0.941572, Valid_loss 1.084510
Epoch 19, Train Loss 0.938401, Valid_loss 1.081315
Epoch 20, Train Loss 0.943883, Valid_loss 1.087316
Epoch 21, Train Loss 0.952531, Valid_loss 1.084085
Epoch 22, Train Loss 0.941384, Valid_loss 1.085095
Epoch 23, Train Loss 0.940518, Valid_loss 1.092455
Epoch 24, Train Loss 0.941018, Valid_loss 1.092860
Epoch 25, Train Loss 0.940831, Valid_loss 1.099354
Epoch 26, Train Loss 0.949901, Valid_loss 1.087755
Epoch 27, Train Loss 0.943791, Valid_loss 1.094907
Epoch 28, Train Loss 0.940306, Valid_loss 1.100023
Epoch 29, Train Loss 0.945215, Valid_loss 1.096758
Epoch 30, Train Loss 0.959829, Valid_loss 1.107336
Epoch 31, Train Loss 0.944952, Valid_loss 1.101921
Epoch 32, Train Loss 0.943571, Valid_loss 1.097639
Epoch 33, Train Loss 0.941703, Valid_loss 1.092608
Epoch 34, Train Loss 0.942245, Valid_loss 1.089760
Epoch 35, Train Loss 0.942161, Valid_loss 1.095258
Epoch 36, Train Loss 0.943927, Valid_loss 1.095992
Epoch 37, Train Loss 0.944803, Valid_loss 1.094359
Epoch 38, Train Loss 0.941540, Valid_loss 1.095597
Epoch 39, Train Loss 0.940986, Valid_loss 1.094219
Epoch 40, Train Loss 0.938895, Valid_loss 1.095701
Epoch 41, Train Loss 0.967650, Valid_loss 1.092932
Epoch 42, Train Loss 0.941963, Valid_loss 1.097333
Epoch 43, Train Loss 0.940926, Valid_loss 1.091304
Epoch 44, Train Loss 0.948637, Valid_loss 1.093372
Epoch 45, Train Loss 0.942242, Valid_loss 1.094809
Epoch 46, Train Loss 0.940291, Valid_loss 1.091046
Epoch 47, Train Loss 0.941303, Valid_loss 1.093169
Epoch 48, Train Loss 0.942678, Valid_loss 1.094842
Epoch 49, Train Loss 0.943671, Valid_loss 1.098128
Epoch 50, Train Loss 0.942112, Valid_loss 1.093297
Epoch 51, Train Loss 0.939171, Valid_loss 1.095061
Epoch 52, Train Loss 0.940294, Valid_loss 1.096125
[I 2025-08-28 08:31:15,827] Trial 1 finished with value: 1.0574061653830789 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.7, 'weight_decay': 0.0001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.3876771798188036.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.125654, Valid_loss 1.167771
Epoch 2, Train Loss 1.018593, Valid_loss 1.054483
Epoch 3, Train Loss 0.985190, Valid_loss 1.145774
Epoch 4, Train Loss 0.982418, Valid_loss 1.125353
Epoch 5, Train Loss 1.002452, Valid_loss 1.056558
Epoch 6, Train Loss 0.961420, Valid_loss 1.056024
Epoch 7, Train Loss 0.980841, Valid_loss 1.065395
Epoch 8, Train Loss 0.974872, Valid_loss 1.045848
Epoch 9, Train Loss 0.973206, Valid_loss 1.067066
Epoch 10, Train Loss 0.945766, Valid_loss 1.086384
Epoch 11, Train Loss 0.949212, Valid_loss 1.073607
Epoch 12, Train Loss 0.965584, Valid_loss 1.066235
Epoch 13, Train Loss 0.958963, Valid_loss 1.118570
Epoch 14, Train Loss 0.954127, Valid_loss 1.102702
Epoch 15, Train Loss 0.946136, Valid_loss 1.070202
Epoch 16, Train Loss 0.946038, Valid_loss 1.086676
Epoch 17, Train Loss 0.949464, Valid_loss 1.067964
Epoch 18, Train Loss 0.949602, Valid_loss 1.078849
Epoch 19, Train Loss 0.939268, Valid_loss 1.093356
Epoch 20, Train Loss 0.948420, Valid_loss 1.088494
Epoch 21, Train Loss 0.940914, Valid_loss 1.092256
Epoch 22, Train Loss 0.948914, Valid_loss 1.086834
Epoch 23, Train Loss 0.943294, Valid_loss 1.080562
Epoch 24, Train Loss 0.944695, Valid_loss 1.082139
Epoch 25, Train Loss 0.940722, Valid_loss 1.095525
Epoch 26, Train Loss 0.951826, Valid_loss 1.105312
Epoch 27, Train Loss 0.945230, Valid_loss 1.089339
Epoch 28, Train Loss 0.943826, Valid_loss 1.094573
Epoch 29, Train Loss 0.942667, Valid_loss 1.082957
Epoch 30, Train Loss 0.943014, Valid_loss 1.104392
Epoch 31, Train Loss 0.942926, Valid_loss 1.089802
Epoch 32, Train Loss 0.943486, Valid_loss 1.102470
Epoch 33, Train Loss 0.945357, Valid_loss 1.108914
Epoch 34, Train Loss 0.941320, Valid_loss 1.102246
Epoch 35, Train Loss 0.943119, Valid_loss 1.097663
Epoch 36, Train Loss 0.943075, Valid_loss 1.146496
Epoch 37, Train Loss 0.952751, Valid_loss 1.080352
Epoch 38, Train Loss 0.951266, Valid_loss 1.078682
Epoch 39, Train Loss 0.963029, Valid_loss 1.083763
Epoch 40, Train Loss 0.941371, Valid_loss 1.090568
Epoch 41, Train Loss 0.942858, Valid_loss 1.092900
Epoch 42, Train Loss 0.940659, Valid_loss 1.094823
Epoch 43, Train Loss 0.940320, Valid_loss 1.098944
Epoch 44, Train Loss 0.943194, Valid_loss 1.097586
Epoch 45, Train Loss 0.943700, Valid_loss 1.092310
Epoch 46, Train Loss 0.943874, Valid_loss 1.090544
Epoch 47, Train Loss 0.941073, Valid_loss 1.095346
Epoch 48, Train Loss 0.942592, Valid_loss 1.086419
Epoch 49, Train Loss 0.939999, Valid_loss 1.092118
Epoch 50, Train Loss 0.942705, Valid_loss 1.089627
Epoch 51, Train Loss 0.944359, Valid_loss 1.148542
Epoch 52, Train Loss 0.943376, Valid_loss 1.093201
Epoch 53, Train Loss 0.940532, Valid_loss 1.088159
Epoch 54, Train Loss 0.939166, Valid_loss 1.092700
Epoch 55, Train Loss 0.942288, Valid_loss 1.091684
Epoch 56, Train Loss 0.941605, Valid_loss 1.097852
Epoch 57, Train Loss 0.940517, Valid_loss 1.090248
Epoch 58, Train Loss 0.939296, Valid_loss 1.093211
Epoch 59, Train Loss 0.938854, Valid_loss 1.093052
Epoch 60, Train Loss 0.938969, Valid_loss 1.096988
Epoch 61, Train Loss 0.939778, Valid_loss 1.096147
Epoch 62, Train Loss 0.939311, Valid_loss 1.092369
Epoch 63, Train Loss 0.938539, Valid_loss 1.097498
Epoch 64, Train Loss 0.939553, Valid_loss 1.095123
Epoch 65, Train Loss 0.940252, Valid_loss 1.095246
Epoch 66, Train Loss 0.939802, Valid_loss 1.092711
Epoch 67, Train Loss 0.940118, Valid_loss 1.091292
Epoch 68, Train Loss 0.938627, Valid_loss 1.095488
Epoch 69, Train Loss 0.939438, Valid_loss 1.096019
[I 2025-08-28 08:58:40,325] Trial 2 finished with value: 1.045848309993744 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.3, 'weight_decay': 0.001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.3876771798188036.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.7, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=9, batch_size=1 -> steps=9
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.090629, Valid_loss 1.061119
Epoch 2, Train Loss 1.077937, Valid_loss 0.988888
Epoch 3, Train Loss 0.991187, Valid_loss 1.013559
Epoch 4, Train Loss 0.903630, Valid_loss 0.933509
Epoch 5, Train Loss 0.916761, Valid_loss 0.824177
Epoch 6, Train Loss 0.907092, Valid_loss 0.752128
Epoch 7, Train Loss 0.771585, Valid_loss 0.703268
Epoch 8, Train Loss 0.790083, Valid_loss 0.772832
Epoch 9, Train Loss 0.737057, Valid_loss 0.740040
Epoch 10, Train Loss 0.734881, Valid_loss 0.647844
Epoch 11, Train Loss 0.735276, Valid_loss 0.609652
Epoch 12, Train Loss 0.644770, Valid_loss 0.637731
Epoch 13, Train Loss 0.664297, Valid_loss 0.608466
Epoch 14, Train Loss 0.725945, Valid_loss 0.578545
Epoch 15, Train Loss 0.699289, Valid_loss 0.714553
Epoch 16, Train Loss 0.661909, Valid_loss 0.583724
Epoch 17, Train Loss 0.608427, Valid_loss 0.641446
Epoch 18, Train Loss 0.613979, Valid_loss 0.562722
Epoch 19, Train Loss 0.577075, Valid_loss 0.553010
Epoch 20, Train Loss 0.623745, Valid_loss 0.594936
Epoch 21, Train Loss 0.619088, Valid_loss 0.520197
Epoch 22, Train Loss 0.621658, Valid_loss 0.765241
Epoch 23, Train Loss 0.527502, Valid_loss 0.555805
Epoch 24, Train Loss 0.496047, Valid_loss 0.540446
Epoch 25, Train Loss 0.530860, Valid_loss 0.495788
Epoch 26, Train Loss 0.590771, Valid_loss 0.488813
Epoch 27, Train Loss 0.638961, Valid_loss 0.448858
Epoch 28, Train Loss 0.542426, Valid_loss 0.452222
Epoch 29, Train Loss 0.493589, Valid_loss 0.458519
Epoch 30, Train Loss 0.508425, Valid_loss 0.514006
Epoch 31, Train Loss 0.471140, Valid_loss 0.454482
Epoch 32, Train Loss 0.493885, Valid_loss 0.414057
Epoch 33, Train Loss 0.537601, Valid_loss 0.410754
Epoch 34, Train Loss 0.553291, Valid_loss 0.405974
Epoch 35, Train Loss 0.476903, Valid_loss 0.418209
Epoch 36, Train Loss 0.534127, Valid_loss 0.455548
Epoch 37, Train Loss 0.426566, Valid_loss 0.443149
Epoch 38, Train Loss 0.480714, Valid_loss 0.430054
Epoch 39, Train Loss 0.505526, Valid_loss 0.403912
Epoch 40, Train Loss 0.511346, Valid_loss 0.495648
Epoch 41, Train Loss 0.532293, Valid_loss 0.401158
Epoch 42, Train Loss 0.411716, Valid_loss 0.410700
Epoch 43, Train Loss 0.405991, Valid_loss 0.377707
Epoch 44, Train Loss 0.425095, Valid_loss 0.380956
Epoch 45, Train Loss 0.420102, Valid_loss 0.489724
Epoch 46, Train Loss 0.403066, Valid_loss 0.381188
Epoch 47, Train Loss 0.399487, Valid_loss 0.545691
Epoch 48, Train Loss 0.407752, Valid_loss 0.380868
Epoch 49, Train Loss 0.484032, Valid_loss 0.372294
Epoch 50, Train Loss 0.375919, Valid_loss 0.347063
Epoch 51, Train Loss 0.389444, Valid_loss 0.369673
Epoch 52, Train Loss 0.402532, Valid_loss 0.408928
환자ID=P1290 -- true: [[2]] -- pred: tensor([[-1.3215,  0.8656,  0.4659]], device='cuda:0')
환자ID=P1300 -- true: [[2]] -- pred: tensor([[-1.3382,  0.8524,  0.4550]], device='cuda:0')
환자ID=P1422 -- true: [[1]] -- pred: tensor([[-1.2702,  0.8280,  0.4323]], device='cuda:0')
환자ID=P1516 -- true: [[0]] -- pred: tensor([[ 2.5252, -0.9021, -1.8117]], device='cuda:0')
환자ID=P1540 -- true: [[0]] -- pred: tensor([[ 2.5646, -0.9575, -1.8144]], device='cuda:0')
환자ID=P1547 -- true: [[0]] -- pred: tensor([[ 2.5256, -0.9123, -1.8148]], device='cuda:0')
환자ID=P1606 -- true: [[2]] -- pred: tensor([[-1.3517,  0.7463,  0.6384]], device='cuda:0')
환자ID=P1707 -- true: [[1]] -- pred: tensor([[-1.0975,  1.1072, -0.0613]], device='cuda:0')
환자ID=P1726 -- true: [[1]] -- pred: tensor([[-1.2111,  1.0099,  0.1734]], device='cuda:0')
Best performance: Epoch 50, Loss 0.375919, Test ACC 0.666667, Test AUC 0.962963, Test Recall 0.666667, Test Precision 0.500000
Confusion Matrix:
 [[3 0 0]
 [0 3 0]
 [0 3 0]]
✅ Total valid splits used: 2
🔁 Repeat 3, Fold 2
cell type :  ACAGCCGCAAGCGAGT-1-1              cardiac muscle cell
ATATCCTGTCCCTAAA-1-1              cardiac muscle cell
CAATGACCAGTTGTCA-1-1              cardiac muscle cell
CTAGACACAAGGTTGG-1-1              cardiac muscle cell
ATCGTCCGTATTTCTC-1-1              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 480853, dtype: string
cell type annotation :  ACAGCCGCAAGCGAGT-1-1              cardiac muscle cell
ATATCCTGTCCCTAAA-1-1              cardiac muscle cell
CAATGACCAGTTGTCA-1-1              cardiac muscle cell
CTAGACACAAGGTTGG-1-1              cardiac muscle cell
ATCGTCCGTATTTCTC-1-1              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 480853, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'mesothelial cell', 'macrophage', 'fat cell', 'endocardial cell', 'cardiac neuron', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'lymphocyte', 'mast cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 111836, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 111836, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 3}
🔍 Split #3
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1290', 'P1300', 'P1358', 'P1371', 'P1422', 'P1425', 'P1430', 'P1437', 'P1447', 'P1462', 'P1479', 'P1504', 'P1510', 'P1515', 'P1516', 'P1539', 'P1540', 'P1547', 'P1558', 'P1582', 'P1600', 'P1602', 'P1603', 'P1606', 'P1610', 'P1617', 'P1630', 'P1678', 'P1702', 'P1707', 'P1718', 'P1722', 'P1726', 'P1735']
  → test  환자 ID: ['P1304', 'P1472', 'P1508', 'P1549', 'P1561', 'P1622', 'P1631', 'P1685']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1558, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1630, Label: 1
    ID: P1678, Label: 0
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1304, Label: 2
    ID: P1472, Label: 2
    ID: P1508, Label: 1
    ID: P1549, Label: 0
    ID: P1561, Label: 0
    ID: P1622, Label: 0
    ID: P1631, Label: 1
    ID: P1685, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1539, Label=0, 셀개수=11076
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1602, Label=1, 셀개수=16580
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1685, Label=1, 셀개수=10043
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0              cardiac muscle cell
1              cardiac muscle cell
2              cardiac muscle cell
3              cardiac muscle cell
4              cardiac muscle cell
                    ...           
592684    cardiac endothelial cell
592685    cardiac endothelial cell
592686    cardiac endothelial cell
592687    cardiac endothelial cell
592688    cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.72it/s]  2%|▏         | 2/100 [00:00<00:10,  8.91it/s]  3%|▎         | 3/100 [00:00<00:11,  8.71it/s]  4%|▍         | 4/100 [00:00<00:11,  8.60it/s]  5%|▌         | 5/100 [00:00<00:10,  8.67it/s]  6%|▌         | 6/100 [00:00<00:10,  8.66it/s]  7%|▋         | 7/100 [00:00<00:10,  8.74it/s]  8%|▊         | 8/100 [00:00<00:10,  8.61it/s]  9%|▉         | 9/100 [00:01<00:10,  8.61it/s] 10%|█         | 10/100 [00:01<00:10,  8.73it/s] 11%|█         | 11/100 [00:01<00:10,  8.81it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.61it/s] 13%|█▎        | 13/100 [00:01<00:10,  8.63it/s] 14%|█▍        | 14/100 [00:01<00:10,  8.52it/s] 15%|█▌        | 15/100 [00:01<00:09,  8.64it/s] 16%|█▌        | 16/100 [00:01<00:09,  8.75it/s] 17%|█▋        | 17/100 [00:01<00:09,  8.70it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.54it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.59it/s] 20%|██        | 20/100 [00:02<00:09,  8.71it/s] 21%|██        | 21/100 [00:02<00:09,  8.70it/s] 22%|██▏       | 22/100 [00:02<00:08,  8.75it/s] 23%|██▎       | 23/100 [00:02<00:08,  8.57it/s] 24%|██▍       | 24/100 [00:02<00:08,  8.71it/s] 25%|██▌       | 25/100 [00:02<00:08,  8.81it/s] 26%|██▌       | 26/100 [00:02<00:08,  8.89it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.64it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.58it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.55it/s] 30%|███       | 30/100 [00:03<00:08,  8.38it/s] 31%|███       | 31/100 [00:03<00:08,  8.45it/s] 32%|███▏      | 32/100 [00:03<00:08,  8.48it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.65it/s] 34%|███▍      | 34/100 [00:03<00:07,  8.66it/s] 35%|███▌      | 35/100 [00:04<00:07,  8.76it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.66it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.74it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.62it/s] 39%|███▉      | 39/100 [00:04<00:07,  8.67it/s] 40%|████      | 40/100 [00:04<00:07,  8.55it/s] 41%|████      | 41/100 [00:04<00:06,  8.68it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.47it/s] 43%|████▎     | 43/100 [00:04<00:06,  8.44it/s] 44%|████▍     | 44/100 [00:05<00:06,  8.56it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.68it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.60it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.74it/s] 48%|████▊     | 48/100 [00:05<00:05,  8.76it/s] 49%|████▉     | 49/100 [00:05<00:05,  8.58it/s] 50%|█████     | 50/100 [00:05<00:05,  8.65it/s] 51%|█████     | 51/100 [00:05<00:05,  8.56it/s] 52%|█████▏    | 52/100 [00:06<00:05,  8.56it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.59it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.60it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.48it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.40it/s] 57%|█████▋    | 57/100 [00:06<00:05,  8.43it/s] 58%|█████▊    | 58/100 [00:06<00:05,  8.37it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.31it/s] 60%|██████    | 60/100 [00:06<00:04,  8.38it/s] 61%|██████    | 61/100 [00:07<00:04,  8.32it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.37it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.42it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.47it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.38it/s] 66%|██████▌   | 66/100 [00:07<00:04,  8.44it/s] 67%|██████▋   | 67/100 [00:07<00:03,  8.35it/s] 68%|██████▊   | 68/100 [00:07<00:03,  8.30it/s] 69%|██████▉   | 69/100 [00:08<00:03,  8.16it/s] 70%|███████   | 70/100 [00:08<00:03,  8.20it/s] 71%|███████   | 71/100 [00:08<00:03,  8.16it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.25it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.20it/s] 74%|███████▍  | 74/100 [00:08<00:03,  8.42it/s] 75%|███████▌  | 75/100 [00:08<00:02,  8.44it/s] 76%|███████▌  | 76/100 [00:08<00:02,  8.51it/s] 77%|███████▋  | 77/100 [00:09<00:02,  8.30it/s] 78%|███████▊  | 78/100 [00:09<00:02,  8.31it/s] 79%|███████▉  | 79/100 [00:09<00:02,  8.06it/s] 80%|████████  | 80/100 [00:09<00:02,  8.09it/s] 81%|████████  | 81/100 [00:09<00:02,  8.13it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.22it/s] 83%|████████▎ | 83/100 [00:09<00:02,  8.31it/s] 84%|████████▍ | 84/100 [00:09<00:01,  8.17it/s] 85%|████████▌ | 85/100 [00:09<00:01,  8.17it/s] 86%|████████▌ | 86/100 [00:10<00:01,  8.19it/s] 87%|████████▋ | 87/100 [00:10<00:01,  8.26it/s] 88%|████████▊ | 88/100 [00:10<00:01,  8.12it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.09it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.17it/s] 91%|█████████ | 91/100 [00:10<00:01,  8.22it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.16it/s] 93%|█████████▎| 93/100 [00:10<00:00,  8.20it/s] 94%|█████████▍| 94/100 [00:11<00:00,  8.08it/s] 95%|█████████▌| 95/100 [00:11<00:00,  8.16it/s] 96%|█████████▌| 96/100 [00:11<00:00,  8.22it/s] 97%|█████████▋| 97/100 [00:11<00:00,  8.09it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.09it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.24it/s]100%|██████████| 100/100 [00:11<00:00,  8.25it/s]100%|██████████| 100/100 [00:11<00:00,  8.45it/s]
[I 2025-08-28 09:18:07,160] A new study created in memory with name: no-name-b1f82ff8-4b6a-4576-bc00-66b94d82e18c
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9113.95 MB
Memory Reserved: 9116.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9113.97 MB
Memory Reserved: 9148.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9113.85 MB
Memory Reserved: 9114.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9113.97 MB
Memory Reserved: 9146.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 09:18:08,284] Trial 0 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9110.04 MB
Memory Reserved: 9114.00 MB
cuda
Epoch 1, Train Loss 0.917638, Valid_loss 1.209628
Epoch 2, Train Loss 0.905138, Valid_loss 1.184782
Epoch 3, Train Loss 0.891310, Valid_loss 1.164586
Epoch 4, Train Loss 0.880893, Valid_loss 1.159968
Epoch 5, Train Loss 0.869346, Valid_loss 1.132100
Epoch 6, Train Loss 0.858416, Valid_loss 1.114707
Epoch 7, Train Loss 0.848052, Valid_loss 1.099623
Epoch 8, Train Loss 0.833858, Valid_loss 1.082278
Epoch 9, Train Loss 0.814557, Valid_loss 1.065284
Epoch 10, Train Loss 0.791021, Valid_loss 1.035148
Epoch 11, Train Loss 0.770514, Valid_loss 1.014228
Epoch 12, Train Loss 0.745683, Valid_loss 1.006794
Epoch 13, Train Loss 0.732413, Valid_loss 0.963062
Epoch 14, Train Loss 0.705170, Valid_loss 0.968815
Epoch 15, Train Loss 0.685716, Valid_loss 0.905191
Epoch 16, Train Loss 0.661986, Valid_loss 0.883231
Epoch 17, Train Loss 0.634027, Valid_loss 0.868857
Epoch 18, Train Loss 0.614838, Valid_loss 0.855985
Epoch 19, Train Loss 0.600218, Valid_loss 0.806196
Epoch 20, Train Loss 0.600484, Valid_loss 0.798771
Epoch 21, Train Loss 0.569672, Valid_loss 0.798425
Epoch 22, Train Loss 0.566264, Valid_loss 0.797687
Epoch 23, Train Loss 0.532524, Valid_loss 0.792826
Epoch 24, Train Loss 0.512710, Valid_loss 0.794978
Epoch 25, Train Loss 0.529462, Valid_loss 0.784787
Epoch 26, Train Loss 0.484658, Valid_loss 0.786428
Epoch 27, Train Loss 0.470149, Valid_loss 0.771604
Epoch 28, Train Loss 0.464516, Valid_loss 0.766896
Epoch 29, Train Loss 0.443314, Valid_loss 0.773708
Epoch 30, Train Loss 0.476178, Valid_loss 0.761013
Epoch 31, Train Loss 0.423016, Valid_loss 0.762251
Epoch 32, Train Loss 0.415834, Valid_loss 0.781716
Epoch 33, Train Loss 0.406401, Valid_loss 0.759719
Epoch 34, Train Loss 0.400956, Valid_loss 0.743408
Epoch 35, Train Loss 0.399735, Valid_loss 0.742623
Epoch 36, Train Loss 0.383670, Valid_loss 0.750137
Epoch 37, Train Loss 0.396411, Valid_loss 0.748864
Epoch 38, Train Loss 0.368935, Valid_loss 0.749809
Epoch 39, Train Loss 0.352586, Valid_loss 0.750462
Epoch 40, Train Loss 0.358951, Valid_loss 0.736137
Epoch 41, Train Loss 0.346824, Valid_loss 0.763936
Epoch 42, Train Loss 0.339797, Valid_loss 0.739340
Epoch 43, Train Loss 0.341395, Valid_loss 0.743398
Epoch 44, Train Loss 0.319796, Valid_loss 0.758132
Epoch 45, Train Loss 0.327212, Valid_loss 0.745934
Epoch 46, Train Loss 0.313454, Valid_loss 0.739874
Epoch 47, Train Loss 0.329457, Valid_loss 0.736902
Epoch 48, Train Loss 0.309042, Valid_loss 0.754735
Epoch 49, Train Loss 0.299318, Valid_loss 0.737660
Epoch 50, Train Loss 0.289144, Valid_loss 0.724853
Epoch 51, Train Loss 0.279229, Valid_loss 0.710186
Epoch 52, Train Loss 0.282748, Valid_loss 0.726558
Epoch 53, Train Loss 0.278415, Valid_loss 0.734983
[I 2025-08-28 09:37:48,400] Trial 1 finished with value: 0.7101858736326297 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.0, 'weight_decay': 0.01, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 0.7101858736326297.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17855.37 MB
Memory Reserved: 17874.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 299.37 MB
Memory Reserved: 320.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17855.54 MB
Memory Reserved: 17876.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 299.37 MB
Memory Reserved: 320.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 09:37:50,105] Trial 2 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17858.70 MB
Memory Reserved: 17876.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 4725.93 MB
Memory Reserved: 4748.00 MB
cuda
Epoch 1, Train Loss 1.000770, Valid_loss 1.443198
Epoch 2, Train Loss 0.917046, Valid_loss 1.672530
Epoch 3, Train Loss 0.925594, Valid_loss 1.391486
Epoch 4, Train Loss 0.929758, Valid_loss 1.428062
Epoch 5, Train Loss 0.909141, Valid_loss 1.311442
Epoch 6, Train Loss 0.903286, Valid_loss 1.471454
Epoch 7, Train Loss 0.898726, Valid_loss 1.352104
Epoch 8, Train Loss 0.903008, Valid_loss 1.124553
Epoch 9, Train Loss 0.907821, Valid_loss 1.495229
Epoch 10, Train Loss 0.906630, Valid_loss 1.371982
Epoch 11, Train Loss 0.916993, Valid_loss 1.237113
Epoch 12, Train Loss 0.886953, Valid_loss 1.155344
Epoch 13, Train Loss 0.910332, Valid_loss 1.203304
Epoch 14, Train Loss 0.900530, Valid_loss 1.355389
Epoch 15, Train Loss 0.896412, Valid_loss 1.225287
Epoch 16, Train Loss 0.879754, Valid_loss 1.198686
Epoch 17, Train Loss 0.908811, Valid_loss 1.278358
Epoch 18, Train Loss 0.891209, Valid_loss 1.233898
Epoch 19, Train Loss 0.889691, Valid_loss 1.270693
Epoch 20, Train Loss 0.886048, Valid_loss 1.231706
Epoch 21, Train Loss 0.898698, Valid_loss 1.388748
Epoch 22, Train Loss 0.900047, Valid_loss 1.413132
Epoch 23, Train Loss 0.892006, Valid_loss 1.231482
Epoch 24, Train Loss 0.889408, Valid_loss 1.423278
Epoch 25, Train Loss 0.894822, Valid_loss 1.304553
Epoch 26, Train Loss 0.921852, Valid_loss 1.477009
Epoch 27, Train Loss 0.896173, Valid_loss 1.278994
Epoch 28, Train Loss 0.892497, Valid_loss 1.382771
Epoch 29, Train Loss 0.893547, Valid_loss 1.364953
Epoch 30, Train Loss 0.889239, Valid_loss 1.367098
Epoch 31, Train Loss 0.901375, Valid_loss 1.325317
Epoch 32, Train Loss 0.894243, Valid_loss 1.363915
Epoch 33, Train Loss 0.893992, Valid_loss 1.363901
Epoch 34, Train Loss 0.889592, Valid_loss 1.369372
Epoch 35, Train Loss 0.896887, Valid_loss 1.362733
Epoch 36, Train Loss 0.890152, Valid_loss 1.324441
Epoch 37, Train Loss 0.890274, Valid_loss 1.353926
Epoch 38, Train Loss 0.887824, Valid_loss 1.352888
Epoch 39, Train Loss 0.888305, Valid_loss 1.372459
Epoch 40, Train Loss 0.893561, Valid_loss 1.347809
Epoch 41, Train Loss 0.888771, Valid_loss 1.356138
Epoch 42, Train Loss 0.886723, Valid_loss 1.369878
Epoch 43, Train Loss 0.885953, Valid_loss 1.367828
Epoch 44, Train Loss 0.884975, Valid_loss 1.364341
Epoch 45, Train Loss 0.887198, Valid_loss 1.365302
Epoch 46, Train Loss 0.895993, Valid_loss 1.360589
Epoch 47, Train Loss 0.886906, Valid_loss 1.365112
Epoch 48, Train Loss 0.905266, Valid_loss 1.366010
Epoch 49, Train Loss 0.890936, Valid_loss 1.419484
Epoch 50, Train Loss 0.890340, Valid_loss 1.384487
Epoch 51, Train Loss 0.883726, Valid_loss 1.377744
Epoch 52, Train Loss 0.882745, Valid_loss 1.378518
Epoch 53, Train Loss 0.882440, Valid_loss 1.380593
[I 2025-08-28 10:06:11,480] Trial 3 finished with value: 1.1245528906583786 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.0, 'weight_decay': 0.01, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 0.7101858736326297.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 4725.93 MB
Memory Reserved: 4748.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9114.84 MB
Memory Reserved: 9156.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9114.90 MB
Memory Reserved: 9134.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9114.74 MB
Memory Reserved: 9134.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9114.90 MB
Memory Reserved: 9134.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 10:06:12,962] Trial 4 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.928982, Valid_loss 1.254654
Epoch 2, Train Loss 0.893682, Valid_loss 1.263980
Epoch 3, Train Loss 0.922402, Valid_loss 1.126076
Epoch 4, Train Loss 0.897937, Valid_loss 1.190023
Epoch 5, Train Loss 0.892103, Valid_loss 1.110698
Epoch 6, Train Loss 0.904777, Valid_loss 1.189159
Epoch 7, Train Loss 0.875264, Valid_loss 1.148830
Epoch 8, Train Loss 0.913922, Valid_loss 1.170690
Epoch 9, Train Loss 0.902984, Valid_loss 1.347867
Epoch 10, Train Loss 0.888855, Valid_loss 1.176971
Epoch 11, Train Loss 0.869957, Valid_loss 1.159886
Epoch 12, Train Loss 0.875432, Valid_loss 1.195724
Epoch 13, Train Loss 0.878741, Valid_loss 1.253159
Epoch 14, Train Loss 0.883608, Valid_loss 1.268754
Epoch 15, Train Loss 0.894250, Valid_loss 1.201299
Epoch 16, Train Loss 0.880590, Valid_loss 1.231185
Epoch 17, Train Loss 0.869900, Valid_loss 1.124527
Epoch 18, Train Loss 0.879725, Valid_loss 1.282049
Epoch 19, Train Loss 0.881503, Valid_loss 1.229336
Epoch 20, Train Loss 0.888873, Valid_loss 1.193127
Epoch 21, Train Loss 0.865378, Valid_loss 1.145151
Epoch 22, Train Loss 0.880433, Valid_loss 1.203801
Epoch 23, Train Loss 0.862794, Valid_loss 1.195656
Epoch 24, Train Loss 0.892788, Valid_loss 1.148726
Epoch 25, Train Loss 0.863802, Valid_loss 1.148691
Epoch 26, Train Loss 0.884038, Valid_loss 1.290577
Epoch 27, Train Loss 0.853783, Valid_loss 1.499241
Epoch 28, Train Loss 0.890845, Valid_loss 1.207750
Epoch 29, Train Loss 0.875721, Valid_loss 1.386341
Epoch 30, Train Loss 0.883350, Valid_loss 1.374157
Epoch 31, Train Loss 0.879855, Valid_loss 1.369989
Epoch 32, Train Loss 0.873279, Valid_loss 1.351993
Epoch 33, Train Loss 0.882395, Valid_loss 1.223646
Epoch 34, Train Loss 0.854997, Valid_loss 1.123018
Epoch 35, Train Loss 0.866672, Valid_loss 1.109502
Epoch 36, Train Loss 0.879259, Valid_loss 1.185595
Epoch 37, Train Loss 0.877257, Valid_loss 1.353657
Epoch 38, Train Loss 0.883002, Valid_loss 1.187546
Epoch 39, Train Loss 0.859763, Valid_loss 1.102586
Epoch 40, Train Loss 0.846650, Valid_loss 1.059204
Epoch 41, Train Loss 0.783603, Valid_loss 2.340600
Epoch 42, Train Loss 0.766640, Valid_loss 1.603436
Epoch 43, Train Loss 0.857997, Valid_loss 1.228097
Epoch 44, Train Loss 0.706592, Valid_loss 1.264206
Epoch 45, Train Loss 0.605162, Valid_loss 1.762483
Epoch 46, Train Loss 0.680628, Valid_loss 1.538286
Epoch 47, Train Loss 0.607483, Valid_loss 1.399593
Epoch 48, Train Loss 0.531124, Valid_loss 1.591558
Epoch 49, Train Loss 0.664140, Valid_loss 1.220374
Epoch 50, Train Loss 0.774284, Valid_loss 1.178494
Epoch 51, Train Loss 0.560688, Valid_loss 1.270851
Epoch 52, Train Loss 0.512301, Valid_loss 1.349095
[I 2025-08-28 10:26:45,659] Trial 5 finished with value: 1.059203952550888 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.3, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 0.7101858736326297.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.0, 'weight_decay': 0.01, 'emb_dim': 8, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.936113, Valid_loss 1.170128
Epoch 2, Train Loss 0.868722, Valid_loss 1.166583
Epoch 3, Train Loss 0.819869, Valid_loss 1.087032
Epoch 4, Train Loss 0.788688, Valid_loss 1.088840
Epoch 5, Train Loss 0.760263, Valid_loss 1.016037
Epoch 6, Train Loss 0.724889, Valid_loss 1.003464
Epoch 7, Train Loss 0.698745, Valid_loss 1.023281
Epoch 8, Train Loss 0.674416, Valid_loss 1.002737
Epoch 9, Train Loss 0.664143, Valid_loss 0.996217
Epoch 10, Train Loss 0.651980, Valid_loss 0.985670
Epoch 11, Train Loss 0.611464, Valid_loss 0.981040
Epoch 12, Train Loss 0.608913, Valid_loss 0.976526
Epoch 13, Train Loss 0.582346, Valid_loss 0.978420
Epoch 14, Train Loss 0.581163, Valid_loss 0.980117
Epoch 15, Train Loss 0.568119, Valid_loss 0.964603
Epoch 16, Train Loss 0.543961, Valid_loss 0.960032
Epoch 17, Train Loss 0.522460, Valid_loss 0.963736
Epoch 18, Train Loss 0.510548, Valid_loss 0.966652
Epoch 19, Train Loss 0.491615, Valid_loss 0.954665
Epoch 20, Train Loss 0.478131, Valid_loss 0.947274
Epoch 21, Train Loss 0.471130, Valid_loss 0.948195
Epoch 22, Train Loss 0.455279, Valid_loss 0.947446
Epoch 23, Train Loss 0.453194, Valid_loss 0.935185
Epoch 24, Train Loss 0.472503, Valid_loss 0.928617
Epoch 25, Train Loss 0.439510, Valid_loss 0.932382
Epoch 26, Train Loss 0.410314, Valid_loss 0.905754
Epoch 27, Train Loss 0.395481, Valid_loss 0.899398
Epoch 28, Train Loss 0.396715, Valid_loss 0.896206
Epoch 29, Train Loss 0.401425, Valid_loss 0.902672
Epoch 30, Train Loss 0.430024, Valid_loss 0.891824
Epoch 31, Train Loss 0.390017, Valid_loss 0.887509
Epoch 32, Train Loss 0.375294, Valid_loss 0.892209
Epoch 33, Train Loss 0.362530, Valid_loss 0.929487
Epoch 34, Train Loss 0.353570, Valid_loss 0.877549
Epoch 35, Train Loss 0.341858, Valid_loss 0.875642
Epoch 36, Train Loss 0.350892, Valid_loss 0.873699
Epoch 37, Train Loss 0.349547, Valid_loss 0.864756
Epoch 38, Train Loss 0.348384, Valid_loss 0.863693
Epoch 39, Train Loss 0.342243, Valid_loss 0.870118
Epoch 40, Train Loss 0.312713, Valid_loss 0.858325
Epoch 41, Train Loss 0.303616, Valid_loss 0.897550
Epoch 42, Train Loss 0.315492, Valid_loss 0.891139
Epoch 43, Train Loss 0.316438, Valid_loss 0.865125
Epoch 44, Train Loss 0.365194, Valid_loss 0.848397
Epoch 45, Train Loss 0.313385, Valid_loss 0.840521
Epoch 46, Train Loss 0.302742, Valid_loss 0.829891
Epoch 47, Train Loss 0.283363, Valid_loss 0.881742
Epoch 48, Train Loss 0.296432, Valid_loss 0.816192
Epoch 49, Train Loss 0.320684, Valid_loss 0.813702
Epoch 50, Train Loss 0.311085, Valid_loss 0.941647
Epoch 51, Train Loss 0.281626, Valid_loss 0.882588
Epoch 52, Train Loss 0.268589, Valid_loss 0.907525
Epoch 53, Train Loss 0.261123, Valid_loss 0.843524
Epoch 54, Train Loss 0.270107, Valid_loss 0.836978
Epoch 55, Train Loss 0.261063, Valid_loss 0.831409
Epoch 56, Train Loss 0.258015, Valid_loss 0.892868
Epoch 57, Train Loss 0.252163, Valid_loss 0.928354
환자ID=P1304 -- true: [[2]] -- pred: tensor([[-1.0405,  0.6745, -0.9942]], device='cuda:0')
환자ID=P1472 -- true: [[2]] -- pred: tensor([[-1.0329,  0.6401, -0.9839]], device='cuda:0')
환자ID=P1508 -- true: [[1]] -- pred: tensor([[-0.9901,  0.6857, -1.0549]], device='cuda:0')
환자ID=P1549 -- true: [[0]] -- pred: tensor([[ 1.6887, -1.1727, -1.7303]], device='cuda:0')
환자ID=P1561 -- true: [[0]] -- pred: tensor([[ 1.8703, -1.2597, -1.7525]], device='cuda:0')
환자ID=P1622 -- true: [[0]] -- pred: tensor([[ 0.4207, -0.2081, -1.6651]], device='cuda:0')
환자ID=P1631 -- true: [[1]] -- pred: tensor([[-0.8960,  0.5972, -1.0607]], device='cuda:0')
환자ID=P1685 -- true: [[1]] -- pred: tensor([[-0.9865,  0.6249, -1.0128]], device='cuda:0')
Best performance: Epoch 49, Loss 0.320684, Test ACC 0.750000, Test AUC 0.861111, Test Recall 0.666667, Test Precision 0.533333
Confusion Matrix:
 [[3 0 0]
 [0 3 0]
 [0 2 0]]
✅ Total valid splits used: 3
🔁 Repeat 3, Fold 3
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 482281, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 482281, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  CTGCTCAAGGCATCAG-1-3              cardiac muscle cell
TCATACTAGACTTCCA-1-3              cardiac muscle cell
GAGCCTGGTCGAGATG-1-3              cardiac muscle cell
CTTACCGCAGAACTCT-1-3              cardiac muscle cell
TTGACCCCATCTAACG-1-3              cardiac muscle cell
                                     ...             
GTTCTATTCCTTCTAA-1-77        cardiac endothelial cell
GAGTCATTCATGGATC-1-77        cardiac endothelial cell
GGTGTTACAAGACAAT-1-77    cardiac ventricle fibroblast
AGCGTCGTCCTCACTG-1-77        cardiac endothelial cell
GTGCTGGCATGATAGA-1-77        cardiac endothelial cell
Name: manual_annotation, Length: 110408, dtype: string
cell type annotation :  CTGCTCAAGGCATCAG-1-3              cardiac muscle cell
TCATACTAGACTTCCA-1-3              cardiac muscle cell
GAGCCTGGTCGAGATG-1-3              cardiac muscle cell
CTTACCGCAGAACTCT-1-3              cardiac muscle cell
TTGACCCCATCTAACG-1-3              cardiac muscle cell
                                     ...             
GTTCTATTCCTTCTAA-1-77        cardiac endothelial cell
GAGTCATTCATGGATC-1-77        cardiac endothelial cell
GGTGTTACAAGACAAT-1-77    cardiac ventricle fibroblast
AGCGTCGTCCTCACTG-1-77        cardiac endothelial cell
GTGCTGGCATGATAGA-1-77        cardiac endothelial cell
Name: manual_annotation, Length: 110408, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'endothelial cell of lymphatic vessel', 'fat cell', 'pericyte cell', 'vascular associated smooth muscle cell', 'lymphocyte', 'cardiac neuron', 'mast cell', 'mesothelial cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 3}
🔍 Split #4
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1290', 'P1300', 'P1304', 'P1358', 'P1422', 'P1425', 'P1430', 'P1437', 'P1472', 'P1479', 'P1508', 'P1510', 'P1515', 'P1516', 'P1540', 'P1547', 'P1549', 'P1558', 'P1561', 'P1582', 'P1606', 'P1610', 'P1617', 'P1622', 'P1630', 'P1631', 'P1678', 'P1685', 'P1702', 'P1707', 'P1718', 'P1722', 'P1726', 'P1735']
  → test  환자 ID: ['P1371', 'P1447', 'P1462', 'P1504', 'P1539', 'P1600', 'P1602', 'P1603']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1371, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1504, Label: 2
    ID: P1539, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1547, Label=0, 셀개수=8253
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1610, Label=0, 셀개수=13919
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1603, Label=0, 셀개수=10638
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685        cardiac endothelial cell
592686    cardiac ventricle fibroblast
592687        cardiac endothelial cell
592688        cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.33it/s]  2%|▏         | 2/100 [00:00<00:11,  8.67it/s]  3%|▎         | 3/100 [00:00<00:10,  8.87it/s]  4%|▍         | 4/100 [00:00<00:10,  9.03it/s]  5%|▌         | 5/100 [00:00<00:10,  8.91it/s]  6%|▌         | 6/100 [00:00<00:10,  8.90it/s]  7%|▋         | 7/100 [00:00<00:10,  8.64it/s]  8%|▊         | 8/100 [00:00<00:10,  8.57it/s]  9%|▉         | 9/100 [00:01<00:10,  8.70it/s] 10%|█         | 10/100 [00:01<00:10,  8.77it/s] 11%|█         | 11/100 [00:01<00:10,  8.76it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.70it/s] 13%|█▎        | 13/100 [00:01<00:09,  8.83it/s] 14%|█▍        | 14/100 [00:01<00:09,  8.95it/s] 15%|█▌        | 15/100 [00:01<00:09,  9.00it/s] 16%|█▌        | 16/100 [00:01<00:09,  8.87it/s] 17%|█▋        | 17/100 [00:01<00:09,  8.82it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.74it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.76it/s] 20%|██        | 20/100 [00:02<00:09,  8.87it/s] 21%|██        | 21/100 [00:02<00:09,  8.78it/s] 22%|██▏       | 22/100 [00:02<00:09,  8.63it/s] 23%|██▎       | 23/100 [00:02<00:08,  8.82it/s] 24%|██▍       | 24/100 [00:02<00:08,  8.81it/s] 25%|██▌       | 25/100 [00:02<00:08,  8.73it/s] 26%|██▌       | 26/100 [00:02<00:08,  8.64it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.65it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.53it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.57it/s] 30%|███       | 30/100 [00:03<00:08,  8.53it/s] 31%|███       | 31/100 [00:03<00:08,  8.54it/s] 32%|███▏      | 32/100 [00:03<00:07,  8.52it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.78it/s] 34%|███▍      | 34/100 [00:03<00:07,  8.75it/s] 35%|███▌      | 35/100 [00:04<00:07,  8.62it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.62it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.55it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.35it/s] 39%|███▉      | 39/100 [00:04<00:07,  8.46it/s] 40%|████      | 40/100 [00:04<00:07,  8.55it/s] 41%|████      | 41/100 [00:04<00:06,  8.49it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.56it/s] 43%|████▎     | 43/100 [00:04<00:06,  8.55it/s] 44%|████▍     | 44/100 [00:05<00:06,  8.55it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.67it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.69it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.75it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.59it/s] 49%|████▉     | 49/100 [00:05<00:05,  8.53it/s] 50%|█████     | 50/100 [00:05<00:05,  8.65it/s] 51%|█████     | 51/100 [00:05<00:05,  8.62it/s] 52%|█████▏    | 52/100 [00:05<00:05,  8.74it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.58it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.58it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.61it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.57it/s] 57%|█████▋    | 57/100 [00:06<00:05,  8.59it/s] 58%|█████▊    | 58/100 [00:06<00:04,  8.68it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.58it/s] 60%|██████    | 60/100 [00:06<00:04,  8.53it/s] 61%|██████    | 61/100 [00:07<00:04,  8.42it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.34it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.31it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.47it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.48it/s] 66%|██████▌   | 66/100 [00:07<00:04,  8.47it/s] 67%|██████▋   | 67/100 [00:07<00:03,  8.45it/s] 68%|██████▊   | 68/100 [00:07<00:03,  8.49it/s] 69%|██████▉   | 69/100 [00:07<00:03,  8.43it/s] 70%|███████   | 70/100 [00:08<00:03,  8.34it/s] 71%|███████   | 71/100 [00:08<00:03,  8.47it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.37it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.42it/s] 74%|███████▍  | 74/100 [00:08<00:03,  8.47it/s] 75%|███████▌  | 75/100 [00:08<00:02,  8.50it/s] 76%|███████▌  | 76/100 [00:08<00:02,  8.38it/s] 77%|███████▋  | 77/100 [00:08<00:02,  8.45it/s] 78%|███████▊  | 78/100 [00:09<00:02,  8.46it/s] 79%|███████▉  | 79/100 [00:09<00:02,  8.54it/s] 80%|████████  | 80/100 [00:09<00:02,  8.53it/s] 81%|████████  | 81/100 [00:09<00:02,  8.58it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.74it/s] 83%|████████▎ | 83/100 [00:09<00:01,  8.68it/s] 84%|████████▍ | 84/100 [00:09<00:01,  8.62it/s] 85%|████████▌ | 85/100 [00:09<00:01,  8.54it/s] 86%|████████▌ | 86/100 [00:09<00:01,  8.61it/s] 87%|████████▋ | 87/100 [00:10<00:01,  8.56it/s] 88%|████████▊ | 88/100 [00:10<00:01,  8.34it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.50it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.60it/s] 91%|█████████ | 91/100 [00:10<00:01,  8.49it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.30it/s] 93%|█████████▎| 93/100 [00:10<00:00,  8.30it/s] 94%|█████████▍| 94/100 [00:10<00:00,  8.16it/s] 95%|█████████▌| 95/100 [00:11<00:00,  8.17it/s] 96%|█████████▌| 96/100 [00:11<00:00,  8.29it/s] 97%|█████████▋| 97/100 [00:11<00:00,  8.44it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.34it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.39it/s]100%|██████████| 100/100 [00:11<00:00,  8.29it/s]100%|██████████| 100/100 [00:11<00:00,  8.57it/s]
[I 2025-08-28 10:48:44,139] A new study created in memory with name: no-name-3ef4aa82-f0a5-48be-a6f5-7f00438489d1
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.134828, Valid_loss 1.098901
Epoch 2, Train Loss 1.049665, Valid_loss 1.155494
Epoch 3, Train Loss 1.043053, Valid_loss 1.450730
Epoch 4, Train Loss 1.006532, Valid_loss 1.317745
Epoch 5, Train Loss 1.016873, Valid_loss 1.160265
Epoch 6, Train Loss 0.981921, Valid_loss 1.238046
Epoch 7, Train Loss 0.973913, Valid_loss 1.267466
Epoch 8, Train Loss 0.983694, Valid_loss 1.231841
Epoch 9, Train Loss 0.978329, Valid_loss 1.208792
Epoch 10, Train Loss 0.973928, Valid_loss 1.234074
Epoch 11, Train Loss 0.973377, Valid_loss 1.256107
Epoch 12, Train Loss 0.973787, Valid_loss 1.235310
Epoch 13, Train Loss 0.965370, Valid_loss 1.239117
Epoch 14, Train Loss 0.965203, Valid_loss 1.246944
Epoch 15, Train Loss 0.967937, Valid_loss 1.309417
Epoch 16, Train Loss 0.975744, Valid_loss 1.259742
Epoch 17, Train Loss 0.961947, Valid_loss 1.257389
Epoch 18, Train Loss 0.961769, Valid_loss 1.262885
Epoch 19, Train Loss 0.965301, Valid_loss 1.261348
Epoch 20, Train Loss 0.963959, Valid_loss 1.256939
Epoch 21, Train Loss 0.962962, Valid_loss 1.260278
Epoch 22, Train Loss 0.962417, Valid_loss 1.271703
Epoch 23, Train Loss 0.962623, Valid_loss 1.256984
Epoch 24, Train Loss 0.964505, Valid_loss 1.254939
Epoch 25, Train Loss 0.980015, Valid_loss 1.265089
Epoch 26, Train Loss 0.964634, Valid_loss 1.261015
Epoch 27, Train Loss 0.974739, Valid_loss 1.255949
Epoch 28, Train Loss 0.966722, Valid_loss 1.253379
Epoch 29, Train Loss 0.963732, Valid_loss 1.254815
Epoch 30, Train Loss 0.965961, Valid_loss 1.263940
Epoch 31, Train Loss 0.963248, Valid_loss 1.273798
Epoch 32, Train Loss 0.970554, Valid_loss 1.257521
Epoch 33, Train Loss 0.964129, Valid_loss 1.255375
Epoch 34, Train Loss 0.961907, Valid_loss 1.264682
Epoch 35, Train Loss 0.974961, Valid_loss 1.251879
Epoch 36, Train Loss 0.964331, Valid_loss 1.271090
Epoch 37, Train Loss 0.966250, Valid_loss 1.260425
Epoch 38, Train Loss 0.974581, Valid_loss 1.249869
Epoch 39, Train Loss 0.971199, Valid_loss 1.257479
Epoch 40, Train Loss 0.982304, Valid_loss 1.248443
Epoch 41, Train Loss 0.963746, Valid_loss 1.260259
Epoch 42, Train Loss 0.964807, Valid_loss 1.263725
Epoch 43, Train Loss 0.987161, Valid_loss 1.277377
Epoch 44, Train Loss 0.972713, Valid_loss 1.245774
Epoch 45, Train Loss 0.969202, Valid_loss 1.254544
Epoch 46, Train Loss 0.978909, Valid_loss 1.266546
Epoch 47, Train Loss 0.963429, Valid_loss 1.257083
Epoch 48, Train Loss 0.963344, Valid_loss 1.257758
Epoch 49, Train Loss 0.973889, Valid_loss 1.252344
Epoch 50, Train Loss 0.966816, Valid_loss 1.255901
Epoch 51, Train Loss 0.960630, Valid_loss 1.255960
Epoch 52, Train Loss 0.960919, Valid_loss 1.257403
[I 2025-08-28 11:09:06,277] Trial 0 finished with value: 1.0989014406998951 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.01, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 1.0989014406998951.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16903.99 MB
Memory Reserved: 16924.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 312.97 MB
Memory Reserved: 352.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16903.99 MB
Memory Reserved: 16924.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 312.55 MB
Memory Reserved: 352.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 11:09:08,105] Trial 1 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16903.99 MB
Memory Reserved: 16944.00 MB
cuda
Epoch 1, Train Loss 1.107986, Valid_loss 1.180817
Epoch 2, Train Loss 1.002918, Valid_loss 1.364028
Epoch 3, Train Loss 0.986627, Valid_loss 1.292349
Epoch 4, Train Loss 1.005699, Valid_loss 1.276906
Epoch 5, Train Loss 0.988537, Valid_loss 1.165713
Epoch 6, Train Loss 0.979067, Valid_loss 1.197704
Epoch 7, Train Loss 0.994602, Valid_loss 1.237530
Epoch 8, Train Loss 0.979447, Valid_loss 1.237520
Epoch 9, Train Loss 0.970435, Valid_loss 1.258697
Epoch 10, Train Loss 0.974392, Valid_loss 1.237722
Epoch 11, Train Loss 0.966133, Valid_loss 1.247142
Epoch 12, Train Loss 0.964572, Valid_loss 1.265942
Epoch 13, Train Loss 0.964346, Valid_loss 1.263428
Epoch 14, Train Loss 0.966307, Valid_loss 1.279702
Epoch 15, Train Loss 0.966075, Valid_loss 1.294306
Epoch 16, Train Loss 0.969063, Valid_loss 1.262433
Epoch 17, Train Loss 0.967579, Valid_loss 1.281002
Epoch 18, Train Loss 0.967083, Valid_loss 1.274467
Epoch 19, Train Loss 0.963770, Valid_loss 1.292521
Epoch 20, Train Loss 0.964933, Valid_loss 1.274224
Epoch 21, Train Loss 0.963404, Valid_loss 1.288511
Epoch 22, Train Loss 0.976169, Valid_loss 1.277273
Epoch 23, Train Loss 0.964885, Valid_loss 1.285254
Epoch 24, Train Loss 0.967602, Valid_loss 1.263704
Epoch 25, Train Loss 0.965042, Valid_loss 1.274583
Epoch 26, Train Loss 0.965291, Valid_loss 1.282272
Epoch 27, Train Loss 0.967244, Valid_loss 1.280943
Epoch 28, Train Loss 0.964306, Valid_loss 1.277261
Epoch 29, Train Loss 0.961682, Valid_loss 1.271203
Epoch 30, Train Loss 0.965002, Valid_loss 1.278315
Epoch 31, Train Loss 0.980573, Valid_loss 1.266139
Epoch 32, Train Loss 0.963494, Valid_loss 1.279000
Epoch 33, Train Loss 0.962721, Valid_loss 1.283626
Epoch 34, Train Loss 0.962957, Valid_loss 1.275326
Epoch 35, Train Loss 0.965447, Valid_loss 1.271609
Epoch 36, Train Loss 0.966518, Valid_loss 1.277067
Epoch 37, Train Loss 0.967046, Valid_loss 1.397662
Epoch 38, Train Loss 0.990730, Valid_loss 1.259878
Epoch 39, Train Loss 0.967091, Valid_loss 1.267838
Epoch 40, Train Loss 0.963647, Valid_loss 1.269565
Epoch 41, Train Loss 0.963016, Valid_loss 1.284280
Epoch 42, Train Loss 0.964208, Valid_loss 1.275699
Epoch 43, Train Loss 0.963510, Valid_loss 1.282707
Epoch 44, Train Loss 0.962339, Valid_loss 1.293857
Epoch 45, Train Loss 0.963887, Valid_loss 1.283675
Epoch 46, Train Loss 0.961766, Valid_loss 1.289446
Epoch 47, Train Loss 0.963517, Valid_loss 1.285784
Epoch 48, Train Loss 0.962093, Valid_loss 1.285250
Epoch 49, Train Loss 0.964514, Valid_loss 1.285448
Epoch 50, Train Loss 0.965187, Valid_loss 1.294869
Epoch 51, Train Loss 0.960712, Valid_loss 1.285218
Epoch 52, Train Loss 0.961365, Valid_loss 1.286334
Epoch 53, Train Loss 0.961047, Valid_loss 1.288373
[I 2025-08-28 11:30:00,295] Trial 2 finished with value: 1.1657130469878514 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 1.0989014406998951.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.982309, Valid_loss 1.098050
Epoch 2, Train Loss 0.726766, Valid_loss 0.987339
Epoch 3, Train Loss 0.649565, Valid_loss 0.920768
Epoch 4, Train Loss 0.563398, Valid_loss 0.970793
Epoch 5, Train Loss 0.551720, Valid_loss 0.915809
Epoch 6, Train Loss 0.573758, Valid_loss 0.985270
Epoch 7, Train Loss 0.498816, Valid_loss 0.810050
Epoch 8, Train Loss 0.453789, Valid_loss 0.697041
Epoch 9, Train Loss 0.457414, Valid_loss 0.767384
Epoch 10, Train Loss 0.399674, Valid_loss 0.802392
Epoch 11, Train Loss 0.397428, Valid_loss 0.716767
Epoch 12, Train Loss 0.407095, Valid_loss 0.772925
Epoch 13, Train Loss 0.368408, Valid_loss 0.895621
Epoch 14, Train Loss 0.358656, Valid_loss 1.082032
Epoch 15, Train Loss 0.375014, Valid_loss 0.848615
Epoch 16, Train Loss 0.371399, Valid_loss 0.877796
Epoch 17, Train Loss 0.317583, Valid_loss 0.727361
Epoch 18, Train Loss 0.313174, Valid_loss 0.799191
Epoch 19, Train Loss 0.330979, Valid_loss 0.899995
Epoch 20, Train Loss 0.288102, Valid_loss 0.861990
Epoch 21, Train Loss 0.285323, Valid_loss 0.710214
Epoch 22, Train Loss 0.292836, Valid_loss 1.034109
Epoch 23, Train Loss 0.294991, Valid_loss 1.027869
Epoch 24, Train Loss 0.267596, Valid_loss 0.856528
Epoch 25, Train Loss 0.267391, Valid_loss 0.981500
Epoch 26, Train Loss 0.323746, Valid_loss 0.712288
Epoch 27, Train Loss 0.225882, Valid_loss 1.052545
Epoch 28, Train Loss 0.249470, Valid_loss 1.069744
Epoch 29, Train Loss 0.271604, Valid_loss 0.969510
Epoch 30, Train Loss 0.238058, Valid_loss 0.873860
Epoch 31, Train Loss 0.229364, Valid_loss 0.867477
Epoch 32, Train Loss 0.211515, Valid_loss 0.744803
Epoch 33, Train Loss 0.214636, Valid_loss 0.943330
Epoch 34, Train Loss 0.257697, Valid_loss 0.631731
Epoch 35, Train Loss 0.260905, Valid_loss 0.987142
Epoch 36, Train Loss 0.204059, Valid_loss 1.132382
Epoch 37, Train Loss 0.197714, Valid_loss 0.760343
Epoch 38, Train Loss 0.212591, Valid_loss 0.908428
Epoch 39, Train Loss 0.248865, Valid_loss 0.981063
Epoch 40, Train Loss 0.183702, Valid_loss 1.010487
Epoch 41, Train Loss 0.160307, Valid_loss 0.867116
Epoch 42, Train Loss 0.188846, Valid_loss 0.926220
Epoch 43, Train Loss 0.201859, Valid_loss 0.749123
Epoch 44, Train Loss 0.218011, Valid_loss 0.770794
Epoch 45, Train Loss 0.170614, Valid_loss 0.922798
Epoch 46, Train Loss 0.178063, Valid_loss 1.361765
Epoch 47, Train Loss 0.193815, Valid_loss 1.150113
Epoch 48, Train Loss 0.150567, Valid_loss 0.889179
Epoch 49, Train Loss 0.185715, Valid_loss 1.178665
Epoch 50, Train Loss 0.146314, Valid_loss 0.786507
Epoch 51, Train Loss 0.125305, Valid_loss 1.101192
Epoch 52, Train Loss 0.127287, Valid_loss 0.918397
Epoch 53, Train Loss 0.113855, Valid_loss 1.073200
Epoch 54, Train Loss 0.101288, Valid_loss 1.275991
[I 2025-08-28 11:58:44,945] Trial 3 finished with value: 0.6317310843927165 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.0, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 3 with value: 0.6317310843927165.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.0, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.955186, Valid_loss 1.078173
Epoch 2, Train Loss 0.747161, Valid_loss 0.949139
Epoch 3, Train Loss 0.734540, Valid_loss 0.804167
Epoch 4, Train Loss 0.623505, Valid_loss 0.732109
Epoch 5, Train Loss 0.576431, Valid_loss 0.652926
Epoch 6, Train Loss 0.559724, Valid_loss 0.807336
Epoch 7, Train Loss 0.555053, Valid_loss 0.906381
Epoch 8, Train Loss 0.488443, Valid_loss 0.969121
Epoch 9, Train Loss 0.490600, Valid_loss 0.889436
Epoch 10, Train Loss 0.464408, Valid_loss 0.600013
Epoch 11, Train Loss 0.433150, Valid_loss 0.604152
Epoch 12, Train Loss 0.451467, Valid_loss 0.571879
Epoch 13, Train Loss 0.429601, Valid_loss 0.781277
Epoch 14, Train Loss 0.379374, Valid_loss 0.714551
Epoch 15, Train Loss 0.399937, Valid_loss 0.729534
Epoch 16, Train Loss 0.345082, Valid_loss 0.535611
Epoch 17, Train Loss 0.371649, Valid_loss 0.580279
Epoch 18, Train Loss 0.350880, Valid_loss 0.642647
Epoch 19, Train Loss 0.356076, Valid_loss 0.735651
Epoch 20, Train Loss 0.314981, Valid_loss 0.754273
Epoch 21, Train Loss 0.305990, Valid_loss 0.810332
Epoch 22, Train Loss 0.305398, Valid_loss 0.757881
Epoch 23, Train Loss 0.295029, Valid_loss 0.494417
Epoch 24, Train Loss 0.308186, Valid_loss 0.686949
Epoch 25, Train Loss 0.285122, Valid_loss 0.697579
Epoch 26, Train Loss 0.262886, Valid_loss 0.463363
Epoch 27, Train Loss 0.289857, Valid_loss 0.507529
Epoch 28, Train Loss 0.251707, Valid_loss 0.580237
Epoch 29, Train Loss 0.255284, Valid_loss 0.529763
Epoch 30, Train Loss 0.228347, Valid_loss 0.646967
Epoch 31, Train Loss 0.260529, Valid_loss 0.795929
Epoch 32, Train Loss 0.235216, Valid_loss 0.435568
Epoch 33, Train Loss 0.234189, Valid_loss 0.709906
Epoch 34, Train Loss 0.209127, Valid_loss 0.723254
Epoch 35, Train Loss 0.216032, Valid_loss 0.988865
Epoch 36, Train Loss 0.227317, Valid_loss 0.561520
Epoch 37, Train Loss 0.243686, Valid_loss 0.397261
Epoch 38, Train Loss 0.211147, Valid_loss 0.618846
Epoch 39, Train Loss 0.200227, Valid_loss 0.938284
Epoch 40, Train Loss 0.192491, Valid_loss 0.783646
Epoch 41, Train Loss 0.163860, Valid_loss 0.989261
Epoch 42, Train Loss 0.243291, Valid_loss 1.007067
Epoch 43, Train Loss 0.182126, Valid_loss 0.572874
Epoch 44, Train Loss 0.193306, Valid_loss 0.506070
Epoch 45, Train Loss 0.158736, Valid_loss 0.754899
Epoch 46, Train Loss 0.171336, Valid_loss 0.683654
Epoch 47, Train Loss 0.187458, Valid_loss 0.426054
Epoch 48, Train Loss 0.152797, Valid_loss 0.600391
Epoch 49, Train Loss 0.143487, Valid_loss 0.451428
Epoch 50, Train Loss 0.141880, Valid_loss 0.669203
Epoch 51, Train Loss 0.118245, Valid_loss 0.464948
Epoch 52, Train Loss 0.117724, Valid_loss 0.574386
Epoch 53, Train Loss 0.126298, Valid_loss 0.831697
환자ID=P1371 -- true: [[2]] -- pred: tensor([[-1.8732,  0.3710,  0.4580]], device='cuda:0')
환자ID=P1447 -- true: [[1]] -- pred: tensor([[-1.9864,  0.7191, -0.0611]], device='cuda:0')
환자ID=P1462 -- true: [[1]] -- pred: tensor([[-2.0139,  0.6131,  0.2196]], device='cuda:0')
환자ID=P1504 -- true: [[2]] -- pred: tensor([[-2.1072,  0.1928,  0.6258]], device='cuda:0')
환자ID=P1539 -- true: [[0]] -- pred: tensor([[ 3.2452, -1.0936, -2.1916]], device='cuda:0')
환자ID=P1600 -- true: [[0]] -- pred: tensor([[ 3.0909, -1.0142, -2.1364]], device='cuda:0')
환자ID=P1602 -- true: [[1]] -- pred: tensor([[ 1.3261,  0.4202, -1.9835]], device='cuda:0')
환자ID=P1603 -- true: [[0]] -- pred: tensor([[ 3.3022, -1.1140, -2.0757]], device='cuda:0')
Best performance: Epoch 37, Loss 0.243686, Test ACC 0.875000, Test AUC 0.944444, Test Recall 0.888889, Test Precision 0.916667
Confusion Matrix:
 [[3 0 0]
 [1 2 0]
 [0 0 2]]
✅ Total valid splits used: 4
🔁 Repeat 3, Fold 4
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 469380, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 469380, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  CAACCAAAGACCCGCT-1-2              cardiac muscle cell
ACGGTTACATCGAACT-1-2              cardiac muscle cell
ACCCTCATCCGGCAGT-1-2              cardiac muscle cell
AACACACCACGGTCTG-1-2              cardiac muscle cell
AAACGCTTCACCGGGT-1-2              cardiac muscle cell
                                     ...             
TCATTGTGTGGATCGA-1-76        cardiac endothelial cell
TTCTAGTTCGTTCTAT-1-76        cardiac endothelial cell
GTAGTACCAGTTGTTG-1-76    cardiac ventricle fibroblast
GCATCGGTCGCCGTGA-1-76        cardiac endothelial cell
TCGGGTGGTGAGAACC-1-76    cardiac ventricle fibroblast
Name: manual_annotation, Length: 123309, dtype: string
cell type annotation :  CAACCAAAGACCCGCT-1-2              cardiac muscle cell
ACGGTTACATCGAACT-1-2              cardiac muscle cell
ACCCTCATCCGGCAGT-1-2              cardiac muscle cell
AACACACCACGGTCTG-1-2              cardiac muscle cell
AAACGCTTCACCGGGT-1-2              cardiac muscle cell
                                     ...             
TCATTGTGTGGATCGA-1-76        cardiac endothelial cell
TTCTAGTTCGTTCTAT-1-76        cardiac endothelial cell
GTAGTACCAGTTGTTG-1-76    cardiac ventricle fibroblast
GCATCGGTCGCCGTGA-1-76        cardiac endothelial cell
TCGGGTGGTGAGAACC-1-76    cardiac ventricle fibroblast
Name: manual_annotation, Length: 123309, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'vascular associated smooth muscle cell', 'macrophage', 'endocardial cell', 'endothelial cell of lymphatic vessel', 'cardiac endothelial cell', 'cardiac ventricle fibroblast', 'pericyte cell', 'cardiac neuron', 'lymphocyte', 'mast cell', 'mesothelial cell']
라벨별 그룹 개수 {2: 2, 0: 3, 1: 3}
🔍 Split #5
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1290', 'P1300', 'P1304', 'P1358', 'P1371', 'P1422', 'P1425', 'P1447', 'P1462', 'P1472', 'P1479', 'P1504', 'P1508', 'P1510', 'P1515', 'P1516', 'P1539', 'P1540', 'P1547', 'P1549', 'P1561', 'P1600', 'P1602', 'P1603', 'P1606', 'P1610', 'P1617', 'P1622', 'P1631', 'P1685', 'P1702', 'P1707', 'P1718', 'P1726']
  → test  환자 ID: ['P1430', 'P1437', 'P1558', 'P1582', 'P1630', 'P1678', 'P1722', 'P1735']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1561, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1631, Label: 1
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1726, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1558, Label: 0
    ID: P1582, Label: 0
    ID: P1630, Label: 1
    ID: P1678, Label: 0
    ID: P1722, Label: 1
    ID: P1735, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1516, Label=0, 셀개수=9361
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1600, Label=0, 셀개수=14882
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1735, Label=1, 셀개수=12009
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685        cardiac endothelial cell
592686    cardiac ventricle fibroblast
592687        cardiac endothelial cell
592688    cardiac ventricle fibroblast
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.93it/s]  2%|▏         | 2/100 [00:00<00:11,  8.90it/s]  3%|▎         | 3/100 [00:00<00:11,  8.76it/s]  4%|▍         | 4/100 [00:00<00:11,  8.67it/s]  5%|▌         | 5/100 [00:00<00:10,  8.67it/s]  6%|▌         | 6/100 [00:00<00:10,  8.58it/s]  7%|▋         | 7/100 [00:00<00:11,  8.31it/s]  8%|▊         | 8/100 [00:00<00:11,  8.29it/s]  9%|▉         | 9/100 [00:01<00:10,  8.35it/s] 10%|█         | 10/100 [00:01<00:10,  8.45it/s] 11%|█         | 11/100 [00:01<00:10,  8.37it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.47it/s] 13%|█▎        | 13/100 [00:01<00:10,  8.50it/s] 14%|█▍        | 14/100 [00:01<00:10,  8.51it/s] 15%|█▌        | 15/100 [00:01<00:09,  8.56it/s] 16%|█▌        | 16/100 [00:01<00:09,  8.56it/s] 17%|█▋        | 17/100 [00:01<00:09,  8.56it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.52it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.41it/s] 20%|██        | 20/100 [00:02<00:09,  8.43it/s] 21%|██        | 21/100 [00:02<00:09,  8.48it/s] 22%|██▏       | 22/100 [00:02<00:08,  8.75it/s] 23%|██▎       | 23/100 [00:02<00:08,  8.68it/s] 24%|██▍       | 24/100 [00:02<00:09,  8.40it/s] 25%|██▌       | 25/100 [00:02<00:08,  8.46it/s] 26%|██▌       | 26/100 [00:03<00:08,  8.66it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.71it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.50it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.53it/s] 30%|███       | 30/100 [00:03<00:08,  8.45it/s] 31%|███       | 31/100 [00:03<00:08,  8.32it/s] 32%|███▏      | 32/100 [00:03<00:08,  8.33it/s] 33%|███▎      | 33/100 [00:03<00:08,  8.30it/s] 34%|███▍      | 34/100 [00:04<00:07,  8.40it/s] 35%|███▌      | 35/100 [00:04<00:07,  8.46it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.49it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.44it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.48it/s] 39%|███▉      | 39/100 [00:04<00:07,  8.57it/s] 40%|████      | 40/100 [00:04<00:07,  8.52it/s] 41%|████      | 41/100 [00:04<00:06,  8.51it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.51it/s] 43%|████▎     | 43/100 [00:05<00:06,  8.59it/s] 44%|████▍     | 44/100 [00:05<00:06,  8.51it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.45it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.52it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.52it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.38it/s] 49%|████▉     | 49/100 [00:05<00:06,  8.41it/s] 50%|█████     | 50/100 [00:05<00:06,  8.19it/s] 51%|█████     | 51/100 [00:06<00:05,  8.28it/s] 52%|█████▏    | 52/100 [00:06<00:05,  8.29it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.38it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.40it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.50it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.30it/s] 57%|█████▋    | 57/100 [00:06<00:05,  8.31it/s] 58%|█████▊    | 58/100 [00:06<00:04,  8.50it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.50it/s] 60%|██████    | 60/100 [00:07<00:04,  8.52it/s] 61%|██████    | 61/100 [00:07<00:04,  8.35it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.39it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.32it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.43it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.46it/s] 66%|██████▌   | 66/100 [00:07<00:04,  8.37it/s] 67%|██████▋   | 67/100 [00:07<00:03,  8.39it/s] 68%|██████▊   | 68/100 [00:08<00:03,  8.42it/s] 69%|██████▉   | 69/100 [00:08<00:03,  8.19it/s] 70%|███████   | 70/100 [00:08<00:03,  8.12it/s] 71%|███████   | 71/100 [00:08<00:03,  8.16it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.09it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.19it/s] 74%|███████▍  | 74/100 [00:08<00:03,  8.15it/s] 75%|███████▌  | 75/100 [00:08<00:03,  8.19it/s] 76%|███████▌  | 76/100 [00:09<00:02,  8.18it/s] 77%|███████▋  | 77/100 [00:09<00:02,  8.00it/s] 78%|███████▊  | 78/100 [00:09<00:02,  8.06it/s] 79%|███████▉  | 79/100 [00:09<00:02,  8.15it/s] 80%|████████  | 80/100 [00:09<00:02,  8.07it/s] 81%|████████  | 81/100 [00:09<00:02,  7.96it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.03it/s] 83%|████████▎ | 83/100 [00:09<00:02,  8.01it/s] 84%|████████▍ | 84/100 [00:10<00:02,  7.92it/s] 85%|████████▌ | 85/100 [00:10<00:01,  7.97it/s] 86%|████████▌ | 86/100 [00:10<00:01,  8.04it/s] 87%|████████▋ | 87/100 [00:10<00:01,  8.03it/s] 88%|████████▊ | 88/100 [00:10<00:01,  8.11it/s] 89%|████████▉ | 89/100 [00:10<00:01,  7.99it/s] 90%|█████████ | 90/100 [00:10<00:01,  7.98it/s] 91%|█████████ | 91/100 [00:10<00:01,  7.95it/s] 92%|█████████▏| 92/100 [00:11<00:00,  8.10it/s] 93%|█████████▎| 93/100 [00:11<00:00,  8.18it/s] 94%|█████████▍| 94/100 [00:11<00:00,  8.15it/s] 95%|█████████▌| 95/100 [00:11<00:00,  8.08it/s] 96%|█████████▌| 96/100 [00:11<00:00,  8.05it/s] 97%|█████████▋| 97/100 [00:11<00:00,  7.99it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.03it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.11it/s]100%|██████████| 100/100 [00:12<00:00,  8.10it/s]100%|██████████| 100/100 [00:12<00:00,  8.33it/s]
[I 2025-08-28 12:28:23,727] A new study created in memory with name: no-name-0f04b7a0-c91d-4a87-bf79-6509b45564c2
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16934.53 MB
Memory Reserved: 16952.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 341.79 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.90 MB
Memory Reserved: 16960.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 342.12 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 12:28:25,088] Trial 0 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16931.43 MB
Memory Reserved: 16962.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16903.99 MB
Memory Reserved: 16922.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 313.89 MB
Memory Reserved: 350.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16903.99 MB
Memory Reserved: 16942.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 312.97 MB
Memory Reserved: 332.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 12:28:26,399] Trial 1 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16904.06 MB
Memory Reserved: 16944.00 MB
cuda
Epoch 1, Train Loss 1.085121, Valid_loss 1.118381
Epoch 2, Train Loss 0.967622, Valid_loss 1.049838
Epoch 3, Train Loss 0.857447, Valid_loss 1.015832
Epoch 4, Train Loss 0.742597, Valid_loss 0.990938
Epoch 5, Train Loss 0.705281, Valid_loss 0.913994
Epoch 6, Train Loss 0.684966, Valid_loss 0.941306
Epoch 7, Train Loss 0.626601, Valid_loss 0.856469
Epoch 8, Train Loss 0.596311, Valid_loss 0.915139
Epoch 9, Train Loss 0.641325, Valid_loss 0.890867
Epoch 10, Train Loss 0.529009, Valid_loss 0.863216
Epoch 11, Train Loss 0.510729, Valid_loss 0.854106
Epoch 12, Train Loss 0.507910, Valid_loss 0.823219
Epoch 13, Train Loss 0.460864, Valid_loss 0.847511
Epoch 14, Train Loss 0.496286, Valid_loss 0.841658
Epoch 15, Train Loss 0.461256, Valid_loss 0.966908
Epoch 16, Train Loss 0.531470, Valid_loss 0.886607
Epoch 17, Train Loss 0.467135, Valid_loss 0.911947
Epoch 18, Train Loss 0.492091, Valid_loss 0.889726
Epoch 19, Train Loss 0.442859, Valid_loss 0.837420
Epoch 20, Train Loss 0.399094, Valid_loss 0.713680
Epoch 21, Train Loss 0.426070, Valid_loss 0.933480
Epoch 22, Train Loss 0.413881, Valid_loss 0.831135
Epoch 23, Train Loss 0.366609, Valid_loss 0.733765
Epoch 24, Train Loss 0.412474, Valid_loss 0.807870
Epoch 25, Train Loss 0.491703, Valid_loss 0.858615
Epoch 26, Train Loss 0.409528, Valid_loss 0.874039
Epoch 27, Train Loss 0.402514, Valid_loss 0.841526
Epoch 28, Train Loss 0.345019, Valid_loss 0.746260
Epoch 29, Train Loss 0.441766, Valid_loss 0.885347
Epoch 30, Train Loss 0.340800, Valid_loss 0.596406
Epoch 31, Train Loss 0.366868, Valid_loss 0.969919
Epoch 32, Train Loss 0.446776, Valid_loss 1.059640
Epoch 33, Train Loss 0.401626, Valid_loss 0.897172
Epoch 34, Train Loss 0.324273, Valid_loss 0.857238
Epoch 35, Train Loss 0.351607, Valid_loss 0.928647
Epoch 36, Train Loss 0.354640, Valid_loss 0.842474
Epoch 37, Train Loss 0.271750, Valid_loss 0.865063
Epoch 38, Train Loss 0.312344, Valid_loss 1.029990
Epoch 39, Train Loss 0.322331, Valid_loss 0.577230
Epoch 40, Train Loss 0.310919, Valid_loss 0.892424
Epoch 41, Train Loss 0.289686, Valid_loss 0.889619
Epoch 42, Train Loss 0.249343, Valid_loss 0.983716
Epoch 43, Train Loss 0.314125, Valid_loss 1.040397
Epoch 44, Train Loss 0.259615, Valid_loss 1.027583
Epoch 45, Train Loss 0.326016, Valid_loss 1.234453
Epoch 46, Train Loss 0.242440, Valid_loss 0.717855
Epoch 47, Train Loss 0.279660, Valid_loss 0.620768
Epoch 48, Train Loss 0.426256, Valid_loss 1.039350
Epoch 49, Train Loss 0.250761, Valid_loss 0.836620
Epoch 50, Train Loss 0.336788, Valid_loss 0.643026
Epoch 51, Train Loss 0.234939, Valid_loss 0.759204
Epoch 52, Train Loss 0.201959, Valid_loss 0.824339
[I 2025-08-28 12:48:24,051] Trial 2 finished with value: 0.5772302346304059 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.3, 'weight_decay': 0.01, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.5772302346304059.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.95 MB
Memory Reserved: 8626.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.97 MB
Memory Reserved: 8658.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.85 MB
Memory Reserved: 8624.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8623.97 MB
Memory Reserved: 8656.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 12:48:25,416] Trial 3 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 8619.88 MB
Memory Reserved: 8624.00 MB
cuda
Epoch 1, Train Loss 1.141174, Valid_loss 1.117186
Epoch 2, Train Loss 1.037419, Valid_loss 1.127143
Epoch 3, Train Loss 1.039419, Valid_loss 1.132284
Epoch 4, Train Loss 1.004812, Valid_loss 1.146966
Epoch 5, Train Loss 1.003372, Valid_loss 1.183998
Epoch 6, Train Loss 0.985169, Valid_loss 1.218821
Epoch 7, Train Loss 0.964159, Valid_loss 1.255652
Epoch 8, Train Loss 0.983004, Valid_loss 1.246062
Epoch 9, Train Loss 0.961851, Valid_loss 1.281653
Epoch 10, Train Loss 0.941191, Valid_loss 1.293067
Epoch 11, Train Loss 0.977971, Valid_loss 1.275046
Epoch 12, Train Loss 0.977503, Valid_loss 1.300302
Epoch 13, Train Loss 0.951502, Valid_loss 1.300073
Epoch 14, Train Loss 0.949492, Valid_loss 1.322717
Epoch 15, Train Loss 0.931685, Valid_loss 1.338170
Epoch 16, Train Loss 0.954726, Valid_loss 1.317018
Epoch 17, Train Loss 0.940459, Valid_loss 1.319609
Epoch 18, Train Loss 0.941689, Valid_loss 1.358207
Epoch 19, Train Loss 0.964870, Valid_loss 1.336664
Epoch 20, Train Loss 0.950663, Valid_loss 1.307447
Epoch 21, Train Loss 0.928871, Valid_loss 1.320199
Epoch 22, Train Loss 0.931791, Valid_loss 1.333100
Epoch 23, Train Loss 0.925362, Valid_loss 1.338580
Epoch 24, Train Loss 0.943026, Valid_loss 1.336216
Epoch 25, Train Loss 0.924273, Valid_loss 1.356307
Epoch 26, Train Loss 0.936018, Valid_loss 1.414992
Epoch 27, Train Loss 0.939917, Valid_loss 1.362435
Epoch 28, Train Loss 0.945799, Valid_loss 1.357082
Epoch 29, Train Loss 0.952564, Valid_loss 1.394513
Epoch 30, Train Loss 0.945361, Valid_loss 1.333532
Epoch 31, Train Loss 0.932305, Valid_loss 1.354061
Epoch 32, Train Loss 0.950263, Valid_loss 1.331036
Epoch 33, Train Loss 0.923023, Valid_loss 1.372626
Epoch 34, Train Loss 0.928013, Valid_loss 1.355337
Epoch 35, Train Loss 0.933467, Valid_loss 1.356350
Epoch 36, Train Loss 0.942389, Valid_loss 1.355853
Epoch 37, Train Loss 0.928859, Valid_loss 1.364363
Epoch 38, Train Loss 0.930283, Valid_loss 1.360460
Epoch 39, Train Loss 0.921051, Valid_loss 1.435115
Epoch 40, Train Loss 0.931672, Valid_loss 1.372701
Epoch 41, Train Loss 0.932505, Valid_loss 1.378589
Epoch 42, Train Loss 0.929533, Valid_loss 1.372358
Epoch 43, Train Loss 0.933626, Valid_loss 1.378819
Epoch 44, Train Loss 0.927662, Valid_loss 1.388303
Epoch 45, Train Loss 0.926599, Valid_loss 1.415583
Epoch 46, Train Loss 0.919557, Valid_loss 1.388736
Epoch 47, Train Loss 0.915601, Valid_loss 1.407253
Epoch 48, Train Loss 0.934659, Valid_loss 1.399941
Epoch 49, Train Loss 0.926206, Valid_loss 1.391728
Epoch 50, Train Loss 0.919521, Valid_loss 1.390254
Epoch 51, Train Loss 0.919197, Valid_loss 1.393451
Epoch 52, Train Loss 0.923908, Valid_loss 1.392137
Epoch 53, Train Loss 0.926285, Valid_loss 1.390894
Epoch 54, Train Loss 0.913809, Valid_loss 1.398614
Epoch 55, Train Loss 0.924147, Valid_loss 1.398802
[I 2025-08-28 13:09:41,936] Trial 4 finished with value: 1.1171859453121822 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 1, 'dropout': 0.7, 'weight_decay': 0.01, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.5772302346304059.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.033597, Valid_loss 1.430140
Epoch 2, Train Loss 0.977918, Valid_loss 1.383780
Epoch 3, Train Loss 0.973129, Valid_loss 1.212024
Epoch 4, Train Loss 0.781583, Valid_loss 0.937423
Epoch 5, Train Loss 0.759047, Valid_loss 0.991113
Epoch 6, Train Loss 0.700199, Valid_loss 0.994097
Epoch 7, Train Loss 0.649466, Valid_loss 0.918017
Epoch 8, Train Loss 0.636387, Valid_loss 0.903664
Epoch 9, Train Loss 0.565616, Valid_loss 1.069146
Epoch 10, Train Loss 0.696127, Valid_loss 0.976923
Epoch 11, Train Loss 0.577560, Valid_loss 0.831316
Epoch 12, Train Loss 0.594274, Valid_loss 0.748578
Epoch 13, Train Loss 0.528861, Valid_loss 0.756180
Epoch 14, Train Loss 0.543897, Valid_loss 0.864555
Epoch 15, Train Loss 0.488263, Valid_loss 0.736991
Epoch 16, Train Loss 0.405903, Valid_loss 0.786818
Epoch 17, Train Loss 0.424096, Valid_loss 0.858907
Epoch 18, Train Loss 0.376663, Valid_loss 0.728658
Epoch 19, Train Loss 0.378087, Valid_loss 0.654827
Epoch 20, Train Loss 0.403042, Valid_loss 0.573171
Epoch 21, Train Loss 0.371325, Valid_loss 0.753694
Epoch 22, Train Loss 0.303902, Valid_loss 1.039358
Epoch 23, Train Loss 0.555582, Valid_loss 0.831721
Epoch 24, Train Loss 0.387018, Valid_loss 1.031870
Epoch 25, Train Loss 0.313238, Valid_loss 0.853457
Epoch 26, Train Loss 0.382112, Valid_loss 1.071494
Epoch 27, Train Loss 0.344330, Valid_loss 1.464934
Epoch 28, Train Loss 0.284818, Valid_loss 1.792848
Epoch 29, Train Loss 0.283784, Valid_loss 1.200199
Epoch 30, Train Loss 0.329802, Valid_loss 1.041349
Epoch 31, Train Loss 0.233398, Valid_loss 1.075676
Epoch 32, Train Loss 0.261169, Valid_loss 1.169314
Epoch 33, Train Loss 0.359820, Valid_loss 1.390619
Epoch 34, Train Loss 0.306037, Valid_loss 1.116173
Epoch 35, Train Loss 0.229135, Valid_loss 1.526709
Epoch 36, Train Loss 0.312075, Valid_loss 0.435009
Epoch 37, Train Loss 0.297912, Valid_loss 0.963404
Epoch 38, Train Loss 0.195801, Valid_loss 1.373048
Epoch 39, Train Loss 0.229104, Valid_loss 0.742209
Epoch 40, Train Loss 0.209698, Valid_loss 1.428445
Epoch 41, Train Loss 0.173986, Valid_loss 1.750088
Epoch 42, Train Loss 0.398677, Valid_loss 1.789016
Epoch 43, Train Loss 0.244171, Valid_loss 1.902744
Epoch 44, Train Loss 0.181487, Valid_loss 1.373419
Epoch 45, Train Loss 0.233266, Valid_loss 1.348257
Epoch 46, Train Loss 0.256206, Valid_loss 1.942336
Epoch 47, Train Loss 0.166332, Valid_loss 1.748438
Epoch 48, Train Loss 0.355073, Valid_loss 1.845374
Epoch 49, Train Loss 0.232021, Valid_loss 1.691118
Epoch 50, Train Loss 0.238711, Valid_loss 1.895677
Epoch 51, Train Loss 0.126745, Valid_loss 1.630757
Epoch 52, Train Loss 0.142391, Valid_loss 1.830601
Epoch 53, Train Loss 0.123909, Valid_loss 1.593657
Epoch 54, Train Loss 0.143898, Valid_loss 1.606824
Epoch 55, Train Loss 0.124363, Valid_loss 1.451621
Epoch 56, Train Loss 0.202368, Valid_loss 1.414422
Epoch 57, Train Loss 0.136105, Valid_loss 1.192905
Epoch 58, Train Loss 0.213744, Valid_loss 1.878974
Epoch 59, Train Loss 0.094349, Valid_loss 1.744981
Epoch 60, Train Loss 0.117777, Valid_loss 1.931773
Epoch 61, Train Loss 0.092564, Valid_loss 1.936314
[I 2025-08-28 13:33:11,103] Trial 5 finished with value: 0.4350092128346053 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 5 with value: 0.4350092128346053.
선택된 trial params: {'learning_rate': 0.001, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.946827, Valid_loss 1.364867
Epoch 2, Train Loss 0.996930, Valid_loss 1.467229
Epoch 3, Train Loss 0.880727, Valid_loss 1.387671
Epoch 4, Train Loss 0.787153, Valid_loss 1.069736
Epoch 5, Train Loss 0.756889, Valid_loss 1.039960
Epoch 6, Train Loss 0.690137, Valid_loss 0.895830
Epoch 7, Train Loss 0.637013, Valid_loss 0.880806
Epoch 8, Train Loss 1.144937, Valid_loss 1.257579
Epoch 9, Train Loss 0.968429, Valid_loss 1.331333
Epoch 10, Train Loss 0.799041, Valid_loss 1.036123
Epoch 11, Train Loss 0.693710, Valid_loss 0.863384
Epoch 12, Train Loss 0.502940, Valid_loss 0.878157
Epoch 13, Train Loss 0.641568, Valid_loss 0.837620
Epoch 14, Train Loss 0.592859, Valid_loss 0.924919
Epoch 15, Train Loss 0.581680, Valid_loss 0.760555
Epoch 16, Train Loss 0.684995, Valid_loss 0.794382
Epoch 17, Train Loss 0.547419, Valid_loss 0.918586
Epoch 18, Train Loss 0.540875, Valid_loss 0.678825
Epoch 19, Train Loss 0.560498, Valid_loss 0.715499
Epoch 20, Train Loss 0.430444, Valid_loss 0.625123
Epoch 21, Train Loss 0.455553, Valid_loss 0.839012
Epoch 22, Train Loss 0.488396, Valid_loss 1.060512
Epoch 23, Train Loss 0.500748, Valid_loss 0.714516
Epoch 24, Train Loss 0.581219, Valid_loss 0.628650
Epoch 25, Train Loss 0.425156, Valid_loss 0.659646
Epoch 26, Train Loss 0.469748, Valid_loss 0.882019
Epoch 27, Train Loss 0.400502, Valid_loss 0.906619
Epoch 28, Train Loss 0.407858, Valid_loss 0.957750
Epoch 29, Train Loss 0.417486, Valid_loss 0.657184
Epoch 30, Train Loss 0.429020, Valid_loss 0.660737
Epoch 31, Train Loss 0.390550, Valid_loss 0.653853
Epoch 32, Train Loss 0.434298, Valid_loss 0.542473
Epoch 33, Train Loss 0.458803, Valid_loss 0.526949
Epoch 34, Train Loss 0.365108, Valid_loss 1.027527
Epoch 35, Train Loss 0.355138, Valid_loss 0.536589
Epoch 36, Train Loss 0.323847, Valid_loss 1.590505
Epoch 37, Train Loss 0.597491, Valid_loss 0.467997
Epoch 38, Train Loss 0.429476, Valid_loss 0.813480
Epoch 39, Train Loss 0.452188, Valid_loss 0.787446
Epoch 40, Train Loss 0.376526, Valid_loss 1.202435
Epoch 41, Train Loss 0.470017, Valid_loss 0.569210
Epoch 42, Train Loss 0.457740, Valid_loss 0.685880
Epoch 43, Train Loss 0.452784, Valid_loss 0.506258
Epoch 44, Train Loss 0.372947, Valid_loss 0.492249
Epoch 45, Train Loss 0.375825, Valid_loss 0.766934
Epoch 46, Train Loss 0.374728, Valid_loss 0.469679
Epoch 47, Train Loss 0.348321, Valid_loss 0.447848
Epoch 48, Train Loss 0.365781, Valid_loss 0.622356
Epoch 49, Train Loss 0.288256, Valid_loss 0.466323
Epoch 50, Train Loss 0.364888, Valid_loss 0.449672
Epoch 51, Train Loss 0.272598, Valid_loss 0.436016
Epoch 52, Train Loss 0.335468, Valid_loss 0.424371
Epoch 53, Train Loss 0.329388, Valid_loss 0.432156
Epoch 54, Train Loss 0.304062, Valid_loss 0.458566
환자ID=P1430 -- true: [[2]] -- pred: tensor([[-3.2880,  1.1441,  1.0234]], device='cuda:0')
환자ID=P1437 -- true: [[2]] -- pred: tensor([[-3.2859,  1.1591,  0.9941]], device='cuda:0')
환자ID=P1558 -- true: [[0]] -- pred: tensor([[ 3.7139, -1.5002, -7.4042]], device='cuda:0')
환자ID=P1582 -- true: [[0]] -- pred: tensor([[ 3.6715, -1.4622, -7.4532]], device='cuda:0')
환자ID=P1630 -- true: [[1]] -- pred: tensor([[-3.2994,  1.1915,  0.9572]], device='cuda:0')
환자ID=P1678 -- true: [[0]] -- pred: tensor([[ 3.7282, -1.5096, -7.4069]], device='cuda:0')
환자ID=P1722 -- true: [[1]] -- pred: tensor([[-3.2971,  1.1761,  0.9783]], device='cuda:0')
환자ID=P1735 -- true: [[1]] -- pred: tensor([[-3.3105,  1.1647,  1.0129]], device='cuda:0')
Best performance: Epoch 52, Loss 0.335468, Test ACC 0.750000, Test AUC 0.944444, Test Recall 0.666667, Test Precision 0.533333
Confusion Matrix:
 [[3 0 0]
 [0 3 0]
 [0 2 0]]
✅ Total valid splits used: 5

📌 Repeat 3: 평균 AUC = 0.9204, 표준편차 = 0.0387
Test ACC 평균 0.763889, Test Recall 평균 0.711111, Test Precision 평균 0.603333
fold_aucs = [0.888888888888889, 0.9629629629629629, 0.8611111111111112, 0.9444444444444443, 0.9444444444444443]
NaN 개수: 0 / 전체 5개

🔁 Repeat 4, Fold 0
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 456589, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 456589, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 12}
cell type :  CTGCTCAAGGCATCAG-1-3              cardiac muscle cell
TCATACTAGACTTCCA-1-3              cardiac muscle cell
GAGCCTGGTCGAGATG-1-3              cardiac muscle cell
CTTACCGCAGAACTCT-1-3              cardiac muscle cell
TTGACCCCATCTAACG-1-3              cardiac muscle cell
                                     ...             
TCATTGTGTGGATCGA-1-76        cardiac endothelial cell
TTCTAGTTCGTTCTAT-1-76        cardiac endothelial cell
GTAGTACCAGTTGTTG-1-76    cardiac ventricle fibroblast
GCATCGGTCGCCGTGA-1-76        cardiac endothelial cell
TCGGGTGGTGAGAACC-1-76    cardiac ventricle fibroblast
Name: manual_annotation, Length: 136100, dtype: string
cell type annotation :  CTGCTCAAGGCATCAG-1-3              cardiac muscle cell
TCATACTAGACTTCCA-1-3              cardiac muscle cell
GAGCCTGGTCGAGATG-1-3              cardiac muscle cell
CTTACCGCAGAACTCT-1-3              cardiac muscle cell
TTGACCCCATCTAACG-1-3              cardiac muscle cell
                                     ...             
TCATTGTGTGGATCGA-1-76        cardiac endothelial cell
TTCTAGTTCGTTCTAT-1-76        cardiac endothelial cell
GTAGTACCAGTTGTTG-1-76    cardiac ventricle fibroblast
GCATCGGTCGCCGTGA-1-76        cardiac endothelial cell
TCGGGTGGTGAGAACC-1-76    cardiac ventricle fibroblast
Name: manual_annotation, Length: 136100, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'endothelial cell of lymphatic vessel', 'fat cell', 'pericyte cell', 'vascular associated smooth muscle cell', 'lymphocyte', 'cardiac neuron', 'mast cell', 'mesothelial cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 4}
🔍 Split #1
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 33
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 9
  → train 환자 ID: ['P1290', 'P1300', 'P1358', 'P1371', 'P1422', 'P1425', 'P1430', 'P1437', 'P1447', 'P1472', 'P1479', 'P1504', 'P1508', 'P1510', 'P1515', 'P1516', 'P1539', 'P1540', 'P1547', 'P1549', 'P1561', 'P1600', 'P1603', 'P1606', 'P1610', 'P1622', 'P1630', 'P1631', 'P1685', 'P1702', 'P1707', 'P1722', 'P1726']
  → test  환자 ID: ['P1304', 'P1462', 'P1558', 'P1582', 'P1602', 'P1617', 'P1678', 'P1718', 'P1735']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1561, Label: 0
    ID: P1600, Label: 0
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1722, Label: 1
    ID: P1726, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1304, Label: 2
    ID: P1462, Label: 1
    ID: P1558, Label: 0
    ID: P1582, Label: 0
    ID: P1602, Label: 1
    ID: P1617, Label: 2
    ID: P1678, Label: 0
    ID: P1718, Label: 0
    ID: P1735, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 33
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 33
기존 (train) label_stat 33
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 11
test_p_index 9
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1516, Label=0, 셀개수=9361
→ valid 환자 ID 및 라벨:
   총 개수: 11
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1610, Label=0, 셀개수=13919
→ test 환자 ID 및 라벨:
   총 개수: 9
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1735, Label=1, 셀개수=12009
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685        cardiac endothelial cell
592686    cardiac ventricle fibroblast
592687        cardiac endothelial cell
592688    cardiac ventricle fibroblast
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.97it/s]  2%|▏         | 2/100 [00:00<00:10,  9.01it/s]  3%|▎         | 3/100 [00:00<00:10,  8.90it/s]  4%|▍         | 4/100 [00:00<00:10,  9.04it/s]  5%|▌         | 5/100 [00:00<00:10,  9.31it/s]  6%|▌         | 6/100 [00:00<00:10,  9.32it/s]  7%|▋         | 7/100 [00:00<00:10,  9.29it/s]  8%|▊         | 8/100 [00:00<00:09,  9.24it/s]  9%|▉         | 9/100 [00:00<00:09,  9.11it/s] 10%|█         | 10/100 [00:01<00:09,  9.14it/s] 11%|█         | 11/100 [00:01<00:09,  9.21it/s] 12%|█▏        | 12/100 [00:01<00:09,  9.21it/s] 13%|█▎        | 13/100 [00:01<00:09,  9.18it/s] 14%|█▍        | 14/100 [00:01<00:09,  9.09it/s] 15%|█▌        | 15/100 [00:01<00:09,  8.99it/s] 16%|█▌        | 16/100 [00:01<00:09,  8.97it/s] 17%|█▋        | 17/100 [00:01<00:09,  8.82it/s] 18%|█▊        | 18/100 [00:01<00:09,  8.93it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.95it/s] 20%|██        | 20/100 [00:02<00:08,  8.96it/s] 21%|██        | 21/100 [00:02<00:08,  8.87it/s] 22%|██▏       | 22/100 [00:02<00:08,  8.76it/s] 23%|██▎       | 23/100 [00:02<00:08,  8.97it/s] 24%|██▍       | 24/100 [00:02<00:08,  9.03it/s] 25%|██▌       | 25/100 [00:02<00:08,  9.06it/s] 26%|██▌       | 26/100 [00:02<00:08,  9.13it/s] 27%|██▋       | 27/100 [00:02<00:07,  9.13it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.92it/s] 29%|██▉       | 29/100 [00:03<00:07,  8.98it/s] 30%|███       | 30/100 [00:03<00:07,  9.02it/s] 31%|███       | 31/100 [00:03<00:07,  9.00it/s] 32%|███▏      | 32/100 [00:03<00:07,  8.96it/s] 33%|███▎      | 33/100 [00:03<00:07,  9.00it/s] 34%|███▍      | 34/100 [00:03<00:07,  8.80it/s] 35%|███▌      | 35/100 [00:03<00:07,  8.97it/s] 36%|███▌      | 36/100 [00:03<00:07,  9.01it/s] 37%|███▋      | 37/100 [00:04<00:06,  9.11it/s] 38%|███▊      | 38/100 [00:04<00:06,  9.02it/s] 39%|███▉      | 39/100 [00:04<00:06,  9.04it/s] 40%|████      | 40/100 [00:04<00:06,  8.84it/s] 41%|████      | 41/100 [00:04<00:06,  8.86it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.76it/s] 43%|████▎     | 43/100 [00:04<00:06,  8.85it/s] 44%|████▍     | 44/100 [00:04<00:06,  8.80it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.72it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.69it/s] 47%|████▋     | 47/100 [00:05<00:05,  8.87it/s] 48%|████▊     | 48/100 [00:05<00:05,  8.75it/s] 49%|████▉     | 49/100 [00:05<00:05,  8.86it/s] 50%|█████     | 50/100 [00:05<00:05,  8.86it/s] 51%|█████     | 51/100 [00:05<00:05,  8.65it/s] 52%|█████▏    | 52/100 [00:05<00:05,  8.71it/s] 53%|█████▎    | 53/100 [00:05<00:05,  8.62it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.71it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.78it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.76it/s] 57%|█████▋    | 57/100 [00:06<00:05,  8.60it/s] 58%|█████▊    | 58/100 [00:06<00:04,  8.52it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.66it/s] 60%|██████    | 60/100 [00:06<00:04,  8.78it/s] 61%|██████    | 61/100 [00:06<00:04,  8.45it/s] 62%|██████▏   | 62/100 [00:06<00:04,  8.59it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.64it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.66it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.66it/s] 66%|██████▌   | 66/100 [00:07<00:03,  8.77it/s] 67%|██████▋   | 67/100 [00:07<00:03,  8.81it/s] 68%|██████▊   | 68/100 [00:07<00:03,  8.69it/s] 69%|██████▉   | 69/100 [00:07<00:03,  8.69it/s] 70%|███████   | 70/100 [00:07<00:03,  8.66it/s] 71%|███████   | 71/100 [00:07<00:03,  8.73it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.66it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.79it/s] 74%|███████▍  | 74/100 [00:08<00:03,  8.63it/s] 75%|███████▌  | 75/100 [00:08<00:02,  8.78it/s] 76%|███████▌  | 76/100 [00:08<00:02,  8.68it/s] 77%|███████▋  | 77/100 [00:08<00:02,  8.68it/s] 78%|███████▊  | 78/100 [00:08<00:02,  8.48it/s] 79%|███████▉  | 79/100 [00:08<00:02,  8.57it/s] 80%|████████  | 80/100 [00:09<00:02,  8.65it/s] 81%|████████  | 81/100 [00:09<00:02,  8.58it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.53it/s] 83%|████████▎ | 83/100 [00:09<00:02,  8.43it/s] 84%|████████▍ | 84/100 [00:09<00:01,  8.50it/s] 85%|████████▌ | 85/100 [00:09<00:01,  8.43it/s] 86%|████████▌ | 86/100 [00:09<00:01,  8.56it/s] 87%|████████▋ | 87/100 [00:09<00:01,  8.58it/s] 88%|████████▊ | 88/100 [00:09<00:01,  8.56it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.41it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.57it/s] 91%|█████████ | 91/100 [00:10<00:01,  8.49it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.36it/s] 93%|█████████▎| 93/100 [00:10<00:00,  8.26it/s] 94%|█████████▍| 94/100 [00:10<00:00,  8.16it/s] 95%|█████████▌| 95/100 [00:10<00:00,  8.16it/s] 96%|█████████▌| 96/100 [00:10<00:00,  8.33it/s] 97%|█████████▋| 97/100 [00:11<00:00,  8.27it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.34it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.24it/s]100%|██████████| 100/100 [00:11<00:00,  8.19it/s]100%|██████████| 100/100 [00:11<00:00,  8.74it/s]
[I 2025-08-28 13:54:55,061] A new study created in memory with name: no-name-bf1cdcba-8d86-4e13-9e09-c7b1f0b85433
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.951603, Valid_loss 1.301372
Epoch 2, Train Loss 0.926210, Valid_loss 1.290535
Epoch 3, Train Loss 0.811646, Valid_loss 1.153196
Epoch 4, Train Loss 0.699854, Valid_loss 1.069988
Epoch 5, Train Loss 0.623738, Valid_loss 0.956415
Epoch 6, Train Loss 0.596596, Valid_loss 0.852612
Epoch 7, Train Loss 0.541046, Valid_loss 0.948598
Epoch 8, Train Loss 0.566255, Valid_loss 0.960504
Epoch 9, Train Loss 0.552632, Valid_loss 0.832476
Epoch 10, Train Loss 0.540065, Valid_loss 0.869272
Epoch 11, Train Loss 0.494367, Valid_loss 0.995049
Epoch 12, Train Loss 0.476319, Valid_loss 0.840763
Epoch 13, Train Loss 0.527261, Valid_loss 0.765814
Epoch 14, Train Loss 0.471024, Valid_loss 0.750170
Epoch 15, Train Loss 0.482629, Valid_loss 0.858632
Epoch 16, Train Loss 0.450545, Valid_loss 0.848365
Epoch 17, Train Loss 0.436793, Valid_loss 0.775557
Epoch 18, Train Loss 0.440790, Valid_loss 0.949791
Epoch 19, Train Loss 0.410066, Valid_loss 0.915596
Epoch 20, Train Loss 0.386654, Valid_loss 0.835230
Epoch 21, Train Loss 0.410138, Valid_loss 0.992513
Epoch 22, Train Loss 0.421621, Valid_loss 1.173320
Epoch 23, Train Loss 0.429043, Valid_loss 0.883880
Epoch 24, Train Loss 0.365248, Valid_loss 0.822807
Epoch 25, Train Loss 0.361250, Valid_loss 0.808542
Epoch 26, Train Loss 0.407279, Valid_loss 0.825550
Epoch 27, Train Loss 0.384097, Valid_loss 1.005053
Epoch 28, Train Loss 0.364732, Valid_loss 0.797037
Epoch 29, Train Loss 0.522152, Valid_loss 0.893498
Epoch 30, Train Loss 0.351953, Valid_loss 1.242283
Epoch 31, Train Loss 0.425629, Valid_loss 0.725068
Epoch 32, Train Loss 0.385320, Valid_loss 0.773133
Epoch 33, Train Loss 0.346094, Valid_loss 0.877365
Epoch 34, Train Loss 0.379827, Valid_loss 0.785542
Epoch 35, Train Loss 0.332497, Valid_loss 0.867831
Epoch 36, Train Loss 0.329745, Valid_loss 0.846142
Epoch 37, Train Loss 0.329288, Valid_loss 0.918040
Epoch 38, Train Loss 0.358345, Valid_loss 1.063609
Epoch 39, Train Loss 0.347126, Valid_loss 0.783503
Epoch 40, Train Loss 0.330856, Valid_loss 0.825451
Epoch 41, Train Loss 0.332178, Valid_loss 0.814999
Epoch 42, Train Loss 0.274404, Valid_loss 0.743343
Epoch 43, Train Loss 0.296604, Valid_loss 0.906813
Epoch 44, Train Loss 0.366194, Valid_loss 1.308113
Epoch 45, Train Loss 0.280045, Valid_loss 0.737330
Epoch 46, Train Loss 0.278289, Valid_loss 0.854958
Epoch 47, Train Loss 0.294729, Valid_loss 0.879134
Epoch 48, Train Loss 0.269148, Valid_loss 0.790297
Epoch 49, Train Loss 0.280275, Valid_loss 0.799436
Epoch 50, Train Loss 0.379663, Valid_loss 0.901626
Epoch 51, Train Loss 0.237331, Valid_loss 0.929764
Epoch 52, Train Loss 0.235512, Valid_loss 0.816307
Epoch 53, Train Loss 0.207696, Valid_loss 0.760706
Epoch 54, Train Loss 0.259413, Valid_loss 0.833388
Epoch 55, Train Loss 0.249224, Valid_loss 0.760711
Epoch 56, Train Loss 0.204702, Valid_loss 0.779502
Epoch 57, Train Loss 0.228462, Valid_loss 0.803726
[I 2025-08-28 14:28:20,655] Trial 0 finished with value: 0.7250678363171491 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.7250678363171491.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9075.55 MB
Memory Reserved: 9096.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9075.54 MB
Memory Reserved: 9098.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9075.54 MB
Memory Reserved: 9096.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9075.54 MB
Memory Reserved: 9098.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 14:28:22,072] Trial 1 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 9076.86 MB
Memory Reserved: 9098.00 MB
cuda
Epoch 1, Train Loss 0.934844, Valid_loss 1.753953
Epoch 2, Train Loss 0.860471, Valid_loss 2.309782
Epoch 3, Train Loss 0.861205, Valid_loss 1.620282
Epoch 4, Train Loss 0.868908, Valid_loss 1.561247
Epoch 5, Train Loss 0.846547, Valid_loss 2.050362
Epoch 6, Train Loss 0.850580, Valid_loss 1.646324
Epoch 7, Train Loss 0.899453, Valid_loss 1.904648
Epoch 8, Train Loss 0.868396, Valid_loss 1.807886
Epoch 9, Train Loss 0.844990, Valid_loss 1.749336
Epoch 10, Train Loss 0.854171, Valid_loss 1.596958
Epoch 11, Train Loss 0.843642, Valid_loss 1.394932
Epoch 12, Train Loss 0.860508, Valid_loss 1.496156
Epoch 13, Train Loss 0.842911, Valid_loss 1.447168
Epoch 14, Train Loss 0.847552, Valid_loss 1.584470
Epoch 15, Train Loss 0.845823, Valid_loss 1.492657
Epoch 16, Train Loss 0.839317, Valid_loss 1.379951
Epoch 17, Train Loss 0.835353, Valid_loss 1.387418
Epoch 18, Train Loss 0.859420, Valid_loss 1.419514
Epoch 19, Train Loss 0.837819, Valid_loss 1.516544
Epoch 20, Train Loss 0.845838, Valid_loss 1.515262
Epoch 21, Train Loss 0.837227, Valid_loss 1.694184
Epoch 22, Train Loss 0.836137, Valid_loss 1.349163
Epoch 23, Train Loss 0.838077, Valid_loss 1.411628
Epoch 24, Train Loss 0.828205, Valid_loss 1.357794
Epoch 25, Train Loss 0.835034, Valid_loss 1.363021
Epoch 26, Train Loss 0.827756, Valid_loss 1.376502
Epoch 27, Train Loss 0.829758, Valid_loss 1.377026
Epoch 28, Train Loss 0.829136, Valid_loss 1.370947
Epoch 29, Train Loss 0.835616, Valid_loss 1.427991
Epoch 30, Train Loss 0.844956, Valid_loss 1.381902
Epoch 31, Train Loss 0.861674, Valid_loss 1.367712
Epoch 32, Train Loss 0.839067, Valid_loss 1.410777
Epoch 33, Train Loss 0.877245, Valid_loss 1.429349
Epoch 34, Train Loss 0.845111, Valid_loss 1.537284
Epoch 35, Train Loss 0.833131, Valid_loss 1.776693
Epoch 36, Train Loss 0.835627, Valid_loss 1.537872
Epoch 37, Train Loss 0.827449, Valid_loss 1.498503
Epoch 38, Train Loss 0.834648, Valid_loss 1.448234
Epoch 39, Train Loss 0.829980, Valid_loss 1.578977
Epoch 40, Train Loss 0.831138, Valid_loss 1.457133
Epoch 41, Train Loss 0.820891, Valid_loss 1.694876
Epoch 42, Train Loss 0.834560, Valid_loss 1.655804
Epoch 43, Train Loss 0.836304, Valid_loss 1.466473
Epoch 44, Train Loss 0.826710, Valid_loss 1.415073
Epoch 45, Train Loss 0.822481, Valid_loss 1.409358
Epoch 46, Train Loss 0.825477, Valid_loss 1.384266
Epoch 47, Train Loss 0.828073, Valid_loss 1.374682
Epoch 48, Train Loss 0.816131, Valid_loss 1.619478
Epoch 49, Train Loss 0.843387, Valid_loss 1.369850
Epoch 50, Train Loss 0.834964, Valid_loss 1.370651
Epoch 51, Train Loss 0.825009, Valid_loss 1.371877
Epoch 52, Train Loss 0.818749, Valid_loss 1.363465
Epoch 53, Train Loss 0.818105, Valid_loss 1.387078
Epoch 54, Train Loss 0.820217, Valid_loss 1.358558
Epoch 55, Train Loss 0.823067, Valid_loss 1.356234
Epoch 56, Train Loss 0.827727, Valid_loss 1.360732
Epoch 57, Train Loss 0.817302, Valid_loss 1.361355
[I 2025-08-28 14:58:33,462] Trial 2 finished with value: 1.349162589419972 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.0, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.7250678363171491.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17876.68 MB
Memory Reserved: 17896.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 321.01 MB
Memory Reserved: 360.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17877.65 MB
Memory Reserved: 17896.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 320.84 MB
Memory Reserved: 360.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 14:58:35,219] Trial 3 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 17876.84 MB
Memory Reserved: 17896.00 MB
cuda
Epoch 1, Train Loss 0.927336, Valid_loss 1.702482
Epoch 2, Train Loss 0.881051, Valid_loss 1.314622
Epoch 3, Train Loss 0.885634, Valid_loss 1.471043
Epoch 4, Train Loss 0.868111, Valid_loss 1.649584
Epoch 5, Train Loss 0.850582, Valid_loss 1.495165
Epoch 6, Train Loss 0.858207, Valid_loss 1.735010
Epoch 7, Train Loss 0.856213, Valid_loss 1.607182
Epoch 8, Train Loss 0.875490, Valid_loss 1.936759
Epoch 9, Train Loss 0.871577, Valid_loss 1.565978
Epoch 10, Train Loss 0.857093, Valid_loss 2.241974
Epoch 11, Train Loss 0.867020, Valid_loss 1.534619
Epoch 12, Train Loss 0.858170, Valid_loss 1.572473
Epoch 13, Train Loss 0.848779, Valid_loss 1.659555
Epoch 14, Train Loss 0.847794, Valid_loss 1.584971
Epoch 15, Train Loss 0.846115, Valid_loss 1.869210
Epoch 16, Train Loss 0.836463, Valid_loss 1.400720
Epoch 17, Train Loss 0.850489, Valid_loss 1.449572
Epoch 18, Train Loss 0.844184, Valid_loss 1.347422
Epoch 19, Train Loss 0.847486, Valid_loss 1.324858
Epoch 20, Train Loss 0.832857, Valid_loss 1.494930
Epoch 21, Train Loss 0.819802, Valid_loss 1.933236
Epoch 22, Train Loss 0.850308, Valid_loss 1.335054
Epoch 23, Train Loss 0.830226, Valid_loss 1.402272
Epoch 24, Train Loss 0.836178, Valid_loss 1.333660
Epoch 25, Train Loss 0.829544, Valid_loss 1.346107
Epoch 26, Train Loss 0.825094, Valid_loss 1.360322
Epoch 27, Train Loss 0.833002, Valid_loss 1.365706
Epoch 28, Train Loss 0.841953, Valid_loss 1.788159
Epoch 29, Train Loss 0.858086, Valid_loss 1.634118
Epoch 30, Train Loss 0.855368, Valid_loss 1.613442
Epoch 31, Train Loss 0.834351, Valid_loss 1.470343
Epoch 32, Train Loss 0.836888, Valid_loss 1.510197
Epoch 33, Train Loss 0.838098, Valid_loss 1.429926
Epoch 34, Train Loss 0.833151, Valid_loss 1.412930
Epoch 35, Train Loss 0.837017, Valid_loss 1.436989
Epoch 36, Train Loss 0.843345, Valid_loss 1.406265
Epoch 37, Train Loss 0.833886, Valid_loss 1.431086
Epoch 38, Train Loss 0.829694, Valid_loss 1.424626
Epoch 39, Train Loss 0.828031, Valid_loss 1.415072
Epoch 40, Train Loss 0.844751, Valid_loss 1.388165
Epoch 41, Train Loss 0.821631, Valid_loss 1.402860
Epoch 42, Train Loss 0.847332, Valid_loss 1.559026
Epoch 43, Train Loss 0.825350, Valid_loss 1.436566
Epoch 44, Train Loss 0.827841, Valid_loss 1.460972
Epoch 45, Train Loss 0.845813, Valid_loss 1.445050
Epoch 46, Train Loss 0.831514, Valid_loss 1.432373
Epoch 47, Train Loss 0.827088, Valid_loss 1.436533
Epoch 48, Train Loss 0.844793, Valid_loss 1.411687
Epoch 49, Train Loss 0.821249, Valid_loss 1.438387
Epoch 50, Train Loss 0.845739, Valid_loss 1.483345
Epoch 51, Train Loss 0.822386, Valid_loss 1.440225
Epoch 52, Train Loss 0.820868, Valid_loss 1.448687
Epoch 53, Train Loss 0.826850, Valid_loss 1.426334
Epoch 54, Train Loss 0.821849, Valid_loss 1.415149
Epoch 55, Train Loss 0.822274, Valid_loss 1.429638
Epoch 56, Train Loss 0.821547, Valid_loss 1.416449
Epoch 57, Train Loss 0.822060, Valid_loss 1.453041
Epoch 58, Train Loss 0.826122, Valid_loss 1.419506
Epoch 59, Train Loss 0.817821, Valid_loss 1.458214
Epoch 60, Train Loss 0.820892, Valid_loss 1.411363
Epoch 61, Train Loss 0.825959, Valid_loss 1.388554
Epoch 62, Train Loss 0.823439, Valid_loss 1.386000
Epoch 63, Train Loss 0.822547, Valid_loss 1.373880
Epoch 64, Train Loss 0.816367, Valid_loss 1.359575
Epoch 65, Train Loss 0.836974, Valid_loss 1.391684
Epoch 66, Train Loss 0.828714, Valid_loss 1.469047
[I 2025-08-28 15:23:07,516] Trial 4 finished with value: 1.314622234214436 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.0, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.7250678363171491.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=9, batch_size=1 -> steps=9
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.006836, Valid_loss 1.263009
Epoch 2, Train Loss 0.823846, Valid_loss 1.197350
Epoch 3, Train Loss 0.711294, Valid_loss 1.115265
Epoch 4, Train Loss 0.647028, Valid_loss 1.150762
Epoch 5, Train Loss 0.627114, Valid_loss 1.201941
Epoch 6, Train Loss 0.597540, Valid_loss 1.135904
Epoch 7, Train Loss 0.607887, Valid_loss 1.110366
Epoch 8, Train Loss 0.518325, Valid_loss 1.131157
Epoch 9, Train Loss 0.555394, Valid_loss 1.090545
Epoch 10, Train Loss 0.464376, Valid_loss 1.082389
Epoch 11, Train Loss 0.486223, Valid_loss 1.144125
Epoch 12, Train Loss 0.491576, Valid_loss 1.070939
Epoch 13, Train Loss 0.444393, Valid_loss 1.110745
Epoch 14, Train Loss 0.421639, Valid_loss 1.131723
Epoch 15, Train Loss 0.453737, Valid_loss 1.161427
Epoch 16, Train Loss 0.457507, Valid_loss 1.084292
Epoch 17, Train Loss 0.408841, Valid_loss 1.174981
Epoch 18, Train Loss 0.386637, Valid_loss 1.128186
Epoch 19, Train Loss 0.382883, Valid_loss 1.181517
Epoch 20, Train Loss 0.516046, Valid_loss 1.125292
Epoch 21, Train Loss 0.414518, Valid_loss 1.230222
Epoch 22, Train Loss 0.423690, Valid_loss 1.077577
Epoch 23, Train Loss 0.383270, Valid_loss 1.165713
Epoch 24, Train Loss 0.372620, Valid_loss 1.019038
Epoch 25, Train Loss 0.367772, Valid_loss 1.097808
Epoch 26, Train Loss 0.342695, Valid_loss 1.048233
Epoch 27, Train Loss 0.376159, Valid_loss 1.063774
Epoch 28, Train Loss 0.367779, Valid_loss 1.243529
Epoch 29, Train Loss 0.389282, Valid_loss 1.076053
Epoch 30, Train Loss 0.391178, Valid_loss 1.089168
Epoch 31, Train Loss 0.323444, Valid_loss 1.102252
Epoch 32, Train Loss 0.308998, Valid_loss 1.095643
Epoch 33, Train Loss 0.330496, Valid_loss 1.152266
Epoch 34, Train Loss 0.297209, Valid_loss 0.987476
Epoch 35, Train Loss 0.270091, Valid_loss 1.080599
Epoch 36, Train Loss 0.292208, Valid_loss 1.145751
Epoch 37, Train Loss 0.323266, Valid_loss 1.175559
Epoch 38, Train Loss 0.295641, Valid_loss 0.998560
Epoch 39, Train Loss 0.286109, Valid_loss 1.171542
Epoch 40, Train Loss 0.274148, Valid_loss 1.084686
Epoch 41, Train Loss 0.393264, Valid_loss 1.207470
Epoch 42, Train Loss 0.230814, Valid_loss 1.181276
Epoch 43, Train Loss 0.270168, Valid_loss 1.139265
Epoch 44, Train Loss 0.301590, Valid_loss 1.166213
Epoch 45, Train Loss 0.279243, Valid_loss 1.199881
Epoch 46, Train Loss 0.224718, Valid_loss 1.211345
Epoch 47, Train Loss 0.296351, Valid_loss 1.043105
Epoch 48, Train Loss 0.237843, Valid_loss 1.094223
Epoch 49, Train Loss 0.267998, Valid_loss 1.017428
Epoch 50, Train Loss 0.311422, Valid_loss 1.275769
Epoch 51, Train Loss 0.302200, Valid_loss 1.086055
Epoch 52, Train Loss 0.243860, Valid_loss 0.942546
Epoch 53, Train Loss 0.247719, Valid_loss 1.054343
Epoch 54, Train Loss 0.232063, Valid_loss 1.111259
환자ID=P1304 -- true: [[2]] -- pred: tensor([[-1.8118,  0.8173, -1.0204]], device='cuda:0')
환자ID=P1462 -- true: [[1]] -- pred: tensor([[-1.9406,  0.4996, -0.6484]], device='cuda:0')
환자ID=P1558 -- true: [[0]] -- pred: tensor([[ 2.4697, -1.2997, -2.9755]], device='cuda:0')
환자ID=P1582 -- true: [[0]] -- pred: tensor([[ 2.4964, -1.3056, -2.9642]], device='cuda:0')
환자ID=P1602 -- true: [[1]] -- pred: tensor([[ 0.2663, -0.0033, -2.3407]], device='cuda:0')
환자ID=P1617 -- true: [[2]] -- pred: tensor([[-1.9074,  0.6325, -0.7992]], device='cuda:0')
환자ID=P1678 -- true: [[0]] -- pred: tensor([[ 2.5282, -1.3244, -2.9472]], device='cuda:0')
환자ID=P1718 -- true: [[0]] -- pred: tensor([[ 2.3963, -1.2220, -2.9522]], device='cuda:0')
환자ID=P1735 -- true: [[1]] -- pred: tensor([[-1.8638,  0.6379, -0.8128]], device='cuda:0')
Best performance: Epoch 52, Loss 0.243860, Test ACC 0.666667, Test AUC 0.777778, Test Recall 0.555556, Test Precision 0.433333
Confusion Matrix:
 [[4 0 0]
 [1 2 0]
 [0 2 0]]
✅ Total valid splits used: 1
🔁 Repeat 4, Fold 1
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 456327, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 456327, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 8, 1: 12, 0: 13}
cell type :  ACAGCCGCAAGCGAGT-1-1          cardiac muscle cell
ATATCCTGTCCCTAAA-1-1          cardiac muscle cell
CAATGACCAGTTGTCA-1-1          cardiac muscle cell
CTAGACACAAGGTTGG-1-1          cardiac muscle cell
ATCGTCCGTATTTCTC-1-1          cardiac muscle cell
                                   ...           
TCGTGGGAGAGTCTTC-1-62               pericyte cell
GGTAGAGTCACCGCTT-1-62    cardiac endothelial cell
GCACGGTGTCCAGCGT-1-62               pericyte cell
TTGTTCAAGAGAGTGA-1-62               pericyte cell
AGATCCATCGATTGGT-1-62    cardiac endothelial cell
Name: manual_annotation, Length: 136362, dtype: string
cell type annotation :  ACAGCCGCAAGCGAGT-1-1          cardiac muscle cell
ATATCCTGTCCCTAAA-1-1          cardiac muscle cell
CAATGACCAGTTGTCA-1-1          cardiac muscle cell
CTAGACACAAGGTTGG-1-1          cardiac muscle cell
ATCGTCCGTATTTCTC-1-1          cardiac muscle cell
                                   ...           
TCGTGGGAGAGTCTTC-1-62               pericyte cell
GGTAGAGTCACCGCTT-1-62    cardiac endothelial cell
GCACGGTGTCCAGCGT-1-62               pericyte cell
TTGTTCAAGAGAGTGA-1-62               pericyte cell
AGATCCATCGATTGGT-1-62    cardiac endothelial cell
Name: manual_annotation, Length: 136362, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'mesothelial cell', 'macrophage', 'fat cell', 'endocardial cell', 'cardiac neuron', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'lymphocyte', 'mast cell']
라벨별 그룹 개수 {2: 3, 1: 3, 0: 3}
🔍 Split #2
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 33
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 9
  → train 환자 ID: ['P1290', 'P1300', 'P1304', 'P1425', 'P1437', 'P1447', 'P1462', 'P1472', 'P1479', 'P1504', 'P1508', 'P1510', 'P1515', 'P1539', 'P1547', 'P1549', 'P1558', 'P1561', 'P1582', 'P1600', 'P1602', 'P1603', 'P1606', 'P1610', 'P1617', 'P1622', 'P1631', 'P1678', 'P1685', 'P1718', 'P1722', 'P1726', 'P1735']
  → test  환자 ID: ['P1358', 'P1371', 'P1422', 'P1430', 'P1516', 'P1540', 'P1630', 'P1702', 'P1707']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1425, Label: 1
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1539, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1430, Label: 2
    ID: P1516, Label: 0
    ID: P1540, Label: 0
    ID: P1630, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 33
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 33
기존 (train) label_stat 33
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 11
test_p_index 9
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1549, Label=0, 셀개수=11709
→ valid 환자 ID 및 라벨:
   총 개수: 11
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1617, Label=2, 셀개수=17986
→ test 환자 ID 및 라벨:
   총 개수: 9
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1707, Label=1, 셀개수=9517
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0              cardiac muscle cell
1              cardiac muscle cell
2              cardiac muscle cell
3              cardiac muscle cell
4              cardiac muscle cell
                    ...           
592684               pericyte cell
592685    cardiac endothelial cell
592686               pericyte cell
592687               pericyte cell
592688    cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.40it/s]  2%|▏         | 2/100 [00:00<00:11,  8.59it/s]  3%|▎         | 3/100 [00:00<00:11,  8.42it/s]  4%|▍         | 4/100 [00:00<00:11,  8.36it/s]  5%|▌         | 5/100 [00:00<00:11,  8.30it/s]  6%|▌         | 6/100 [00:00<00:11,  8.29it/s]  7%|▋         | 7/100 [00:00<00:11,  8.16it/s]  8%|▊         | 8/100 [00:00<00:11,  8.14it/s]  9%|▉         | 9/100 [00:01<00:11,  8.12it/s] 10%|█         | 10/100 [00:01<00:11,  8.14it/s] 11%|█         | 11/100 [00:01<00:10,  8.19it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.34it/s] 13%|█▎        | 13/100 [00:01<00:10,  8.26it/s] 14%|█▍        | 14/100 [00:01<00:10,  8.19it/s] 15%|█▌        | 15/100 [00:01<00:10,  8.24it/s] 16%|█▌        | 16/100 [00:01<00:10,  8.15it/s] 17%|█▋        | 17/100 [00:02<00:10,  8.20it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.24it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.25it/s] 20%|██        | 20/100 [00:02<00:09,  8.12it/s] 21%|██        | 21/100 [00:02<00:09,  8.20it/s] 22%|██▏       | 22/100 [00:02<00:09,  8.20it/s] 23%|██▎       | 23/100 [00:02<00:09,  8.23it/s] 24%|██▍       | 24/100 [00:02<00:09,  8.23it/s] 25%|██▌       | 25/100 [00:03<00:09,  8.17it/s] 26%|██▌       | 26/100 [00:03<00:09,  8.19it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.33it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.37it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.40it/s] 30%|███       | 30/100 [00:03<00:08,  8.38it/s] 31%|███       | 31/100 [00:03<00:08,  8.41it/s] 32%|███▏      | 32/100 [00:03<00:08,  8.39it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.39it/s] 34%|███▍      | 34/100 [00:04<00:07,  8.41it/s] 35%|███▌      | 35/100 [00:04<00:07,  8.35it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.17it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.22it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.26it/s] 39%|███▉      | 39/100 [00:04<00:07,  8.20it/s] 40%|████      | 40/100 [00:04<00:07,  8.05it/s] 41%|████      | 41/100 [00:04<00:07,  7.90it/s] 42%|████▏     | 42/100 [00:05<00:07,  7.94it/s] 43%|████▎     | 43/100 [00:05<00:07,  7.82it/s] 44%|████▍     | 44/100 [00:05<00:07,  7.95it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.07it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.11it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.14it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.03it/s] 49%|████▉     | 49/100 [00:05<00:06,  8.01it/s] 50%|█████     | 50/100 [00:06<00:06,  7.98it/s] 51%|█████     | 51/100 [00:06<00:06,  8.13it/s] 52%|█████▏    | 52/100 [00:06<00:05,  8.23it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.27it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.25it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.22it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.05it/s] 57%|█████▋    | 57/100 [00:06<00:05,  8.12it/s] 58%|█████▊    | 58/100 [00:07<00:05,  8.20it/s] 59%|█████▉    | 59/100 [00:07<00:04,  8.30it/s] 60%|██████    | 60/100 [00:07<00:04,  8.13it/s] 61%|██████    | 61/100 [00:07<00:04,  8.26it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.04it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.04it/s] 64%|██████▍   | 64/100 [00:07<00:04,  7.94it/s] 65%|██████▌   | 65/100 [00:07<00:04,  7.98it/s] 66%|██████▌   | 66/100 [00:08<00:04,  8.08it/s] 67%|██████▋   | 67/100 [00:08<00:04,  8.07it/s] 68%|██████▊   | 68/100 [00:08<00:04,  7.91it/s] 69%|██████▉   | 69/100 [00:08<00:03,  8.11it/s] 70%|███████   | 70/100 [00:08<00:03,  8.15it/s] 71%|███████   | 71/100 [00:08<00:03,  7.97it/s] 72%|███████▏  | 72/100 [00:08<00:03,  7.88it/s] 73%|███████▎  | 73/100 [00:08<00:03,  7.74it/s] 74%|███████▍  | 74/100 [00:09<00:03,  7.77it/s] 75%|███████▌  | 75/100 [00:09<00:03,  7.62it/s] 76%|███████▌  | 76/100 [00:09<00:03,  7.79it/s] 77%|███████▋  | 77/100 [00:09<00:02,  7.83it/s] 78%|███████▊  | 78/100 [00:09<00:02,  8.06it/s] 79%|███████▉  | 79/100 [00:09<00:02,  7.94it/s] 80%|████████  | 80/100 [00:09<00:02,  8.03it/s] 81%|████████  | 81/100 [00:09<00:02,  8.02it/s] 82%|████████▏ | 82/100 [00:10<00:02,  7.88it/s] 83%|████████▎ | 83/100 [00:10<00:02,  7.90it/s] 84%|████████▍ | 84/100 [00:10<00:02,  7.93it/s] 85%|████████▌ | 85/100 [00:10<00:01,  7.89it/s] 86%|████████▌ | 86/100 [00:10<00:01,  7.88it/s] 87%|████████▋ | 87/100 [00:10<00:01,  7.89it/s] 88%|████████▊ | 88/100 [00:10<00:01,  7.92it/s] 89%|████████▉ | 89/100 [00:10<00:01,  7.78it/s] 90%|█████████ | 90/100 [00:11<00:01,  7.88it/s] 91%|█████████ | 91/100 [00:11<00:01,  7.97it/s] 92%|█████████▏| 92/100 [00:11<00:01,  7.85it/s] 93%|█████████▎| 93/100 [00:11<00:00,  7.75it/s] 94%|█████████▍| 94/100 [00:11<00:00,  7.90it/s] 95%|█████████▌| 95/100 [00:11<00:00,  7.86it/s] 96%|█████████▌| 96/100 [00:11<00:00,  7.93it/s] 97%|█████████▋| 97/100 [00:12<00:00,  7.69it/s] 98%|█████████▊| 98/100 [00:12<00:00,  7.73it/s] 99%|█████████▉| 99/100 [00:12<00:00,  7.68it/s]100%|██████████| 100/100 [00:12<00:00,  7.64it/s]100%|██████████| 100/100 [00:12<00:00,  8.06it/s]
[I 2025-08-28 15:55:16,629] A new study created in memory with name: no-name-035adf90-6514-4d2f-a610-cf781b05f8c6
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.973440, Valid_loss 1.206919
Epoch 2, Train Loss 0.850174, Valid_loss 1.279345
Epoch 3, Train Loss 0.722637, Valid_loss 0.873614
Epoch 4, Train Loss 0.623662, Valid_loss 0.898699
Epoch 5, Train Loss 0.553615, Valid_loss 0.954475
Epoch 6, Train Loss 0.527129, Valid_loss 0.931372
Epoch 7, Train Loss 0.500824, Valid_loss 0.863402
Epoch 8, Train Loss 0.489876, Valid_loss 0.876994
Epoch 9, Train Loss 0.427970, Valid_loss 0.703995
Epoch 10, Train Loss 0.464861, Valid_loss 0.831437
Epoch 11, Train Loss 0.405336, Valid_loss 1.213625
Epoch 12, Train Loss 0.452694, Valid_loss 1.181026
Epoch 13, Train Loss 0.360886, Valid_loss 0.799124
Epoch 14, Train Loss 0.379259, Valid_loss 0.953239
Epoch 15, Train Loss 0.317892, Valid_loss 1.124491
Epoch 16, Train Loss 0.378116, Valid_loss 1.024598
Epoch 17, Train Loss 0.345050, Valid_loss 0.844643
Epoch 18, Train Loss 0.338457, Valid_loss 0.920834
Epoch 19, Train Loss 0.349051, Valid_loss 1.181248
Epoch 20, Train Loss 0.309192, Valid_loss 0.896572
Epoch 21, Train Loss 0.283135, Valid_loss 0.932395
Epoch 22, Train Loss 0.308745, Valid_loss 0.843917
Epoch 23, Train Loss 0.278181, Valid_loss 1.052502
Epoch 24, Train Loss 0.293392, Valid_loss 0.969998
Epoch 25, Train Loss 0.261071, Valid_loss 1.190346
Epoch 26, Train Loss 0.264353, Valid_loss 1.035622
Epoch 27, Train Loss 0.274242, Valid_loss 0.975482
Epoch 28, Train Loss 0.258914, Valid_loss 0.878469
Epoch 29, Train Loss 0.253468, Valid_loss 0.995349
Epoch 30, Train Loss 0.275917, Valid_loss 1.133477
Epoch 31, Train Loss 0.246270, Valid_loss 0.920329
Epoch 32, Train Loss 0.255422, Valid_loss 0.811979
Epoch 33, Train Loss 0.235642, Valid_loss 0.872139
Epoch 34, Train Loss 0.247072, Valid_loss 1.106094
Epoch 35, Train Loss 0.224394, Valid_loss 0.887623
Epoch 36, Train Loss 0.214801, Valid_loss 0.962532
Epoch 37, Train Loss 0.260363, Valid_loss 1.089279
Epoch 38, Train Loss 0.231336, Valid_loss 1.221485
Epoch 39, Train Loss 0.202140, Valid_loss 0.946366
Epoch 40, Train Loss 0.193050, Valid_loss 0.798061
Epoch 41, Train Loss 0.223079, Valid_loss 0.847781
Epoch 42, Train Loss 0.243621, Valid_loss 1.160155
Epoch 43, Train Loss 0.196450, Valid_loss 0.831956
Epoch 44, Train Loss 0.231473, Valid_loss 1.020098
Epoch 45, Train Loss 0.203129, Valid_loss 1.010456
Epoch 46, Train Loss 0.184629, Valid_loss 0.979443
Epoch 47, Train Loss 0.176904, Valid_loss 1.333521
Epoch 48, Train Loss 0.221190, Valid_loss 0.994776
Epoch 49, Train Loss 0.167438, Valid_loss 0.872635
Epoch 50, Train Loss 0.189160, Valid_loss 1.107446
Epoch 51, Train Loss 0.155145, Valid_loss 1.176982
Epoch 52, Train Loss 0.152719, Valid_loss 1.115539
Epoch 53, Train Loss 0.144617, Valid_loss 1.119766
Epoch 54, Train Loss 0.135727, Valid_loss 1.173807
[I 2025-08-28 16:13:13,074] Trial 0 finished with value: 0.7039948857643388 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.0, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.7039948857643388.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 7474.33 MB
Memory Reserved: 7496.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 14656.30 MB
Memory Reserved: 14698.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 7474.30 MB
Memory Reserved: 7496.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 14656.30 MB
Memory Reserved: 14698.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 16:13:14,933] Trial 1 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 7472.98 MB
Memory Reserved: 7496.00 MB
cuda
Epoch 1, Train Loss 1.228335, Valid_loss 1.117349
Epoch 2, Train Loss 1.073278, Valid_loss 1.147181
Epoch 3, Train Loss 0.995643, Valid_loss 1.182696
Epoch 4, Train Loss 0.845166, Valid_loss 0.947437
Epoch 5, Train Loss 0.700715, Valid_loss 0.937967
Epoch 6, Train Loss 0.735575, Valid_loss 0.894599
Epoch 7, Train Loss 0.657931, Valid_loss 0.876717
Epoch 8, Train Loss 0.619039, Valid_loss 0.852023
Epoch 9, Train Loss 0.611190, Valid_loss 0.783705
Epoch 10, Train Loss 0.666335, Valid_loss 0.871476
Epoch 11, Train Loss 0.559664, Valid_loss 0.739572
Epoch 12, Train Loss 0.612005, Valid_loss 0.742374
Epoch 13, Train Loss 0.562089, Valid_loss 0.711697
Epoch 14, Train Loss 0.544187, Valid_loss 0.759241
Epoch 15, Train Loss 0.605372, Valid_loss 0.783627
Epoch 16, Train Loss 0.563274, Valid_loss 0.785629
Epoch 17, Train Loss 0.554415, Valid_loss 0.750124
Epoch 18, Train Loss 0.552007, Valid_loss 0.669054
Epoch 19, Train Loss 0.551003, Valid_loss 0.711458
Epoch 20, Train Loss 0.526179, Valid_loss 0.697464
Epoch 21, Train Loss 0.560363, Valid_loss 0.667517
Epoch 22, Train Loss 0.524177, Valid_loss 0.791069
Epoch 23, Train Loss 0.517013, Valid_loss 0.670289
Epoch 24, Train Loss 0.452700, Valid_loss 0.640784
Epoch 25, Train Loss 0.447847, Valid_loss 0.632740
Epoch 26, Train Loss 0.440860, Valid_loss 0.662560
Epoch 27, Train Loss 0.467026, Valid_loss 0.691576
Epoch 28, Train Loss 0.406479, Valid_loss 0.705605
Epoch 29, Train Loss 0.502758, Valid_loss 0.689472
Epoch 30, Train Loss 0.424872, Valid_loss 0.628517
Epoch 31, Train Loss 0.398721, Valid_loss 0.659770
Epoch 32, Train Loss 0.396058, Valid_loss 0.719529
Epoch 33, Train Loss 0.410255, Valid_loss 0.832872
Epoch 34, Train Loss 0.354652, Valid_loss 0.687003
Epoch 35, Train Loss 0.386176, Valid_loss 0.709392
Epoch 36, Train Loss 0.419363, Valid_loss 0.702908
Epoch 37, Train Loss 0.406115, Valid_loss 0.968278
Epoch 38, Train Loss 0.423533, Valid_loss 0.880407
Epoch 39, Train Loss 0.313181, Valid_loss 0.820501
Epoch 40, Train Loss 0.402317, Valid_loss 0.612710
Epoch 41, Train Loss 0.385764, Valid_loss 0.625179
Epoch 42, Train Loss 0.339264, Valid_loss 0.713639
Epoch 43, Train Loss 0.338832, Valid_loss 0.913109
Epoch 44, Train Loss 0.396156, Valid_loss 0.883644
Epoch 45, Train Loss 0.380991, Valid_loss 0.629481
Epoch 46, Train Loss 0.362412, Valid_loss 0.641390
Epoch 47, Train Loss 0.330242, Valid_loss 0.768419
Epoch 48, Train Loss 0.306331, Valid_loss 0.819329
Epoch 49, Train Loss 0.281220, Valid_loss 0.772321
Epoch 50, Train Loss 0.279839, Valid_loss 0.827651
Epoch 51, Train Loss 0.304428, Valid_loss 0.818752
Epoch 52, Train Loss 0.324077, Valid_loss 0.844463
Epoch 53, Train Loss 0.364546, Valid_loss 0.854734
[I 2025-08-28 16:40:11,460] Trial 2 finished with value: 0.612709947607734 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.612709947607734.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.047148, Valid_loss 1.408701
Epoch 2, Train Loss 0.988756, Valid_loss 1.274239
Epoch 3, Train Loss 0.953496, Valid_loss 1.250921
Epoch 4, Train Loss 0.940086, Valid_loss 1.303324
Epoch 5, Train Loss 0.931861, Valid_loss 1.332128
Epoch 6, Train Loss 0.926245, Valid_loss 1.335426
Epoch 7, Train Loss 0.923788, Valid_loss 1.372483
Epoch 8, Train Loss 0.928995, Valid_loss 1.327292
Epoch 9, Train Loss 0.934527, Valid_loss 1.343617
Epoch 10, Train Loss 0.917601, Valid_loss 1.334938
Epoch 11, Train Loss 0.921452, Valid_loss 1.360655
Epoch 12, Train Loss 0.923986, Valid_loss 1.373873
Epoch 13, Train Loss 0.918919, Valid_loss 1.389053
Epoch 14, Train Loss 0.922861, Valid_loss 1.395561
Epoch 15, Train Loss 0.919378, Valid_loss 1.389415
Epoch 16, Train Loss 0.918752, Valid_loss 1.400065
Epoch 17, Train Loss 0.917302, Valid_loss 1.391742
Epoch 18, Train Loss 0.920008, Valid_loss 1.409124
Epoch 19, Train Loss 0.918116, Valid_loss 1.401645
Epoch 20, Train Loss 0.928267, Valid_loss 1.390823
Epoch 21, Train Loss 0.917789, Valid_loss 1.399409
Epoch 22, Train Loss 0.918000, Valid_loss 1.421166
Epoch 23, Train Loss 0.918576, Valid_loss 1.397247
Epoch 24, Train Loss 0.918822, Valid_loss 1.427001
Epoch 25, Train Loss 0.918292, Valid_loss 1.421253
Epoch 26, Train Loss 0.918002, Valid_loss 1.399816
Epoch 27, Train Loss 0.918107, Valid_loss 1.412250
Epoch 28, Train Loss 0.920665, Valid_loss 1.415841
Epoch 29, Train Loss 0.918823, Valid_loss 1.403017
Epoch 30, Train Loss 0.918637, Valid_loss 1.401489
Epoch 31, Train Loss 0.918345, Valid_loss 1.407552
Epoch 32, Train Loss 0.917012, Valid_loss 1.402840
Epoch 33, Train Loss 0.919601, Valid_loss 1.417468
Epoch 34, Train Loss 0.917326, Valid_loss 1.412126
Epoch 35, Train Loss 0.918581, Valid_loss 1.406976
Epoch 36, Train Loss 0.918476, Valid_loss 1.414160
Epoch 37, Train Loss 0.922409, Valid_loss 1.410065
Epoch 38, Train Loss 0.917353, Valid_loss 1.403545
Epoch 39, Train Loss 0.919448, Valid_loss 1.400221
Epoch 40, Train Loss 0.918826, Valid_loss 1.415349
Epoch 41, Train Loss 0.918973, Valid_loss 1.403863
Epoch 42, Train Loss 0.918546, Valid_loss 1.392344
Epoch 43, Train Loss 0.918066, Valid_loss 1.404763
Epoch 44, Train Loss 0.917694, Valid_loss 1.413986
Epoch 45, Train Loss 0.917925, Valid_loss 1.406652
Epoch 46, Train Loss 0.919218, Valid_loss 1.409885
Epoch 47, Train Loss 0.919160, Valid_loss 1.404811
Epoch 48, Train Loss 0.921562, Valid_loss 1.415682
Epoch 49, Train Loss 0.918985, Valid_loss 1.412547
Epoch 50, Train Loss 0.920944, Valid_loss 1.404346
Epoch 51, Train Loss 0.916151, Valid_loss 1.406473
Epoch 52, Train Loss 0.916183, Valid_loss 1.409877
[I 2025-08-28 16:58:33,849] Trial 3 finished with value: 1.2509212548082524 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.612709947607734.
선택된 trial params: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=11, batch_size=1 -> steps=11
👉 test  samples=9, batch_size=1 -> steps=9
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.971725, Valid_loss 1.238630
Epoch 2, Train Loss 0.947751, Valid_loss 1.304368
Epoch 3, Train Loss 0.952099, Valid_loss 1.267894
Epoch 4, Train Loss 0.941842, Valid_loss 1.144212
Epoch 5, Train Loss 0.894871, Valid_loss 1.313619
Epoch 6, Train Loss 0.821552, Valid_loss 0.875660
Epoch 7, Train Loss 0.700295, Valid_loss 0.847723
Epoch 8, Train Loss 0.660950, Valid_loss 0.758122
Epoch 9, Train Loss 0.587282, Valid_loss 0.790120
Epoch 10, Train Loss 0.628056, Valid_loss 0.688293
Epoch 11, Train Loss 0.517673, Valid_loss 0.675101
Epoch 12, Train Loss 0.507766, Valid_loss 0.659487
Epoch 13, Train Loss 0.500385, Valid_loss 0.701647
Epoch 14, Train Loss 0.453372, Valid_loss 0.774836
Epoch 15, Train Loss 0.493465, Valid_loss 0.744018
Epoch 16, Train Loss 0.490584, Valid_loss 0.773638
Epoch 17, Train Loss 0.489478, Valid_loss 0.754434
Epoch 18, Train Loss 0.407198, Valid_loss 0.749472
Epoch 19, Train Loss 0.421385, Valid_loss 0.854004
Epoch 20, Train Loss 0.386830, Valid_loss 0.643297
Epoch 21, Train Loss 0.485794, Valid_loss 0.730067
Epoch 22, Train Loss 0.348974, Valid_loss 0.695690
Epoch 23, Train Loss 0.430916, Valid_loss 0.826873
Epoch 24, Train Loss 0.352766, Valid_loss 0.580449
Epoch 25, Train Loss 0.324008, Valid_loss 0.944981
Epoch 26, Train Loss 0.407188, Valid_loss 0.755434
Epoch 27, Train Loss 0.381330, Valid_loss 0.632112
Epoch 28, Train Loss 0.351731, Valid_loss 0.655842
Epoch 29, Train Loss 0.379852, Valid_loss 0.920121
Epoch 30, Train Loss 0.302865, Valid_loss 0.746983
Epoch 31, Train Loss 0.298849, Valid_loss 1.162149
Epoch 32, Train Loss 0.337715, Valid_loss 1.003126
Epoch 33, Train Loss 0.479370, Valid_loss 0.773212
Epoch 34, Train Loss 0.346603, Valid_loss 0.678545
Epoch 35, Train Loss 0.301781, Valid_loss 0.641520
Epoch 36, Train Loss 0.420618, Valid_loss 0.995612
Epoch 37, Train Loss 0.315215, Valid_loss 0.874994
Epoch 38, Train Loss 0.344961, Valid_loss 0.571057
Epoch 39, Train Loss 0.271740, Valid_loss 0.711516
Epoch 40, Train Loss 0.229126, Valid_loss 1.140681
Epoch 41, Train Loss 0.365952, Valid_loss 1.194892
Epoch 42, Train Loss 0.304445, Valid_loss 0.793877
Epoch 43, Train Loss 0.321705, Valid_loss 0.890340
Epoch 44, Train Loss 0.353920, Valid_loss 0.663938
Epoch 45, Train Loss 0.255522, Valid_loss 0.730324
Epoch 46, Train Loss 0.290566, Valid_loss 1.122638
Epoch 47, Train Loss 0.306331, Valid_loss 0.613649
Epoch 48, Train Loss 0.308238, Valid_loss 0.805153
Epoch 49, Train Loss 0.276437, Valid_loss 0.987430
Epoch 50, Train Loss 0.335936, Valid_loss 0.849713
Epoch 51, Train Loss 0.261290, Valid_loss 0.778333
Epoch 52, Train Loss 0.279822, Valid_loss 0.978243
Epoch 53, Train Loss 0.275006, Valid_loss 1.011028
환자ID=P1358 -- true: [[2]] -- pred: tensor([[-3.7614,  0.3091,  0.3007]], device='cuda:0')
환자ID=P1371 -- true: [[2]] -- pred: tensor([[-3.5023,  0.4267,  0.0212]], device='cuda:0')
환자ID=P1422 -- true: [[1]] -- pred: tensor([[-3.4271,  0.4939, -0.1088]], device='cuda:0')
환자ID=P1430 -- true: [[2]] -- pred: tensor([[-3.7176,  0.3307,  0.2306]], device='cuda:0')
환자ID=P1516 -- true: [[0]] -- pred: tensor([[ 2.8680, -1.6494, -4.9049]], device='cuda:0')
환자ID=P1540 -- true: [[0]] -- pred: tensor([[ 3.0673, -2.2728, -4.8972]], device='cuda:0')
환자ID=P1630 -- true: [[1]] -- pred: tensor([[-3.7632,  0.2944,  0.3244]], device='cuda:0')
환자ID=P1702 -- true: [[0]] -- pred: tensor([[ 3.0810, -2.2419, -4.9249]], device='cuda:0')
환자ID=P1707 -- true: [[1]] -- pred: tensor([[-3.6945,  0.3423,  0.2085]], device='cuda:0')
Best performance: Epoch 38, Loss 0.344961, Test ACC 0.555556, Test AUC 0.851852, Test Recall 0.555556, Test Precision 0.466667
Confusion Matrix:
 [[3 0 0]
 [0 2 1]
 [0 3 0]]
✅ Total valid splits used: 2
🔁 Repeat 4, Fold 2
cell type :  TTCTTCCGTTCAACGT-1-0              cardiac muscle cell
CATCCACCATCTAACG-1-0              cardiac muscle cell
ACCCAAACAGCTAACT-1-0              cardiac muscle cell
AAGGAATCAACTGGTT-1-0              cardiac muscle cell
TACCCGTAGCGTGCTC-1-0              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 474271, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0              cardiac muscle cell
CATCCACCATCTAACG-1-0              cardiac muscle cell
ACCCAAACAGCTAACT-1-0              cardiac muscle cell
AAGGAATCAACTGGTT-1-0              cardiac muscle cell
TACCCGTAGCGTGCTC-1-0              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 474271, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  AGTTAGCCATGCCATA-1-11         cardiac muscle cell
ACCACAATCTGTCTCG-1-11         cardiac muscle cell
CCGCAAGAGGAAGTGA-1-11         cardiac muscle cell
ACAACCACAGCCTTCT-1-11         cardiac muscle cell
ACTCTCGCAGGAAGTC-1-11         cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 118418, dtype: string
cell type annotation :  AGTTAGCCATGCCATA-1-11         cardiac muscle cell
ACCACAATCTGTCTCG-1-11         cardiac muscle cell
CCGCAAGAGGAAGTGA-1-11         cardiac muscle cell
ACAACCACAGCCTTCT-1-11         cardiac muscle cell
ACTCTCGCAGGAAGTC-1-11         cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 118418, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac endothelial cell', 'cardiac ventricle fibroblast', 'endothelial cell of lymphatic vessel', 'cardiac neuron', 'mast cell', 'vascular associated smooth muscle cell', 'pericyte cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {1: 3, 2: 2, 0: 3}
🔍 Split #3
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1290', 'P1300', 'P1304', 'P1358', 'P1371', 'P1422', 'P1430', 'P1447', 'P1462', 'P1479', 'P1504', 'P1508', 'P1510', 'P1516', 'P1539', 'P1540', 'P1547', 'P1549', 'P1558', 'P1582', 'P1602', 'P1603', 'P1606', 'P1610', 'P1617', 'P1622', 'P1630', 'P1631', 'P1678', 'P1702', 'P1707', 'P1718', 'P1722', 'P1735']
  → test  환자 ID: ['P1425', 'P1437', 'P1472', 'P1515', 'P1561', 'P1600', 'P1685', 'P1726']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1430, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1479, Label: 1
    ID: P1504, Label: 2
    ID: P1508, Label: 1
    ID: P1510, Label: 1
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1582, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1425, Label: 1
    ID: P1437, Label: 2
    ID: P1472, Label: 2
    ID: P1515, Label: 0
    ID: P1561, Label: 0
    ID: P1600, Label: 0
    ID: P1685, Label: 1
    ID: P1726, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1540, Label=0, 셀개수=11638
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1603, Label=0, 셀개수=10638
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1726, Label=1, 셀개수=12389
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0              cardiac muscle cell
1              cardiac muscle cell
2              cardiac muscle cell
3              cardiac muscle cell
4              cardiac muscle cell
                    ...           
592684    cardiac endothelial cell
592685    cardiac endothelial cell
592686    cardiac endothelial cell
592687    cardiac endothelial cell
592688    cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:12,  8.10it/s]  2%|▏         | 2/100 [00:00<00:11,  8.24it/s]  3%|▎         | 3/100 [00:00<00:11,  8.19it/s]  4%|▍         | 4/100 [00:00<00:11,  8.41it/s]  5%|▌         | 5/100 [00:00<00:11,  8.42it/s]  6%|▌         | 6/100 [00:00<00:11,  8.53it/s]  7%|▋         | 7/100 [00:00<00:10,  8.51it/s]  8%|▊         | 8/100 [00:00<00:10,  8.48it/s]  9%|▉         | 9/100 [00:01<00:10,  8.42it/s] 10%|█         | 10/100 [00:01<00:10,  8.52it/s] 11%|█         | 11/100 [00:01<00:10,  8.41it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.33it/s] 13%|█▎        | 13/100 [00:01<00:10,  8.30it/s] 14%|█▍        | 14/100 [00:01<00:10,  8.32it/s] 15%|█▌        | 15/100 [00:01<00:10,  8.36it/s] 16%|█▌        | 16/100 [00:01<00:09,  8.54it/s] 17%|█▋        | 17/100 [00:02<00:09,  8.45it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.50it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.28it/s] 20%|██        | 20/100 [00:02<00:09,  8.42it/s] 21%|██        | 21/100 [00:02<00:09,  8.34it/s] 22%|██▏       | 22/100 [00:02<00:09,  8.41it/s] 23%|██▎       | 23/100 [00:02<00:09,  8.35it/s] 24%|██▍       | 24/100 [00:02<00:09,  8.34it/s] 25%|██▌       | 25/100 [00:02<00:09,  8.32it/s] 26%|██▌       | 26/100 [00:03<00:08,  8.43it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.35it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.23it/s] 29%|██▉       | 29/100 [00:03<00:08,  8.12it/s] 30%|███       | 30/100 [00:03<00:08,  8.19it/s] 31%|███       | 31/100 [00:03<00:08,  8.23it/s] 32%|███▏      | 32/100 [00:03<00:08,  8.28it/s] 33%|███▎      | 33/100 [00:03<00:08,  8.25it/s] 34%|███▍      | 34/100 [00:04<00:08,  8.07it/s] 35%|███▌      | 35/100 [00:04<00:07,  8.27it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.09it/s] 37%|███▋      | 37/100 [00:04<00:07,  8.17it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.11it/s] 39%|███▉      | 39/100 [00:04<00:07,  8.20it/s] 40%|████      | 40/100 [00:04<00:07,  8.07it/s] 41%|████      | 41/100 [00:04<00:07,  8.10it/s] 42%|████▏     | 42/100 [00:05<00:07,  8.20it/s] 43%|████▎     | 43/100 [00:05<00:06,  8.36it/s] 44%|████▍     | 44/100 [00:05<00:06,  8.44it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.34it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.17it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.12it/s] 48%|████▊     | 48/100 [00:05<00:06,  7.88it/s] 49%|████▉     | 49/100 [00:05<00:06,  7.85it/s] 50%|█████     | 50/100 [00:06<00:06,  7.97it/s] 51%|█████     | 51/100 [00:06<00:06,  8.02it/s] 52%|█████▏    | 52/100 [00:06<00:05,  8.09it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.13it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.19it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.02it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.18it/s] 57%|█████▋    | 57/100 [00:06<00:05,  8.12it/s] 58%|█████▊    | 58/100 [00:07<00:05,  8.02it/s] 59%|█████▉    | 59/100 [00:07<00:05,  8.11it/s] 60%|██████    | 60/100 [00:07<00:04,  8.26it/s] 61%|██████    | 61/100 [00:07<00:04,  8.26it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.21it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.26it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.38it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.36it/s] 66%|██████▌   | 66/100 [00:07<00:04,  8.30it/s] 67%|██████▋   | 67/100 [00:08<00:03,  8.33it/s] 68%|██████▊   | 68/100 [00:08<00:03,  8.18it/s] 69%|██████▉   | 69/100 [00:08<00:03,  8.18it/s] 70%|███████   | 70/100 [00:08<00:03,  8.03it/s] 71%|███████   | 71/100 [00:08<00:03,  7.99it/s] 72%|███████▏  | 72/100 [00:08<00:03,  7.95it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.04it/s] 74%|███████▍  | 74/100 [00:08<00:03,  8.02it/s] 75%|███████▌  | 75/100 [00:09<00:03,  8.07it/s] 76%|███████▌  | 76/100 [00:09<00:03,  7.90it/s] 77%|███████▋  | 77/100 [00:09<00:02,  7.96it/s] 78%|███████▊  | 78/100 [00:09<00:02,  7.93it/s] 79%|███████▉  | 79/100 [00:09<00:02,  7.91it/s] 80%|████████  | 80/100 [00:09<00:02,  8.03it/s] 81%|████████  | 81/100 [00:09<00:02,  8.20it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.14it/s] 83%|████████▎ | 83/100 [00:10<00:02,  8.11it/s] 84%|████████▍ | 84/100 [00:10<00:02,  7.90it/s] 85%|████████▌ | 85/100 [00:10<00:01,  7.85it/s] 86%|████████▌ | 86/100 [00:10<00:01,  7.90it/s] 87%|████████▋ | 87/100 [00:10<00:01,  7.76it/s] 88%|████████▊ | 88/100 [00:10<00:01,  7.82it/s] 89%|████████▉ | 89/100 [00:10<00:01,  7.85it/s] 90%|█████████ | 90/100 [00:11<00:01,  7.67it/s] 91%|█████████ | 91/100 [00:11<00:01,  7.63it/s] 92%|█████████▏| 92/100 [00:11<00:01,  7.82it/s] 93%|█████████▎| 93/100 [00:11<00:00,  7.80it/s] 94%|█████████▍| 94/100 [00:11<00:00,  7.86it/s] 95%|█████████▌| 95/100 [00:11<00:00,  7.97it/s] 96%|█████████▌| 96/100 [00:11<00:00,  7.86it/s] 97%|█████████▋| 97/100 [00:11<00:00,  7.82it/s] 98%|█████████▊| 98/100 [00:12<00:00,  7.89it/s] 99%|█████████▉| 99/100 [00:12<00:00,  7.85it/s]100%|██████████| 100/100 [00:12<00:00,  7.93it/s]100%|██████████| 100/100 [00:12<00:00,  8.14it/s]
[I 2025-08-28 17:26:24,581] A new study created in memory with name: no-name-0a9f1da1-f14e-48f7-b214-4e1885f0acff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16934.53 MB
Memory Reserved: 16952.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 341.79 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16933.90 MB
Memory Reserved: 16960.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 342.12 MB
Memory Reserved: 380.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 17:26:25,951] Trial 0 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16930.11 MB
Memory Reserved: 16960.00 MB
cuda
Epoch 1, Train Loss 1.089660, Valid_loss 1.090010
Epoch 2, Train Loss 1.065865, Valid_loss 1.144728
Epoch 3, Train Loss 1.002097, Valid_loss 1.140474
Epoch 4, Train Loss 0.973887, Valid_loss 1.315509
Epoch 5, Train Loss 0.917826, Valid_loss 1.256819
Epoch 6, Train Loss 0.928900, Valid_loss 1.237820
Epoch 7, Train Loss 0.875383, Valid_loss 1.211909
Epoch 8, Train Loss 0.897990, Valid_loss 1.274898
Epoch 9, Train Loss 0.920291, Valid_loss 1.198037
Epoch 10, Train Loss 0.817376, Valid_loss 1.229543
Epoch 11, Train Loss 0.775881, Valid_loss 1.263855
Epoch 12, Train Loss 0.747229, Valid_loss 1.194169
Epoch 13, Train Loss 0.751086, Valid_loss 1.171027
Epoch 14, Train Loss 0.718364, Valid_loss 1.130836
Epoch 15, Train Loss 0.695292, Valid_loss 1.162208
Epoch 16, Train Loss 0.780599, Valid_loss 1.198062
Epoch 17, Train Loss 0.736670, Valid_loss 1.177923
Epoch 18, Train Loss 0.712208, Valid_loss 1.167896
Epoch 19, Train Loss 0.785406, Valid_loss 1.152220
Epoch 20, Train Loss 0.711049, Valid_loss 1.179496
Epoch 21, Train Loss 0.697151, Valid_loss 1.157641
Epoch 22, Train Loss 0.664914, Valid_loss 1.142094
Epoch 23, Train Loss 0.698404, Valid_loss 1.155871
Epoch 24, Train Loss 0.700539, Valid_loss 1.177522
Epoch 25, Train Loss 0.657610, Valid_loss 1.187982
Epoch 26, Train Loss 0.596747, Valid_loss 1.122998
Epoch 27, Train Loss 0.736660, Valid_loss 1.127304
Epoch 28, Train Loss 0.587669, Valid_loss 1.202225
Epoch 29, Train Loss 0.870322, Valid_loss 1.341627
Epoch 30, Train Loss 0.658502, Valid_loss 1.229045
Epoch 31, Train Loss 0.668149, Valid_loss 1.225854
Epoch 32, Train Loss 0.655845, Valid_loss 1.228022
Epoch 33, Train Loss 0.633282, Valid_loss 1.253638
Epoch 34, Train Loss 0.610072, Valid_loss 1.431269
Epoch 35, Train Loss 0.717336, Valid_loss 1.205273
Epoch 36, Train Loss 0.667999, Valid_loss 1.271264
Epoch 37, Train Loss 0.611373, Valid_loss 1.402106
Epoch 38, Train Loss 0.638811, Valid_loss 1.208606
Epoch 39, Train Loss 0.582807, Valid_loss 1.081740
Epoch 40, Train Loss 0.655551, Valid_loss 1.253733
Epoch 41, Train Loss 0.577525, Valid_loss 1.374270
Epoch 42, Train Loss 0.575203, Valid_loss 1.255063
Epoch 43, Train Loss 0.725244, Valid_loss 1.252316
Epoch 44, Train Loss 0.626397, Valid_loss 1.213967
Epoch 45, Train Loss 0.617863, Valid_loss 1.331063
Epoch 46, Train Loss 0.648202, Valid_loss 1.131909
Epoch 47, Train Loss 0.509390, Valid_loss 1.245341
Epoch 48, Train Loss 0.567856, Valid_loss 1.286438
Epoch 49, Train Loss 0.654079, Valid_loss 1.286898
Epoch 50, Train Loss 0.705218, Valid_loss 1.212069
Epoch 51, Train Loss 0.573991, Valid_loss 1.239456
Epoch 52, Train Loss 0.527997, Valid_loss 1.189527
Epoch 53, Train Loss 0.595710, Valid_loss 1.232294
Epoch 54, Train Loss 0.612762, Valid_loss 1.183731
Epoch 55, Train Loss 0.581880, Valid_loss 1.238897
Epoch 56, Train Loss 0.574455, Valid_loss 1.226369
Epoch 57, Train Loss 0.542197, Valid_loss 1.217385
Epoch 58, Train Loss 0.572782, Valid_loss 1.214556
Epoch 59, Train Loss 0.553673, Valid_loss 1.289058
Epoch 60, Train Loss 0.555762, Valid_loss 1.291957
[I 2025-08-28 18:01:19,326] Trial 1 finished with value: 1.0817396342754364 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 2, 'dropout': 0.7, 'weight_decay': 0.001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 1.0817396342754364.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.883482, Valid_loss 1.329211
Epoch 2, Train Loss 0.720893, Valid_loss 1.534457
Epoch 3, Train Loss 0.797177, Valid_loss 1.340594
Epoch 4, Train Loss 0.694476, Valid_loss 1.022461
Epoch 5, Train Loss 0.570161, Valid_loss 1.499254
Epoch 6, Train Loss 0.578864, Valid_loss 1.235282
Epoch 7, Train Loss 0.527288, Valid_loss 1.295980
Epoch 8, Train Loss 0.487605, Valid_loss 1.087331
Epoch 9, Train Loss 0.450613, Valid_loss 1.247058
Epoch 10, Train Loss 0.426047, Valid_loss 1.118927
Epoch 11, Train Loss 0.457316, Valid_loss 1.162225
Epoch 12, Train Loss 0.356115, Valid_loss 1.277535
Epoch 13, Train Loss 0.396929, Valid_loss 1.402683
Epoch 14, Train Loss 0.371724, Valid_loss 1.335393
Epoch 15, Train Loss 0.370850, Valid_loss 1.217626
Epoch 16, Train Loss 0.316573, Valid_loss 1.480628
Epoch 17, Train Loss 0.345245, Valid_loss 1.046393
Epoch 18, Train Loss 0.359720, Valid_loss 1.145372
Epoch 19, Train Loss 0.306361, Valid_loss 1.462866
Epoch 20, Train Loss 0.357363, Valid_loss 1.317940
Epoch 21, Train Loss 0.371418, Valid_loss 1.538794
Epoch 22, Train Loss 0.338369, Valid_loss 1.383056
Epoch 23, Train Loss 0.335090, Valid_loss 1.179451
Epoch 24, Train Loss 0.331244, Valid_loss 1.340197
Epoch 25, Train Loss 0.380553, Valid_loss 1.138410
Epoch 26, Train Loss 0.285694, Valid_loss 1.401740
Epoch 27, Train Loss 0.352115, Valid_loss 1.550227
Epoch 28, Train Loss 0.292149, Valid_loss 1.306184
Epoch 29, Train Loss 0.339716, Valid_loss 1.319797
Epoch 30, Train Loss 0.290572, Valid_loss 1.241934
Epoch 31, Train Loss 0.316812, Valid_loss 1.522594
Epoch 32, Train Loss 0.328832, Valid_loss 1.727549
Epoch 33, Train Loss 0.345858, Valid_loss 1.333520
Epoch 34, Train Loss 0.305020, Valid_loss 1.297389
Epoch 35, Train Loss 0.313026, Valid_loss 0.914962
Epoch 36, Train Loss 0.321149, Valid_loss 1.429921
Epoch 37, Train Loss 0.274974, Valid_loss 1.239983
Epoch 38, Train Loss 0.278625, Valid_loss 1.251494
Epoch 39, Train Loss 0.288986, Valid_loss 1.134884
Epoch 40, Train Loss 0.292215, Valid_loss 1.433947
Epoch 41, Train Loss 0.304353, Valid_loss 1.185933
Epoch 42, Train Loss 0.260394, Valid_loss 1.699233
Epoch 43, Train Loss 0.312880, Valid_loss 1.311915
Epoch 44, Train Loss 0.270053, Valid_loss 1.296422
Epoch 45, Train Loss 0.215348, Valid_loss 1.037655
Epoch 46, Train Loss 0.346563, Valid_loss 1.552339
Epoch 47, Train Loss 0.276781, Valid_loss 1.277630
Epoch 48, Train Loss 0.250015, Valid_loss 1.257069
Epoch 49, Train Loss 0.248553, Valid_loss 1.559209
Epoch 50, Train Loss 0.331755, Valid_loss 1.334044
Epoch 51, Train Loss 0.193554, Valid_loss 1.226516
Epoch 52, Train Loss 0.191486, Valid_loss 1.247349
Epoch 53, Train Loss 0.207509, Valid_loss 1.479453
[I 2025-08-28 18:22:57,517] Trial 2 finished with value: 0.9149617770065864 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.3, 'weight_decay': 0.01, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 2 with value: 0.9149617770065864.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16903.99 MB
Memory Reserved: 16924.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 312.97 MB
Memory Reserved: 352.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16903.99 MB
Memory Reserved: 16924.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 312.55 MB
Memory Reserved: 352.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 18:22:59,172] Trial 3 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16903.99 MB
Memory Reserved: 16944.00 MB
cuda
Epoch 1, Train Loss 1.013209, Valid_loss 1.187249
Epoch 2, Train Loss 0.972673, Valid_loss 1.119902
Epoch 3, Train Loss 1.006058, Valid_loss 1.148041
Epoch 4, Train Loss 0.911688, Valid_loss 1.109784
Epoch 5, Train Loss 0.890632, Valid_loss 1.046181
Epoch 6, Train Loss 0.782921, Valid_loss 0.958469
Epoch 7, Train Loss 0.842561, Valid_loss 0.967451
Epoch 8, Train Loss 0.821462, Valid_loss 0.925435
Epoch 9, Train Loss 0.765121, Valid_loss 0.828369
Epoch 10, Train Loss 0.704566, Valid_loss 0.905029
Epoch 11, Train Loss 0.614334, Valid_loss 0.824264
Epoch 12, Train Loss 0.647852, Valid_loss 0.847689
Epoch 13, Train Loss 0.608875, Valid_loss 0.888795
Epoch 14, Train Loss 0.618373, Valid_loss 0.815372
Epoch 15, Train Loss 0.636056, Valid_loss 0.825179
Epoch 16, Train Loss 0.593327, Valid_loss 0.753430
Epoch 17, Train Loss 0.663884, Valid_loss 0.830642
Epoch 18, Train Loss 0.597852, Valid_loss 0.712374
Epoch 19, Train Loss 0.668966, Valid_loss 1.042867
Epoch 20, Train Loss 0.615223, Valid_loss 0.813485
Epoch 21, Train Loss 0.617141, Valid_loss 0.724005
Epoch 22, Train Loss 0.614312, Valid_loss 0.734855
Epoch 23, Train Loss 0.599463, Valid_loss 0.812864
Epoch 24, Train Loss 0.573740, Valid_loss 0.809557
Epoch 25, Train Loss 0.585509, Valid_loss 0.809235
Epoch 26, Train Loss 0.543246, Valid_loss 0.820940
Epoch 27, Train Loss 0.512966, Valid_loss 0.746155
Epoch 28, Train Loss 0.480542, Valid_loss 0.833309
Epoch 29, Train Loss 0.521711, Valid_loss 0.821592
Epoch 30, Train Loss 0.476759, Valid_loss 0.864796
Epoch 31, Train Loss 0.495283, Valid_loss 0.847919
Epoch 32, Train Loss 0.471477, Valid_loss 0.752494
Epoch 33, Train Loss 0.510769, Valid_loss 0.792685
Epoch 34, Train Loss 0.537915, Valid_loss 0.703459
Epoch 35, Train Loss 0.486465, Valid_loss 0.814443
Epoch 36, Train Loss 0.440047, Valid_loss 0.789902
Epoch 37, Train Loss 0.483457, Valid_loss 0.813929
Epoch 38, Train Loss 0.452480, Valid_loss 0.866106
Epoch 39, Train Loss 0.478962, Valid_loss 0.889274
Epoch 40, Train Loss 0.449740, Valid_loss 0.857620
Epoch 41, Train Loss 0.485101, Valid_loss 0.896190
Epoch 42, Train Loss 0.436058, Valid_loss 0.775446
Epoch 43, Train Loss 0.456095, Valid_loss 0.797424
Epoch 44, Train Loss 0.458259, Valid_loss 0.786411
Epoch 45, Train Loss 0.509600, Valid_loss 1.038129
Epoch 46, Train Loss 0.410005, Valid_loss 0.877660
Epoch 47, Train Loss 0.385656, Valid_loss 0.837993
Epoch 48, Train Loss 0.408702, Valid_loss 0.848950
Epoch 49, Train Loss 0.522342, Valid_loss 0.968245
Epoch 50, Train Loss 0.381598, Valid_loss 0.771928
Epoch 51, Train Loss 0.412641, Valid_loss 0.818734
Epoch 52, Train Loss 0.395326, Valid_loss 0.812568
Epoch 53, Train Loss 0.455702, Valid_loss 0.945272
Epoch 54, Train Loss 0.427970, Valid_loss 0.877632
Epoch 55, Train Loss 0.346563, Valid_loss 0.870655
Epoch 56, Train Loss 0.370291, Valid_loss 0.876371
Epoch 57, Train Loss 0.364805, Valid_loss 0.847883
Epoch 58, Train Loss 0.416308, Valid_loss 0.832596
Epoch 59, Train Loss 0.377472, Valid_loss 0.879208
Epoch 60, Train Loss 0.368124, Valid_loss 0.854039
Epoch 61, Train Loss 0.390921, Valid_loss 0.880976
Epoch 62, Train Loss 0.382415, Valid_loss 0.867301
Epoch 63, Train Loss 0.397593, Valid_loss 0.933739
Epoch 64, Train Loss 0.324908, Valid_loss 0.841359
Epoch 65, Train Loss 0.371499, Valid_loss 0.876505
Epoch 66, Train Loss 0.359380, Valid_loss 0.881876
[I 2025-08-28 18:49:42,259] Trial 4 finished with value: 0.7034587934613228 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.7, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 4 with value: 0.7034587934613228.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.7, 'weight_decay': 0.001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.134943, Valid_loss 1.008073
Epoch 2, Train Loss 1.034681, Valid_loss 1.065600
Epoch 3, Train Loss 0.952129, Valid_loss 1.100112
Epoch 4, Train Loss 0.936060, Valid_loss 1.068410
Epoch 5, Train Loss 0.863535, Valid_loss 1.006033
Epoch 6, Train Loss 0.768655, Valid_loss 1.003358
Epoch 7, Train Loss 0.765375, Valid_loss 0.975599
Epoch 8, Train Loss 0.835105, Valid_loss 0.991095
Epoch 9, Train Loss 0.727843, Valid_loss 0.969121
Epoch 10, Train Loss 0.672275, Valid_loss 0.952198
Epoch 11, Train Loss 0.708473, Valid_loss 1.000096
Epoch 12, Train Loss 0.644477, Valid_loss 0.988916
Epoch 13, Train Loss 0.621687, Valid_loss 0.912583
Epoch 14, Train Loss 0.594298, Valid_loss 1.014920
Epoch 15, Train Loss 0.636411, Valid_loss 0.975994
Epoch 16, Train Loss 0.604099, Valid_loss 0.997791
Epoch 17, Train Loss 0.580126, Valid_loss 0.988595
Epoch 18, Train Loss 0.604846, Valid_loss 0.972017
Epoch 19, Train Loss 0.570069, Valid_loss 0.884323
Epoch 20, Train Loss 0.685169, Valid_loss 0.955037
Epoch 21, Train Loss 0.558728, Valid_loss 0.957595
Epoch 22, Train Loss 0.535820, Valid_loss 0.968798
Epoch 23, Train Loss 0.551294, Valid_loss 0.954224
Epoch 24, Train Loss 0.543113, Valid_loss 0.992981
Epoch 25, Train Loss 0.621617, Valid_loss 0.990258
Epoch 26, Train Loss 0.509278, Valid_loss 0.953435
Epoch 27, Train Loss 0.529855, Valid_loss 0.979046
Epoch 28, Train Loss 0.517921, Valid_loss 1.051680
Epoch 29, Train Loss 0.520426, Valid_loss 0.942691
Epoch 30, Train Loss 0.493869, Valid_loss 0.976617
Epoch 31, Train Loss 0.516001, Valid_loss 0.988481
Epoch 32, Train Loss 0.499832, Valid_loss 1.010420
Epoch 33, Train Loss 0.529407, Valid_loss 1.012887
Epoch 34, Train Loss 0.466002, Valid_loss 0.953041
Epoch 35, Train Loss 0.506014, Valid_loss 0.989349
Epoch 36, Train Loss 0.525299, Valid_loss 0.979861
Epoch 37, Train Loss 0.405700, Valid_loss 0.916653
Epoch 38, Train Loss 0.490529, Valid_loss 1.047999
Epoch 39, Train Loss 0.522554, Valid_loss 0.924845
Epoch 40, Train Loss 0.438344, Valid_loss 1.043841
Epoch 41, Train Loss 0.476754, Valid_loss 0.962276
Epoch 42, Train Loss 0.425203, Valid_loss 0.971390
Epoch 43, Train Loss 0.485964, Valid_loss 0.916434
Epoch 44, Train Loss 0.470901, Valid_loss 0.958724
Epoch 45, Train Loss 0.497467, Valid_loss 1.012644
Epoch 46, Train Loss 0.406123, Valid_loss 0.879371
Epoch 47, Train Loss 0.439185, Valid_loss 1.074126
Epoch 48, Train Loss 0.423609, Valid_loss 1.047314
Epoch 49, Train Loss 0.392778, Valid_loss 1.008783
Epoch 50, Train Loss 0.367010, Valid_loss 1.058582
Epoch 51, Train Loss 0.438390, Valid_loss 1.034343
Epoch 52, Train Loss 0.367018, Valid_loss 1.031278
Epoch 53, Train Loss 0.406687, Valid_loss 1.048785
Epoch 54, Train Loss 0.389139, Valid_loss 1.030431
Epoch 55, Train Loss 0.396194, Valid_loss 1.013168
Epoch 56, Train Loss 0.368046, Valid_loss 0.957322
Epoch 57, Train Loss 0.453816, Valid_loss 1.025556
Epoch 58, Train Loss 0.399169, Valid_loss 1.025504
Epoch 59, Train Loss 0.337255, Valid_loss 1.009395
Epoch 60, Train Loss 0.402219, Valid_loss 1.003647
Epoch 61, Train Loss 0.389646, Valid_loss 1.021564
Epoch 62, Train Loss 0.324117, Valid_loss 1.009447
Epoch 63, Train Loss 0.384483, Valid_loss 1.007928
Epoch 64, Train Loss 0.412454, Valid_loss 0.985073
Epoch 65, Train Loss 0.383296, Valid_loss 1.041730
Epoch 66, Train Loss 0.357672, Valid_loss 1.049423
환자ID=P1425 -- true: [[1]] -- pred: tensor([[-0.9430,  0.8991, -0.4375]], device='cuda:0')
환자ID=P1437 -- true: [[2]] -- pred: tensor([[-0.9965,  0.9147, -0.3839]], device='cuda:0')
환자ID=P1472 -- true: [[2]] -- pred: tensor([[-0.8530,  0.8253, -0.5753]], device='cuda:0')
환자ID=P1515 -- true: [[0]] -- pred: tensor([[ 2.0371, -1.1679, -1.8746]], device='cuda:0')
환자ID=P1561 -- true: [[0]] -- pred: tensor([[ 2.0522, -1.2073, -1.8804]], device='cuda:0')
환자ID=P1600 -- true: [[0]] -- pred: tensor([[ 1.9856, -1.0619, -1.8481]], device='cuda:0')
환자ID=P1685 -- true: [[1]] -- pred: tensor([[-0.7059,  0.7782, -0.7495]], device='cuda:0')
환자ID=P1726 -- true: [[1]] -- pred: tensor([[-0.9399,  0.8997, -0.4436]], device='cuda:0')
Best performance: Epoch 46, Loss 0.406123, Test ACC 0.750000, Test AUC 0.861111, Test Recall 0.666667, Test Precision 0.533333
Confusion Matrix:
 [[3 0 0]
 [0 3 0]
 [0 2 0]]
✅ Total valid splits used: 3
🔁 Repeat 4, Fold 3
cell type :  ACAGCCGCAAGCGAGT-1-1          cardiac muscle cell
ATATCCTGTCCCTAAA-1-1          cardiac muscle cell
CAATGACCAGTTGTCA-1-1          cardiac muscle cell
CTAGACACAAGGTTGG-1-1          cardiac muscle cell
ATCGTCCGTATTTCTC-1-1          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 487279, dtype: string
cell type annotation :  ACAGCCGCAAGCGAGT-1-1          cardiac muscle cell
ATATCCTGTCCCTAAA-1-1          cardiac muscle cell
CAATGACCAGTTGTCA-1-1          cardiac muscle cell
CTAGACACAAGGTTGG-1-1          cardiac muscle cell
ATCGTCCGTATTTCTC-1-1          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 487279, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'mesothelial cell', 'macrophage', 'fat cell', 'endocardial cell', 'cardiac neuron', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'lymphocyte', 'mast cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  TTCTTCCGTTCAACGT-1-0              cardiac muscle cell
CATCCACCATCTAACG-1-0              cardiac muscle cell
ACCCAAACAGCTAACT-1-0              cardiac muscle cell
AAGGAATCAACTGGTT-1-0              cardiac muscle cell
TACCCGTAGCGTGCTC-1-0              cardiac muscle cell
                                     ...             
AGAAGCGAGCGTCTGC-1-73        cardiac endothelial cell
TACTTCATCCCTTTGG-1-73        cardiac endothelial cell
ATATCCTGTTAGCGGA-1-73        cardiac endothelial cell
TACTTACCAAAGCACG-1-73        cardiac endothelial cell
GTCAGCGCAACACTAC-1-73    cardiac ventricle fibroblast
Name: manual_annotation, Length: 105410, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0              cardiac muscle cell
CATCCACCATCTAACG-1-0              cardiac muscle cell
ACCCAAACAGCTAACT-1-0              cardiac muscle cell
AAGGAATCAACTGGTT-1-0              cardiac muscle cell
TACCCGTAGCGTGCTC-1-0              cardiac muscle cell
                                     ...             
AGAAGCGAGCGTCTGC-1-73        cardiac endothelial cell
TACTTCATCCCTTTGG-1-73        cardiac endothelial cell
ATATCCTGTTAGCGGA-1-73        cardiac endothelial cell
TACTTACCAAAGCACG-1-73        cardiac endothelial cell
GTCAGCGCAACACTAC-1-73    cardiac ventricle fibroblast
Name: manual_annotation, Length: 105410, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 3}
🔍 Split #4
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1304', 'P1358', 'P1371', 'P1422', 'P1425', 'P1430', 'P1437', 'P1462', 'P1472', 'P1504', 'P1510', 'P1515', 'P1516', 'P1540', 'P1547', 'P1549', 'P1558', 'P1561', 'P1582', 'P1600', 'P1602', 'P1606', 'P1610', 'P1617', 'P1630', 'P1631', 'P1678', 'P1685', 'P1702', 'P1707', 'P1718', 'P1722', 'P1726', 'P1735']
  → test  환자 ID: ['P1290', 'P1300', 'P1447', 'P1479', 'P1508', 'P1539', 'P1603', 'P1622']
  → train 환자 ID 및 라벨:
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1504, Label: 2
    ID: P1510, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1540, Label: 0
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1617, Label: 2
    ID: P1630, Label: 1
    ID: P1631, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1722, Label: 1
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1447, Label: 1
    ID: P1479, Label: 1
    ID: P1508, Label: 1
    ID: P1539, Label: 0
    ID: P1603, Label: 0
    ID: P1622, Label: 0
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1722, Label=1, 셀개수=21432
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1516, Label=0, 셀개수=9361
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1549, Label=0, 셀개수=11709
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1600, Label=0, 셀개수=14882
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1606, Label=2, 셀개수=8523
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1622, Label=0, 셀개수=7210
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685        cardiac endothelial cell
592686        cardiac endothelial cell
592687        cardiac endothelial cell
592688    cardiac ventricle fibroblast
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:10,  9.14it/s]  2%|▏         | 2/100 [00:00<00:11,  8.78it/s]  3%|▎         | 3/100 [00:00<00:11,  8.74it/s]  4%|▍         | 4/100 [00:00<00:11,  8.66it/s]  5%|▌         | 5/100 [00:00<00:10,  8.75it/s]  6%|▌         | 6/100 [00:00<00:10,  8.78it/s]  7%|▋         | 7/100 [00:00<00:10,  8.96it/s]  8%|▊         | 8/100 [00:00<00:10,  9.04it/s]  9%|▉         | 9/100 [00:01<00:10,  9.05it/s] 10%|█         | 10/100 [00:01<00:09,  9.03it/s] 11%|█         | 11/100 [00:01<00:09,  9.15it/s] 12%|█▏        | 12/100 [00:01<00:09,  9.26it/s] 13%|█▎        | 13/100 [00:01<00:09,  9.36it/s] 14%|█▍        | 14/100 [00:01<00:09,  9.28it/s] 15%|█▌        | 15/100 [00:01<00:09,  9.32it/s] 16%|█▌        | 16/100 [00:01<00:08,  9.38it/s] 17%|█▋        | 17/100 [00:01<00:08,  9.39it/s] 18%|█▊        | 18/100 [00:01<00:08,  9.22it/s] 19%|█▉        | 19/100 [00:02<00:08,  9.22it/s] 20%|██        | 20/100 [00:02<00:09,  8.85it/s] 21%|██        | 21/100 [00:02<00:08,  8.83it/s] 22%|██▏       | 22/100 [00:02<00:08,  8.86it/s] 23%|██▎       | 23/100 [00:02<00:08,  8.85it/s] 24%|██▍       | 24/100 [00:02<00:08,  8.73it/s] 25%|██▌       | 25/100 [00:02<00:08,  8.65it/s] 26%|██▌       | 26/100 [00:02<00:08,  8.83it/s] 27%|██▋       | 27/100 [00:03<00:08,  8.90it/s] 28%|██▊       | 28/100 [00:03<00:08,  8.91it/s] 29%|██▉       | 29/100 [00:03<00:07,  8.93it/s] 30%|███       | 30/100 [00:03<00:07,  9.00it/s] 31%|███       | 31/100 [00:03<00:07,  9.13it/s] 32%|███▏      | 32/100 [00:03<00:07,  9.21it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.91it/s] 34%|███▍      | 34/100 [00:03<00:07,  8.86it/s] 35%|███▌      | 35/100 [00:03<00:07,  8.80it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.89it/s] 37%|███▋      | 37/100 [00:04<00:06,  9.02it/s] 38%|███▊      | 38/100 [00:04<00:06,  9.02it/s] 39%|███▉      | 39/100 [00:04<00:06,  9.02it/s] 40%|████      | 40/100 [00:04<00:06,  8.94it/s] 41%|████      | 41/100 [00:04<00:06,  8.94it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.81it/s] 43%|████▎     | 43/100 [00:04<00:06,  8.99it/s] 44%|████▍     | 44/100 [00:04<00:06,  9.01it/s] 45%|████▌     | 45/100 [00:05<00:06,  8.79it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.62it/s] 47%|████▋     | 47/100 [00:05<00:06,  8.41it/s] 48%|████▊     | 48/100 [00:05<00:06,  8.44it/s] 49%|████▉     | 49/100 [00:05<00:05,  8.66it/s] 50%|█████     | 50/100 [00:05<00:05,  8.82it/s] 51%|█████     | 51/100 [00:05<00:05,  8.86it/s] 52%|█████▏    | 52/100 [00:05<00:05,  8.91it/s] 53%|█████▎    | 53/100 [00:05<00:05,  9.00it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.93it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.71it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.80it/s] 57%|█████▋    | 57/100 [00:06<00:04,  8.87it/s] 58%|█████▊    | 58/100 [00:06<00:04,  8.90it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.85it/s] 60%|██████    | 60/100 [00:06<00:04,  8.69it/s] 61%|██████    | 61/100 [00:06<00:04,  8.80it/s] 62%|██████▏   | 62/100 [00:06<00:04,  8.82it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.69it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.60it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.69it/s] 66%|██████▌   | 66/100 [00:07<00:03,  8.63it/s] 67%|██████▋   | 67/100 [00:07<00:03,  8.56it/s] 68%|██████▊   | 68/100 [00:07<00:03,  8.43it/s] 69%|██████▉   | 69/100 [00:07<00:03,  8.27it/s] 70%|███████   | 70/100 [00:07<00:03,  8.10it/s] 71%|███████   | 71/100 [00:08<00:03,  8.19it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.25it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.40it/s] 74%|███████▍  | 74/100 [00:08<00:03,  8.59it/s] 75%|███████▌  | 75/100 [00:08<00:02,  8.64it/s] 76%|███████▌  | 76/100 [00:08<00:02,  8.59it/s] 77%|███████▋  | 77/100 [00:08<00:02,  8.64it/s] 78%|███████▊  | 78/100 [00:08<00:02,  8.65it/s] 79%|███████▉  | 79/100 [00:08<00:02,  8.57it/s] 80%|████████  | 80/100 [00:09<00:02,  8.54it/s] 81%|████████  | 81/100 [00:09<00:02,  8.33it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.26it/s] 83%|████████▎ | 83/100 [00:09<00:02,  8.14it/s] 84%|████████▍ | 84/100 [00:09<00:01,  8.23it/s] 85%|████████▌ | 85/100 [00:09<00:01,  8.08it/s] 86%|████████▌ | 86/100 [00:09<00:01,  8.15it/s] 87%|████████▋ | 87/100 [00:09<00:01,  8.12it/s] 88%|████████▊ | 88/100 [00:10<00:01,  8.27it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.34it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.17it/s] 91%|█████████ | 91/100 [00:10<00:01,  8.00it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.01it/s] 93%|█████████▎| 93/100 [00:10<00:00,  8.25it/s] 94%|█████████▍| 94/100 [00:10<00:00,  8.30it/s] 95%|█████████▌| 95/100 [00:10<00:00,  8.22it/s] 96%|█████████▌| 96/100 [00:11<00:00,  8.26it/s] 97%|█████████▋| 97/100 [00:11<00:00,  8.15it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.30it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.29it/s]100%|██████████| 100/100 [00:11<00:00,  8.30it/s]100%|██████████| 100/100 [00:11<00:00,  8.68it/s]
[I 2025-08-28 19:17:00,171] A new study created in memory with name: no-name-ebe2a52c-779c-4f47-b64c-9ae19c633b02
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 7488.35 MB
Memory Reserved: 7510.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 14684.32 MB
Memory Reserved: 14726.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 7488.32 MB
Memory Reserved: 7510.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 14684.32 MB
Memory Reserved: 14726.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 19:17:01,772] Trial 0 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 7490.25 MB
Memory Reserved: 7510.00 MB
cuda
Epoch 1, Train Loss 0.908482, Valid_loss 1.426412
Epoch 2, Train Loss 0.752427, Valid_loss 1.196555
Epoch 3, Train Loss 0.703558, Valid_loss 0.915865
Epoch 4, Train Loss 0.590075, Valid_loss 0.889151
Epoch 5, Train Loss 0.497420, Valid_loss 0.867651
Epoch 6, Train Loss 0.472170, Valid_loss 1.055339
Epoch 7, Train Loss 0.487489, Valid_loss 0.581163
Epoch 8, Train Loss 0.398394, Valid_loss 0.706586
Epoch 9, Train Loss 0.371588, Valid_loss 0.558878
Epoch 10, Train Loss 0.357637, Valid_loss 0.522195
Epoch 11, Train Loss 0.303472, Valid_loss 0.451887
Epoch 12, Train Loss 0.371444, Valid_loss 0.501720
Epoch 13, Train Loss 0.302122, Valid_loss 0.424024
Epoch 14, Train Loss 0.261802, Valid_loss 0.513581
Epoch 15, Train Loss 0.278450, Valid_loss 0.446072
Epoch 16, Train Loss 0.258378, Valid_loss 0.444205
Epoch 17, Train Loss 0.334590, Valid_loss 0.453180
Epoch 18, Train Loss 0.243219, Valid_loss 0.522961
Epoch 19, Train Loss 0.236622, Valid_loss 0.498286
Epoch 20, Train Loss 0.213015, Valid_loss 0.582890
Epoch 21, Train Loss 0.223808, Valid_loss 0.441928
Epoch 22, Train Loss 0.236937, Valid_loss 0.587480
Epoch 23, Train Loss 0.204725, Valid_loss 0.428614
Epoch 24, Train Loss 0.189428, Valid_loss 0.883604
Epoch 25, Train Loss 0.338999, Valid_loss 0.469795
Epoch 26, Train Loss 0.256821, Valid_loss 0.394306
Epoch 27, Train Loss 0.188181, Valid_loss 0.351003
Epoch 28, Train Loss 0.197396, Valid_loss 0.320516
Epoch 29, Train Loss 0.248207, Valid_loss 0.353967
Epoch 30, Train Loss 0.174172, Valid_loss 0.403377
Epoch 31, Train Loss 0.184936, Valid_loss 0.352886
Epoch 32, Train Loss 0.189069, Valid_loss 0.843403
Epoch 33, Train Loss 0.179382, Valid_loss 0.374341
Epoch 34, Train Loss 0.179168, Valid_loss 0.452267
Epoch 35, Train Loss 0.225221, Valid_loss 0.619421
Epoch 36, Train Loss 0.177440, Valid_loss 0.385241
Epoch 37, Train Loss 0.146910, Valid_loss 0.312209
Epoch 38, Train Loss 0.149329, Valid_loss 0.523795
Epoch 39, Train Loss 0.159844, Valid_loss 0.470353
Epoch 40, Train Loss 0.155168, Valid_loss 0.289233
Epoch 41, Train Loss 0.161384, Valid_loss 0.492852
Epoch 42, Train Loss 0.165304, Valid_loss 0.437033
Epoch 43, Train Loss 0.152203, Valid_loss 0.483865
Epoch 44, Train Loss 0.164444, Valid_loss 0.324451
Epoch 45, Train Loss 0.132488, Valid_loss 0.329137
Epoch 46, Train Loss 0.172772, Valid_loss 1.054457
Epoch 47, Train Loss 0.203515, Valid_loss 0.869789
Epoch 48, Train Loss 0.134190, Valid_loss 0.754380
Epoch 49, Train Loss 0.136239, Valid_loss 0.336762
Epoch 50, Train Loss 0.124003, Valid_loss 0.392731
Epoch 51, Train Loss 0.109845, Valid_loss 0.439063
Epoch 52, Train Loss 0.113504, Valid_loss 0.327379
Epoch 53, Train Loss 0.100455, Valid_loss 0.461184
Epoch 54, Train Loss 0.096375, Valid_loss 0.506359
[I 2025-08-28 19:45:10,448] Trial 1 finished with value: 0.2892329077391575 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.0, 'weight_decay': 0.01, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 0.2892329077391575.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.981988, Valid_loss 1.188553
Epoch 2, Train Loss 0.923701, Valid_loss 1.446471
Epoch 3, Train Loss 0.914419, Valid_loss 1.308972
Epoch 4, Train Loss 0.931955, Valid_loss 1.444361
Epoch 5, Train Loss 0.912073, Valid_loss 1.370185
Epoch 6, Train Loss 0.923982, Valid_loss 1.455385
Epoch 7, Train Loss 0.908007, Valid_loss 1.382952
Epoch 8, Train Loss 0.902281, Valid_loss 1.457595
Epoch 9, Train Loss 0.898579, Valid_loss 1.486179
Epoch 10, Train Loss 0.892729, Valid_loss 1.452178
Epoch 11, Train Loss 0.903253, Valid_loss 1.375462
Epoch 12, Train Loss 0.890218, Valid_loss 1.504302
Epoch 13, Train Loss 0.893674, Valid_loss 1.473174
Epoch 14, Train Loss 0.891363, Valid_loss 1.394035
Epoch 15, Train Loss 0.894866, Valid_loss 1.462362
Epoch 16, Train Loss 0.890847, Valid_loss 1.688146
Epoch 17, Train Loss 0.893820, Valid_loss 1.423292
Epoch 18, Train Loss 0.897164, Valid_loss 1.468885
Epoch 19, Train Loss 0.890952, Valid_loss 1.352704
Epoch 20, Train Loss 0.892914, Valid_loss 1.363554
Epoch 21, Train Loss 0.895772, Valid_loss 1.281130
Epoch 22, Train Loss 0.892637, Valid_loss 1.410006
Epoch 23, Train Loss 0.892411, Valid_loss 1.333395
Epoch 24, Train Loss 0.888559, Valid_loss 1.393651
Epoch 25, Train Loss 0.885352, Valid_loss 1.321438
Epoch 26, Train Loss 0.881575, Valid_loss 1.455355
Epoch 27, Train Loss 0.883713, Valid_loss 1.378129
Epoch 28, Train Loss 0.897756, Valid_loss 1.544806
Epoch 29, Train Loss 0.898977, Valid_loss 1.342390
Epoch 30, Train Loss 0.883628, Valid_loss 1.328793
Epoch 31, Train Loss 0.872660, Valid_loss 1.315535
Epoch 32, Train Loss 0.895384, Valid_loss 1.369258
Epoch 33, Train Loss 0.882143, Valid_loss 1.318352
Epoch 34, Train Loss 0.881467, Valid_loss 1.283407
Epoch 35, Train Loss 0.882636, Valid_loss 1.345786
Epoch 36, Train Loss 0.893003, Valid_loss 1.318323
Epoch 37, Train Loss 0.885295, Valid_loss 1.326466
Epoch 38, Train Loss 0.888232, Valid_loss 1.385920
Epoch 39, Train Loss 0.880415, Valid_loss 1.338600
Epoch 40, Train Loss 0.875457, Valid_loss 1.345185
Epoch 41, Train Loss 0.871709, Valid_loss 1.327653
Epoch 42, Train Loss 0.899947, Valid_loss 1.529869
Epoch 43, Train Loss 0.894074, Valid_loss 1.466495
Epoch 44, Train Loss 0.908368, Valid_loss 1.345746
Epoch 45, Train Loss 0.882827, Valid_loss 1.416370
Epoch 46, Train Loss 0.877608, Valid_loss 1.309822
Epoch 47, Train Loss 0.899535, Valid_loss 1.424562
Epoch 48, Train Loss 0.890285, Valid_loss 1.477661
Epoch 49, Train Loss 0.888956, Valid_loss 1.492541
Epoch 50, Train Loss 0.887182, Valid_loss 1.523534
Epoch 51, Train Loss 0.884606, Valid_loss 1.530209
Epoch 52, Train Loss 0.884867, Valid_loss 1.533664
[I 2025-08-28 20:10:20,371] Trial 2 finished with value: 1.1885530551274617 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 2, 'dropout': 0.0, 'weight_decay': 0.0001, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 0.2892329077391575.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
CUDA OOM 발생 — 단계적 백오프 시작.
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 7468.79 MB
Memory Reserved: 7490.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 14664.78 MB
Memory Reserved: 14686.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 7468.78 MB
Memory Reserved: 7490.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[OOM RETRY] batch_size 1 → 1 낮춰서 다시 시도합니다.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 14664.78 MB
Memory Reserved: 14686.00 MB
cuda
[OOM RETRY] batch_size=1에서도 OOM. batch_size를 더 낮춰서 다시 시도합니다... (batch_size 1이었을 경우 중단합니다.)
[I 2025-08-28 20:10:22,144] Trial 3 pruned. Pruned due to OOM after backoff
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 7473.07 MB
Memory Reserved: 7490.00 MB
cuda
Epoch 1, Train Loss 1.087864, Valid_loss 1.499771
Epoch 2, Train Loss 0.986541, Valid_loss 1.404042
Epoch 3, Train Loss 0.949076, Valid_loss 1.571461
Epoch 4, Train Loss 0.964143, Valid_loss 1.519597
Epoch 5, Train Loss 0.937749, Valid_loss 1.592604
Epoch 6, Train Loss 0.884927, Valid_loss 1.651036
Epoch 7, Train Loss 0.893399, Valid_loss 1.262338
Epoch 8, Train Loss 0.936484, Valid_loss 1.779638
Epoch 9, Train Loss 0.921648, Valid_loss 1.515308
Epoch 10, Train Loss 0.909879, Valid_loss 1.499353
Epoch 11, Train Loss 0.913758, Valid_loss 1.385028
Epoch 12, Train Loss 0.896757, Valid_loss 1.452714
Epoch 13, Train Loss 0.895090, Valid_loss 1.463429
Epoch 14, Train Loss 0.889059, Valid_loss 1.507157
Epoch 15, Train Loss 0.894046, Valid_loss 1.494160
Epoch 16, Train Loss 0.890306, Valid_loss 1.497040
Epoch 17, Train Loss 0.885347, Valid_loss 1.520130
Epoch 18, Train Loss 0.892432, Valid_loss 1.539644
Epoch 19, Train Loss 0.887366, Valid_loss 1.525484
Epoch 20, Train Loss 0.885802, Valid_loss 1.549785
Epoch 21, Train Loss 0.886406, Valid_loss 1.646769
Epoch 22, Train Loss 0.893379, Valid_loss 1.572167
Epoch 23, Train Loss 0.886245, Valid_loss 1.558511
Epoch 24, Train Loss 0.884936, Valid_loss 1.545785
Epoch 25, Train Loss 0.886988, Valid_loss 1.537877
Epoch 26, Train Loss 0.886051, Valid_loss 1.527307
Epoch 27, Train Loss 0.886361, Valid_loss 1.551404
Epoch 28, Train Loss 0.885985, Valid_loss 1.519195
Epoch 29, Train Loss 0.887517, Valid_loss 1.532317
Epoch 30, Train Loss 0.894360, Valid_loss 1.707728
Epoch 31, Train Loss 0.901852, Valid_loss 1.525552
Epoch 32, Train Loss 0.885848, Valid_loss 1.532368
Epoch 33, Train Loss 0.885098, Valid_loss 1.547174
Epoch 34, Train Loss 0.894988, Valid_loss 1.532664
Epoch 35, Train Loss 0.887783, Valid_loss 1.531043
Epoch 36, Train Loss 0.885886, Valid_loss 1.535546
Epoch 37, Train Loss 0.886969, Valid_loss 1.532098
Epoch 38, Train Loss 0.889779, Valid_loss 1.548711
Epoch 39, Train Loss 0.887854, Valid_loss 1.541635
Epoch 40, Train Loss 0.887769, Valid_loss 1.536911
Epoch 41, Train Loss 0.885671, Valid_loss 1.557569
Epoch 42, Train Loss 0.885910, Valid_loss 1.531827
Epoch 43, Train Loss 0.888421, Valid_loss 1.538578
Epoch 44, Train Loss 0.886982, Valid_loss 1.546604
Epoch 45, Train Loss 0.885630, Valid_loss 1.520026
Epoch 46, Train Loss 0.884725, Valid_loss 1.534419
Epoch 47, Train Loss 0.889014, Valid_loss 1.536343
Epoch 48, Train Loss 0.886139, Valid_loss 1.547437
Epoch 49, Train Loss 0.886819, Valid_loss 1.546758
Epoch 50, Train Loss 0.886830, Valid_loss 1.557424
Epoch 51, Train Loss 0.885280, Valid_loss 1.549336
Epoch 52, Train Loss 0.885272, Valid_loss 1.556689
Epoch 53, Train Loss 0.883949, Valid_loss 1.541567
Epoch 54, Train Loss 0.883986, Valid_loss 1.549060
Epoch 55, Train Loss 0.885971, Valid_loss 1.538735
Epoch 56, Train Loss 0.884845, Valid_loss 1.542388
Epoch 57, Train Loss 0.883904, Valid_loss 1.547968
[I 2025-08-28 20:33:10,496] Trial 4 finished with value: 1.2623382955789566 and parameters: {'learning_rate': 0.01, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.001, 'emb_dim': 64, 'augment_num': 100, 'pca': False}. Best is trial 1 with value: 0.2892329077391575.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.0, 'weight_decay': 0.01, 'emb_dim': 64, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 19.85 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.878431, Valid_loss 1.094968
Epoch 2, Train Loss 0.673690, Valid_loss 0.921972
Epoch 3, Train Loss 0.582905, Valid_loss 0.850600
Epoch 4, Train Loss 0.505566, Valid_loss 0.664421
Epoch 5, Train Loss 0.532887, Valid_loss 0.782356
Epoch 6, Train Loss 0.476791, Valid_loss 0.725153
Epoch 7, Train Loss 0.413254, Valid_loss 0.700769
Epoch 8, Train Loss 0.351501, Valid_loss 1.378262
Epoch 9, Train Loss 0.447993, Valid_loss 0.522083
Epoch 10, Train Loss 0.387994, Valid_loss 0.795706
Epoch 11, Train Loss 0.392112, Valid_loss 0.619981
Epoch 12, Train Loss 0.351613, Valid_loss 0.966734
Epoch 13, Train Loss 0.313947, Valid_loss 0.544953
Epoch 14, Train Loss 0.294070, Valid_loss 1.300570
Epoch 15, Train Loss 0.340720, Valid_loss 0.560705
Epoch 16, Train Loss 0.271097, Valid_loss 0.537142
Epoch 17, Train Loss 0.284689, Valid_loss 0.438736
Epoch 18, Train Loss 0.206962, Valid_loss 0.386349
Epoch 19, Train Loss 0.269639, Valid_loss 0.562835
Epoch 20, Train Loss 0.263091, Valid_loss 0.352284
Epoch 21, Train Loss 0.232110, Valid_loss 0.670828
Epoch 22, Train Loss 0.222235, Valid_loss 0.989617
Epoch 23, Train Loss 0.254919, Valid_loss 0.746543
Epoch 24, Train Loss 0.197499, Valid_loss 0.526542
Epoch 25, Train Loss 0.201481, Valid_loss 0.558460
Epoch 26, Train Loss 0.282489, Valid_loss 0.366707
Epoch 27, Train Loss 0.216160, Valid_loss 0.375112
Epoch 28, Train Loss 0.248203, Valid_loss 0.855849
Epoch 29, Train Loss 0.171782, Valid_loss 0.787955
Epoch 30, Train Loss 0.272428, Valid_loss 0.675265
Epoch 31, Train Loss 0.186640, Valid_loss 0.320126
Epoch 32, Train Loss 0.167942, Valid_loss 0.308091
Epoch 33, Train Loss 0.226718, Valid_loss 0.615910
Epoch 34, Train Loss 0.175743, Valid_loss 0.416346
Epoch 35, Train Loss 0.172131, Valid_loss 0.555495
Epoch 36, Train Loss 0.149547, Valid_loss 1.137471
Epoch 37, Train Loss 0.254697, Valid_loss 0.769553
Epoch 38, Train Loss 0.213833, Valid_loss 0.683672
Epoch 39, Train Loss 0.215391, Valid_loss 1.301802
Epoch 40, Train Loss 0.169739, Valid_loss 0.283537
Epoch 41, Train Loss 0.173308, Valid_loss 0.351705
Epoch 42, Train Loss 0.135022, Valid_loss 0.244567
Epoch 43, Train Loss 0.275381, Valid_loss 0.822221
Epoch 44, Train Loss 0.160587, Valid_loss 0.615518
Epoch 45, Train Loss 0.167728, Valid_loss 0.373113
Epoch 46, Train Loss 0.142905, Valid_loss 0.290369
Epoch 47, Train Loss 0.165106, Valid_loss 0.348661
Epoch 48, Train Loss 0.145071, Valid_loss 0.484054
Epoch 49, Train Loss 0.124944, Valid_loss 0.418041
Epoch 50, Train Loss 0.113523, Valid_loss 1.035516
Epoch 51, Train Loss 0.125212, Valid_loss 0.312395
Epoch 52, Train Loss 0.114209, Valid_loss 0.334099
Epoch 53, Train Loss 0.102057, Valid_loss 0.781537
환자ID=P1290 -- true: [[2]] -- pred: tensor([[-1.9594,  0.8062,  1.1598]], device='cuda:0')
환자ID=P1300 -- true: [[2]] -- pred: tensor([[-1.6693,  1.3260,  0.0572]], device='cuda:0')
환자ID=P1447 -- true: [[1]] -- pred: tensor([[-1.2672,  2.0955, -1.0155]], device='cuda:0')
환자ID=P1479 -- true: [[1]] -- pred: tensor([[ 0.4386,  0.6100, -1.9530]], device='cuda:0')
환자ID=P1508 -- true: [[1]] -- pred: tensor([[-0.0453,  0.9896, -1.9096]], device='cuda:0')
환자ID=P1539 -- true: [[0]] -- pred: tensor([[ 2.8254, -2.0693, -3.1395]], device='cuda:0')
환자ID=P1603 -- true: [[0]] -- pred: tensor([[ 2.7205, -2.0241, -3.0051]], device='cuda:0')
환자ID=P1622 -- true: [[0]] -- pred: tensor([[ 2.6902, -1.9357, -2.9856]], device='cuda:0')
Best performance: Epoch 42, Loss 0.135022, Test ACC 0.875000, Test AUC 0.944444, Test Recall 0.833333, Test Precision 0.916667
Confusion Matrix:
 [[3 0 0]
 [0 3 0]
 [0 1 1]]
✅ Total valid splits used: 4
🔁 Repeat 4, Fold 4
cell type :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 496290, dtype: string
cell type annotation :  TTCTTCCGTTCAACGT-1-0          cardiac muscle cell
CATCCACCATCTAACG-1-0          cardiac muscle cell
ACCCAAACAGCTAACT-1-0          cardiac muscle cell
AAGGAATCAACTGGTT-1-0          cardiac muscle cell
TACCCGTAGCGTGCTC-1-0          cardiac muscle cell
                                   ...           
TTATTGCGTCGGTGTC-1-79    cardiac endothelial cell
GTCACGGGTTGTATGC-1-79    cardiac endothelial cell
GTCATGATCTTTCGAT-1-79    cardiac endothelial cell
GCGATCGTCAGAGTGG-1-79    cardiac endothelial cell
GCCCGAACAGAGAAAG-1-79    cardiac endothelial cell
Name: manual_annotation, Length: 496290, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'macrophage', 'endocardial cell', 'cardiac ventricle fibroblast', 'cardiac endothelial cell', 'cardiac neuron', 'endothelial cell of lymphatic vessel', 'vascular associated smooth muscle cell', 'pericyte cell', 'mast cell', 'lymphocyte', 'mesothelial cell']
라벨별 그룹 개수 {2: 9, 1: 12, 0: 13}
cell type :  CAACCAAAGACCCGCT-1-2              cardiac muscle cell
ACGGTTACATCGAACT-1-2              cardiac muscle cell
ACCCTCATCCGGCAGT-1-2              cardiac muscle cell
AACACACCACGGTCTG-1-2              cardiac muscle cell
AAACGCTTCACCGGGT-1-2              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 96399, dtype: string
cell type annotation :  CAACCAAAGACCCGCT-1-2              cardiac muscle cell
ACGGTTACATCGAACT-1-2              cardiac muscle cell
ACCCTCATCCGGCAGT-1-2              cardiac muscle cell
AACACACCACGGTCTG-1-2              cardiac muscle cell
AAACGCTTCACCGGGT-1-2              cardiac muscle cell
                                     ...             
CGTCCATAGAATTTGG-1-78        cardiac endothelial cell
GCTTCACAGCGTTGTT-1-78        cardiac endothelial cell
TCTCTGGCAGTCGCAC-1-78    cardiac ventricle fibroblast
CAACAACCAGAGGCTA-1-78                   pericyte cell
CATTGTTGTCGTACAT-1-78        cardiac endothelial cell
Name: manual_annotation, Length: 96399, dtype: string
✅ [DEBUG] manual_annotation 유니크값: ['cardiac muscle cell', 'fat cell', 'vascular associated smooth muscle cell', 'macrophage', 'endocardial cell', 'endothelial cell of lymphatic vessel', 'cardiac endothelial cell', 'cardiac ventricle fibroblast', 'pericyte cell', 'cardiac neuron', 'lymphocyte', 'mast cell', 'mesothelial cell']
라벨별 그룹 개수 {2: 2, 1: 3, 0: 3}
🔍 Split #5
  → train_p_index 환자 수 (환자 단위로 묶인 index list): 34
  → test_p_index 환자 수  (환자 단위로 묶인 index list): 8
  → train 환자 ID: ['P1290', 'P1300', 'P1304', 'P1358', 'P1371', 'P1422', 'P1425', 'P1430', 'P1437', 'P1447', 'P1462', 'P1472', 'P1479', 'P1508', 'P1515', 'P1516', 'P1539', 'P1540', 'P1558', 'P1561', 'P1582', 'P1600', 'P1602', 'P1603', 'P1617', 'P1622', 'P1630', 'P1678', 'P1685', 'P1702', 'P1707', 'P1718', 'P1726', 'P1735']
  → test  환자 ID: ['P1504', 'P1510', 'P1547', 'P1549', 'P1606', 'P1610', 'P1631', 'P1722']
  → train 환자 ID 및 라벨:
    ID: P1290, Label: 2
    ID: P1300, Label: 2
    ID: P1304, Label: 2
    ID: P1358, Label: 2
    ID: P1371, Label: 2
    ID: P1422, Label: 1
    ID: P1425, Label: 1
    ID: P1430, Label: 2
    ID: P1437, Label: 2
    ID: P1447, Label: 1
    ID: P1462, Label: 1
    ID: P1472, Label: 2
    ID: P1479, Label: 1
    ID: P1508, Label: 1
    ID: P1515, Label: 0
    ID: P1516, Label: 0
    ID: P1539, Label: 0
    ID: P1540, Label: 0
    ID: P1558, Label: 0
    ID: P1561, Label: 0
    ID: P1582, Label: 0
    ID: P1600, Label: 0
    ID: P1602, Label: 1
    ID: P1603, Label: 0
    ID: P1617, Label: 2
    ID: P1622, Label: 0
    ID: P1630, Label: 1
    ID: P1678, Label: 0
    ID: P1685, Label: 1
    ID: P1702, Label: 0
    ID: P1707, Label: 1
    ID: P1718, Label: 0
    ID: P1726, Label: 1
    ID: P1735, Label: 1
  → test 환자 ID 및 라벨:
    ID: P1504, Label: 2
    ID: P1510, Label: 1
    ID: P1547, Label: 0
    ID: P1549, Label: 0
    ID: P1606, Label: 2
    ID: P1610, Label: 0
    ID: P1631, Label: 1
    ID: P1722, Label: 1
전체 데이터 index 길이 42
label_stat (train 환자 라벨 목록) 갯수 34
train_data에서 환자 단위로, train과 validation 나누기
기존 train_p_index 34
기존 (train) label_stat 34
train-vali 분할 후! 
train y 의 classes : {0, 1, 2} valid y 의 classes : {0, 1, 2} label_stat 의 classes : {0, 1, 2}
train_p_index_ 22
valid_p_index 12
test_p_index 8
→ train 환자 ID 및 라벨:
   총 개수: 22
   환자ID=P1718, Label=0, 셀개수=9278
   환자ID=P1515, Label=0, 셀개수=14502
   환자ID=P1304, Label=2, 셀개수=19123
   환자ID=P1437, Label=2, 셀개수=21695
   환자ID=P1603, Label=0, 셀개수=10638
   환자ID=P1678, Label=0, 셀개수=10085
   환자ID=P1371, Label=2, 셀개수=16233
   환자ID=P1735, Label=1, 셀개수=12009
   환자ID=P1707, Label=1, 셀개수=9517
   환자ID=P1539, Label=0, 셀개수=11076
   환자ID=P1685, Label=1, 셀개수=10043
   환자ID=P1479, Label=1, 셀개수=19124
   환자ID=P1422, Label=1, 셀개수=23315
   환자ID=P1630, Label=1, 셀개수=17633
   환자ID=P1622, Label=0, 셀개수=7210
   환자ID=P1508, Label=1, 셀개수=20536
   환자ID=P1602, Label=1, 셀개수=16580
   환자ID=P1472, Label=2, 셀개수=19513
   환자ID=P1462, Label=1, 셀개수=21715
   환자ID=P1430, Label=2, 셀개수=11131
   환자ID=P1582, Label=0, 셀개수=18855
   환자ID=P1516, Label=0, 셀개수=9361
→ valid 환자 ID 및 라벨:
   총 개수: 12
   환자ID=P1300, Label=2, 셀개수=17318
   환자ID=P1425, Label=1, 셀개수=15378
   환자ID=P1540, Label=0, 셀개수=11638
   환자ID=P1447, Label=1, 셀개수=11151
   환자ID=P1290, Label=2, 셀개수=8357
   환자ID=P1561, Label=0, 셀개수=10016
   환자ID=P1726, Label=1, 셀개수=12389
   환자ID=P1558, Label=0, 셀개수=10469
   환자ID=P1702, Label=0, 셀개수=13550
   환자ID=P1358, Label=2, 셀개수=23984
   환자ID=P1617, Label=2, 셀개수=17986
   환자ID=P1600, Label=0, 셀개수=14882
→ test 환자 ID 및 라벨:
   총 개수: 8
   환자ID=P1504, Label=2, 셀개수=8133
   환자ID=P1510, Label=1, 셀개수=10744
   환자ID=P1547, Label=0, 셀개수=8253
   환자ID=P1549, Label=0, 셀개수=11709
   환자ID=P1606, Label=2, 셀개수=8523
   환자ID=P1610, Label=0, 셀개수=13919
   환자ID=P1631, Label=1, 셀개수=13686
   환자ID=P1722, Label=1, 셀개수=21432
✅ Checking cell_type before mixups...
Unique types: {<class 'str'>}
Example values (first 10): ['cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell', 'cardiac muscle cell']
NaN exists? False
🔍 isna count: 0
🧪 Types in set(cell_type): {<class 'str'>}
전체 데이터 길이 592689
전체 cell type 길이 0                  cardiac muscle cell
1                  cardiac muscle cell
2                  cardiac muscle cell
3                  cardiac muscle cell
4                  cardiac muscle cell
                      ...             
592684        cardiac endothelial cell
592685        cardiac endothelial cell
592686    cardiac ventricle fibroblast
592687                   pericyte cell
592688        cardiac endothelial cell
Length: 592689, dtype: string
cell type의 NaN 개수 체크 0
======= sample mixup ... ============
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.75it/s]  2%|▏         | 2/100 [00:00<00:11,  8.46it/s]  3%|▎         | 3/100 [00:00<00:10,  8.86it/s]  4%|▍         | 4/100 [00:00<00:10,  8.83it/s]  5%|▌         | 5/100 [00:00<00:10,  8.94it/s]  6%|▌         | 6/100 [00:00<00:10,  9.22it/s]  7%|▋         | 7/100 [00:00<00:10,  9.27it/s]  8%|▊         | 8/100 [00:00<00:09,  9.37it/s]  9%|▉         | 9/100 [00:00<00:09,  9.42it/s] 10%|█         | 10/100 [00:01<00:09,  9.40it/s] 11%|█         | 11/100 [00:01<00:09,  9.37it/s] 12%|█▏        | 12/100 [00:01<00:09,  9.34it/s] 13%|█▎        | 13/100 [00:01<00:09,  9.40it/s] 14%|█▍        | 14/100 [00:01<00:09,  9.46it/s] 15%|█▌        | 15/100 [00:01<00:09,  9.23it/s] 16%|█▌        | 16/100 [00:01<00:09,  9.02it/s] 17%|█▋        | 17/100 [00:01<00:09,  9.07it/s] 18%|█▊        | 18/100 [00:01<00:09,  8.97it/s] 19%|█▉        | 19/100 [00:02<00:08,  9.01it/s] 20%|██        | 20/100 [00:02<00:08,  8.99it/s] 21%|██        | 21/100 [00:02<00:08,  9.09it/s] 22%|██▏       | 22/100 [00:02<00:08,  8.97it/s] 23%|██▎       | 23/100 [00:02<00:08,  9.11it/s] 24%|██▍       | 24/100 [00:02<00:08,  9.13it/s] 25%|██▌       | 25/100 [00:02<00:08,  9.14it/s] 26%|██▌       | 26/100 [00:02<00:08,  9.04it/s] 27%|██▋       | 27/100 [00:02<00:07,  9.18it/s] 28%|██▊       | 28/100 [00:03<00:07,  9.27it/s] 29%|██▉       | 29/100 [00:03<00:07,  9.18it/s] 30%|███       | 30/100 [00:03<00:07,  9.17it/s] 31%|███       | 31/100 [00:03<00:07,  9.07it/s] 32%|███▏      | 32/100 [00:03<00:07,  9.07it/s] 33%|███▎      | 33/100 [00:03<00:07,  8.88it/s] 34%|███▍      | 34/100 [00:03<00:07,  8.85it/s] 35%|███▌      | 35/100 [00:03<00:07,  8.93it/s] 36%|███▌      | 36/100 [00:03<00:07,  9.02it/s] 37%|███▋      | 37/100 [00:04<00:06,  9.01it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.75it/s] 39%|███▉      | 39/100 [00:04<00:06,  8.83it/s] 40%|████      | 40/100 [00:04<00:06,  8.86it/s] 41%|████      | 41/100 [00:04<00:06,  8.86it/s] 42%|████▏     | 42/100 [00:04<00:06,  8.82it/s] 43%|████▎     | 43/100 [00:04<00:06,  8.85it/s] 44%|████▍     | 44/100 [00:04<00:06,  8.88it/s] 45%|████▌     | 45/100 [00:04<00:06,  8.76it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.86it/s] 47%|████▋     | 47/100 [00:05<00:05,  8.91it/s] 48%|████▊     | 48/100 [00:05<00:05,  8.98it/s] 49%|████▉     | 49/100 [00:05<00:05,  8.88it/s] 50%|█████     | 50/100 [00:05<00:05,  8.93it/s] 51%|█████     | 51/100 [00:05<00:05,  8.84it/s] 52%|█████▏    | 52/100 [00:05<00:05,  8.89it/s] 53%|█████▎    | 53/100 [00:05<00:05,  8.82it/s] 54%|█████▍    | 54/100 [00:05<00:05,  8.82it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.68it/s] 56%|█████▌    | 56/100 [00:06<00:05,  8.65it/s] 57%|█████▋    | 57/100 [00:06<00:04,  8.73it/s] 58%|█████▊    | 58/100 [00:06<00:04,  8.62it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.61it/s] 60%|██████    | 60/100 [00:06<00:04,  8.57it/s] 61%|██████    | 61/100 [00:06<00:04,  8.67it/s] 62%|██████▏   | 62/100 [00:06<00:04,  8.65it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.55it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.57it/s] 65%|██████▌   | 65/100 [00:07<00:04,  8.56it/s] 66%|██████▌   | 66/100 [00:07<00:03,  8.69it/s] 67%|██████▋   | 67/100 [00:07<00:03,  8.73it/s] 68%|██████▊   | 68/100 [00:07<00:03,  8.68it/s] 69%|██████▉   | 69/100 [00:07<00:03,  8.74it/s] 70%|███████   | 70/100 [00:07<00:03,  8.58it/s] 71%|███████   | 71/100 [00:07<00:03,  8.65it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.67it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.78it/s] 74%|███████▍  | 74/100 [00:08<00:02,  8.71it/s] 75%|███████▌  | 75/100 [00:08<00:02,  8.74it/s] 76%|███████▌  | 76/100 [00:08<00:02,  8.76it/s] 77%|███████▋  | 77/100 [00:08<00:02,  8.55it/s] 78%|███████▊  | 78/100 [00:08<00:02,  8.63it/s] 79%|███████▉  | 79/100 [00:08<00:02,  8.76it/s] 80%|████████  | 80/100 [00:08<00:02,  8.64it/s] 81%|████████  | 81/100 [00:09<00:02,  8.61it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.61it/s] 83%|████████▎ | 83/100 [00:09<00:01,  8.66it/s] 84%|████████▍ | 84/100 [00:09<00:01,  8.67it/s] 85%|████████▌ | 85/100 [00:09<00:01,  8.53it/s] 86%|████████▌ | 86/100 [00:09<00:01,  8.64it/s] 87%|████████▋ | 87/100 [00:09<00:01,  8.63it/s] 88%|████████▊ | 88/100 [00:09<00:01,  8.53it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.45it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.45it/s] 91%|█████████ | 91/100 [00:10<00:01,  8.60it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.63it/s] 93%|█████████▎| 93/100 [00:10<00:00,  8.57it/s] 94%|█████████▍| 94/100 [00:10<00:00,  8.58it/s] 95%|█████████▌| 95/100 [00:10<00:00,  8.53it/s] 96%|█████████▌| 96/100 [00:10<00:00,  8.44it/s] 97%|█████████▋| 97/100 [00:10<00:00,  8.60it/s] 98%|█████████▊| 98/100 [00:11<00:00,  8.64it/s] 99%|█████████▉| 99/100 [00:11<00:00,  8.71it/s]100%|██████████| 100/100 [00:11<00:00,  8.80it/s]100%|██████████| 100/100 [00:11<00:00,  8.83it/s]
[I 2025-08-28 21:01:30,231] A new study created in memory with name: no-name-7f71e592-310e-4eed-9fb8-207d17444f1f
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.980057, Valid_loss 1.130895
Epoch 2, Train Loss 0.972278, Valid_loss 1.131512
Epoch 3, Train Loss 0.937883, Valid_loss 0.946912
Epoch 4, Train Loss 0.892882, Valid_loss 0.891247
Epoch 5, Train Loss 0.866247, Valid_loss 0.862377
Epoch 6, Train Loss 0.796544, Valid_loss 0.821344
Epoch 7, Train Loss 0.786456, Valid_loss 0.758954
Epoch 8, Train Loss 0.776055, Valid_loss 0.819003
Epoch 9, Train Loss 0.761544, Valid_loss 0.782563
Epoch 10, Train Loss 0.776293, Valid_loss 0.926668
Epoch 11, Train Loss 0.740470, Valid_loss 0.737491
Epoch 12, Train Loss 0.676279, Valid_loss 0.720269
Epoch 13, Train Loss 0.703799, Valid_loss 0.724335
Epoch 14, Train Loss 0.690450, Valid_loss 0.714086
Epoch 15, Train Loss 0.684402, Valid_loss 0.710258
Epoch 16, Train Loss 0.635544, Valid_loss 0.776924
Epoch 17, Train Loss 0.674113, Valid_loss 0.684103
Epoch 18, Train Loss 0.649124, Valid_loss 0.700344
Epoch 19, Train Loss 0.690138, Valid_loss 0.679400
Epoch 20, Train Loss 0.609431, Valid_loss 0.679599
Epoch 21, Train Loss 0.571792, Valid_loss 0.662667
Epoch 22, Train Loss 0.565267, Valid_loss 0.638449
Epoch 23, Train Loss 0.581115, Valid_loss 0.639969
Epoch 24, Train Loss 0.572757, Valid_loss 0.646447
Epoch 25, Train Loss 0.549876, Valid_loss 0.624901
Epoch 26, Train Loss 0.579368, Valid_loss 0.620011
Epoch 27, Train Loss 0.555195, Valid_loss 0.646958
Epoch 28, Train Loss 0.559833, Valid_loss 0.606130
Epoch 29, Train Loss 0.537374, Valid_loss 0.592539
Epoch 30, Train Loss 0.524272, Valid_loss 0.610677
Epoch 31, Train Loss 0.521530, Valid_loss 0.609893
Epoch 32, Train Loss 0.532813, Valid_loss 0.607559
Epoch 33, Train Loss 0.524266, Valid_loss 0.592390
Epoch 34, Train Loss 0.524387, Valid_loss 0.580286
Epoch 35, Train Loss 0.550063, Valid_loss 0.585393
Epoch 36, Train Loss 0.562546, Valid_loss 0.571471
Epoch 37, Train Loss 0.462557, Valid_loss 0.575201
Epoch 38, Train Loss 0.505071, Valid_loss 0.565872
Epoch 39, Train Loss 0.497647, Valid_loss 0.540408
Epoch 40, Train Loss 0.465143, Valid_loss 0.543935
Epoch 41, Train Loss 0.463633, Valid_loss 0.560670
Epoch 42, Train Loss 0.474285, Valid_loss 0.549181
Epoch 43, Train Loss 0.533448, Valid_loss 0.553329
Epoch 44, Train Loss 0.477090, Valid_loss 0.546912
Epoch 45, Train Loss 0.496651, Valid_loss 0.545999
Epoch 46, Train Loss 0.454323, Valid_loss 0.522804
Epoch 47, Train Loss 0.396914, Valid_loss 0.524617
Epoch 48, Train Loss 0.453791, Valid_loss 0.534328
Epoch 49, Train Loss 0.446217, Valid_loss 0.527779
Epoch 50, Train Loss 0.432360, Valid_loss 0.529182
Epoch 51, Train Loss 0.429747, Valid_loss 0.529913
Epoch 52, Train Loss 0.421936, Valid_loss 0.529341
Epoch 53, Train Loss 0.405749, Valid_loss 0.524719
Epoch 54, Train Loss 0.393636, Valid_loss 0.525932
Epoch 55, Train Loss 0.365324, Valid_loss 0.518611
Epoch 56, Train Loss 0.398663, Valid_loss 0.516927
Epoch 57, Train Loss 0.409833, Valid_loss 0.515849
Epoch 58, Train Loss 0.433254, Valid_loss 0.519478
Epoch 59, Train Loss 0.397524, Valid_loss 0.517747
Epoch 60, Train Loss 0.373745, Valid_loss 0.501716
Epoch 61, Train Loss 0.356763, Valid_loss 0.500157
Epoch 62, Train Loss 0.407300, Valid_loss 0.509395
Epoch 63, Train Loss 0.344489, Valid_loss 0.510857
[I 2025-08-28 21:36:59,299] Trial 0 finished with value: 0.500156594440341 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.500156594440341.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 18.01 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 0.965167, Valid_loss 1.341878
Epoch 2, Train Loss 0.909293, Valid_loss 1.243366
Epoch 3, Train Loss 0.916333, Valid_loss 1.236894
Epoch 4, Train Loss 0.867538, Valid_loss 0.917597
Epoch 5, Train Loss 0.770591, Valid_loss 0.818110
Epoch 6, Train Loss 0.809593, Valid_loss 1.132934
Epoch 7, Train Loss 0.679796, Valid_loss 1.425518
Epoch 8, Train Loss 0.672567, Valid_loss 0.781292
Epoch 9, Train Loss 0.622029, Valid_loss 0.721439
Epoch 10, Train Loss 0.534194, Valid_loss 0.694558
Epoch 11, Train Loss 0.560956, Valid_loss 0.658705
Epoch 12, Train Loss 0.561612, Valid_loss 0.631261
Epoch 13, Train Loss 0.548629, Valid_loss 0.636828
Epoch 14, Train Loss 0.521038, Valid_loss 0.664931
Epoch 15, Train Loss 0.680263, Valid_loss 0.677947
Epoch 16, Train Loss 0.508330, Valid_loss 0.628562
Epoch 17, Train Loss 0.523717, Valid_loss 0.646443
Epoch 18, Train Loss 0.464138, Valid_loss 0.620191
Epoch 19, Train Loss 0.588856, Valid_loss 0.623324
Epoch 20, Train Loss 0.533001, Valid_loss 0.606511
Epoch 21, Train Loss 0.492753, Valid_loss 0.572972
Epoch 22, Train Loss 0.446454, Valid_loss 0.604517
Epoch 23, Train Loss 0.528811, Valid_loss 0.576549
Epoch 24, Train Loss 0.480055, Valid_loss 0.597508
Epoch 25, Train Loss 0.540604, Valid_loss 0.590858
Epoch 26, Train Loss 0.462397, Valid_loss 0.577020
Epoch 27, Train Loss 0.430510, Valid_loss 0.585849
Epoch 28, Train Loss 0.461302, Valid_loss 0.570456
Epoch 29, Train Loss 0.458244, Valid_loss 0.550375
Epoch 30, Train Loss 0.615930, Valid_loss 0.960336
Epoch 31, Train Loss 0.530179, Valid_loss 0.560953
Epoch 32, Train Loss 0.480525, Valid_loss 0.586561
Epoch 33, Train Loss 0.461110, Valid_loss 0.556542
Epoch 34, Train Loss 0.471612, Valid_loss 0.552592
Epoch 35, Train Loss 0.475919, Valid_loss 0.546491
Epoch 36, Train Loss 0.469644, Valid_loss 0.550643
Epoch 37, Train Loss 0.520234, Valid_loss 0.538566
Epoch 38, Train Loss 0.450554, Valid_loss 0.556235
Epoch 39, Train Loss 0.460211, Valid_loss 0.556530
Epoch 40, Train Loss 0.466411, Valid_loss 0.551285
Epoch 41, Train Loss 0.447131, Valid_loss 0.551281
Epoch 42, Train Loss 0.435402, Valid_loss 0.552015
Epoch 43, Train Loss 0.464356, Valid_loss 0.558647
Epoch 44, Train Loss 0.461742, Valid_loss 0.540055
Epoch 45, Train Loss 0.460492, Valid_loss 0.525547
Epoch 46, Train Loss 0.723863, Valid_loss 0.542867
Epoch 47, Train Loss 0.477946, Valid_loss 0.532951
Epoch 48, Train Loss 0.456416, Valid_loss 0.558237
Epoch 49, Train Loss 0.466065, Valid_loss 0.555973
Epoch 50, Train Loss 0.440822, Valid_loss 0.528190
Epoch 51, Train Loss 0.418321, Valid_loss 0.521840
Epoch 52, Train Loss 0.410237, Valid_loss 0.514272
Epoch 53, Train Loss 0.386362, Valid_loss 0.515493
Epoch 54, Train Loss 0.363217, Valid_loss 0.514582
Epoch 55, Train Loss 0.378329, Valid_loss 0.510301
Epoch 56, Train Loss 0.374657, Valid_loss 0.521028
Epoch 57, Train Loss 0.398168, Valid_loss 0.518711
Epoch 58, Train Loss 0.369821, Valid_loss 0.523574
Epoch 59, Train Loss 0.376174, Valid_loss 0.531113
[I 2025-08-28 21:59:57,459] Trial 1 finished with value: 0.5103009874777248 and parameters: {'learning_rate': 0.001, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.01, 'emb_dim': 32, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.500156594440341.
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=0, batch_size=1 -> steps=0
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.284021, Valid_loss 1.072146
Epoch 2, Train Loss 1.241532, Valid_loss 0.965802
Epoch 3, Train Loss 1.130396, Valid_loss 0.831504
Epoch 4, Train Loss 1.133308, Valid_loss 0.770019
Epoch 5, Train Loss 0.994536, Valid_loss 0.747458
Epoch 6, Train Loss 1.023864, Valid_loss 0.721992
Epoch 7, Train Loss 0.948157, Valid_loss 0.701041
Epoch 8, Train Loss 0.913847, Valid_loss 0.694394
Epoch 9, Train Loss 1.009890, Valid_loss 0.712504
Epoch 10, Train Loss 0.902545, Valid_loss 0.686604
Epoch 11, Train Loss 0.904394, Valid_loss 0.683108
Epoch 12, Train Loss 0.917889, Valid_loss 0.660195
Epoch 13, Train Loss 0.850393, Valid_loss 0.701964
Epoch 14, Train Loss 0.854993, Valid_loss 0.665044
Epoch 15, Train Loss 0.855342, Valid_loss 0.701832
Epoch 16, Train Loss 0.823771, Valid_loss 0.660289
Epoch 17, Train Loss 0.860273, Valid_loss 0.646249
Epoch 18, Train Loss 0.825094, Valid_loss 0.669981
Epoch 19, Train Loss 0.850922, Valid_loss 0.725492
Epoch 20, Train Loss 0.799815, Valid_loss 0.631905
Epoch 21, Train Loss 0.747436, Valid_loss 0.650048
Epoch 22, Train Loss 0.803503, Valid_loss 0.596778
Epoch 23, Train Loss 0.762806, Valid_loss 0.629501
Epoch 24, Train Loss 0.865822, Valid_loss 0.654053
Epoch 25, Train Loss 0.794997, Valid_loss 0.608731
Epoch 26, Train Loss 0.775183, Valid_loss 0.658805
Epoch 27, Train Loss 0.826232, Valid_loss 0.622147
Epoch 28, Train Loss 0.857538, Valid_loss 0.641937
Epoch 29, Train Loss 0.863059, Valid_loss 0.625814
Epoch 30, Train Loss 0.828714, Valid_loss 0.620875
Epoch 31, Train Loss 0.811309, Valid_loss 0.666836
Epoch 32, Train Loss 0.798927, Valid_loss 0.601594
Epoch 33, Train Loss 0.766685, Valid_loss 0.588755
Epoch 34, Train Loss 0.755134, Valid_loss 0.571654
Epoch 35, Train Loss 0.787436, Valid_loss 0.588259
Epoch 36, Train Loss 0.763754, Valid_loss 0.624986
Epoch 37, Train Loss 0.777821, Valid_loss 0.612893
Epoch 38, Train Loss 0.711554, Valid_loss 0.567252
Epoch 39, Train Loss 0.871927, Valid_loss 0.664886
Epoch 40, Train Loss 0.748349, Valid_loss 0.625530
Epoch 41, Train Loss 0.827807, Valid_loss 0.624668
Epoch 42, Train Loss 0.818921, Valid_loss 0.609819
Epoch 43, Train Loss 0.758459, Valid_loss 0.592289
Epoch 44, Train Loss 0.883978, Valid_loss 0.655588
Epoch 45, Train Loss 0.794533, Valid_loss 0.635662
Epoch 46, Train Loss 0.784880, Valid_loss 0.566445
Epoch 47, Train Loss 0.698948, Valid_loss 0.636816
Epoch 48, Train Loss 0.666748, Valid_loss 0.593925
Epoch 49, Train Loss 0.694038, Valid_loss 0.563594
Epoch 50, Train Loss 0.804690, Valid_loss 0.547997
Epoch 51, Train Loss 0.649003, Valid_loss 0.549278
Epoch 52, Train Loss 0.715669, Valid_loss 0.535791
Epoch 53, Train Loss 0.716004, Valid_loss 0.547372
Epoch 54, Train Loss 0.672277, Valid_loss 0.551505
[I 2025-08-28 22:20:54,388] Trial 2 finished with value: 0.5357905142009258 and parameters: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 1, 'dropout': 0.5, 'weight_decay': 0.01, 'emb_dim': 8, 'augment_num': 100, 'pca': False}. Best is trial 0 with value: 0.500156594440341.
선택된 trial params: {'learning_rate': 0.0001, 'epochs': 100, 'heads': 2, 'dropout': 0.3, 'weight_decay': 0.0001, 'emb_dim': 8, 'augment_num': 100, 'pca': False}
👉 train samples(학습 샘플(bag))=122, batch_size=1 -> steps(샘플수/batch크기)=122
👉 valid samples=12, batch_size=1 -> steps=12
👉 test  samples=8, batch_size=1 -> steps=8
Memory Allocated: 16.69 MB
Memory Reserved: 42.00 MB
cuda
Epoch 1, Train Loss 1.183259, Valid_loss 1.085425
Epoch 2, Train Loss 1.089805, Valid_loss 1.060503
Epoch 3, Train Loss 1.049245, Valid_loss 1.047796
Epoch 4, Train Loss 0.956511, Valid_loss 1.030537
Epoch 5, Train Loss 0.929415, Valid_loss 1.008320
Epoch 6, Train Loss 0.890877, Valid_loss 0.925004
Epoch 7, Train Loss 0.851811, Valid_loss 0.911153
Epoch 8, Train Loss 0.808201, Valid_loss 0.932847
Epoch 9, Train Loss 0.791987, Valid_loss 0.850367
Epoch 10, Train Loss 0.763244, Valid_loss 0.861729
Epoch 11, Train Loss 0.778725, Valid_loss 0.882554
Epoch 12, Train Loss 0.728237, Valid_loss 0.844227
Epoch 13, Train Loss 0.728244, Valid_loss 0.826644
Epoch 14, Train Loss 0.745623, Valid_loss 0.814637
Epoch 15, Train Loss 0.712797, Valid_loss 0.827480
Epoch 16, Train Loss 0.660243, Valid_loss 0.826270
Epoch 17, Train Loss 0.618567, Valid_loss 0.794502
Epoch 18, Train Loss 0.673134, Valid_loss 0.771951
Epoch 19, Train Loss 0.638883, Valid_loss 0.787035
Epoch 20, Train Loss 0.616868, Valid_loss 0.805893
Epoch 21, Train Loss 0.590229, Valid_loss 0.771525
Epoch 22, Train Loss 0.656963, Valid_loss 0.786168
Epoch 23, Train Loss 0.630167, Valid_loss 0.768989
Epoch 24, Train Loss 0.599880, Valid_loss 0.748409
Epoch 25, Train Loss 0.581837, Valid_loss 0.734010
Epoch 26, Train Loss 0.558376, Valid_loss 0.728115
Epoch 27, Train Loss 0.592200, Valid_loss 0.720973
Epoch 28, Train Loss 0.554154, Valid_loss 0.700191
Epoch 29, Train Loss 0.583373, Valid_loss 0.720553
Epoch 30, Train Loss 0.545497, Valid_loss 0.709146
Epoch 31, Train Loss 0.523971, Valid_loss 0.704969
Epoch 32, Train Loss 0.560950, Valid_loss 0.755425
Epoch 33, Train Loss 0.528024, Valid_loss 0.697213
Epoch 34, Train Loss 0.533721, Valid_loss 0.684365
Epoch 35, Train Loss 0.534754, Valid_loss 0.689112
Epoch 36, Train Loss 0.527197, Valid_loss 0.667300
Epoch 37, Train Loss 0.563532, Valid_loss 0.688802
Epoch 38, Train Loss 0.506929, Valid_loss 0.666552
Epoch 39, Train Loss 0.513327, Valid_loss 0.629727
Epoch 40, Train Loss 0.519738, Valid_loss 0.640441
Epoch 41, Train Loss 0.488440, Valid_loss 0.641995
Epoch 42, Train Loss 0.495961, Valid_loss 0.633744
Epoch 43, Train Loss 0.552183, Valid_loss 0.638074
Epoch 44, Train Loss 0.481143, Valid_loss 0.608687
Epoch 45, Train Loss 0.482233, Valid_loss 0.624604
Epoch 46, Train Loss 0.466468, Valid_loss 0.600712
Epoch 47, Train Loss 0.481981, Valid_loss 0.610565
Epoch 48, Train Loss 0.448594, Valid_loss 0.623444
Epoch 49, Train Loss 0.480073, Valid_loss 0.621185
Epoch 50, Train Loss 0.430774, Valid_loss 0.579564
Epoch 51, Train Loss 0.457605, Valid_loss 0.597643
Epoch 52, Train Loss 0.398820, Valid_loss 0.598721
환자ID=P1504 -- true: [[2]] -- pred: tensor([[0.1460, 1.2822, 0.8691]], device='cuda:0')
환자ID=P1510 -- true: [[1]] -- pred: tensor([[0.2114, 1.1845, 0.8553]], device='cuda:0')
환자ID=P1547 -- true: [[0]] -- pred: tensor([[ 2.1027, -0.0540, -0.6168]], device='cuda:0')
환자ID=P1549 -- true: [[0]] -- pred: tensor([[ 2.2046, -0.1002, -0.6576]], device='cuda:0')
환자ID=P1606 -- true: [[2]] -- pred: tensor([[0.0787, 1.0850, 0.9766]], device='cuda:0')
환자ID=P1610 -- true: [[0]] -- pred: tensor([[ 2.0931, -0.0370, -0.5687]], device='cuda:0')
환자ID=P1631 -- true: [[1]] -- pred: tensor([[0.6330, 1.2414, 0.4541]], device='cuda:0')
환자ID=P1722 -- true: [[1]] -- pred: tensor([[0.1860, 1.3115, 0.8715]], device='cuda:0')
Best performance: Epoch 50, Loss 0.430774, Test ACC 0.750000, Test AUC 0.916667, Test Recall 0.666667, Test Precision 0.533333
Confusion Matrix:
 [[3 0 0]
 [0 3 0]
 [0 2 0]]
✅ Total valid splits used: 5

📌 Repeat 4: 평균 AUC = 0.8704, 표준편차 = 0.0577
Test ACC 평균 0.719444, Test Recall 평균 0.655556, Test Precision 평균 0.576667
fold_aucs = [0.7777777777777778, 0.8518518518518517, 0.8611111111111112, 0.9444444444444443, 0.9166666666666666]
NaN 개수: 0 / 전체 5개


================ 전체 Repeat 요약 ================
Repeat 0: AUC 0.8185 ± 0.1348 | ACC 0.6722 | Recall 0.6444 | Precision 0.5567 | NaN 0/5
Repeat 1: AUC 0.7537 ± 0.1942 | ACC 0.6611 | Recall 0.6111 | Precision 0.5150 | NaN 0/5
Repeat 2: AUC 0.8944 ± 0.1247 | ACC 0.7139 | Recall 0.6889 | Precision 0.5983 | NaN 0/5
Repeat 3: AUC 0.9204 ± 0.0387 | ACC 0.7639 | Recall 0.7111 | Precision 0.6033 | NaN 0/5
Repeat 4: AUC 0.8704 ± 0.0577 | ACC 0.7194 | Recall 0.6556 | Precision 0.5767 | NaN 0/5

🏁 최종 결과 (각 Repeat의 AUC 평균의 평균): 0.8515 ± 0.0593
